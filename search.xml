<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>10个帮程序员减压放松的网站（转载）</title>
    <url>/10-websites-for-helping-programmers-to-relax/</url>
    <content><![CDATA[<p>同学们工作之余，不妨放下微博跟朋友圈，来这10个网站感受一下看着就醉了的情境：「念完往上一推音乐键，我往后一靠，潮乎乎的软皮耳机里头，音乐排山倒海。」今天推荐的网站，利用代入感强的图片与音频，迅速帮你抹平焦虑，获得平和心态，特别献给改稿千遍的设计师们。</p>
<span id="more"></span>
<h2 id="1-Calm"><a class="header-anchor" href="#1-Calm"></a>1. <a href="http://www.calm.com/">Calm</a></h2>
<p>这是同类型中最火的网站了，站如其名，「平和」，通过自然的图像（阳光下的暖流、淙淙的小溪等）与缓缓的音乐，帮你在短时间内放松下来。</p>
<p>左侧有时间设定，从 2 分钟到 20 分钟，右底部可以改变音频、图像，调节音量等。还有 IOS 客户端下载呦。</p>
<center>
<img src="/assets/10-websites-for-helping-programmers-to-relax/1.jpg" alt="Calm"/>
</center>
<h2 id="2-Do-Nothing-For-2-Minutes"><a class="header-anchor" href="#2-Do-Nothing-For-2-Minutes"></a>2. <a href="http://www.donothingfor2minutes.com/">Do Nothing For 2 Minutes</a></h2>
<p>「木头人，两分钟」，这是一个简单到极致的网站，当你打开的时候，自动开始计时，这时间你不能触碰键盘和鼠标，否则 2 分钟会重置。</p>
<p>你需要做的，就是放下手头的工作，静静地享受潮声，这也很棒，不是吗？两分钟足够你冷静下来，休息一下了。</p>
<center>
<img src="/assets/10-websites-for-helping-programmers-to-relax/2.jpg" alt="Do Nothing For 2 Minutes"/>
</center>
<h2 id="3-Get-Relaxed"><a class="header-anchor" href="#3-Get-Relaxed"></a>3. <a href="http://www.getrelaxed.com/">Get Relaxed</a></h2>
<p>如果两分钟不足以让你彻底放松，试试这个。如下图，打开网站后，头枕着双手往后仰，欣赏自然风光，聆听网站为你精心挑选的音乐。</p>
<p>图像 3 秒一换，有 15 种，每种持续大概 2 – 4 分钟，现在，开始吧！</p>
<p>提醒：网站有简陋广告，稍微影响体验。</p>
<center>
<img src="/assets/10-websites-for-helping-programmers-to-relax/3.jpg" alt="Get Relaxed"/>
</center>
<h2 id="4-LoungeV-Studio"><a class="header-anchor" href="#4-LoungeV-Studio"></a>4. <a href="http://www.loungev.com/">LoungeV Studio</a></h2>
<p>前三个都是图像，现在来个新鲜的。这个网站提供高清的自然风光视频 + 音乐。有沙滩、瀑布、水下景色等等，网站背景是一个温馨的客厅，右侧有视频可选，对喜欢看视频的同学来说，还是蛮不错的。</p>
<center>
<img src="/assets/10-websites-for-helping-programmers-to-relax/4.jpg" alt="LoungeV Studio"/>
</center>
<h2 id="5-A-Soft-Murmur"><a class="header-anchor" href="#5-A-Soft-Murmur"></a>5. <a href="http://asoftmurmur.com/">A Soft Murmur</a></h2>
<p>这个网站太棒了！小编玩了好久都舍不得停下来。网站让你自由创造美妙的声音。你可以通过混合不同的声音（雨声、火柴燃烧的声音、打雷声、海潮声……不一而足。但是，总有一款令你爱不释手！）当然，声音的大小也可以自己调节。</p>
<p>如果你对混合的声音非常满意，也可以分享到脸书、谷歌等….</p>
<center>
<img src="/assets/10-websites-for-helping-programmers-to-relax/5.jpg" alt="A Soft Murmur"/>
</center>
<h2 id="6-Nature-Sounds-For-Me"><a class="header-anchor" href="#6-Nature-Sounds-For-Me"></a>6. <a href="http://naturesoundsfor.me/">Nature Sounds For Me</a></h2>
<p>这个比上面那个界面稍逊，但是玩起来更嗨！它提供的声音除了以上的自然类声音，还有很多你想不到的：绵羊咩咩、骏马跺脚喷气、不同的鸟叫声，甚至是心脏跳动、厨房叮当的声音，不仅令人身临其境，而且搭配起来简直不能更欢乐！</p>
<p>当然，它还有 IOS 客户端。</p>
<center>
<img src="/assets/10-websites-for-helping-programmers-to-relax/6.jpg" alt="Nature Sounds For Me"/>
</center>
<h2 id="7-Noisli"><a class="header-anchor" href="#7-Noisli"></a>7. <a href="http://www.noisli.com/">Noisli</a></h2>
<p>这个网站根据你的情绪变化，选择不同的音乐和背景颜色。颜色大多朴素平和，背景声音也有对应的图标可以选择。还有一点贴心的设计是，网站右侧有便签本，你可以一边享受静谧时光一边随手记点事。</p>
<p>为了造福大众，网站还提供 IOS 版。</p>
<center>
<img src="/assets/10-websites-for-helping-programmers-to-relax/7.jpg" alt="Noisli"/>
</center>
<h2 id="8-Soundrown"><a class="header-anchor" href="#8-Soundrown"></a>8. <a href="http://soundrown.com/">Soundrown</a></h2>
<p>网站一进去，有 3 个关键词：放松、专注、逃离。的确，它成功做到了这一点。它有 10 种不同的声音帮助你放松心情，也可以混合使用。不同的声音对应不同的背景，网站非常有设计感，相信你会重新回来体验一次。</p>
<center>
<img src="/assets/10-websites-for-helping-programmers-to-relax/8.jpg" alt="Soundrown"/>
</center>
<h2 id="9-The-Thoughts-Room"><a class="header-anchor" href="#9-The-Thoughts-Room"></a>9. <a href="http://thequietplaceproject.com/">The Thoughts Room</a></h2>
<p>一句话简洁：世界的秘密——树洞类网站。你可以在这里向全世界倾诉你的任何想法，网站支持 37 种语言，不过看了一下，没有中国…</p>
<center>
<img src="/assets/10-websites-for-helping-programmers-to-relax/9.jpg" alt="The Thoughts Room"/>
</center>
<h2 id="10-Raining-Fm"><a class="header-anchor" href="#10-Raining-Fm"></a>10. <a href="http://raining.fm/">Raining.Fm</a></h2>
<p>有时候，我们需要的仅仅是一点点雨声来帮助我们平静。网站专门提供雨声，因为单一，所以也更加专业。网站有 3 种不同的雨声类型，右侧有定时器可以在你放松时提醒你，简单也好用的一个网站，赞一个。</p>
<center>
<img src="/assets/10-websites-for-helping-programmers-to-relax/10.jpg" alt="Raining.Fm"/>
</center>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/10-websites-for-helping-programmers-to-relax/">http://xnerv.wang/10-websites-for-helping-programmers-to-relax/</a></strong><br>
转载自：<a href="http://www.myexception.cn/other/1825517.html">10个帮程序员减压放松的网站</a></p>
]]></content>
      <categories>
        <category>程序员生活</category>
      </categories>
      <tags>
        <tag>程序员生活</tag>
        <tag>转载</tag>
      </tags>
  </entry>
  <entry>
    <title>16个很有用的在线工具（转载）</title>
    <url>/16-useful-online-tools/</url>
    <content><![CDATA[<h2 id="1-ExplainShell-com-命令解释"><a class="header-anchor" href="#1-ExplainShell-com-命令解释"></a>1. <a href="http://explainshell.com/">ExplainShell.com</a> 命令解释</h2>
<p><img src="https:////images0.cnblogs.com/news/66372/201407/311846578997821.jpg" alt="explainshell"></p>
<p>对于 Linux 用户来说每天都会写各种命令和脚本，那么你可以使用这个网站工具来查看命令式如何工作的，这样可以避免不必要的错误出现；也是一个很好的学习命令的方式。</p>
<h2 id="2-BashrcGenerator-com-定制个性命令提示符"><a class="header-anchor" href="#2-BashrcGenerator-com-定制个性命令提示符"></a>2. <a href="http://simlinux.com/BashrcGenerator.com/">BashrcGenerator.com</a> 定制个性命令提示符</h2>
<p><img src="https:////images0.cnblogs.com/news/66372/201407/311846584158262.jpg" alt="BashrcGenerator"></p>
<p>简单说就是个性化生成命令提示符，可将生成的代码写入到用户家目录的 .bashrc 或者可以设置全局变量文件/etc/profile 对所有用户生效。</p>
<p>可参考：<a href="http://stackoverflow.com/questions/4133904/ps1-line-with-git-current-branch-and-colors">http://stackoverflow.com/questions/4133904/ps1-line-with-git-current-branch-and-colors</a></p>
<span id="more"></span>
<h2 id="3-Vim-adventures-com-通过-RPG-游戏练习-VIM-使用"><a class="header-anchor" href="#3-Vim-adventures-com-通过-RPG-游戏练习-VIM-使用"></a>3. <a href="http://vim-adventures.com/">Vim-adventures.com</a> 通过 RPG 游戏练习 VIM 使用</h2>
<p><img src="https:////images0.cnblogs.com/news/66372/201407/311846586021207.jpg" alt="Vim-adventures"></p>
<p>通过 RPG 游戏练习 VIM 编辑器的使用，使用h,j,k,l字符移动人物来获得新的命令能力和搜集钥匙，查看帮助可使用:help;赶脚这个非常 cool!</p>
<h2 id="4-Try-Github-在线学习-Git-版本控制"><a class="header-anchor" href="#4-Try-Github-在线学习-Git-版本控制"></a>4. <a href="https://try.github.io/levels/1/challenges/2">Try Github</a> 在线学习 Git 版本控制</h2>
<p><img src="https:////images0.cnblogs.com/news/66372/201407/311846588214907.jpg" alt="Try Github"></p>
<p>十五分钟学会 Git，很明显这个网站模拟了一个控制台，以很时尚的界面让人对 Git 不再望而生畏。</p>
<h2 id="5-Shortcutfoo-com"><a class="header-anchor" href="#5-Shortcutfoo-com"></a>5. <a href="http://shortcutfoo.com/">Shortcutfoo.com</a></h2>
<p><img src="https:////images0.cnblogs.com/news/66372/201407/311846584465721.jpg" alt="Shortcutfoo.com"></p>
<p>是一个练习快捷键的好地方，涵盖了 vim、sublime、emacs、git 等软件的快捷使用方式和友好的说明。</p>
<h2 id="6-GitHub-Free-Programming-Books-免费编程书籍"><a class="header-anchor" href="#6-GitHub-Free-Programming-Books-免费编程书籍"></a>6. <a href="https://github.com/geekwolf/free-programming-books">GitHub Free Programming Books</a> 免费编程书籍</h2>
<p><img src="https:////images0.cnblogs.com/news/66372/201407/311846583999735.jpg" alt="GitHub Free Programming Books"></p>
<p>以 Github 管理的方式搜集了免费的编程和系统管理等书籍，给作者点 1024 个赞~~，另外连接是 fork 原作者，后续增加中文书籍。</p>
<h2 id="7-Collabedit-com-实时文本交互聊天"><a class="header-anchor" href="#7-Collabedit-com-实时文本交互聊天"></a>7. <a href="http://collabedit.com/">Collabedit.com</a> 实时文本交互聊天</h2>
<p><img src="https:////images0.cnblogs.com/news/66372/201407/311846591809862.jpg" alt="Collabedit.com">   先说下使用，你可以创建一个文档<code>http://collabedit.com/yb22u</code>填写相关的用户名和选择语言；然后可以将此文档地址发给另一个人，那么互相之间就可以实时看到对方的输入，有高亮语法；使用场合嘛，比如通过 collabedit 可以考量对方编程能力等。</p>
<h2 id="8-Cpp-sh-在线编写运行分享-C-代码编辑器"><a class="header-anchor" href="#8-Cpp-sh-在线编写运行分享-C-代码编辑器"></a>8. <a href="http://cpp.sh/">Cpp.sh</a> 在线编写运行分享 C++ 代码编辑器</h2>
<p><img src="https:////images0.cnblogs.com/news/66372/201407/311846592741835.jpg" alt="Cpp.sh"></p>
<p>可在线编辑运行 C++ 代码，亦可 Ctrl+Z 生成 url 分享给好友。</p>
<h2 id="9-Copy-sh-浏览器运行虚拟机"><a class="header-anchor" href="#9-Copy-sh-浏览器运行虚拟机"></a>9. <a href="http://copy.sh/v24/">Copy.sh</a> 浏览器运行虚拟机</h2>
<p><img src="https:////images0.cnblogs.com/news/66372/201407/311846596336791.jpg" alt="Copy.sh"></p>
<p>又一个非常 crazy 的工具，在线运行虚拟机，可以选择下载虚拟机镜像也可以上传自己的 iso，<a href="http://copy.sh">copy.sh</a> 在线运行虚拟机源码：<a href="https://github.com/copy/v86">https://github.com/copy/v86</a>；</p>
<h2 id="10-Commandlinefu-com-命令或记录网站"><a class="header-anchor" href="#10-Commandlinefu-com-命令或记录网站"></a>10. <a href="http://commandlinefu.com/">Commandlinefu.com</a> 命令或记录网站</h2>
<p><img src="https:////images0.cnblogs.com/news/66372/201407/311846598377262.jpg" alt="Commandlinefu.com"></p>
<p>做运维的应该都知道这个网站，可以分享自己的 CLI 库，也可以学习借鉴别人的命令脚本。</p>
<h2 id="11-Alias-sh-命令别名数据库"><a class="header-anchor" href="#11-Alias-sh-命令别名数据库"></a>11. <a href="http://alias.sh/">Alias.sh</a> 命令别名数据库</h2>
<p><img src="https:////images0.cnblogs.com/news/66372/201407/311847005875633.jpg" alt="Alias.sh"></p>
<p>有点类似 commandlinefu 了，可以通过这个网站借鉴获取和分享有用的命令别名。</p>
<p>比如 lr 别名定义了显示目录树。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">alias</span> lr=<span class="string">&#x27;ls -R  grep &quot;:$&quot;  sed -e &#x27;</span>\<span class="string">&#x27;&#x27;</span>s/:$//<span class="string">&#x27;\&#x27;</span><span class="string">&#x27; -e &#x27;</span>\<span class="string">&#x27;&#x27;</span>s/[^-][^\/]*\//--/g<span class="string">&#x27;\&#x27;</span><span class="string">&#x27; -e &#x27;</span>\<span class="string">&#x27;&#x27;</span>s/^/   /<span class="string">&#x27;\&#x27;</span><span class="string">&#x27; -e &#x27;</span>\<span class="string">&#x27;&#x27;</span>s/-//<span class="string">&#x27;\&#x27;</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h2 id="12-Distrowatch-com-提供了-Linux-发行版的详细信息"><a class="header-anchor" href="#12-Distrowatch-com-提供了-Linux-发行版的详细信息"></a>12. <a href="http://distrowatch.com/">Distrowatch.com</a> 提供了 Linux 发行版的详细信息</h2>
<p><img src="https:////images0.cnblogs.com/news/66372/201407/311847005717105.jpg" alt="Distrowatch.com"></p>
<p>通过 Distrowath 不仅可以精确的查看互联网都有哪些流行的 Linux 发行版，还可以查看每个发行版的相关信息如默认桌面环境、默认应用程序及镜像的下载链接；堪称 Linux 的数据库。</p>
<h2 id="13-Linuxmanpages-com-在线查看命令帮助"><a class="header-anchor" href="#13-Linuxmanpages-com-在线查看命令帮助"></a>13. <a href="http://linuxmanpages.com/">Linuxmanpages.com</a> 在线查看命令帮助</h2>
<p><img src="https:////images0.cnblogs.com/news/66372/201407/311847008525319.jpg" alt="Linuxmanpages.com"></p>
<p>相当于系统内部的 man、help、info 等的综合吧。</p>
<h2 id="14-AwesomeCow-com-适用-Linux-环境的软件搜索引擎-AwesomeCow-com"><a class="header-anchor" href="#14-AwesomeCow-com-适用-Linux-环境的软件搜索引擎-AwesomeCow-com"></a>14. <a href="http://awesomecow.com/">AwesomeCow.com</a> 适用 Linux 环境的软件搜索引擎**<img src="https:////images0.cnblogs.com/news/66372/201407/311847017123189.jpg" alt="AwesomeCow.com"></h2>
<p>如果有款 win 下好用的软件想在 linux 下使用，或许可以通过 AwesomeCow 找到与其类似或者一样的软件，或者通过 WINE。</p>
<h2 id="15-PenguSpy-com-Linux-好玩游戏合集"><a class="header-anchor" href="#15-PenguSpy-com-Linux-好玩游戏合集"></a>15. <a href="http://penguspy.com/">PenguSpy.com</a> Linux 好玩游戏合集</h2>
<p><img src="https:////images0.cnblogs.com/news/66372/201407/311847024774789.jpg" alt="PenguSpy.com"></p>
<h2 id="16-Linux-Cross-Reference-by-Free-Electrons-在线查看内核代码及不同版本的差异"><a class="header-anchor" href="#16-Linux-Cross-Reference-by-Free-Electrons-在线查看内核代码及不同版本的差异"></a>16. <a href="http://lxr.free-electrons.com/">Linux Cross Reference by Free Electrons</a> 在线查看内核代码及不同版本的差异</h2>
<p><img src="https:////images0.cnblogs.com/news/66372/201407/311847033214132.jpg" alt="Linux Cross Reference by Free Electrons"></p>
<p>对于内核开发者或许有很大的帮助。</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/16-useful-online-tools/">http://xnerv.wang/16-useful-online-tools/</a></strong><br>
转载自：<a href="https://news.cnblogs.com/n/214828/">16个很有用的在线工具</a></p>
]]></content>
      <categories>
        <category>程序员生活</category>
      </categories>
      <tags>
        <tag>程序员生活</tag>
        <tag>转载</tag>
      </tags>
  </entry>
  <entry>
    <title>23种设计模式全解析（转载）</title>
    <url>/23-design-patterns-analysis/</url>
    <content><![CDATA[<h2 id="一、设计模式的分类"><a class="header-anchor" href="#一、设计模式的分类"></a>一、设计模式的分类</h2>
<p>总体来说设计模式分为三大类：</p>
<ul>
<li>创建型模式，共五种：工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式。</li>
<li>结构型模式，共七种：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式。</li>
<li>行为型模式，共十一种：策略模式、模板方法模式、观察者模式、迭代子模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。</li>
</ul>
<p>其实还有两类：并发型模式和线程池模式。用一个图片来整体描述一下：</p>
<p><img src="/assets/23-design-patterns-analysis/1.jpg" alt=""></p>
<span id="more"></span>
<h2 id="二、设计模式的六大原则"><a class="header-anchor" href="#二、设计模式的六大原则"></a>二、设计模式的六大原则</h2>
<h3 id="总原则：开闭原则（Open-Close-Principle）"><a class="header-anchor" href="#总原则：开闭原则（Open-Close-Principle）"></a>总原则：开闭原则（Open Close Principle）</h3>
<p>开闭原则就是说<strong>对扩展开放，对修改关闭</strong>。在程序需要进行拓展的时候，不能去修改原有的代码，而是要扩展原有代码，实现一个热插拔的效果。所以一句话概括就是：为了使程序的扩展性好，易于维护和升级。想要达到这样的效果，我们需要使用接口和抽象类等，后面的具体设计中我们会提到这点。</p>
<h3 id="1、单一职责原则"><a class="header-anchor" href="#1、单一职责原则"></a>1、单一职责原则</h3>
<p>不要存在多于一个导致类变更的原因，也就是说每个类应该实现单一的职责，如若不然，就应该把类拆分。</p>
<h3 id="2、里氏替换原则（Liskov-Substitution-Principle）"><a class="header-anchor" href="#2、里氏替换原则（Liskov-Substitution-Principle）"></a>2、里氏替换原则（Liskov Substitution Principle）</h3>
<p>里氏代换原则(Liskov Substitution Principle LSP)面向对象设计的基本原则之一。 里氏代换原则中说，任何基类可以出现的地方，子类一定可以出现。 LSP是继承复用的基石，只有当衍生类可以替换掉基类，软件单位的功能不受到影响时，基类才能真正被复用，而衍生类也能够在基类的基础上增加新的行为。里氏代换原则是对“开-闭”原则的补充。实现“开-闭”原则的关键步骤就是抽象化。而基类与子类的继承关系就是抽象化的具体实现，所以里氏代换原则是对实现抽象化的具体步骤的规范。—— From Baidu 百科</p>
<p>历史替换原则中，子类对父类的方法尽量不要重写和重载。因为父类代表了定义好的结构，通过这个规范的接口与外界交互，子类不应该随便破坏它。</p>
<h3 id="3、依赖倒转原则（Dependence-Inversion-Principle）"><a class="header-anchor" href="#3、依赖倒转原则（Dependence-Inversion-Principle）"></a>3、依赖倒转原则（Dependence Inversion Principle）</h3>
<p>这个是开闭原则的基础，具体内容：面向接口编程，依赖于抽象而不依赖于具体。写代码时用到具体类时，不与具体类交互，而与具体类的上层接口交互。</p>
<h3 id="4、接口隔离原则（Interface-Segregation-Principle）"><a class="header-anchor" href="#4、接口隔离原则（Interface-Segregation-Principle）"></a>4、接口隔离原则（Interface Segregation Principle）</h3>
<p>这个原则的意思是：每个接口中不存在子类用不到却必须实现的方法，如果不然，就要将接口拆分。使用多个隔离的接口，比使用单个接口（多个接口方法集合到一个的接口）要好。</p>
<h3 id="5、迪米特法则（最少知道原则）（Demeter-Principle）"><a class="header-anchor" href="#5、迪米特法则（最少知道原则）（Demeter-Principle）"></a>5、迪米特法则（最少知道原则）（Demeter Principle）</h3>
<p>就是说：一个类对自己依赖的类知道的越少越好。也就是说无论被依赖的类多么复杂，都应该将逻辑封装在方法的内部，通过public方法提供给外部。这样当被依赖的类变化时，才能最小的影响该类。</p>
<p>最少知道原则的另一个表达方式是：只与直接的朋友通信。类之间只要有耦合关系，就叫朋友关系。耦合分为依赖、关联、聚合、组合等。我们称出现为成员变量、方法参数、方法返回值中的类为直接朋友。局部变量、临时变量则不是直接的朋友。我们要求陌生的类不要作为局部变量出现在类中。</p>
<h3 id="6、合成复用原则（Composite-Reuse-Principle）"><a class="header-anchor" href="#6、合成复用原则（Composite-Reuse-Principle）"></a>6、合成复用原则（Composite Reuse Principle）</h3>
<p>原则是尽量首先使用合成/聚合的方式，而不是使用继承。</p>
<h2 id="三、Java的23中设计模式"><a class="header-anchor" href="#三、Java的23中设计模式"></a>三、Java的23中设计模式</h2>
<h3 id="A、创建模式"><a class="header-anchor" href="#A、创建模式"></a>A、创建模式</h3>
<p>从这一块开始，我们详细介绍Java中23种设计模式的概念，应用场景等情况，并结合他们的特点及设计模式的原则进行分析。</p>
<p>首先，简单工厂模式不属于23中涉及模式，简单工厂一般分为：普通简单工厂、多方法简单工厂、静态方法简单工厂。</p>
<h4 id="0、简单工厂模式"><a class="header-anchor" href="#0、简单工厂模式"></a>0、简单工厂模式</h4>
<p>简单工厂模式模式分为三种：</p>
<h5 id="01、普通"><a class="header-anchor" href="#01、普通"></a>01、普通</h5>
<p>就是建立一个工厂类，对实现了同一接口的一些类进行实例的创建。首先看下关系图：</p>
<p><img src="/assets/23-design-patterns-analysis/2.jpg" alt=""></p>
<p>举例如下：（我们举一个发送邮件和短信的例子）</p>
<p>首先，创建二者的共同接口：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">Sender</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">Send</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其次，创建实现类：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MailSender</span> <span class="keyword">implements</span> <span class="title class_">Sender</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">Send</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(“<span class="built_in">this</span> is mailsender!”);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SmsSender</span> <span class="keyword">implements</span> <span class="title class_">Sender</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">Send</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(“<span class="built_in">this</span> is sms sender!”);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最后，建工厂类：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SendFactory</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> Sender <span class="title function_">produce</span><span class="params">(String type)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (“mail”.equals(type)) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">MailSender</span>();</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (“sms”.equals(type)) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">SmsSender</span>();</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            System.out.println(“请输入正确的类型!”);</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>我们来测试下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FactoryTest</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SendFactory</span> <span class="variable">factory</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SendFactory</span>();</span><br><span class="line">        <span class="type">Sender</span> <span class="variable">sender</span> <span class="operator">=</span> factory.produce(“sms”);</span><br><span class="line">        sender.Send();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>输出：<code>this is sms sender!</code></p>
<h5 id="02、多个方法"><a class="header-anchor" href="#02、多个方法"></a>02、多个方法</h5>
<p>是对普通工厂方法模式的改进，在普通工厂方法模式中，如果传递的字符串出错，则不能正确创建对象，而多个工厂方法模式是提供多个工厂方法，分别创建对象。关系图：</p>
<p><img src="/assets/23-design-patterns-analysis/3.jpg" alt=""></p>
<p>将上面的代码做下修改，改动下SendFactory类就行，如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SendFactory</span> &#123;</span><br><span class="line">   <span class="keyword">public</span> Sender <span class="title function_">produceMail</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">MailSender</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> Sender <span class="title function_">produceSms</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">SmsSender</span>();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>测试类如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FactoryTest</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SendFactory</span> <span class="variable">factory</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SendFactory</span>();</span><br><span class="line">        <span class="type">Sender</span> <span class="variable">sender</span> <span class="operator">=</span> factory.produceMail();</span><br><span class="line">        sender.Send();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>输出：<code>this is mailsender!</code></p>
<h5 id="03、多个静态方法"><a class="header-anchor" href="#03、多个静态方法"></a>03、多个静态方法</h5>
<p>将上面的多个工厂方法模式里的方法置为静态的，不需要创建实例，直接调用即可。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SendFactory</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Sender <span class="title function_">produceMail</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">MailSender</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Sender <span class="title function_">produceSms</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">SmsSender</span>();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FactoryTest</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">Sender</span> <span class="variable">sender</span> <span class="operator">=</span> SendFactory.produceMail();</span><br><span class="line">        sender.Send();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>输出：<code>this is mailsender!</code></p>
<p>总体来说，工厂模式适合：凡是出现了大量的产品需要创建，并且具有共同的接口时，可以通过工厂方法模式进行创建。在以上的三种模式中，第一种如果传入的字符串有误，不能正确创建对象，第三种相对于第二种，不需要实例化工厂类，所以，大多数情况下，我们会选用第三种——静态工厂方法模式。</p>
<h4 id="1、工厂方法模式（Factory-Method）"><a class="header-anchor" href="#1、工厂方法模式（Factory-Method）"></a>1、工厂方法模式（Factory Method）</h4>
<p>简单工厂模式有一个问题就是，类的创建依赖工厂类，也就是说，如果想要拓展程序，必须对工厂类进行修改，这违背了闭包原则，所以，从设计角度考虑，有一定的问题，如何解决？就用到工厂方法模式，创建一个工厂接口和创建多个工厂实现类，这样一旦需要增加新的功能，直接增加新的工厂类就可以了，不需要修改之前的代码。</p>
<p><img src="/assets/23-design-patterns-analysis/4.jpg" alt=""></p>
<p>请看例子：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">Sender</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">Send</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>两个实现类：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MailSender</span> <span class="keyword">implements</span> <span class="title class_">Sender</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">Send</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(“<span class="built_in">this</span> is mailsender!”);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SmsSender</span> <span class="keyword">implements</span> <span class="title class_">Sender</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">Send</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(“<span class="built_in">this</span> is sms sender!”);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>两个工厂类：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SendMailFactory</span> <span class="keyword">implements</span> <span class="title class_">Provider</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Sender <span class="title function_">produce</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">MailSender</span>();</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SendSmsFactory</span> <span class="keyword">implements</span> <span class="title class_">Provider</span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Sender <span class="title function_">produce</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">SmsSender</span>();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>再提供一个接口：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">Provider</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> Sender <span class="title function_">produce</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>测试类：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Test</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">Provider</span> <span class="variable">provider</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SendMailFactory</span>();</span><br><span class="line">        <span class="type">Sender</span> <span class="variable">sender</span> <span class="operator">=</span> provider.produce();</span><br><span class="line">        sender.Send();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其实这个模式的好处就是，如果你现在想增加一个功能：发及时信息，则只需做一个实现类，实现Sender接口，同时做一个工厂类，实现Provider接口，就OK了，无需去改动现成的代码。这样做，拓展性较好！</p>
<h4 id="2、抽象工厂模式"><a class="header-anchor" href="#2、抽象工厂模式"></a>2、抽象工厂模式</h4>
<p>工厂方法模式和抽象工厂模式不好分清楚，他们的区别如下：</p>
<blockquote>
<p>工厂方法模式：<br>
一个抽象产品类，可以派生出多个具体产品类。<br>
一个抽象工厂类，可以派生出多个具体工厂类。<br>
每个具体工厂类只能创建一个具体产品类的实例。</p>
<p>抽象工厂模式：<br>
多个抽象产品类，每个抽象产品类可以派生出多个具体产品类。<br>
一个抽象工厂类，可以派生出多个具体工厂类。<br>
每个具体工厂类可以创建多个具体产品类的实例，也就是创建的是一个产品线下的多个产品。</p>
<p>区别：<br>
工厂方法模式只有一个抽象产品类，而抽象工厂模式有多个。<br>
工厂方法模式的具体工厂类只能创建一个具体产品类的实例，而抽象工厂模式可以创建多个。</pre></p>
</blockquote>
<blockquote>
<p>工厂方法创建 “一种” 产品，他的着重点在于&quot;怎么创建&quot;，也就是说如果你开发，你的大量代码很可能围绕着这种产品的构造，初始化这些细节上面。也因为如此，类似的产品之间有很多可以复用的特征，所以会和模版方法相随。</p>
<p>抽象工厂需要创建一些列产品，着重点在于&quot;创建哪些&quot;产品上，也就是说，如果你开发，你的主要任务是划分不同差异的产品线，并且尽量保持每条产品线接口一致，从而可以从同一个抽象工厂继承。</pre></p>
</blockquote>
<blockquote>
<p>对于java来说，你能见到的大部分抽象工厂模式都是这样的：<br>
—它的里面是一堆工厂方法，每个工厂方法返回某种类型的对象。</p>
<p>比如说工厂可以生产鼠标和键盘。那么抽象工厂的实现类（它的某个具体子类）的对象都可以生产鼠标和键盘，但可能工厂A生产的是罗技的键盘和鼠标，工厂B是微软的。</p>
<p>这样A和B就是工厂，对应于抽象工厂；<br>
每个工厂生产的鼠标和键盘就是产品，对应于工厂方法；</p>
<p>用了工厂方法模式，你替换生成键盘的工厂方法，就可以把键盘从罗技换到微软。但是用了抽象工厂模式，你只要换家工厂，就可以同时替换鼠标和键盘一套。如果你要的产品有几十个，当然用抽象工厂模式一次替换全部最方便（这个工厂会替你用相应的工厂方法）</p>
<p>所以说抽象工厂就像工厂，而工厂方法则像是工厂的一种产品生产线</pre></p>
</blockquote>
<h4 id="3、单例模式（Singleton）"><a class="header-anchor" href="#3、单例模式（Singleton）"></a>3、单例模式（Singleton）</h4>
<p>单例对象（Singleton）是一种常用的设计模式。在Java应用中，单例对象能保证在一个JVM中，该对象只有一个实例存在。这样的模式有几个好处：</p>
<ol>
<li>某些类创建比较频繁，对于一些大型的对象，这是一笔很大的系统开销。</li>
<li>省去了new操作符，降低了系统内存的使用频率，减轻GC压力。</li>
<li>有些类如交易所的核心交易引擎，控制着交易流程，如果该类可以创建多个的话，系统完全乱了。（比如一个军队出现了多个司令员同时指挥，肯定会乱成一团），所以只有使用单例模式，才能保证核心交易服务器独立控制整个流程。</li>
</ol>
<p>首先我们写一个简单的单例类：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Singleton</span> &#123;</span><br><span class="line">    <span class="comment">/* 持有私有静态实例，防止被引用，此处赋值为null，目的是实现延迟加载 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="type">Singleton</span> <span class="variable">instance</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">    <span class="comment">/* 私有构造方法，防止被实例化 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="title function_">Singleton</span><span class="params">()</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/* 静态工程方法，创建实例 */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title function_">getInstance</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (instance == <span class="literal">null</span>) &#123;</span><br><span class="line">            instance = <span class="keyword">new</span> <span class="title class_">Singleton</span>();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> instance;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/* 如果该对象被用于序列化，可以保证对象在序列化前后保持一致 */</span></span><br><span class="line">    <span class="keyword">public</span> Object <span class="title function_">readResolve</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> instance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这个类可以满足基本要求，但是，像这样毫无线程安全保护的类，如果我们把它放入多线程的环境下，肯定就会出现问题了，如何解决？我们首先会想到对getInstance方法加synchronized关键字，如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">synchronized</span> Singleton <span class="title function_">getInstance</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (instance == <span class="literal">null</span>) &#123;</span><br><span class="line">            instance = <span class="keyword">new</span> <span class="title class_">Singleton</span>();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> instance;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>但是，synchronized关键字锁住的是这个对象，这样的用法，在性能上会有所下降，因为每次调用getInstance()，都要对对象上锁，事实上，只有在第一次创建对象的时候需要加锁，之后就不需要了，所以，这个地方需要改进。我们改成下面这个：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title function_">getInstance</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (instance == <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">synchronized</span> (instance) &#123;</span><br><span class="line">                <span class="keyword">if</span> (instance == <span class="literal">null</span>) &#123;</span><br><span class="line">                    instance = <span class="keyword">new</span> <span class="title class_">Singleton</span>();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> instance;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>似乎解决了之前提到的问题，将synchronized关键字加在了内部，也就是说当调用的时候是不需要加锁的，只有在instance为null，并创建对象的时候才需要加锁，性能有一定的提升。但是，这样的情况，还是有可能有问题的，看下面的情况：在Java指令中创建对象和赋值操作是分开进行的，也就是说<code>instance = new Singleton();</code>语句是分两步执行的。但是JVM并不保证这两个操作的先后顺序，也就是说有可能JVM会为新的Singleton实例分配空间，然后直接赋值给instance成员，然后再去初始化这个Singleton实例。这样就可能出错了，我们以A、B两个线程为例：<br>
a&gt; A、B线程同时进入了第一个if判断<br>
b&gt;A首先进入synchronized块，由于instance为null，所以它执行<code>instance = new Singleton();</code><br>
c&gt;由于JVM内部的优化机制，JVM先画出了一些分配给Singleton实例的空白内存，并赋值给instance成员（注意此时JVM没有开始初始化这个实例），然后A离开了synchronized块。<br>
d&gt;B进入synchronized块，由于instance此时不是null，因此它马上离开了synchronized块并将结果返回给调用该方法的程序。<br>
e&gt;此时B线程打算使用Singleton实例，却发现它没有被初始化，于是错误发生了。</p>
<p>所以程序还是有可能发生错误，其实程序在运行过程是很复杂的，从这点我们就可以看出，尤其是在写多线程环境下的程序更有难度，有挑战性。我们对该程序做进一步优化：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">SingletonFactory</span>&#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">static</span> <span class="type">Singleton</span> <span class="variable">instance</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Singleton</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title function_">getInstance</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> SingletonFactory.instance;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>实际情况是，单例模式使用内部类来维护单例的实现，JVM内部的机制能够保证当一个类被加载的时候，这个类的加载过程是线程互斥的。这样当我们第一次调用getInstance的时候，JVM能够帮我们保证instance只被创建一次，并且会保证把赋值给instance的内存初始化完毕，这样我们就不用担心上面的问题。同时该方法也只会在第一次调用的时候使用互斥机制，这样就解决了低性能问题。这样我们暂时总结一个完美的单例模式：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Singleton</span> &#123;</span><br><span class="line">    <span class="comment">/* 私有构造方法，防止被实例化 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="title function_">Singleton</span><span class="params">()</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/* 此处使用一个内部类来维护单例 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">SingletonFactory</span> &#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">static</span> <span class="type">Singleton</span> <span class="variable">instance</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Singleton</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/* 获取实例 */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title function_">getInstance</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> SingletonFactory.instance;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/* 如果该对象被用于序列化，可以保证对象在序列化前后保持一致 */</span></span><br><span class="line">    <span class="keyword">public</span> Object <span class="title function_">readResolve</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> getInstance();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其实说它完美，也不一定，如果在构造函数中抛出异常，实例将永远得不到创建，也会出错。所以说，十分完美的东西是没有的，我们只能根据实际情况，选择最适合自己应用场景的实现方法。也有人这样实现：因为我们只需要在创建类的时候进行同步，所以只要将创建和getInstance()分开，单独为创建加synchronized关键字，也是可以的：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SingletonTest</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="type">SingletonTest</span> <span class="variable">instance</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="title function_">SingletonTest</span><span class="params">()</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title function_">syncInit</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (instance == <span class="literal">null</span>) &#123;</span><br><span class="line">            instance = <span class="keyword">new</span> <span class="title class_">SingletonTest</span>();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> SingletonTest <span class="title function_">getInstance</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (instance == <span class="literal">null</span>) &#123;</span><br><span class="line">            syncInit();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> instance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>考虑性能的话，整个程序只需创建一次实例，所以性能也不会有什么影响。</p>
<p><strong>补充：采用”影子实例”的办法为单例对象的属性同步更新</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SingletonTest</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="type">SingletonTest</span> <span class="variable">instance</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">Vector</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">    <span class="keyword">public</span> Vector <span class="title function_">getProperties</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> properties;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">private</span> <span class="title function_">SingletonTest</span><span class="params">()</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title function_">syncInit</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (instance == <span class="literal">null</span>) &#123;</span><br><span class="line">            instance = <span class="keyword">new</span> <span class="title class_">SingletonTest</span>();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> SingletonTest <span class="title function_">getInstance</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (instance == <span class="literal">null</span>) &#123;</span><br><span class="line">            syncInit();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> instance;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">updateProperties</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">SingletonTest</span> <span class="variable">shadow</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SingletonTest</span>();</span><br><span class="line">        properties = shadow.getProperties();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>通过单例模式的学习告诉我们：</p>
<ol>
<li>单例模式理解起来简单，但是具体实现起来还是有一定的难度。</li>
<li>synchronized关键字锁定的是对象，在用的时候，一定要在恰当的地方使用（注意需要使用锁的对象和过程，可能有的时候并不是整个对象及整个过程都需要锁）。</li>
</ol>
<p>到这儿，单例模式基本已经讲完了，结尾处，笔者突然想到另一个问题，就是采用类的静态方法，实现单例模式的效果，也是可行的，此处二者有什么不同？</p>
<p>首先，静态类不能实现接口。（从类的角度说是可以的，但是那样就破坏了静态了。因为接口中不允许有static修饰的方法，所以即使实现了也是非静态的）</p>
<p>其次，单例可以被延迟初始化，静态类一般在第一次加载是初始化。之所以延迟加载，是因为有些类比较庞大，所以延迟加载有助于提升性能。</p>
<p>再次，单例类可以被继承，他的方法可以被覆写。但是静态类内部方法都是static，无法被覆写。</p>
<p>最后一点，单例类比较灵活，毕竟从实现上只是一个普通的Java类，只要满足单例的基本需求，你可以在里面随心所欲的实现一些其它功能，但是静态类不行。从上面这些概括中，基本可以看出二者的区别，但是，从另一方面讲，我们上面最后实现的那个单例模式，内部就是用一个静态类来实现的，所以，二者有很大的关联，只是我们考虑问题的层面不同罢了。两种思想的结合，才能造就出完美的解决方案，就像HashMap采用数组+链表来实现一样，其实生活中很多事情都是这样，单用不同的方法来处理问题，总是有优点也有缺点，最完美的方法是，结合各个方法的优点，才能最好的解决问题！</p>
<h4 id="4、建造者模式（Builder）"><a class="header-anchor" href="#4、建造者模式（Builder）"></a>4、建造者模式（Builder）</h4>
<h4 id="5、原型模式（Prototype）"><a class="header-anchor" href="#5、原型模式（Prototype）"></a>5、原型模式（Prototype）</h4>
<p>原型模式虽然是创建型的模式，但是与工程模式没有关系，从名字即可看出，该模式的思想就是将一个对象作为原型，对其进行复制、克隆，产生一个和原对象类似的新对象。本小结会通过对象的复制，进行讲解。在Java中，复制对象是通过clone()实现的，先创建一个原型类：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Prototype</span> <span class="keyword">implements</span> <span class="title class_">Cloneable</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> Object <span class="title function_">clone</span><span class="params">()</span> <span class="keyword">throws</span> CloneNotSupportedException &#123;</span><br><span class="line">        <span class="type">Prototype</span> <span class="variable">proto</span> <span class="operator">=</span> (Prototype) <span class="built_in">super</span>.clone();</span><br><span class="line">        <span class="keyword">return</span> proto;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>很简单，一个原型类，只需要实现Cloneable接口，覆写clone方法，此处clone方法可以改成任意的名称，因为Cloneable接口是个空接口，你可以任意定义实现类的方法名，如cloneA或者cloneB，因为此处的重点是super.clone()这句话，super.clone()调用的是Object的clone()方法，而在Object类中，clone()是native的，具体怎么实现，我会在另一篇文章中，关于解读Java中本地方法的调用，此处不再深究。在这儿，我将结合对象的浅复制和深复制来说一下，首先需要了解对象深、浅复制的概念：</p>
<p>浅复制：将一个对象复制后，基本数据类型的变量都会重新创建，而引用类型，指向的还是原对象所指向的。</p>
<p>深复制：将一个对象复制后，不论是基本数据类型还有引用类型，都是重新创建的。简单来说，就是深复制进行了完全彻底的复制，而浅复制不彻底。</p>
<p>此处，写一个深浅复制的例子：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Prototype</span> <span class="keyword">implements</span> <span class="title class_">Cloneable</span>, Serializable &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">long</span> <span class="variable">serialVersionUID</span> <span class="operator">=</span> <span class="number">1L</span>;</span><br><span class="line">    <span class="keyword">private</span> String string;</span><br><span class="line">    <span class="keyword">private</span> SerializableObject obj;</span><br><span class="line">    <span class="comment">/* 浅复制 */</span></span><br><span class="line">    <span class="keyword">public</span> Object <span class="title function_">clone</span><span class="params">()</span> <span class="keyword">throws</span> CloneNotSupportedException &#123;</span><br><span class="line">        <span class="type">Prototype</span> <span class="variable">proto</span> <span class="operator">=</span> (Prototype) <span class="built_in">super</span>.clone();</span><br><span class="line">        <span class="keyword">return</span> proto;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/* 深复制 */</span></span><br><span class="line">    <span class="keyword">public</span> Object <span class="title function_">deepClone</span><span class="params">()</span> <span class="keyword">throws</span> IOException, ClassNotFoundException &#123;</span><br><span class="line">        <span class="comment">/* 写入当前对象的二进制流 */</span></span><br><span class="line">        <span class="type">ByteArrayOutputStream</span> <span class="variable">bos</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ByteArrayOutputStream</span>();</span><br><span class="line">        <span class="type">ObjectOutputStream</span> <span class="variable">oos</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ObjectOutputStream</span>(bos);</span><br><span class="line">        oos.writeObject(<span class="built_in">this</span>);</span><br><span class="line">        <span class="comment">/* 读出二进制流产生的新对象 */</span></span><br><span class="line">        <span class="type">ByteArrayInputStream</span> <span class="variable">bis</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ByteArrayInputStream</span>(bos.toByteArray());</span><br><span class="line">        <span class="type">ObjectInputStream</span> <span class="variable">ois</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ObjectInputStream</span>(bis);</span><br><span class="line">        <span class="keyword">return</span> ois.readObject();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getString</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> string;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setString</span><span class="params">(String string)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.string = string;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> SerializableObject <span class="title function_">getObj</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> obj;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setObj</span><span class="params">(SerializableObject obj)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.obj = obj;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SerializableObject</span> <span class="keyword">implements</span> <span class="title class_">Serializable</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">long</span> <span class="variable">serialVersionUID</span> <span class="operator">=</span> <span class="number">1L</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>要实现深复制，需要采用流的形式读入当前对象的二进制输入，再写出二进制数据对应的对象。</p>
<h3 id="B、结构模式（7种）"><a class="header-anchor" href="#B、结构模式（7种）"></a>B、结构模式（7种）</h3>
<p>我们接着讨论设计模式，上篇文章我讲完了5种创建型模式，这章开始，我将讲下7种结构型模式：适配器模式、装饰模式、代理模式、外观模式、桥接模式、组合模式、享元模式。其中对象的适配器模式是各种模式的起源，我们看下面的图：</p>
<p><img src="/assets/23-design-patterns-analysis/5.jpg" alt=""></p>
<h4 id="6、适配器模式"><a class="header-anchor" href="#6、适配器模式"></a>6、适配器模式</h4>
<p>适配器模式将某个类的接口转换成客户端期望的另一个接口表示，目的是消除由于接口不匹配所造成的类的兼容性问题。主要分为三类：类的适配器模式、对象的适配器模式、接口的适配器模式。</p>
<h5 id="01、类的适配器模式"><a class="header-anchor" href="#01、类的适配器模式"></a>01、类的适配器模式</h5>
<p><img src="/assets/23-design-patterns-analysis/6.jpg" alt=""></p>
<p>核心思想就是：有一个Source类，拥有一个方法，待适配，目标接口是Targetable，通过Adapter类，将Source的功能扩展到Targetable里，看代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Source</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">method1</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(“<span class="built_in">this</span> is original method!”);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">Targetable</span> &#123;</span><br><span class="line">    <span class="comment">/* 与原类中的方法相同 */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">method1</span><span class="params">()</span>;</span><br><span class="line">    <span class="comment">/* 新类的方法 */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">method2</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Adapter</span> <span class="keyword">extends</span> <span class="title class_">Source</span> <span class="keyword">implements</span> <span class="title class_">Targetable</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">method2</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(“<span class="built_in">this</span> is the targetable method!”);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Adapter类继承Source类，实现Targetable接口，下面是测试类：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">AdapterTest</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">Targetable</span> <span class="variable">target</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Adapter</span>();</span><br><span class="line">        target.method1();</span><br><span class="line">        target.method2();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">this is original method!</span><br><span class="line">this is the targetable method!</span><br></pre></td></tr></table></figure>
<p>这样Targetable接口的实现类就具有了Source类的功能。</p>
<h5 id="02、对象的适配器模式"><a class="header-anchor" href="#02、对象的适配器模式"></a>02、对象的适配器模式</h5>
<p>基本思路和类的适配器模式相同，只是将Adapter类作修改，这次不继承Source类，而是持有Source类的实例，以达到解决兼容性的问题。看图：</p>
<p><img src="/assets/23-design-patterns-analysis/7.jpg" alt=""></p>
<p>只需要修改Adapter类的源码即可：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Wrapper</span> <span class="keyword">implements</span> <span class="title class_">Targetable</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> Source source;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Wrapper</span><span class="params">(Source source)</span>&#123;</span><br><span class="line">        <span class="built_in">super</span>();</span><br><span class="line">        <span class="built_in">this</span>.source = source;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">method2</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(“<span class="built_in">this</span> is the targetable method!”);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">method1</span><span class="params">()</span> &#123;</span><br><span class="line">        source.method1();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>测试类：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">AdapterTest</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">Source</span> <span class="variable">source</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Source</span>();</span><br><span class="line">        <span class="type">Targetable</span> <span class="variable">target</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Wrapper</span>(source);</span><br><span class="line">        target.method1();</span><br><span class="line">        target.method2();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>输出与第一种一样，只是适配的方法不同而已。</p>
<h5 id="03、接口的适配器模式"><a class="header-anchor" href="#03、接口的适配器模式"></a>03、接口的适配器模式</h5>
<p>第三种适配器模式是<strong>接口的适配器模式</strong>，接口的适配器是这样的：有时我们写的一个接口中有多个抽象方法，当我们写该接口的实现类时，必须实现该接口的所有方法，这明显有时比较浪费，因为并不是所有的方法都是我们需要的，有时只需要某一些，此处为了解决这个问题，我们引入了接口的适配器模式，借助于一个抽象类，该抽象类实现了该接口，实现了所有的方法，而我们不和原始的接口打交道，只和该抽象类取得联系，所以我们写一个类，继承该抽象类，重写我们需要的方法就行。看一下类图：</p>
<p><img src="/assets/23-design-patterns-analysis/8.jpg" alt=""></p>
<p>这个很好理解，在实际开发中，我们也常会遇到这种接口中定义了太多的方法，以致于有时我们在一些实现类中并不是都需要。看代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">Sourceable</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">method1</span><span class="params">()</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">method2</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>抽象类Wrapper2：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">class</span> <span class="title class_">Wrapper2</span> <span class="keyword">implements</span> <span class="title class_">Sourceable</span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">method1</span><span class="params">()</span>&#123;&#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">method2</span><span class="params">()</span>&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SourceSub1</span> <span class="keyword">extends</span> <span class="title class_">Wrapper2</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">method1</span><span class="params">()</span>&#123;</span><br><span class="line">        System.out.println(“the sourceable interface’s first Sub1!”);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SourceSub2</span> <span class="keyword">extends</span> <span class="title class_">Wrapper2</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">method2</span><span class="params">()</span>&#123;</span><br><span class="line">        System.out.println(“the sourceable interface’s second Sub2!”);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WrapperTest</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">Sourceable</span> <span class="variable">source1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SourceSub1</span>();</span><br><span class="line">        <span class="type">Sourceable</span> <span class="variable">source2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SourceSub2</span>();</span><br><span class="line">        source1.method1();</span><br><span class="line">        source1.method2();</span><br><span class="line">        source2.method1();</span><br><span class="line">        source2.method2();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>测试输出：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">the sourceable interface’s first Sub1!</span><br><span class="line">the sourceable interface’s second Sub2!</span><br></pre></td></tr></table></figure>
<p>达到了我们的效果！</p>
<p>讲了这么多，总结一下三种适配器模式的应用场景：</p>
<p>类的适配器模式：当希望将<strong>一个类</strong>转换成满足<strong>另一个新接口</strong>的类时，可以使用类的适配器模式，创建一个新类，继承原有的类，实现新的接口即可。</p>
<p>对象的适配器模式：当希望将一个对象转换成满足另一个新接口的对象时，可以创建一个Wrapper类，持有原类的一个实例，在Wrapper类的方法中，调用实例的方法就行。</p>
<p>接口的适配器模式：当不希望实现一个接口中所有的方法时，可以创建一个抽象类Wrapper，实现所有方法，我们写别的类的时候，继承抽象类即可。</p>
<h4 id="7-装饰模式（Decorator）"><a class="header-anchor" href="#7-装饰模式（Decorator）"></a>7. 装饰模式（Decorator）</h4>
<p>顾名思义，装饰模式就是给一个对象增加一些新的功能，而且是动态的，要求装饰对象和被装饰对象实现同一个接口，装饰对象持有被装饰对象的实例，关系图如下：</p>
<p><img src="/assets/23-design-patterns-analysis/9.jpg" alt=""></p>
<p>Source类是被装饰类，Decorator类是一个装饰类，可以为Source类动态的添加一些功能，代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">Sourceable</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">method</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Source</span> <span class="keyword">implements</span> <span class="title class_">Sourceable</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">method</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(“the original method!”);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Decorator</span> <span class="keyword">implements</span> <span class="title class_">Sourceable</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> Sourceable source;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Decorator</span><span class="params">(Sourceable source)</span>&#123;</span><br><span class="line">        <span class="built_in">super</span>();</span><br><span class="line">        <span class="built_in">this</span>.source = source;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">method</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(“before decorator!”);</span><br><span class="line">        source.method();</span><br><span class="line">        System.out.println(“after decorator!”);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>测试类：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">DecoratorTest</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">Sourceable</span> <span class="variable">source</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Source</span>();</span><br><span class="line">        <span class="type">Sourceable</span> <span class="variable">obj</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Decorator</span>(source);</span><br><span class="line">        obj.method();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">before decorator!</span><br><span class="line">the original method!</span><br><span class="line">after decorator!</span><br></pre></td></tr></table></figure>
<p>装饰器模式的应用场景：</p>
<ol>
<li>需要扩展一个类的功能。</li>
<li>动态的为一个对象增加功能，而且还能动态撤销。（继承不能做到这一点，继承的功能是静态的，不能动态增删。）</li>
</ol>
<p>缺点：产生过多相似的对象，不易排错！</p>
<h4 id="8、代理模式（Proxy）"><a class="header-anchor" href="#8、代理模式（Proxy）"></a>8、代理模式（Proxy）</h4>
<p>其实每个模式名称就表明了该模式的作用，代理模式就是多一个代理类出来，替原对象进行一些操作，比如我们在租房子的时候回去找中介，为什么呢？因为你对该地区房屋的信息掌握的不够全面，希望找一个更熟悉的人去帮你做，此处的代理就是这个意思。再如我们有的时候打官司，我们需要请律师，因为律师在法律方面有专长，可以替我们进行操作，表达我们的想法。先来看看关系图：</p>
<p><img src="/assets/23-design-patterns-analysis/10.jpg" alt=""></p>
<p>根据上文的阐述，代理模式就比较容易的理解了，我们看下代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">Sourceable</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">method</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Source</span> <span class="keyword">implements</span> <span class="title class_">Sourceable</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">method</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(“the original method!”);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Proxy</span> <span class="keyword">implements</span> <span class="title class_">Sourceable</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> Source source;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Proxy</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="built_in">super</span>();</span><br><span class="line">        <span class="built_in">this</span>.source = <span class="keyword">new</span> <span class="title class_">Source</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">method</span><span class="params">()</span> &#123;</span><br><span class="line">        before();</span><br><span class="line">        source.method();</span><br><span class="line">        atfer();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">atfer</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(“after proxy!”);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">before</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(“before proxy!”);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>测试类：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ProxyTest</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">Sourceable</span> <span class="variable">source</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Proxy</span>();</span><br><span class="line">        source.method();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">before proxy!</span><br><span class="line">the original method!</span><br><span class="line">after proxy!</span><br></pre></td></tr></table></figure>
<p>代理模式的应用场景：</p>
<p>如果已有的方法在使用的时候需要对原有的方法进行改进，此时有两种办法：</p>
<ol>
<li>修改原有的方法来适应。这样违反了“对扩展开放，对修改关闭”的原则。</li>
<li>就是采用一个代理类调用原有的方法，且对产生的结果进行控制。这种方法就是代理模式。</li>
</ol>
<p>使用代理模式，可以将功能划分的更加清晰，有助于后期维护！</p>
<h4 id="9、外观模式（Facade）"><a class="header-anchor" href="#9、外观模式（Facade）"></a>9、外观模式（Facade）</h4>
<p>外观模式是为了解决类与类之家的依赖关系的，像spring一样，可以将类和类之间的关系配置到配置文件中，而外观模式就是将他们的关系放在一个Facade类中，降低了类类之间的耦合度，该模式中没有涉及到接口，看下类图：（我们以一个计算机的启动过程为例）</p>
<p><img src="/assets/23-design-patterns-analysis/11.jpg" alt=""></p>
<p>我们先看下实现类：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CPU</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">startup</span><span class="params">()</span>&#123;</span><br><span class="line">        System.out.println(“cpu startup!”);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">shutdown</span><span class="params">()</span>&#123;</span><br><span class="line">        System.out.println(“cpu shutdown!”);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Memory</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">startup</span><span class="params">()</span>&#123;</span><br><span class="line">        System.out.println(“memory startup!”);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">shutdown</span><span class="params">()</span>&#123;</span><br><span class="line">        System.out.println(“memory shutdown!”);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Disk</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">startup</span><span class="params">()</span>&#123;</span><br><span class="line">        System.out.println(“disk startup!”);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">shutdown</span><span class="params">()</span>&#123;</span><br><span class="line">        System.out.println(“disk shutdown!”);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Computer</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> CPU cpu;</span><br><span class="line">    <span class="keyword">private</span> Memory memory;</span><br><span class="line">    <span class="keyword">private</span> Disk disk;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Computer</span><span class="params">()</span>&#123;</span><br><span class="line">        cpu = <span class="keyword">new</span> <span class="title class_">CPU</span>();</span><br><span class="line">        memory = <span class="keyword">new</span> <span class="title class_">Memory</span>();</span><br><span class="line">        disk = <span class="keyword">new</span> <span class="title class_">Disk</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">startup</span><span class="params">()</span>&#123;</span><br><span class="line">        System.out.println(“start the computer!”);</span><br><span class="line">        cpu.startup();</span><br><span class="line">        memory.startup();</span><br><span class="line">        disk.startup();</span><br><span class="line">        System.out.println(“start computer finished!”);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">shutdown</span><span class="params">()</span>&#123;</span><br><span class="line">        System.out.println(“begin to close the computer!”);</span><br><span class="line">        cpu.shutdown();</span><br><span class="line">        memory.shutdown();</span><br><span class="line">        disk.shutdown();</span><br><span class="line">        System.out.println(“computer closed!”);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>User类如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">User</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">Computer</span> <span class="variable">computer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Computer</span>();</span><br><span class="line">        computer.startup();</span><br><span class="line">        computer.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">start the computer!</span><br><span class="line">cpu startup!</span><br><span class="line">memory startup!</span><br><span class="line">disk startup!</span><br><span class="line">start computer finished!</span><br><span class="line">begin to close the computer!</span><br><span class="line">cpu shutdown!</span><br><span class="line">memory shutdown!</span><br><span class="line">disk shutdown!</span><br><span class="line">computer closed!</span><br></pre></td></tr></table></figure>
<p>如果我们没有Computer类，那么，CPU、Memory、Disk他们之间将会相互持有实例，产生关系，这样会造成严重的依赖，修改一个类，可能会带来其他类的修改，这不是我们想要看到的，有了Computer类，他们之间的关系被放在了Computer类里，这样就起到了解耦的作用，这，就是外观模式！</p>
<h4 id="10、桥接模式（Bridge）"><a class="header-anchor" href="#10、桥接模式（Bridge）"></a>10、桥接模式（Bridge）</h4>
<p>桥接模式就是把事物和其具体实现分开，使他们可以各自独立的变化。桥接的用意是：<strong>将抽象化与实现化解耦，使得二者可以独立变化</strong>，像我们常用的JDBC桥DriverManager一样，JDBC进行连接数据库的时候，在各个数据库之间进行切换，基本不需要动太多的代码，甚至丝毫不用动，原因就是JDBC提供统一接口，每个数据库提供各自的实现，用一个叫做数据库驱动的程序来桥接就行了。我们来看看关系图：</p>
<p><img src="/assets/23-design-patterns-analysis/12.jpg" alt=""></p>
<p>实现代码：</p>
<p>先定义接口：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">Sourceable</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">method</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>分别定义两个实现类：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SourceSub1</span> <span class="keyword">implements</span> <span class="title class_">Sourceable</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">method</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(“<span class="built_in">this</span> is the first sub!”);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SourceSub2</span> <span class="keyword">implements</span> <span class="title class_">Sourceable</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">method</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(“<span class="built_in">this</span> is the second sub!”);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>定义一个桥，持有Sourceable的一个实例：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">class</span> <span class="title class_">Bridge</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> Sourceable source;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">method</span><span class="params">()</span>&#123;</span><br><span class="line">        source.method();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> Sourceable <span class="title function_">getSource</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> source;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setSource</span><span class="params">(Sourceable source)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.source = source;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyBridge</span> <span class="keyword">extends</span> <span class="title class_">Bridge</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">method</span><span class="params">()</span>&#123;</span><br><span class="line">        getSource().method();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>测试类：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BridgeTest</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">Bridge</span> <span class="variable">bridge</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">MyBridge</span>();</span><br><span class="line">        <span class="comment">/*调用第一个对象*/</span></span><br><span class="line">        <span class="type">Sourceable</span> <span class="variable">source1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SourceSub1</span>();</span><br><span class="line">        bridge.setSource(source1);</span><br><span class="line">        bridge.method();</span><br><span class="line">        <span class="comment">/*调用第二个对象*/</span></span><br><span class="line">        <span class="type">Sourceable</span> <span class="variable">source2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SourceSub2</span>();</span><br><span class="line">        bridge.setSource(source2);</span><br><span class="line">        bridge.method();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>output：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">this is the first sub!</span><br><span class="line">this is the second sub!</span><br></pre></td></tr></table></figure>
<p>这样，就通过对Bridge类的调用，实现了对接口Sourceable的实现类SourceSub1和SourceSub2的调用。接下来我再画个图，大家就应该明白了，因为这个图是我们JDBC连接的原理，有数据库学习基础的，一结合就都懂了。</p>
<p><img src="/assets/23-design-patterns-analysis/13.jpg" alt=""></p>
<h4 id="11-组合模式（Composite）"><a class="header-anchor" href="#11-组合模式（Composite）"></a>11. 组合模式（Composite）</h4>
<p>组合模式有时又叫<strong>部分-整体</strong>模式在处理类似树形结构的问题时比较方便，看看关系图：</p>
<p><img src="/assets/23-design-patterns-analysis/14.jpg" alt=""></p>
<p>直接来看代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TreeNode</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> TreeNode parent;</span><br><span class="line">    <span class="keyword">private</span> Vector&lt;TreeNode&gt; children = <span class="keyword">new</span> <span class="title class_">Vector</span>&lt;TreeNode&gt;();</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">TreeNode</span><span class="params">(String name)</span>&#123;</span><br><span class="line">        <span class="built_in">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getName</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> name;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setName</span><span class="params">(String name)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> TreeNode <span class="title function_">getParent</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> parent;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setParent</span><span class="params">(TreeNode parent)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.parent = parent;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//添加孩子节点</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">add</span><span class="params">(TreeNode node)</span>&#123;</span><br><span class="line">        children.add(node);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//删除孩子节点</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">remove</span><span class="params">(TreeNode node)</span>&#123;</span><br><span class="line">        children.remove(node);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//取得孩子节点</span></span><br><span class="line">    <span class="keyword">public</span> Enumeration&lt;TreeNode&gt; <span class="title function_">getChildren</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> children.elements();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Tree</span> &#123;</span><br><span class="line">    <span class="type">TreeNode</span> <span class="variable">root</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Tree</span><span class="params">(String name)</span> &#123;</span><br><span class="line">        root = <span class="keyword">new</span> <span class="title class_">TreeNode</span>(name);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">Tree</span> <span class="variable">tree</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Tree</span>(“A”);</span><br><span class="line">        <span class="type">TreeNode</span> <span class="variable">nodeB</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TreeNode</span>(“B”);</span><br><span class="line">        <span class="type">TreeNode</span> <span class="variable">nodeC</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TreeNode</span>(“C”);</span><br><span class="line">        nodeB.add(nodeC);</span><br><span class="line">        tree.root.add(nodeB);</span><br><span class="line">        System.out.println(“build the tree finished!”);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>使用场景：将多个对象组合在一起进行操作，常用于表示树形结构中，例如二叉树，数等。</p>
<h4 id="12、享元模式（Flyweight）"><a class="header-anchor" href="#12、享元模式（Flyweight）"></a>12、享元模式（Flyweight）</h4>
<p>享元模式的主要目的是实现对象的共享，即共享池，当系统中对象多的时候可以减少内存的开销，通常与工厂模式一起使用。</p>
<p><img src="/assets/23-design-patterns-analysis/15.jpg" alt=""></p>
<p>FlyWeightFactory负责创建和管理享元单元，当一个客户端请求时，工厂需要检查当前对象池中是否有符合条件的对象，如果有，就返回已经存在的对象，如果没有，则创建一个新对象，FlyWeight是超类。一提到共享池，我们很容易联想到Java里面的JDBC连接池，想想每个连接的特点，我们不难总结出：适用于作共享的一些个对象，他们有一些共有的属性，就拿数据库连接池来说，url、driverClassName、username、password及dbname，这些属性对于每个连接来说都是一样的，所以就适合用享元模式来处理，建一个工厂类，将上述类似属性作为内部数据，其它的作为外部数据，在方法调用时，当做参数传进来，这样就节省了空间，减少了实例的数量。</p>
<p>看个例子：</p>
<p><img src="/assets/23-design-patterns-analysis/16.jpg" alt=""></p>
<p>看下数据库连接池的代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ConnectionPool</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> Vector&lt;Connection&gt; pool;</span><br><span class="line">    <span class="comment">/*公有属性*/</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">String</span> <span class="variable">url</span> <span class="operator">=</span> “jdbc:mysql:<span class="comment">//localhost:3306/test”;</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">String</span> <span class="variable">username</span> <span class="operator">=</span> “root”;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">String</span> <span class="variable">password</span> <span class="operator">=</span> “root”;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">String</span> <span class="variable">driverClassName</span> <span class="operator">=</span> “com.mysql.jdbc.Driver”;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> <span class="variable">poolSize</span> <span class="operator">=</span> <span class="number">100</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="type">ConnectionPool</span> <span class="variable">instance</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">    <span class="type">Connection</span> <span class="variable">conn</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">    <span class="comment">/*构造方法，做一些初始化工作*/</span></span><br><span class="line">    <span class="keyword">private</span> <span class="title function_">ConnectionPool</span><span class="params">()</span> &#123;</span><br><span class="line">        pool = <span class="keyword">new</span> <span class="title class_">Vector</span>&lt;Connection&gt;(poolSize);</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; poolSize; i++) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                Class.forName(driverClassName);</span><br><span class="line">                conn = DriverManager.getConnection(url, username, password);</span><br><span class="line">                pool.add(conn);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (ClassNotFoundException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (SQLException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/* 返回连接到连接池 */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title function_">release</span><span class="params">()</span> &#123;</span><br><span class="line">        pool.add(conn);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/* 返回连接池中的一个数据库连接 */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">synchronized</span> Connection <span class="title function_">getConnection</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (pool.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="type">Connection</span> <span class="variable">conn</span> <span class="operator">=</span> pool.get(<span class="number">0</span>);</span><br><span class="line">            pool.remove(conn);</span><br><span class="line">            <span class="keyword">return</span> conn;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>通过连接池的管理，实现了数据库连接的共享，不需要每一次都重新创建连接，节省了数据库重新创建的开销，提升了系统的性能！</p>
<h3 id="C、关系模式（11种）"><a class="header-anchor" href="#C、关系模式（11种）"></a>C、关系模式（11种）</h3>
<p>先来张图，看看这11中模式的关系：</p>
<p>第一类：通过父类与子类的关系进行实现。<br>
第二类：两个类之间。<br>
第三类：类的状态。<br>
第四类：通过中间类</p>
<p><img src="/assets/23-design-patterns-analysis/17.jpg" alt=""></p>
<h4 id="父类与子类关系"><a class="header-anchor" href="#父类与子类关系"></a>父类与子类关系</h4>
<h4 id="13、策略模式（strategy）"><a class="header-anchor" href="#13、策略模式（strategy）"></a>13、策略模式（strategy）</h4>
<p>策略模式定义了一系列算法，并将每个算法封装起来，使他们可以相互替换，且算法的变化不会影响到使用算法的客户。需要设计一个接口，为一系列实现类提供统一的方法，多个实现类实现该接口，设计一个抽象类（可有可无，属于辅助类），提供辅助函数，关系图如下：<br>
<img src="/assets/23-design-patterns-analysis/18.jpg" alt=""></p>
<p>图中ICalculator提供同意的方法，<br>
AbstractCalculator是辅助类，提供辅助方法，接下来，依次实现下每个类：</p>
<p>首先统一接口：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">ICalculator</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">calculate</span><span class="params">(String exp)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>辅助类：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">class</span> <span class="title class_">AbstractCalculator</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span>[] split(String exp,String opt)&#123;</span><br><span class="line">        String array[] = exp.split(opt);</span><br><span class="line">        <span class="type">int</span> arrayInt[] = <span class="keyword">new</span> <span class="title class_">int</span>[<span class="number">2</span>];</span><br><span class="line">        arrayInt[<span class="number">0</span>] = Integer.parseInt(array[<span class="number">0</span>]);</span><br><span class="line">        arrayInt[<span class="number">1</span>] = Integer.parseInt(array[<span class="number">1</span>]);</span><br><span class="line">        <span class="keyword">return</span> arrayInt;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>三个实现类：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Plus</span> <span class="keyword">extends</span> <span class="title class_">AbstractCalculator</span> <span class="keyword">implements</span> <span class="title class_">ICalculator</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">calculate</span><span class="params">(String exp)</span> &#123;</span><br><span class="line">        <span class="type">int</span> arrayInt[] = split(exp,”\\+”);</span><br><span class="line">        <span class="keyword">return</span> arrayInt[<span class="number">0</span>]+arrayInt[<span class="number">1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Minus</span> <span class="keyword">extends</span> <span class="title class_">AbstractCalculator</span> <span class="keyword">implements</span> <span class="title class_">ICalculator</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">calculate</span><span class="params">(String exp)</span> &#123;</span><br><span class="line">        <span class="type">int</span> arrayInt[] = split(exp,”-“);</span><br><span class="line">        <span class="keyword">return</span> arrayInt[<span class="number">0</span>]-arrayInt[<span class="number">1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Multiply</span> <span class="keyword">extends</span> <span class="title class_">AbstractCalculator</span> <span class="keyword">implements</span> <span class="title class_">ICalculator</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">calculate</span><span class="params">(String exp)</span> &#123;</span><br><span class="line">        <span class="type">int</span> arrayInt[] = split(exp,”\\*”);</span><br><span class="line">        <span class="keyword">return</span> arrayInt[<span class="number">0</span>]*arrayInt[<span class="number">1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>简单的测试类：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">StrategyTest</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">exp</span> <span class="operator">=</span> “<span class="number">2</span>+<span class="number">8</span>”;</span><br><span class="line">        <span class="type">ICalculator</span> <span class="variable">cal</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Plus</span>();</span><br><span class="line">        <span class="type">int</span> <span class="variable">result</span> <span class="operator">=</span> cal.calculate(exp);</span><br><span class="line">        System.out.println(result);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>输出：<code>10</code></p>
<p>策略模式的决定权在用户，系统本身提供不同算法的实现，新增或者删除算法，对各种算法做封装。因此，策略模式多用在算法决策系统中，外部用户只需要决定用哪个算法即可。</p>
<h4 id="14、模板方法模式（Template-Method）"><a class="header-anchor" href="#14、模板方法模式（Template-Method）"></a>14、模板方法模式（Template Method）</h4>
<p>解释一下模板方法模式，就是指：一个抽象类中，有一个主方法，再定义1…n个方法，可以是抽象的，也可以是实际的方法，定义一个类，继承该抽象类，重写抽象方法，通过调用抽象类，实现对子类的调用，先看个关系图：</p>
<p><img src="/assets/23-design-patterns-analysis/19.jpg" alt=""></p>
<p>就是在AbstractCalculator类中定义一个主方法calculate，calculate()调用spilt()等，Plus和Minus分别继承AbstractCalculator类，通过对AbstractCalculator的调用实现对子类的调用，看下面的例子：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">class</span> <span class="title class_">AbstractCalculator</span> &#123;</span><br><span class="line">    <span class="comment">/*主方法，实现对本类其它方法的调用*/</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">final</span> <span class="type">int</span> <span class="title function_">calculate</span><span class="params">(String exp,String opt)</span>&#123;</span><br><span class="line">        <span class="type">int</span> array[] = split(exp,opt);</span><br><span class="line">        <span class="keyword">return</span> calculate(array[<span class="number">0</span>],array[<span class="number">1</span>]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/*被子类重写的方法*/</span></span><br><span class="line">    <span class="keyword">abstract</span> <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">calculate</span><span class="params">(<span class="type">int</span> num1,<span class="type">int</span> num2)</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span>[] split(String exp,String opt)&#123;</span><br><span class="line">        String array[] = exp.split(opt);</span><br><span class="line">        <span class="type">int</span> arrayInt[] = <span class="keyword">new</span> <span class="title class_">int</span>[<span class="number">2</span>];</span><br><span class="line">        arrayInt[<span class="number">0</span>] = Integer.parseInt(array[<span class="number">0</span>]);</span><br><span class="line">        arrayInt[<span class="number">1</span>] = Integer.parseInt(array[<span class="number">1</span>]);</span><br><span class="line">        <span class="keyword">return</span> arrayInt;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Plus</span> <span class="keyword">extends</span> <span class="title class_">AbstractCalculator</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">calculate</span><span class="params">(<span class="type">int</span> num1,<span class="type">int</span> num2)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> num1 + num2;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>测试类：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">StrategyTest</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">exp</span> <span class="operator">=</span> “<span class="number">8</span>+<span class="number">8</span>”;</span><br><span class="line">        <span class="type">AbstractCalculator</span> <span class="variable">cal</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Plus</span>();</span><br><span class="line">        <span class="type">int</span> <span class="variable">result</span> <span class="operator">=</span> cal.calculate(exp, “\\+”);</span><br><span class="line">        System.out.println(result);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>我跟踪下这个小程序的执行过程：首先将exp和”\+”做参数，调用AbstractCalculator类里的calculate(String,String)方法，在calculate(String,String)里调用同类的split()，之后再调用calculate(int ,int)方法，从这个方法进入到子类中，执行完return num1 + num2后，将值返回到AbstractCalculator类，赋给result，打印出来。正好验证了我们开头的思路。</p>
<h4 id="类之间的关系"><a class="header-anchor" href="#类之间的关系"></a>类之间的关系</h4>
<h4 id="15、观察者模式（Observer）"><a class="header-anchor" href="#15、观察者模式（Observer）"></a>15、观察者模式（Observer）</h4>
<p>包括这个模式在内的接下来的四个模式，都是类和类之间的关系，不涉及到继承，学的时候应该 记得归纳，记得本文最开始的那个图。观察者模式很好理解，类似于邮件订阅和RSS订阅，当我们浏览一些博客或wiki时，经常会看到RSS图标，就这的意思是，当你订阅了该文章，如果后续有更新，会及时通知你。其实，简单来讲就一句话：当一个对象变化时，其它依赖该对象的对象都会收到通知，并且随着变化！对象之间是一种一对多的关系。先来看看关系图：</p>
<p><img src="/assets/23-design-patterns-analysis/20.jpg" alt=""></p>
<p>我解释下这些类的作用：MySubject类就是我们的主对象，Observer1和Observer2是依赖于MySubject的对象，当MySubject变化时，Observer1和Observer2必然变化。AbstractSubject类中定义着需要监控的对象列表，可以对其进行修改：增加或删除被监控对象，且当MySubject变化时，负责通知在列表内存在的对象。我们看实现代码：</p>
<p>一个Observer接口：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">Observer</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">update</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>两个实现类：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Observer1</span> <span class="keyword">implements</span> <span class="title class_">Observer</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">update</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(“observer1 has received!”);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Observer2</span> <span class="keyword">implements</span> <span class="title class_">Observer</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">update</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(“observer2 has received!”);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Subject接口及实现类：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">Subject</span> &#123;</span><br><span class="line">    <span class="comment">/*增加观察者*/</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">add</span><span class="params">(Observer observer)</span>;</span><br><span class="line">    <span class="comment">/*删除观察者*/</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">del</span><span class="params">(Observer observer)</span>;</span><br><span class="line">    <span class="comment">/*通知所有的观察者*/</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">notifyObservers</span><span class="params">()</span>;</span><br><span class="line">    <span class="comment">/*自身的操作*/</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">operation</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">class</span> <span class="title class_">AbstractSubject</span> <span class="keyword">implements</span> <span class="title class_">Subject</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> Vector&lt;Observer&gt; vector = <span class="keyword">new</span> <span class="title class_">Vector</span>&lt;Observer&gt;();</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">add</span><span class="params">(Observer observer)</span> &#123;</span><br><span class="line">        vector.add(observer);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">del</span><span class="params">(Observer observer)</span> &#123;</span><br><span class="line">        vector.remove(observer);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">notifyObservers</span><span class="params">()</span> &#123;</span><br><span class="line">        Enumeration&lt;Observer&gt; enumo = vector.elements();</span><br><span class="line">        <span class="keyword">while</span>(enumo.hasMoreElements())&#123;</span><br><span class="line">            enumo.nextElement().update();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MySubject</span> <span class="keyword">extends</span> <span class="title class_">AbstractSubject</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">operation</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(“update self!”);</span><br><span class="line">        notifyObservers();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>测试类：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ObserverTest</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">Subject</span> <span class="variable">sub</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">MySubject</span>();</span><br><span class="line">        sub.add(<span class="keyword">new</span> <span class="title class_">Observer1</span>());</span><br><span class="line">        sub.add(<span class="keyword">new</span> <span class="title class_">Observer2</span>());</span><br><span class="line">        sub.operation();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">update self!</span><br><span class="line">observer1 has received!</span><br><span class="line">observer2 has received!</span><br></pre></td></tr></table></figure>
<p>这些东西，其实不难，只是有些抽象，不太容易整体理解，建议读者：<strong>根据关系图，新建项目，自己写代码（或者参考我的代码）,按照总体思路走一遍，这样才能体会它的思想，理解起来容易！</strong></p>
<h4 id="16、迭代子模式（Iterator）"><a class="header-anchor" href="#16、迭代子模式（Iterator）"></a>16、迭代子模式（Iterator）</h4>
<p>顾名思义，迭代器模式就是顺序访问聚集中的对象，一般来说，集合中非常常见，如果对集合类比较熟悉的话，理解本模式会十分轻松。这句话包含两层意思：一是需要遍历的对象，即聚集对象，二是迭代器对象，用于对聚集对象进行遍历访问。我们看下关系图：</p>
<p><img src="/assets/23-design-patterns-analysis/21.jpg" alt=""></p>
<p>这个思路和我们常用的一模一样，MyCollection中定义了集合的一些操作，MyIterator中定义了一系列迭代操作，且持有Collection实例，我们来看看实现代码：</p>
<p>两个接口：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">Collection</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> Iterator <span class="title function_">iterator</span><span class="params">()</span>;</span><br><span class="line">    <span class="comment">/*取得集合元素*/</span></span><br><span class="line">    <span class="keyword">public</span> Object <span class="title function_">get</span><span class="params">(<span class="type">int</span> i)</span>;</span><br><span class="line">    <span class="comment">/*取得集合大小*/</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">size</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">Iterator</span> &#123;</span><br><span class="line">    <span class="comment">//前移</span></span><br><span class="line">    <span class="keyword">public</span> Object <span class="title function_">previous</span><span class="params">()</span>;</span><br><span class="line">    <span class="comment">//后移</span></span><br><span class="line">    <span class="keyword">public</span> Object <span class="title function_">next</span><span class="params">()</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">hasNext</span><span class="params">()</span>;</span><br><span class="line">    <span class="comment">//取得第一个元素</span></span><br><span class="line">    <span class="keyword">public</span> Object <span class="title function_">first</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>两个实现：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyCollection</span> <span class="keyword">implements</span> <span class="title class_">Collection</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> String string[] = &#123;“A”,”B”,”C”,”D”,”E”&#125;;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Iterator <span class="title function_">iterator</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">MyIterator</span>(<span class="built_in">this</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Object <span class="title function_">get</span><span class="params">(<span class="type">int</span> i)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> string[i];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">size</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> string.length;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyIterator</span> <span class="keyword">implements</span> <span class="title class_">Iterator</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> Collection collection;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> <span class="variable">pos</span> <span class="operator">=</span> -<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">MyIterator</span><span class="params">(Collection collection)</span>&#123;</span><br><span class="line">        <span class="built_in">this</span>.collection = collection;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Object <span class="title function_">previous</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span>(pos &gt; <span class="number">0</span>)&#123;</span><br><span class="line">            pos–;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> collection.get(pos);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Object <span class="title function_">next</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span>(pos&lt;collection.size()-<span class="number">1</span>)&#123;</span><br><span class="line">            pos++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> collection.get(pos);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">hasNext</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span>(pos&lt;collection.size()-<span class="number">1</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Object <span class="title function_">first</span><span class="params">()</span> &#123;</span><br><span class="line">        pos = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">return</span> collection.get(pos);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>测试类：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Test</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">Collection</span> <span class="variable">collection</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">MyCollection</span>();</span><br><span class="line">        <span class="type">Iterator</span> <span class="variable">it</span> <span class="operator">=</span> collection.iterator();</span><br><span class="line">        <span class="keyword">while</span>(it.hasNext())&#123;</span><br><span class="line">            System.out.println(it.next());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>输出：<code>A B C D E</code></p>
<p>此处我们貌似模拟了一个集合类的过程，感觉是不是很爽？其实JDK中各个类也都是这些基本的东西，加一些设计模式，再加一些优化放到一起的，只要我们把这些东西学会了，掌握好了，我们也可以写出自己的集合类，甚至框架！</p>
<h4 id="17、责任链模式（Chain-of-Responsibility）"><a class="header-anchor" href="#17、责任链模式（Chain-of-Responsibility）"></a>17、责任链模式（Chain of Responsibility）</h4>
<p>接下来我们将要谈谈责任链模式，有多个对象，每个对象持有对下一个对象的引用，这样就会形成一条链，请求在这条链上传递，直到某一对象决定处理该请求。但是发出者并不清楚到底最终那个对象会处理该请求，所以，责任链模式可以实现，在隐瞒客户端的情况下，对系统进行动态的调整。先看看关系图：<br>
<img src="/assets/23-design-patterns-analysis/22.jpg" alt=""></p>
<p>Abstracthandler类提供了get和set方法，方便MyHandle类设置和修改引用对象，MyHandle类是核心，实例化后生成一系列相互持有的对象，构成一条链。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">Handler</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">operator</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">class</span> <span class="title class_">AbstractHandler</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> Handler handler;</span><br><span class="line">    <span class="keyword">public</span> Handler <span class="title function_">getHandler</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> handler;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setHandler</span><span class="params">(Handler handler)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.handler = handler;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">public class MyHandler extends AbstractHandler implements Handler &#123;</span><br><span class="line">    private String name;</span><br><span class="line">    public MyHandler(String name) &#123;</span><br><span class="line">        this.name = name;</span><br><span class="line">    &#125;</span><br><span class="line">    @Override</span><br><span class="line">    public void operator() &#123;</span><br><span class="line">        System.out.println(name+”deal!”);</span><br><span class="line">        if(getHandler()!=null)&#123;</span><br><span class="line">            getHandler().operator();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Test</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">MyHandler</span> <span class="variable">h1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">MyHandler</span>(“h1”);</span><br><span class="line">        <span class="type">MyHandler</span> <span class="variable">h2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">MyHandler</span>(“h2”);</span><br><span class="line">        <span class="type">MyHandler</span> <span class="variable">h3</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">MyHandler</span>(“h3”);</span><br><span class="line">        h1.setHandler(h2);</span><br><span class="line">        h2.setHandler(h3);</span><br><span class="line">        h1.operator();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">h1deal!</span><br><span class="line">h2deal!</span><br><span class="line">h3deal!</span><br></pre></td></tr></table></figure>
<p>此处强调一点就是，链接上的请求可以是一条链，可以是一个树，还可以是一个环，模式本身不约束这个，需要我们自己去实现，同时，在一个时刻，命令只允许由一个对象传给另一个对象，而不允许传给多个对象。</p>
<h4 id="18、命令模式（Command）"><a class="header-anchor" href="#18、命令模式（Command）"></a>18、命令模式（Command）</h4>
<p>命令模式很好理解，举个例子，司令员下令让士兵去干件事情，从整个事情的角度来考虑，司令员的作用是，发出口令，口令经过传递，传到了士兵耳朵里，士兵去执行。这个过程好在，三者相互解耦，任何一方都不用去依赖其他人，只需要做好自己的事儿就行，司令员要的是结果，不会去关注到底士兵是怎么实现的。我们看看关系图：</p>
<p><img src="/assets/23-design-patterns-analysis/23.jpg" alt=""></p>
<p>Invoker是调用者（司令员），Receiver是被调用者（士兵），MyCommand是命令，实现了Command接口，持有接收对象，看实现代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">Command</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">exe</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyCommand</span> <span class="keyword">implements</span> <span class="title class_">Command</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> Receiver receiver;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">MyCommand</span><span class="params">(Receiver receiver)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.receiver = receiver;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">exe</span><span class="params">()</span> &#123;</span><br><span class="line">        receiver.action();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Receiver</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">action</span><span class="params">()</span>&#123;</span><br><span class="line">        System.out.println(“command received!”);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Invoker</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> Command command;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Invoker</span><span class="params">(Command command)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.command = command;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">action</span><span class="params">()</span>&#123;</span><br><span class="line">        command.exe();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Test</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">Receiver</span> <span class="variable">receiver</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Receiver</span>();</span><br><span class="line">        <span class="type">Command</span> <span class="variable">cmd</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">MyCommand</span>(receiver);</span><br><span class="line">        <span class="type">Invoker</span> <span class="variable">invoker</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Invoker</span>(cmd);</span><br><span class="line">        invoker.action();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>输出：<code>command received!</code></p>
<p>这个很哈理解，命令模式的目的就是达到命令的发出者和执行者之间解耦，实现请求和执行分开，熟悉Struts的同学应该知道，Struts其实就是一种将请求和呈现分离的技术，其中必然涉及命令模式的思想！</p>
<p>其实每个设计模式都是很重要的一种思想，看上去很熟，其实是因为我们在学到的东西中都有涉及，尽管有时我们并不知道，其实在Java本身的设计之中处处都有体现，像AWT、JDBC、集合类、IO管道或者是Web框架，里面设计模式无处不在。因为我们篇幅有限，很难讲每一个设计模式都讲的很详细，不过我会尽我所能，尽量在有限的空间和篇幅内，把意思写清楚了，更好让大家明白。本章不出意外的话，应该是设计模式最后一讲了，首先还是上一下上篇开头的那个图：</p>
<p><img src="/assets/23-design-patterns-analysis/24.jpg" alt=""></p>
<p>本章讲讲第三类和第四类。</p>
<h4 id="类的状态"><a class="header-anchor" href="#类的状态"></a>类的状态</h4>
<h4 id="19、备忘录模式（Memento）"><a class="header-anchor" href="#19、备忘录模式（Memento）"></a>19、备忘录模式（Memento）</h4>
<p>主要目的是保存一个对象的某个状态，以便在适当的时候恢复对象，个人觉得叫备份模式更形象些，通俗的讲下：假设有原始类A，A中有各种属性，A可以决定需要备份的属性，备忘录类B是用来存储A的一些内部状态，类C呢，就是一个用来存储备忘录的，且只能存储，不能修改等操作。做个图来分析一下：</p>
<p><img src="/assets/23-design-patterns-analysis/25.jpg" alt=""></p>
<p>Original类是原始类，里面有需要保存的属性value及创建一个备忘录类，用来保存value值。Memento类是备忘录类，Storage类是存储备忘录的类，持有Memento类的实例，该模式很好理解。直接看源码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Original</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> String value;</span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getValue</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> value;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setValue</span><span class="params">(String value)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.value = value;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Original</span><span class="params">(String value)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.value = value;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> Memento <span class="title function_">createMemento</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Memento</span>(value);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">restoreMemento</span><span class="params">(Memento memento)</span>&#123;</span><br><span class="line">        <span class="built_in">this</span>.value = memento.getValue();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Memento</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> String value;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Memento</span><span class="params">(String value)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.value = value;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getValue</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> value;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setValue</span><span class="params">(String value)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.value = value;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Storage</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> Memento memento;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Storage</span><span class="params">(Memento memento)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.memento = memento;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> Memento <span class="title function_">getMemento</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> memento;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setMemento</span><span class="params">(Memento memento)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.memento = memento;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>测试类：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Test</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 创建原始类</span></span><br><span class="line">        <span class="type">Original</span> <span class="variable">origi</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Original</span>(“egg”);</span><br><span class="line">        <span class="comment">// 创建备忘录</span></span><br><span class="line">        <span class="type">Storage</span> <span class="variable">storage</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Storage</span>(origi.createMemento());</span><br><span class="line">        <span class="comment">// 修改原始类的状态</span></span><br><span class="line">        System.out.println(“初始化状态为：” + origi.getValue());</span><br><span class="line">        origi.setValue(“niu”);</span><br><span class="line">        System.out.println(“修改后的状态为：” + origi.getValue());</span><br><span class="line">        <span class="comment">// 回复原始类的状态</span></span><br><span class="line">        origi.restoreMemento(storage.getMemento());</span><br><span class="line">        System.out.println(“恢复后的状态为：” + origi.getValue());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">初始化状态为：egg</span><br><span class="line">修改后的状态为：niu</span><br><span class="line">恢复后的状态为：egg</span><br></pre></td></tr></table></figure>
<p>简单描述下：新建原始类时，value被初始化为egg，后经过修改，将value的值置为niu，最后倒数第二行进行恢复状态，结果成功恢复了。其实我觉得这个模式叫“备份-恢复”模式最形象。</p>
<h4 id="20、状态模式（State）"><a class="header-anchor" href="#20、状态模式（State）"></a>20、状态模式（State）</h4>
<p>核心思想就是：当对象的状态改变时，同时改变其行为，很好理解！就拿QQ来说，有几种状态，在线、隐身、忙碌等，每个状态对应不同的操作，而且你的好友也能看到你的状态，所以，状态模式就两点：1、可以通过改变状态来获得不同的行为。2、你的好友能同时看到你的变化。看图：</p>
<p><img src="/assets/23-design-patterns-analysis/26.jpg" alt=""></p>
<p>State类是个状态类，Context类可以实现切换，我们来看看代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.xtfggef.dp.state;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 状态类的核心类</span></span><br><span class="line"><span class="comment"> * 2012-12-1</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> erqing</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">State</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> String value;</span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getValue</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> value;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setValue</span><span class="params">(String value)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.value = value;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">method1</span><span class="params">()</span>&#123;</span><br><span class="line">        System.out.println(“execute the first opt!”);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">method2</span><span class="params">()</span>&#123;</span><br><span class="line">        System.out.println(“execute the second opt!”);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.xtfggef.dp.state;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 状态模式的切换类   2012-12-1</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> erqing</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Context</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> State state;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Context</span><span class="params">(State state)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.state = state;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> State <span class="title function_">getState</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> state;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setState</span><span class="params">(State state)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.state = state;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">method</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (state.getValue().equals(“state1”)) &#123;</span><br><span class="line">            state.method1();</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (state.getValue().equals(“state2”)) &#123;</span><br><span class="line">            state.method2();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>测试类：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Test</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">State</span> <span class="variable">state</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">State</span>();</span><br><span class="line">        <span class="type">Context</span> <span class="variable">context</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Context</span>(state);</span><br><span class="line">        <span class="comment">//设置第一种状态</span></span><br><span class="line">        state.setValue(“state1”);</span><br><span class="line">        context.method();</span><br><span class="line">        <span class="comment">//设置第二种状态</span></span><br><span class="line">        state.setValue(“state2”);</span><br><span class="line">        context.method();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">execute the first opt!</span><br><span class="line">execute the second opt!</span><br></pre></td></tr></table></figure>
<p>根据这个特性，状态模式在日常开发中用的挺多的，尤其是做网站的时候，我们有时希望根据对象的某一属性，区别开他们的一些功能，比如说简单的权限控制等。</p>
<h4 id="通过中间类"><a class="header-anchor" href="#通过中间类"></a>通过中间类</h4>
<h4 id="21、访问者模式（Visitor）"><a class="header-anchor" href="#21、访问者模式（Visitor）"></a>21、访问者模式（Visitor）</h4>
<p>访问者模式把数据结构和作用于结构上的操作解耦合，使得操作集合可相对自由地演化。访问者模式适用于数据结构相对稳定算法又易变化的系统。因为访问者模式使得算法操作增加变得容易。若系统数据结构对象易于变化，经常有新的数据对象增加进来，则不适合使用访问者模式。访问者模式的优点是增加操作很容易，因为增加操作意味着增加新的访问者。访问者模式将有关行为集中到一个访问者对象中，其改变不影响系统数据结构。其缺点就是增加新的数据结构很困难。—— From 百科</p>
<p>简单来说，访问者模式就是一种分离对象数据结构与行为的方法，通过这种分离，可达到为一个被访问者动态添加新的操作而无需做其它的修改的效果。简单关系图：</p>
<p><img src="/assets/23-design-patterns-analysis/27.jpg" alt=""></p>
<p>来看看原码：一个Visitor类，存放要访问的对象，</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">Visitor</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">visit</span><span class="params">(Subject sub)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyVisitor</span> <span class="keyword">implements</span> <span class="title class_">Visitor</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">visit</span><span class="params">(Subject sub)</span> &#123;</span><br><span class="line">        System.out.println(“visit the subject：”+sub.getSubject());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Subject类，accept方法，接受将要访问它的对象，getSubject()获取将要被访问的属性，</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">Subject</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">accept</span><span class="params">(Visitor visitor)</span>;</span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getSubject</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MySubject</span> <span class="keyword">implements</span> <span class="title class_">Subject</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">accept</span><span class="params">(Visitor visitor)</span> &#123;</span><br><span class="line">        visitor.visit(<span class="built_in">this</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getSubject</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> “love”;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>测试：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Test</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">Visitor</span> <span class="variable">visitor</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">MyVisitor</span>();</span><br><span class="line">        <span class="type">Subject</span> <span class="variable">sub</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">MySubject</span>();</span><br><span class="line">        sub.accept(visitor);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>输出：<code>visit the subject：love</code></p>
<p>该模式适用场景：如果我们想为一个现有的类增加新功能，不得不考虑几个事情：1、新功能会不会与现有功能出现兼容性问题？2、以后会不会再需要添加？3、如果类不允许修改代码怎么办？面对这些问题，最好的解决方法就是使用访问者模式，访问者模式适用于数据结构相对稳定的系统，把数据结构和算法解耦，</p>
<h4 id="22、中介者模式（Mediator）"><a class="header-anchor" href="#22、中介者模式（Mediator）"></a>22、中介者模式（Mediator）</h4>
<p>中介者模式也是用来降低类类之间的耦合的，因为如果类类之间有依赖关系的话，不利于功能的拓展和维护，因为只要修改一个对象，其它关联的对象都得进行修改。如果使用中介者模式，只需关心和Mediator类的关系，具体类类之间的关系及调度交给Mediator就行，这有点像spring容器的作用。先看看图：</p>
<p><img src="/assets/23-design-patterns-analysis/28.jpg" alt=""></p>
<p>User类统一接口，User1和User2分别是不同的对象，二者之间有关联，如果不采用中介者模式，则需要二者相互持有引用，这样二者的耦合度很高，为了解耦，引入了Mediator类，提供统一接口，MyMediator为其实现类，里面持有User1和User2的实例，用来实现对User1和User2的控制。这样User1和User2两个对象相互独立，他们只需要保持好和Mediator之间的关系就行，剩下的全由MyMediator类来维护！基本实现：<br>
···java<br>
public interface Mediator {<br>
public void createMediator();<br>
public void workAll();<br>
}</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">```java</span><br><span class="line">public class MyMediator implements Mediator &#123;</span><br><span class="line">    private User user1;</span><br><span class="line">    private User user2;</span><br><span class="line">    public User getUser1() &#123;</span><br><span class="line">        return user1;</span><br><span class="line">    &#125;</span><br><span class="line">    public User getUser2() &#123;</span><br><span class="line">        return user2;</span><br><span class="line">    &#125;</span><br><span class="line">    @Override</span><br><span class="line">    public void createMediator() &#123;</span><br><span class="line">        user1 = new User1(this);</span><br><span class="line">        user2 = new User2(this);</span><br><span class="line">    &#125;</span><br><span class="line">    @Override</span><br><span class="line">    public void workAll() &#123;</span><br><span class="line">        user1.work();</span><br><span class="line">        user2.work();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">class</span> <span class="title class_">User</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> Mediator mediator;</span><br><span class="line">    <span class="keyword">public</span> Mediator <span class="title function_">getMediator</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> mediator;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">User</span><span class="params">(Mediator mediator)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.mediator = mediator;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">work</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">User1</span> <span class="keyword">extends</span> <span class="title class_">User</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">User1</span><span class="params">(Mediator mediator)</span>&#123;</span><br><span class="line">        <span class="built_in">super</span>(mediator);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">work</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(“user1 exe!”);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">User2</span> <span class="keyword">extends</span> <span class="title class_">User</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">User2</span><span class="params">(Mediator mediator)</span>&#123;</span><br><span class="line">        <span class="built_in">super</span>(mediator);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">work</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(“user2 exe!”);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>测试类：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Test</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">Mediator</span> <span class="variable">mediator</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">MyMediator</span>();</span><br><span class="line">        mediator.createMediator();</span><br><span class="line">        mediator.workAll();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">user1 exe!</span><br><span class="line">user2 exe!</span><br></pre></td></tr></table></figure>
<h4 id="23、解释器模式（Interpreter）"><a class="header-anchor" href="#23、解释器模式（Interpreter）"></a>23、解释器模式（Interpreter）</h4>
<p>解释器模式是我们暂时的最后一讲，一般主要应用在OOP开发中的编译器的开发中，所以适用面比较窄。</p>
<p><img src="/assets/23-design-patterns-analysis/29.jpg" alt=""></p>
<p>Context类是一个上下文环境类，Plus和Minus分别是用来计算的实现，代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">Expression</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">interpret</span><span class="params">(Context context)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Plus</span> <span class="keyword">implements</span> <span class="title class_">Expression</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">interpret</span><span class="params">(Context context)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> context.getNum1()+context.getNum2();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Minus</span> <span class="keyword">implements</span> <span class="title class_">Expression</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">interpret</span><span class="params">(Context context)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> context.getNum1()-context.getNum2();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Context</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> num1;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> num2;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Context</span><span class="params">(<span class="type">int</span> num1, <span class="type">int</span> num2)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.num1 = num1;</span><br><span class="line">        <span class="built_in">this</span>.num2 = num2;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getNum1</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> num1;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setNum1</span><span class="params">(<span class="type">int</span> num1)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.num1 = num1;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getNum2</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> num2;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setNum2</span><span class="params">(<span class="type">int</span> num2)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.num2 = num2;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Test</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 计算9+2-8的值</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">result</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Minus</span>().interpret((<span class="keyword">new</span> <span class="title class_">Context</span>(<span class="keyword">new</span> <span class="title class_">Plus</span>()</span><br><span class="line">                .interpret(<span class="keyword">new</span> <span class="title class_">Context</span>(<span class="number">9</span>, <span class="number">2</span>)), <span class="number">8</span>)));</span><br><span class="line">        System.out.println(result);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最后输出正确的结果：<code>3</code>。基本就这样，解释器模式用来做各种各样的解释器，如正则表达式等的解释器等等！</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/23-design-patterns-analysis/">http://xnerv.wang/23-design-patterns-analysis/</a></strong><br>
转载自：<a href="http://blog.csdn.net/longyulu/article/details/9159589">23种设计模式全解析</a></p>
]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>设计模式</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Acquire and Release Semantics（转载）</title>
    <url>/acquire-and-release-semantics/</url>
    <content><![CDATA[<div class="entry-content">
<p>Generally speaking, in <a href="http://preshing.com/20120612/an-introduction-to-lock-free-programming">lock-free programming</a>, there are two ways in which threads can manipulate shared memory: They can compete with each other for a resource, or they can pass information co-operatively from one thread to another. Acquire and release semantics are crucial for the latter: reliable passing of information between threads. In fact, I would venture to guess that incorrect or missing acquire and release semantics is the <code>#1</code> type of lock-free programming error.</p>
<span id="more"></span>
<p>In this post, I’ll demonstrate various ways to achieve acquire and release semantics in C++. I’ll touch upon the C++11 atomic library standard in an introductory way, so you don’t already need to know it. And to be clear from the start, the information here pertains to lock-free programming <em>without</em> <a href="http://preshing.com/20120612/an-introduction-to-lock-free-programming#sequential-consistency">sequential consistency</a>. We’re dealing directly with memory ordering in a multicore or multiprocessor environment.</p>
<p>Unfortunately, the terms <em>acquire and release semantics</em> appear to be in even worse shape than the term <em>lock-free</em>, in that the more you scour the web, the more seemingly contradictory definitions you’ll find. Bruce Dawson offers a couple of good definitions (credited to Herb Sutter) about halfway through <a href="http://msdn.microsoft.com/en-us/library/windows/desktop/ee418650.aspx">this white paper</a>. I’d like to offer a couple of definitions of my own, staying close to the principles behind C++11 atomics:</p>
<blockquote>
<p><strong>Acquire semantics</strong> is a property that can only apply to operations that <strong>read</strong> from shared memory, whether they are <a href="http://preshing.com/20120612/an-introduction-to-lock-free-programming#atomic-rmw">read-modify-write</a> operations or plain loads. The operation is then considered a <strong>read-acquire</strong>. Acquire semantics prevent memory reordering of the read-acquire with any read or write operation that <strong>follows</strong> it in program order.<br>
<img src="/assets/acquire-and-release-semantics/read-acquire.png" alt="read acquire "><br>
<strong>Release semantics</strong> is a property that can only apply to operations that <strong>write</strong> to shared memory, whether they are read-modify-write operations or plain stores. The operation is then considered a <strong>write-release</strong>. Release semantics prevent memory reordering of the write-release with any read or write operation that <strong>precedes</strong> it in program order.<br>
<img src="/assets/acquire-and-release-semantics/write-release.png" alt="write release"></p>
</blockquote>
<p>Once you digest the above definitions, it’s not hard to see that acquire and release semantics can be achieved using simple combinations of the memory barrier types I <a href="http://preshing.com/20120710/memory-barriers-are-like-source-control-operations">described at length in my previous post</a>. The barriers must (somehow) be placed <em>after</em> the read-acquire operation, but <em>before</em> the write-release. <em>[Update: Please note that these barriers are technically more strict than what’s required for acquire and release semantics on a single memory operation, but they do achieve the desired effect.]</em></p>
<center>
<img src="/assets/acquire-and-release-semantics/acq-rel-barriers.png" alt="acq rel barriers"/>
</center>
<p>What’s cool is that neither acquire nor release semantics requires the use of a <code>#StoreLoad</code> barrier, which is often a more expensive memory barrier type. For example, on PowerPC, the <code>lwsync</code> (short for “lightweight sync”) instruction acts as all three <code>#LoadLoad</code>, <code>#LoadStore</code> and <code>#StoreStore</code> barriers at the same time, yet is less expensive than the <code>sync</code> instruction, which includes a <code>#StoreLoad</code> barrier.</p>
<h2 id="With-Explicit-Platform-Specific-Fence-Instructions"><a class="header-anchor" href="#With-Explicit-Platform-Specific-Fence-Instructions"></a>With Explicit Platform-Specific Fence Instructions</h2>
<p>One way to obtain the desired memory barriers is by issuing explicit fence instructions. Let’s start with a simple example. Suppose we’re coding for PowerPC, and <code>__lwsync()</code> is a compiler intrinsic function that emits the <code>lwsync</code> instruction. Since <code>lwsync</code> provides so many barrier types, we can use it in the following code to establish either acquire or release semantics as needed. In Thread 1, the store to <code>Ready</code> turns into a write-release, and in Thread 2, the load from <code>Ready</code> becomes a read-acquire.</p>
<center>
<img src="/assets/acquire-and-release-semantics/platform-fences.png" alt="platform fences"/>
</center>
<p>If we let both threads run and find that <code>r1 == 1</code>, that serves as confirmation that the value of <code>A</code> assigned in Thread 1 was passed successfully to Thread 2. As such, we are guaranteed that <code>r2 == 42</code>. In my previous post, I already <a href="http://preshing.com/20120710/memory-barriers-are-like-source-control-operations">gave a lengthy analogy</a> for <code>#LoadLoad</code> and <code>#StoreStore</code> to illustrate how this works, so I won’t rehash that explanation here.</p>
<center>
<a href="http://preshing.com/20120710/memory-barriers-are-like-source-control-operations"><img src="/assets/acquire-and-release-semantics/analogy-small.png" alt="analogy small"/></a>
</center>
<p>In formal terms, we say that the store to <code>Ready</code> <em>synchronized-with</em> the load. I’ve written a separate post about <em>synchronizes-with</em> <a href="http://preshing.com/20130823/the-synchronizes-with-relation">here</a>. For now, suffice to say that for this technique to work in general, the acquire and release semantics must apply to the same variable – in this case, <code>Ready</code> – and both the load and store must be atomic operations. Here, <code>Ready</code> is a simple aligned <code>int</code>, so the operations are already atomic on PowerPC.</p>
<h2 id="With-Fences-in-Portable-C-11"><a class="header-anchor" href="#With-Fences-in-Portable-C-11"></a>With Fences in Portable C++11</h2>
<p>The above example is compiler- and processor-specific. One approach for supporting multiple platforms is to convert the code to C++11. All C++11 identifiers exist in the <code>std</code> namespace, so to keep the following examples brief, let’s assume the statement <code>using namespace std;</code> was placed somewhere earlier in the code.</p>
<p>C++11’s atomic library standard defines a portable function <code>atomic_thread_fence()</code> that takes a single argument to specify the type of fence. There are several possible values for this argument, but the values we’re most interested in here are <code>memory_order_acquire</code> and <code>memory_order_release</code>. We’ll use this function in place of <code>__lwsync()</code>.</p>
<p>There’s one more change to make before this example is complete. On PowerPC, we knew that both operations on <code>Ready</code> were atomic, but we can’t make that assumption about every platform. To ensure atomicity on all platforms, we’ll change the type of <code>Ready</code> from <code>int</code> to <code>atomic&lt;int&gt;</code>. I know, it’s kind of a silly change, considering that aligned loads and stores of <code>int</code> are already atomic on every modern CPU that exists today. I’ll write more about this in the post on <a href="http://preshing.com/20130823/the-synchronizes-with-relation"><em>synchronizes-with</em></a>, but for now, let’s do it for the warm fuzzy feeling of 100% correctness in theory. No changes to <code>A</code> are necessary.</p>
<center>
<img src="/assets/acquire-and-release-semantics/cpp11-fences.png" alt="cpp11 fences"/>
</center>
<p>The <code>memory_order_relaxed</code> arguments above mean “ensure these operations are atomic, but don’t impose any ordering constraints/memory barriers that aren’t already there.”</p>
<p>Once again, both of the above <code>atomic_thread_fence()</code> calls can be (and hopefully are) implemented as <code>lwsync</code> on PowerPC. Similarly, they could both emit a <code>dmb</code> instruction on ARM, which I believe is at least as effective as PowerPC’s <code>lwsync</code>. On x86/64, both <code>atomic_thread_fence()</code> calls can simply be implemented as <a href="http://preshing.com/20120625/memory-ordering-at-compile-time">compiler barriers</a>, since <em>usually</em>, every load on x86/64 already implies acquire semantics and every store implies release semantics. This is why x86/64 is often said to be <a href="http://preshing.com/20120930/weak-vs-strong-memory-models">strongly ordered</a>.</p>
<h2 id="Without-Fences-in-Portable-C-11"><a class="header-anchor" href="#Without-Fences-in-Portable-C-11"></a>Without Fences in Portable C++11</h2>
<p>In C++11, it’s possible to achieve acquire and release semantics on <code>Ready</code> without issuing explicit fence instructions. You just need to specify memory ordering constraints directly on the operations on <code>Ready</code>:</p>
<center>
<img src="/assets/acquire-and-release-semantics/cpp11-no-fences.png" alt="cpp11 no fences"/>
</center>
<p>Think of it as rolling each fence instruction into the operations on <code>Ready</code> themselves. <em>[Update: Please note that this form is <a href="http://preshing.com/20131125/acquire-and-release-fences-dont-work-the-way-youd-expect">not exactly the same</a> as the version using standalone fences; technically, it’s less strict.]</em> The compiler will emit any instructions necessary to obtain the required barrier effects. In particular, on Itanium, each operation can be easily implemented as a single instruction: <code>ld.acq</code> and <code>st.rel</code>. Just as before, <code>r1 == 1</code> indicates a <em>synchronizes-with</em> relationship, serving as confirmation that <code>r2 == 42</code>.</p>
<p>This is actually the preferred way to express acquire and release semantics in C++11. In fact, the <code>atomic_thread_fence()</code> function used in the previous example was <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2008/n2633.html">added relatively late</a> in the creation of the standard.</p>
<h2 id="Acquire-and-Release-While-Locking"><a class="header-anchor" href="#Acquire-and-Release-While-Locking"></a>Acquire and Release While Locking</h2>
<p>As you can see, none of the examples in this post took advantage of the <code>#LoadStore</code> barriers provided by acquire and release semantics. Really, only the <code>#LoadLoad</code> and <code>#StoreStore</code> parts were necessary. That’s just because in this post, I chose a simple example to let us focus on API and syntax.</p>
<p>One case in which the <code>#LoadStore</code> part becomes essential is when using acquire and release semantics to implement a (mutex) lock. In fact, this is where the names come from: acquiring a lock implies acquire semantics, while releasing a lock implies release semantics! All the memory operations in between are contained inside a nice little barrier sandwich, preventing any undesireable memory reordering across the boundaries.</p>
<center>
<img src="/assets/acquire-and-release-semantics/acq-rel-lock.png" alt="acq rel lock"/>
</center>
<p>Here, acquire and release semantics ensure that all modifications made while holding the lock will propagate fully to the next thread that obtains the lock. Every implementation of a lock, even one you <a href="http://preshing.com/20120226/roll-your-own-lightweight-mutex">roll on your own</a>, should provide these guarantees. Again, it’s all about passing information reliably between threads, especially in a multicore or multiprocessor environment.</p>
<p>In a followup post, I’ll show a <a href="http://preshing.com/20121019/this-is-why-they-call-it-a-weakly-ordered-cpu">working demonstration</a> of C++11 code, running on real hardware, which can be plainly observed to break if acquire and release semantics are not used.</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/acquire-and-release-semantics/">http://xnerv.wang/acquire-and-release-semantics/</a></strong><br>
转载自：<a href="http://preshing.com/20120913/acquire-and-release-semantics/">Acquire and Release Semantics</a></p>
]]></content>
      <categories>
        <category>OS</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>OS</tag>
        <tag>Memory Barrier</tag>
      </tags>
  </entry>
  <entry>
    <title>Active FTP vs. Passive FTP, a Definitive Explanation（转载）</title>
    <url>/active-ftp-vs-passive-ftp-a-definitive-explanation/</url>
    <content><![CDATA[<h2 id="Introduction"><a class="header-anchor" href="#Introduction"></a>Introduction</h2>
<p>One of the most commonly seen questions when dealing with firewalls and other Internet connectivity issues is the difference between active and passive FTP and how best to support either or both of them. Hopefully the following text will help to clear up some of the confusion over how to support FTP in a firewalled environment.</p>
<p>This may not be <em>the</em> definitive explanation, as the title claims, however, I’ve heard enough good feedback and seen this document linked in enough places to know that quite a few people have found it to be useful. I am always looking for ways to improve things though, and if you find something that is not quite clear or needs more explanation, please let me know! Recent additions to this document include the examples of both active and passive command line FTP sessions. These session examples should help make things a bit clearer. They also provide a nice picture into what goes on behind the scenes during an FTP session. Now, on to the information…</p>
<span id="more"></span>
<h2 id="The-Basics"><a class="header-anchor" href="#The-Basics"></a>The Basics</h2>
<p>FTP is a TCP based service exclusively. There is no UDP component to FTP. FTP is an unusual service in that it utilizes two ports, a ‘data’ port and a ‘command’ port (also known as the control port). Traditionally these are port 21 for the command port and port 20 for the data port. The confusion begins however, when we find that depending on the mode, the data port is not always on port 20.</p>
<h2 id="Active-FTP"><a class="header-anchor" href="#Active-FTP"></a>Active FTP</h2>
<p>In active mode FTP the client connects from a random unprivileged port (N &gt; 1023) to the FTP server’s command port, port 21. Then, the client starts listening to port N+1 and sends the FTP command <code>PORT N+1</code> to the FTP server. The server will then connect back to the client’s specified data port from its local data port, which is port 20.</p>
<p>From the server-side firewall’s standpoint, to support active mode FTP the following communication channels need to be opened:</p>
<ul>
<li>FTP server’s port 21 from anywhere (Client initiates connection)</li>
<li>FTP server’s port 21 to ports &gt; 1023 (Server responds to client’s control port)</li>
<li>FTP server’s port 20 to ports &gt; 1023 (Server initiates data connection to client’s data port)</li>
<li>FTP server’s port 20 from ports &gt; 1023 (Client sends ACKs to server’s data port)</li>
</ul>
<p>When drawn out, the connection appears as follows:</p>
<center>
<img src="http://slacksite.com/images/ftp/activeftp.gif" alt="Active FTP"/>
</center>
<p>In step 1, the client’s command port contacts the server’s command port and sends the command <code>PORT 1027</code>. The server then sends an ACK back to the client’s command port in step 2. In step 3 the server initiates a connection on its local data port to the data port the client specified earlier. Finally, the client sends an ACK back as shown in step 4.</p>
<p>The main problem with active mode FTP actually falls on the client side. The FTP client doesn’t make the actual connection to the data port of the server–it simply tells the server what port it is listening on and the server connects back to the specified port on the client. From the client side firewall this appears to be an outside system initiating a connection to an internal client–something that is usually blocked.</p>
<h2 id="Active-FTP-Example"><a class="header-anchor" href="#Active-FTP-Example"></a>Active FTP Example</h2>
<p>Below is an actual example of an active FTP session. The only things that have been changed are the server names, IP addresses, and user names. In this example an FTP session is initiated from <a href="http://testbox1.slacksite.com">testbox1.slacksite.com</a> (192.168.150.80), a linux box running the standard FTP command line client, to <a href="http://testbox2.slacksite.com">testbox2.slacksite.com</a> (192.168.150.90), a linux box running ProFTPd 1.2.2RC2. The debugging (<code>-d</code>) flag is used with the FTP client to show what is going on behind the scenes. Everything in <font color="red">red</font> is the debugging output which shows the actual FTP commands being sent to the server and the responses generated from those commands. Normal server output is shown in black, and user input is in <strong>bold</strong>.</p>
<p>There are a few interesting things to consider about this dialog. Notice that when the <code>PORT</code> command is issued, it specifies a port on the <em>client</em> (192.168.150.80) system, rather than the server. We will see the opposite behavior when we use passive FTP. While we are on the subject, a quick note about the format of the <code>PORT</code> command. As you can see in the example below it is formatted as a series of six numbers separated by commas. The first four octets are the IP address while the last two octets comprise the port that will be used for the data connection. To find the actual port multiply the fifth octet by 256 and then add the sixth octet to the total. Thus in the example below the port number is ( (14*256) + 178), or 3762. A quick check with <code>netstat</code> should confirm this information.</p>
<blockquote>
<p><samp>testbox1: {/home/p-t/slacker/public_html} % <strong>ftp -d testbox2</strong><br>
Connected to <a href="http://testbox2.slacksite.com">testbox2.slacksite.com</a>.<br>
220 <a href="http://testbox2.slacksite.com">testbox2.slacksite.com</a> FTP server ready.<br>
Name (testbox2:slacker): <strong>slacker</strong><br>
<font color="red">—&gt; USER slacker</font><br>
331 Password required for slacker.<br>
Password: <strong>TmpPass</strong><br>
<font color="red">—&gt; PASS XXXX</font><br>
230 User slacker logged in.<br>
<font color="red">—&gt; SYST<br>
215 UNIX Type: L8</font><br>
Remote system type is UNIX.<br>
Using binary mode to transfer files.<br>
ftp&gt; <strong>ls</strong><br>
<font color="red">ftp: setsockopt (ignored): Permission denied<br>
—&gt; PORT 192,168,150,80,14,178</font><br>
200 PORT command successful.<br>
<font color="red">—&gt; LIST</font><br>
150 Opening ASCII mode data connection for file list.<br>
drwx------   3 slacker    users         104 Jul 27 01:45 public_html<br>
226 Transfer complete.<br>
ftp&gt; <strong>quit</strong><br>
<font color="red">—&gt; QUIT</font><br>
221 Goodbye.<br>
</samp></p>
</blockquote>
<h2 id="Passive-FTP"><a class="header-anchor" href="#Passive-FTP"></a>Passive FTP</h2>
<p>In order to resolve the issue of the server initiating the connection to the client a different method for FTP connections was developed. This was known as passive mode, or <code>PASV</code>, after the command used by the client to tell the server it is in passive mode.</p>
<p>In passive mode FTP the client initiates both connections to the server, solving the problem of firewalls filtering the incoming data port connection to the client from the server. When opening an FTP connection, the client opens two random unprivileged ports locally (N &gt; 1023 and N+1). The first port contacts the server on port 21, but instead of then issuing a <code>PORT</code> command and allowing the server to connect back to its data port, the client will issue the <code>PASV</code> command. The result of this is that the server then opens a random unprivileged port (P &gt; 1023) and sends <code>P</code> back to the client in response to the <code>PASV</code> command. The client then initiates the connection from port N+1 to port P on the server to transfer data.</p>
<p>From the server-side firewall’s standpoint, to support passive mode FTP the following communication channels need to be opened:</p>
<ul>
<li>FTP server’s port 21 from anywhere (Client initiates connection)</li>
<li>FTP server’s port 21 to ports &gt; 1023 (Server responds to client’s control port)</li>
<li>FTP server’s ports &gt; 1023 from anywhere (Client initiates data connection to random port specified by server)</li>
<li>FTP server’s ports &gt; 1023 to remote ports &gt; 1023 (Server sends ACKs (and data) to client’s data port)</li>
</ul>
<p>When drawn, a passive mode FTP connection looks like this:</p>
<center>
<img src="http://slacksite.com/images/ftp/passiveftp.gif" alt="Passive FTP"/>
</center>
<p>In step 1, the client contacts the server on the command port and issues the <code>PASV</code> command. The server then replies in step 2 with <code>PORT 2024</code>, telling the client which port it is listening to for the data connection. In step 3 the client then initiates the data connection from its data port to the specified server data port. Finally, the server sends back an ACK in step 4 to the client’s data port.</p>
<p>While passive mode FTP solves many of the problems from the client side, it opens up a whole range of problems on the server side. The biggest issue is the need to allow any remote connection to high numbered ports on the server. Fortunately, many FTP daemons, including the popular WU-FTPD allow the administrator to specify a range of ports which the FTP server will use. See <a href="#appendix-1">Appendix 1</a> for more information.</p>
<p>The second issue involves supporting and troubleshooting clients which do (or do not) support passive mode. As an example, the command line FTP utility provided with Solaris does not support passive mode, necessitating a third-party FTP client, such as ncftp.<br>
NOTE: This is no longer the case–use the <code>-p</code> option with the Solaris FTP client to enable passive mode!</p>
<p>With the massive popularity of the World Wide Web, many people prefer to use their web browser as an FTP client. Most browsers only support passive mode when accessing ftp:// URLs. This can either be good or bad depending on what the servers and firewalls are configured to support.</p>
<h2 id="Passive-FTP-Example"><a class="header-anchor" href="#Passive-FTP-Example"></a>Passive FTP Example</h2>
<p>Below is an actual example of a passive FTP session. The only things that have been changed are the server names, IP addresses, and user names. In this example an FTP session is initiated from <a href="http://testbox1.slacksite.com">testbox1.slacksite.com</a> (192.168.150.80), a linux box running the standard FTP command line client, to <a href="http://testbox2.slacksite.com">testbox2.slacksite.com</a> (192.168.150.90), a linux box running ProFTPd 1.2.2RC2. The debugging (<code>-d</code>) flag is used with the FTP client to show what is going on behind the scenes. Everything in <font color="red">red</font> is the debugging output which shows the actual FTP commands being sent to the server and the responses generated from those commands. Normal server output is shown in black, and user input is in <strong>bold</strong>.</p>
<p>Notice the difference in the <code>PORT</code> command in this example as opposed to the active FTP example. Here, we see a port being opened on the <em>server</em> (192.168.150.90) system, rather than the client. See the discussion about the format of the <code>PORT</code> command above, in the <a href="#active-ftp-example-section">Active FTP Example section</a>.</p>
<blockquote>
<p><samp>testbox1: {/home/p-t/slacker/public_html} % <strong>ftp -d testbox2</strong><br>
Connected to <a href="http://testbox2.slacksite.com">testbox2.slacksite.com</a>.<br>
220 <a href="http://testbox2.slacksite.com">testbox2.slacksite.com</a> FTP server ready.<br>
Name (testbox2:slacker): <strong>slacker</strong><br>
<font color="red">—&gt; USER slacker</font><br>
331 Password required for slacker.<br>
Password: <strong>TmpPass</strong><br>
<font color="red">—&gt; PASS XXXX</font><br>
230 User slacker logged in.<br>
<font color="red">—&gt; SYST<br>
215 UNIX Type: L8</font><br>
Remote system type is UNIX.<br>
Using binary mode to transfer files.<br>
ftp&gt; <strong>passive</strong><br>
Passive mode on.<br>
ftp&gt; <strong>ls</strong><br>
<font color="red">ftp: setsockopt (ignored): Permission denied<br>
—&gt; PASV</font><br>
227 Entering Passive Mode (192,168,150,90,195,149).<br>
<font color="red">—&gt; LIST</font><br>
150 Opening ASCII mode data connection for file list<br>
drwx------   3 slacker    users         104 Jul 27 01:45 public_html<br>
226 Transfer complete.<br>
ftp&gt; <strong>quit</strong><br>
<font color="red">—&gt; QUIT</font><br>
221 Goodbye.<br>
</samp></p>
</blockquote>
<h2 id="Other-Notes"><a class="header-anchor" href="#Other-Notes"></a>Other Notes</h2>
<p>A reader, Maarten Sjouw, pointed out that active FTP will not function when used in conjunction with a client-side NAT (Network Address Translation) device which is not smart enough to alter the IP address info in FTP packets.</p>
<h2 id="Summary"><a class="header-anchor" href="#Summary"></a>Summary</h2>
<p>The following chart should help admins remember how each FTP mode works:</p>
<blockquote>
<p><samp>Active FTP :<br>
command : client &gt;1023 -&gt; server 21<br>
data    : client &gt;1023 &lt;- server 20</p>
<p>Passive FTP :<br>
command : client &gt;1023 -&gt; server 21<br>
data    : client &gt;1024 -&gt; server &gt;1023<br>
</samp></p>
</blockquote>
<p>A quick summary of the pros and cons of active vs. passive FTP is also in order:</p>
<p>Active FTP is beneficial to the FTP server admin, but detrimental to the client side admin. The FTP server attempts to make connections to random high ports on the client, which would almost certainly be blocked by a firewall on the client side. Passive FTP is beneficial to the client, but detrimental to the FTP server admin. The client will make both connections to the server, but one of them will be to a random high port, which would almost certainly be blocked by a firewall on the server side.</p>
<p>Luckily, there is somewhat of a compromise. Since admins running FTP servers will need to make their servers accessible to the greatest number of clients, they will almost certainly need to support passive FTP. The exposure of high level ports on the server can be minimized by specifying a limited port range for the FTP server to use. Thus, everything except for this range of ports can be firewalled on the server side. While this doesn’t eliminate all risk to the server, it decreases it tremendously. See <a href="#appendix-1">Appendix 1</a> for more information.</p>
<h2 id="References"><a class="header-anchor" href="#References"></a>References</h2>
<p>An excellent reference on how various internet protocols work and the issues involved in firewalling them can be found in the O’Reilly and Associates book, <em>Building Internet Firewalls, 2nd Ed</em>, by Brent Chapman and Elizabeth Zwicky.<br>
**Note 2012:**This book is VERY old and the information contained therein may be outdated!</p>
<p>Finally, the definitive reference on FTP would be RFC 959, which sets forth the official specifications of the FTP protocol. RFCs can be downloaded from numerous locations, including <a href="http://www.faqs.org/rfcs/rfc959.html">http://www.faqs.org/rfcs/rfc959.html</a>.</p>
<h2 id="Appendix-1"><a class="header-anchor" href="#Appendix-1"></a>Appendix 1</h2>
<h3 id="Introduction-v2"><a class="header-anchor" href="#Introduction-v2"></a>Introduction</h3>
<p>This appendix will describe methods used to configure various popular FTP servers to limit the number of passive ports they will listen on. As mentioned in the main text, FTP server admins will almost definitely need to support passive FTP in order to allow the greatest number of clients to access their FTP resources. In order to support passive FTP, however, a large number of high-numbered ports on the server must be opened through a firewall. Luckily, most FTP servers allow this port range to be specified so as to limit exposure to attacks.</p>
<h3 id="ProFTPd"><a class="header-anchor" href="#ProFTPd"></a>ProFTPd</h3>
<p>ProFTPd, <a href="http://www.proftpd.net">http://www.proftpd.net</a>, is an increasingly popular FTP server due to its modularity and Apache-style configuration directives. ProFTPd also supports virtual hosts “out of the box”, causing it to become one of the most common FTP servers used by web hosting companies.</p>
<p>As of version 1.20RC3 and later (current version as of this writing is 1.2.4), ProFTPd supports a directive called <code>PassivePorts</code>. The <code>PassivePorts</code> directive is usually used in a global context in the <code>proftpd.conf</code> file (the location of which varies depending on how ProFTPd was configured and installed). <code>PassivePorts</code> takes two arguments, the minimum port number and the maximum port number, as in the below example:</p>
<p><samp>PassivePorts 51000 51999<br>
</samp></p>
<p>The ProFTPd documentation has the following to say about the <code>PassivePorts</code> directive:</p>
<blockquote>
<p>PassivePorts restricts the range of ports from which the server will select when sent the PASV command from a client. The server will randomly choose a number from within the specified range until an open port is found. Should no open ports be found within the given range, the server will default to a normal kernel-assigned port, and a message logged.</p>
<p>The port range selected must be in the non-privileged range (eg. greater than or equal to 1024); it is STRONGLY RECOMMENDED that the choosen range be large enough to handle many simultaneous passive connections (for example, 49152-65534, the IANA-registered ephemeral port range).</p>
</blockquote>
<p>If you are attempting to use SSH port forwarding to securely tunnel the FTP command channel over an SSH connection (so that passwords are not sent in clear text), be aware that you must set the <code>AllowForeignAddress</code> directive to “on” in the <code>proftpd.conf</code> file. If this is not set and a tunnelled connection is attempted, ProFTPd will log a message similar to the following:</p>
<p><samp>SECURITY VIOLATION: Passive connection from a.b.c.d rejected<br>
</samp></p>
<p><font color="RED">Important Note: Please read and understand the documentation about the <code>AllowForeignAddress</code> directive before implementing it. This can open your FTP server up to bounce attacks. It is strongly recommended that this option not be set on systems being used as anonymous FTP servers.</font></p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/active-ftp-vs-passive-ftp-a-definitive-explanation/">http://xnerv.wang/active-ftp-vs-passive-ftp-a-definitive-explanation/</a></strong><br>
转载自：<a href="http://slacksite.com/other/ftp.html">Active FTP vs. Passive FTP, a Definitive Explanation</a></p>
]]></content>
      <categories>
        <category>网络协议</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>网络协议</tag>
        <tag>FTP</tag>
        <tag>Active FTP</tag>
        <tag>Passive FTP</tag>
      </tags>
  </entry>
  <entry>
    <title>彻底研究Python的编码问题</title>
    <url>/all-truths-about-python-encoding-problem/</url>
    <content><![CDATA[<p>Python的初学者（以及很多熟练工）相信都遇到过下面的运行时错误信息：</p>
<blockquote>
<p>UnicodeDecodeError: ‘ASCII’ codec can’t decode byte 0xe4 in position 0: ordinal not in range(128)</p>
</blockquote>
<p>然后百度一下发现说明这个问题的网页有一大把，基本无非是下面两种解决方案：</p>
<ol>
<li>在Python文件的开头加一句<code>#coding=utf-8</code>。</li>
<li>在代码中加入：</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(<span class="string">&#x27;utf8&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>一般大家的做法是把两者都加上，然后问题一般也会得到解决。但很少有人会去深究过Python会什么会产生这样的编码问题，以及为什么通过加上面的代码可以解决这个问题。作为一个合格的程序员，遇到这种问题就应该追根究底，否则就只是以码谋生的码畜了 :)</p>
<span id="more"></span>
<h2 id="string与Unicode-string"><a class="header-anchor" href="#string与Unicode-string"></a>string与Unicode string</h2>
<p>Python的编码问题一般只在Python2.x中存在，在Python3.x中则基本不会遇到这样的问题。根本原因在于Python2.x中存在两种字符串：string和Unicode string，两者都继承自basic string。</p>
<p>string类似于C语言中的char*，或者C++中的std::string，本质上都是byte数组，本身不具备特定的encoding类型，而是由string的使用者决定的。例如向string中写入一个汉字，如果是UTF-8编码，则可能是三个char（或者更多），如果是GBK编码，则可能是两个char，但对于Python解释器，它并不清楚string用的是encoding，一切都是bytes。。。</p>
<p>而Unicode string则明确地存储了Unicode编码的字符串。在Python2.x中，<code>a1=&quot;abc&quot;;</code>，a1就是一个string（是什么编码还不确定，等下再谈）。而<code>a2=u&quot;abc&quot;;</code>，a2就是一个Unicode string。</p>
<h2 id="C-C-中的文件编码和字符串编码"><a class="header-anchor" href="#C-C-中的文件编码和字符串编码"></a>C/C++中的文件编码和字符串编码</h2>
<p>C/C++不仅仅是一种编程语言，更是一个深入了解计算机底层原理的窗口和机会，一个只会堆砌代码而浮于表面的程序员，是不能称之为一个真正意义上的程序员的（这跟月薪有没有上3w没有关系）。</p>
<p>我们先回过头来看看C/C++中是如何处理文件编码和字符串编码的问题的。以VC为例，VC下有两个编码的选项，分为Source encoding和Execution encoding。前者指定了源文件的编码（这比<a href="https://en.wikipedia.org/wiki/Byte_order_mark">BOM</a>更准确），后者是字符串常量等的编码。简单说，如果指定Source encoding为GBK，同时指定Execution encoding为UTF-8，则首先所有的源文件必须用GBK编码保存，否则VC在读入源文件时可能会无法解码其中的一些字符。同时，像<code>const char* a3=&quot;中文&quot;;</code>这样的常量字符串赋值语句，a3就是使用了UTF-8编码保存的字符串。在中文Windows系统下，如果不特意设置这两种编码，VC则一般使用的是system default encoding。</p>
<p>（参考 <a href="https://stackoverflow.com/questions/9739070/char-encoding">Char * encoding</a>, <a href="https://msdn.microsoft.com/en-us/library/mt708818.aspx">/execution-charset (Set Execution Character Set)</a>, <a href="https://msdn.microsoft.com/en-us/library/mt708819.aspx">/source-charset (Set Source Character Set)</a>。）</p>
<h2 id="Python中的文件编码和字符串编码"><a class="header-anchor" href="#Python中的文件编码和字符串编码"></a>Python中的文件编码和字符串编码</h2>
<p>对比C/C++处理编码的方法，我们再看看Python是怎么做的。</p>
<p>首先，类似于Source encoding，Python可以通过在文件开头加上<code>#coding=utf-8</code>这句来向Python解析器指明本py源文件的编码。然后，麻烦事情来了，与C/C++中的Execution encoding有很大的不同，对于Python2.x的string而言，对其用字符串常量赋值时，string中存储的encoding，是跟<code>#coding=utf-8</code>挂钩的，而不是像C++中的Execution encoding一样有一个单独的选项来指定。也就是说，如果指定了<code>#coding=utf-8</code>，那么在运行时，<code>a1=&quot;中文&quot;</code>就会用UTF-8编码来存储和读取变量a1，如果没有设置<code>#coding=utf-8</code>及其它任何<code>#coding=xxx</code>，那么就是用默认的ASCII编码，但显然ASCII是无法编码<code>&quot;中文&quot;</code>的，于是在运行时你就会看到类似下面的报错：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">SyntaxError: Non-ASCII character <span class="string">&#x27;\xe4&#x27;</span> <span class="keyword">in</span> file D:\test.py on line <span class="number">1</span>, but no encoding declared; see http://python.org/dev/peps/pep-0263/ <span class="keyword">for</span> details</span><br></pre></td></tr></table></figure>
<p>而关于<code>sys.defaultencoding</code>，这个在没有明确指明解码方式的时候使用。比如有如下代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#! /usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line">s = <span class="string">&#x27;中文&#x27;</span></span><br><span class="line">s.encode(<span class="string">&#x27;gb18030&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>这句代码将<code>s</code>（string类型）重新编码为<code>gb18030</code>的格式（仍然是string类型）， Python会自动的先将<code>s</code>解码为<code>Unicode string类型</code>，然后再编码成<code>gb18030</code>。因为解码是Python自动进行的，我们没有指明解码方式，Python就会使用<code>sys.defaultencoding</code>指明的方式来解码。很多情况下<code>sys.defaultencoding</code>是ASCII，如果<code>s</code>不是这个类型就会出错。</p>
<p>拿上面的情况来说，我的<code>sys.defaultencoding</code>是ASCII，而<code>s</code>的编码方式和文件的编码方式一致，是UTF-8的，所以出错了:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">UnicodeDecodeError: <span class="string">&#x27;ascii&#x27;</span> codec can<span class="string">&#x27;t decode byte 0xe4 in position 0: ordinal not in range(128)</span></span><br></pre></td></tr></table></figure>
<p>但是<code>sys.setdefaultencoding('utf8')</code>有的时候也会导致一些意想不到的问题，所以目前网上主流意见是不推荐使用 。例如这篇文章中提到使用<code>sys.setdefaultencoding</code>可能会遇到的一些问题：<a href="https://anonbadger.wordpress.com/2015/06/16/why-sys-setdefaultencoding-will-break-code/">Why sys.setdefaultencoding() will break code</a></p>
<p>在Python3.x中，编码的问题基本不存在了，也没有了sys.setsystemencoding。因为Python3.x取消了string，只有Unicode string，也避免了很多编码转换的问题。</p>
<h2 id="关于-coding-utf-8"><a class="header-anchor" href="#关于-coding-utf-8"></a>关于<code>#coding:utf-8</code></h2>
<p><code>#coding:utf-8</code>指引Python解释器如何读取整个py文件，有些IDE也会根据这个comment来自动决定保存格式及显示格式，应该与py文件的保存格式一致。</p>
<p>根据<a href="http://www.python.org/dev/peps/pep-0263/">PEP 263 – Defining Python Source Code Encodings</a>中的说明，其实写成<code>#coding=utf-8</code>，<code>#coding:utf-8</code>或者<code>#-*- coding:utf-8 -*-</code>都是可以的，正则定义为<code>coding[:=]\s*([-\w.]+)</code>。</p>
<h2 id="encode-decode"><a class="header-anchor" href="#encode-decode"></a>encode/decode</h2>
<p>encode是将Unicode string转化为指定encoding编码的string，而decode是将某种encoding编码的string转化为Unicode string。</p>
<p>如果decode指定错了encoding，例如，假设<code>a1</code>已经是Unicode编码的字符串变量，执行：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span> a1.decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>则可能报错：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Traceback (most recent call last):</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">  File <span class="string">&quot;C:\Python27\lib\encodings\utf_8.py&quot;</span>, line <span class="number">16</span>, <span class="keyword">in</span> decode</span><br><span class="line">    <span class="keyword">return</span> codecs.utf_8_decode(<span class="built_in">input</span>, errors, <span class="literal">True</span>)</span><br><span class="line">UnicodeEncodeError: <span class="string">&#x27;ascii&#x27;</span> codec can<span class="string">&#x27;t encode character u&#x27;</span>\u3010<span class="string">&#x27; in position 0: ordinal not in range(128)</span></span><br></pre></td></tr></table></figure>
<h3 id="print-sys-xxx-write"><a class="header-anchor" href="#print-sys-xxx-write"></a>print/sys.xxx.write</h3>
<p>print和sys.xxx.write在输出unicode-object string时会自动转换编码为sys.xxx.encoding，无需自己来转。<br>
但是，如果是utf8 string，而当前环境是Windows，则输出显然会乱码。如果是中文版Windows，用的是GB编码（code page 936）。如果是英文版Windows，用的可能是ANSI编码（code page 1252）。</p>
<h2 id="最佳实践"><a class="header-anchor" href="#最佳实践"></a>最佳实践</h2>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/all-truths-about-python-encoding-problem/">http://xnerv.wang/all-truths-about-python-encoding-problem/</a></strong></p>
]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>编程语言</tag>
        <tag>Python</tag>
        <tag>原创</tag>
        <tag>未完成</tag>
      </tags>
  </entry>
  <entry>
    <title>Allocating and freeing memory across module boundaries（转载）</title>
    <url>/allocating-and-freeing-memory-across-module-boundaries/</url>
    <content><![CDATA[<p>I’m sure it’s been drilled into your head by now that you have to free memory with the same allocator that allocated it. LocalAlloc matches LocalFree, GlobalAlloc matches GlobalFree, new[] matches delete[]. But this rule goes deeper.</p>
<span id="more"></span>
<p>If you have a function that allocates and returns some data, the caller must know how to free that memory. You have a variety of ways of accomplishing this. One is to state explicitly how the memory should be freed. For example, the FormatMessage documentation explicitly states that you should use the LocalFree function to free the buffer that is allocated if you pass the FORMAT_MESSAGE_ALLOCATE_BUFFER flag. All BSTRs must be freed with SysFreeString. And all memory returned across COM interface boundaries must be allocated and freed with the COM task allocator.</p>
<p>Note, however, that if you decide that a block of memory should be freed with the C runtime, such as with free, or with the C++ runtime via delete or delete[], you have a new problem: Which runtime?</p>
<p>If you choose to link with the static runtime library, then your module has its own private copy of the C/C++ runtime. When your module calls new or malloc, the memory can only be freed by your module calling delete or free. If another module calls delete or free, that will use the C/C++ runtime of <strong>that other module</strong> which is not the same as yours. Indeed, even if you choose to link with the DLL version of the C/C++ runtime library, you still have to agree which version of the C/C++ runtime to use. If your DLL uses MSVCRT20.DLL to allocate memory, then anybody who wants to free that memory must also use MSVCRT20.DLL.</p>
<p>If you’re paying close attention, you might spot a looming problem. Requiring all your clients to use a particular version of the C/C++ runtime might seem reasonable if you control all of the clients and are willing to recompile all of them each time the compiler changes. But in real life, people often don’t want to take that risk. “If it ain’t broke, don’t fix it.” Switching to a new compiler risks exposing a subtle bug, say, forgetting to declare a variable as volatile or inadvertently relying on temporaries having a particular lifetime.</p>
<p>In practice, you may wish to convert only part of your program to a new compiler while leaving old modules alone. (For example, you may want to take advantage of new language features such as templates, which are available only in the new compiler.) But if you do that, then you lose the ability to free memory that was allocated by the old DLL, since that DLL expects you to use MSVCRT20.DLL, whereas the new compiler uses MSVCR71.DLL.</p>
<p>The solution to this requires planning ahead. One option is to use a fixed <strong>external allocator</strong> such as <strong>LocalAlloc or CoTaskMemAlloc</strong>. These are allocators that are universally available and don’t depend on which version of the compiler you’re using.</p>
<p>Another option is to wrap your preferred allocator inside exported functions that manage the allocation. This is the mechanism used by the NetApi family of functions. For example, the NetGroupEnum function allocates memory and returns it through the bufptr parameter. When the caller is finished with the memory, it frees it with the NetApiBufferFree function. In this manner, the memory allocation method is isolated from the caller. Internally, the NetApi functions might be using LocalAlloc or HeapAllocate or possibly even new and free. It doesn’t matter; as long as NetApiBufferFree frees the memory with the same allocator that NetGroupEnum used to allocate the memory in the first place.</p>
<p>Although I personally prefer using a fixed external allocator, many people find it more convenient to use the wrapper technique. That way, they can use their favorite allocator throughout their module. Either way works. The point is that when memory leaves your DLL, the code you gave the memory to must know how to free it, even if it’s using a different compiler from the one that was used to build your DLL.</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/allocating-and-freeing-memory-across-module-boundaries/">http://xnerv.wang/allocating-and-freeing-memory-across-module-boundaries/</a></strong><br>
转载自：<a href="https://blogs.msdn.microsoft.com/oldnewthing/20060915-04/?p=29723">Allocating and freeing memory across module boundaries</a></p>
]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Windows</tag>
        <tag>Heap</tag>
        <tag>DLL</tag>
        <tag>DLL Hell</tag>
      </tags>
  </entry>
  <entry>
    <title>C++异常机制的实现方式和开销分析（转载）</title>
    <url>/analysis-about-cpp-exception-implementation/</url>
    <content><![CDATA[<p>在我几年前开始写《C++编码规范与指导》一文时，就已经规划着要加入这样一篇讨论 C++ 异常机制的文章了。没想到时隔几年以后才有机会把这个尾巴补完 :-)。</p>
<p>还是那句开场白：“在恰当的场合使用恰当的特性” 对每个称职的 C++ 程序员来说都是一个基本标准。想要做到这点，就必须要了解语言中每个特性的实现方式及其时空开销。异常处理由于涉及大量底层内容，向来是 C++ 各种高级机制中较难理解和透彻掌握的部分。本文将在尽量少引入底层细节的前提下，讨论 C++ 中这一崭新特性，并分析其实现开销：</p>
<span id="more"></span>
<h2 id="关于线程"><a class="header-anchor" href="#关于线程"></a>关于线程</h2>
<p>进程和线程的概念相信各位看官早已耳熟能详。在这里，我只想带大家回忆几点重要概念：</p>
<ol>
<li>一个进程中可以同时包含多个线程。</li>
<li>我们通常认为线程是操作系统可识别的最小并发执行和调度单位（不要跟俺说还有 Green Thread 或者 Fiber，OS Kernel 不认识也不参与这些物件的调度）。</li>
<li>同一进程中的多个线程共享代码段（代码和常量）、数据段（静态和全局变量）和扩展段（堆存储），但是<strong>每个线程有自己的栈段</strong>。栈段又叫运行时栈，用来存放所有局部变量和临时变量（参数、返回值、临时构造的变量等）。这一条对下文中的某些概念来说是非常重要的 。但是请注意，这里提到的各个“段”都是逻辑上的说法，在物理上某些硬件架构或者操作系统可能不使用段式存储。不过没关系，编译器会保证这些逻辑概念和假设的前提条件对每个 C/C++ 程序员来说始终是成立的。</li>
<li>由于共享了除栈以外的所有内存地址段，线程不可以有自己的“静态”或“全局”变量，为了弥补这一缺憾，操作系统通常会提供一种称为 <strong>TLS</strong>（Thread Local Storage，即：“线程本地存储”）的机制。通过该机制可以实现类似的功能。TLS 通常是线程控制块（TCB）中的某个指针所指向的一个指针数组，数组中的每个元素称为一个槽（Slot），每个槽中的指针由使用者定义，可以指向任意位置（但通常是指向堆存储中的某个偏移）。</li>
</ol>
<h2 id="函数的调用和返回"><a class="header-anchor" href="#函数的调用和返回"></a>函数的调用和返回</h2>
<p>接着我们来回顾下一个预备知识：编译器如何实现函数的调用和返回。一般来说，编译器会为当前调用栈里的每个函数建立一个栈框架（Stack Frame）。“栈框架”担负着以下重要任务：</p>
<ol>
<li>传递参数：通常，函数的调用参数总是在这个函数栈框架的最顶端。</li>
<li>传递返回地址：告诉被调用者的 return 语句应该 return 到哪里去，通常指向该函数调用的下一条语句（代码段中的偏移）。</li>
<li>存放调用者的当前栈指针：便于清理被调用者的所有局部变量、并恢复调用者的现场。</li>
<li>存放当前函数内的所有局部变量：记得吗？刚才说过所有局部和临时变量都是存储在栈上的。</li>
</ol>
<p>最后再复习一点：栈是一种“后进先出”（LIFO）的数据结构，不过实际上大部分栈的实现都支持随机访问。</p>
<p>下面我们来看个具体例子：</p>
<p>假设有 FuncA、FuncB 和 FuncC 三个函数，每个函数均接收两个整形值作为其参数。在某线程上的某一时间段内，FuncA 调用了 FuncB，而 FuncB 又调用了 FuncC。则，它们的栈框架看起来应该像这样：</p>
<center>
<img src="/assets/analysis-about-cpp-exception-implementation/函数栈框架.png" alt="函数栈框架"/>
</center>
图1 函数调用栈框架示例
<p>正如上图所示的那样，随着函数被逐级调用，编译器会为每一个函数建立自己的栈框架，栈空间逐渐消耗。随着函数的逐级返回，该函数的栈框架也将被逐级销毁，栈空间得以逐步释放。顺便说一句，递归函数的嵌套调用深度通常也是取决于运行时栈空间的剩余尺寸。</p>
<p>这里顺便解释另一个术语：<strong>调用约定</strong>（calling convention）。调用约定通常指：调用者将参数压入栈中（或放入寄存器中）的顺序，以及返回时由谁（调用者还是被调用者）来清理这些参数等细节规程方面的约定。</p>
<p>最后再说一句，这里所展示的函数调用乃是最“经典”的方式。实际情况是：在开启了优化选项后，编译器可能不会为一个内联甚至非内联的函数生成栈框架，编译器可能使用很多优化技术消除这个构造。不过对于一个 C/C++ 程序员来说，达到这样的理解程度通常就足够了。</p>
<h2 id="C-函数的调用和返回"><a class="header-anchor" href="#C-函数的调用和返回"></a>C++ 函数的调用和返回</h2>
<p>首先澄清一点，这里说的 “C++ 函数”是指：</p>
<ol>
<li>该函数可能会直接或间接地抛出一个异常：即该函数的定义存放在一个 C++ 编译（而不是传统 C）单元内，并且该函数没有使用“throw()”异常过滤器。</li>
<li>或者该函数的定义内使用了 try 块。</li>
</ol>
<p>以上两者满足其一即可。为了能够成功地捕获异常和正确地完成栈回退（stack unwind），编译器必须要引入一些额外的数据结构和相应的处理机制。我们首先来看看引入了异常处理机制的栈框架大概是什么样子：</p>
<center>
<img src="/assets/analysis-about-cpp-exception-implementation/C++函数调用栈.png" alt="C++函数调用栈"/>
</center>
图2 C++函数调用栈框架示例
<p>由图2可见，在每个 C++ 函数的栈框架中都多了一些东西。仔细观察的话，你会发现，多出来的东西正好是一个 EXP 类型的结构体。进一步分析就会发现，这是一个典型的单向链表式结构：</p>
<ol>
<li>piPrev 成员指向链表的上一个节点，它主要用于在函数调用栈中逐级向上寻找匹配的 catch 块，并完成栈回退工作。</li>
<li>piHandler 成员指向完成异常捕获和栈回退所必须的数据结构（主要是两张记载着关键数据的表：“try”块表：<code>tblTryBlocks</code> 及“栈回退表”：<code>tblUnwind</code>）。</li>
<li>nStep 成员用来定位 try 块，以及在栈回退表中寻找正确的入口。</li>
</ol>
<p>需要说明的是：<strong>编译器会为每一个“C++ 函数”定义一个 <code>EHDL</code> 结构，不过只会为包含了“try”块的函数定义 <code>tblTryBlocks</code> 成员</strong>。此外，异常处理器还会为每个线程维护一个指向当前异常处理框架的指针。该指针指向异常处理器链表的链尾，通常存放在某个 TLS 槽或能起到类似作用的地方。</p>
<p>最后，请再看一遍图2，并至少对其中的数据结构留下一个大体印象。我们会在后面多个小节中详细讨论它们。</p>
<p><strong>注意</strong>：为了简化起见，本文中描述的数据结构内，大多省略了一些与话题无关的成员。</p>
<h2 id="栈回退（Stack-Unwind）机制"><a class="header-anchor" href="#栈回退（Stack-Unwind）机制"></a>栈回退（Stack Unwind）机制</h2>
<p>“栈回退”是伴随异常处理机制引入 C++ 中的一个新概念，主要用来确保在异常被抛出、捕获并处理后，所有生命期已结束的对象都会被正确地析构，它们所占用的空间会被正确地回收。</p>
<p>受益于栈回退机制的引入，以及 C++ 类所支持的“资源申请即初始化”语意，使得我们终于能够彻底告别既不优雅也不安全的 setjmp/longjmp 调用，简便又安全地实现远程跳转了。我想这也是 C++ 异常处理机制在错误处理以外唯一一种合理的应用方式了。</p>
<p>下面我们就来具体看看编译器是如何实现栈回退机制的：</p>
<center>
<img src="/assets/analysis-about-cpp-exception-implementation/栈回退.png" alt="栈回退"/>
</center>
图3 C++ 栈回退机制
<p>图3中的“FuncUnWind”函数内，所有真实代码均以黑色和蓝色字体标示，编译器生成的代码则由灰色和橙色字体标明。此时，在图2里给出的 nStep 变量和 tblUnwind 成员作用就十分明显了。</p>
<p>nStep 变量用于跟踪函数内局部对象的构造、析构阶段。再配合编译器为每个函数生成的 tblUnwind 表，就可以完成退栈机制。表中的 <code>pfnDestroyer</code> 字段记录了对应阶段应当执行的析构操作（析构函数指针）；<code>pObj</code> 字段则记录了与之相对应的对象 this 指针偏移。将 pObj 所指的偏移值加上当前栈框架基址（EBP），就是要代入 pfnDestroyer 所指析构函数的 this 指针，这样即可完成对该对象的析构工作。而 nNextIdx 字段则指向下一个需要析构对象所在的行（下标）。</p>
<p>在发生异常时，异常处理器首先检查当前函数栈框架内的 <code>nStep</code> 值，并通过 <code>piHandler</code> 取得 <code>tblUnwind[]</code> 表。然后将 nStep 作为下标带入表中，执行该行定义的析构操作，然后转向由 nNextIdx 指向的下一行，直到 nNextIdx 为 -1 为止。在当前函数的栈回退工作结束后，异常处理器可沿当前函数栈框架内 <code>piPrev</code>的值回溯到异常处理链中的上一节点重复上述操作，直到所有回退工作完成为止。</p>
<p>值得一提的是，nStep 的值完全在编译时决定，运行时仅需执行若干次简单的整形立即数赋值（通常是直接赋值给CPU里的某个寄存器）。此外，对于所有内部类型以及使用了默认构造、析构方法（并且它的所有成员和基类也使用了默认方法）的类型，其创建和销毁均不影响 nStep 的值。</p>
<p><strong>注意</strong>：如果在栈回退的过程中，由于析构函数的调用而再次引发了异常（异常中的异常），则被认为是一次异常处理机制的严重失败。此时进程将被强行禁止。为防止出现这种情况，应在所有可能抛出异常的析构函数中使用“std::uncaught_exception()”方法判断当前是否正在进行栈回退（即：存在一个未捕获或未完全处理完毕的异常）。如是，则应抑制异常的再次抛出。</p>
<h2 id="异常捕获机制"><a class="header-anchor" href="#异常捕获机制"></a>异常捕获机制</h2>
<p>一个异常被抛出时，就会立即引发 C++ 的异常捕获机制：</p>
<center>
<img src="/assets/analysis-about-cpp-exception-implementation/异常捕获机制.png" alt="异常捕获机制"/>
</center>
图4 C++ 异常捕获机制
<p>在上一小节中，我们已经看到了 <code>nStep</code> 变量在跟踪对象构造、析构方面的作用。实际上 nStep 除了能够跟踪对象创建、销毁阶段以外，还能够标识当前执行点是否在 try 块中，以及（如果当前函数有多个 try 块的话）究竟在哪个 try 块中。这是通过在每一个 try 块的入口和出口各为 nStep 赋予一个唯一 ID 值，并确保 nStep 在对应 try 块内的变化恰在此范围之内来实现的。</p>
<p>在具体实现异常捕获时，首先，C++ 异常处理器检查发生异常的位置是否在当前函数的某个 try 块之内。这项工作可以通过将当前函数的 nStep 值依次在 <code>piHandler</code> 指向 <code>tblTryBlocks[]</code> 表的条目中进行范围为 [nBeginStep, nEndStep) 的比对来完成。</p>
<p>例如：若图4 中的 FuncB 在 nStep == 2 时发生了异常，则通过比对 FuncB 的 tblTryBlocks[] 表发现 2∈[1, 3)，故该异常发生在 FuncB 内的第一个 try 块中。</p>
<p>其次，如果异常发生的位置在当前函数中的某个 try 块内，则尝试匹配该 <code>tblTryBlocks[]</code> 相应条目中的 <code>tblCatchBlocks[]</code> 表。<code>tblCatchBlocks[]</code> 表中记录了与指定 try 块配套出现的所有 catch 块相关信息，包括这个 catch 块所能捕获的异常类型及其起始地址等信息。</p>
<p>若找到了一个匹配的 catch 块，则复制当前异常对象到此 catch 块，然后跳转到其入口地址执行块内代码。</p>
<p>否则，则说明异常发生位置不在当前函数的 try 块内，或者这个 try 块中没有与当前异常相匹配的 catch 块，此时则沿着函数栈框架中 <code>piPrev</code> 所指地址（即：异常处理链中的上一个节点）逐级重复以上过程，直至找到一个匹配的 catch 块或到达异常处理链的首节点。对于后者，我们称为发生了未捕获的异常，对于 C++ 异常处理器而言，未捕获的异常是一个严重错误，将导致当前进程被强制结束。</p>
<p><strong>注意</strong>：虽然在图4示例中的 tblTryBlocks[] 只有一个条目，这个条目中的 tblCatchBlocks[] 也只有一行。但是在实际情况中，这两个表中都允许有多条记录。意即：一个函数中可以有多个 try 块，每个 try 块后均可跟随多个与之配套的 catch 块。</p>
<p><strong>注意</strong>：按照标准意义上的理解，异常时的栈回退是伴随着异常捕获过程沿着异常处理链逐层向上进行的。但是有些编译器是在先完成异常捕获后再一次性进行栈回退的。无论具体实现使用了哪种方式，除非正在开发一个内存严格受限的嵌入式应用，通常我们按照标准语意来理解都不会产生什么问题。</p>
<p><strong>备注</strong>：实际上 tblCatchBlocks 中还有一些较为关键但被故意省略的字段。比如指明该 catch 块异常对象复制方式（传值（拷贝构造）或传址（引用或指针））的字段，以及在何处存放被复制的异常对象（相对于入口地址的偏移位置）等信息。</p>
<h2 id="异常的抛出"><a class="header-anchor" href="#异常的抛出"></a>异常的抛出</h2>
<p>接下来讨论整个 C++ 异常处理机制中的最后一个环节，异常的抛出：</p>
<center>
<img src="/assets/analysis-about-cpp-exception-implementation/异常抛出.png" alt="异常抛出"/>
</center>
图5 C++ 异常抛出
<p>在编译一段 C++ 代码时，编译器会将所有 throw 语句替换为其 C++ 运行时库中的某一指定函数，这里我们叫它 <code>__CxxRTThrowExp</code>（与本文提到的所有其它数据结构和属性名一样，在实际应用中它可以是任意名称）。该函数接收一个编译器认可的内部结构（我们叫它 <code>EXCEPTION</code> 结构）。这个结构中包含了待抛出异常对象的起始地址、用于销毁它的析构函数，以及它的 type_info 信息。对于没有启用 RTTI 机制（编译器禁用了 RTTI 机制或没有在类层次结构中使用虚表）的异常类层次结构，可能还要包含其所有基类的 type_info 信息，以便与相应的 catch 块进行匹配。</p>
<p>在图5中的深灰色框图内，我们使用 C++ 伪代码展示了函数 FuncA 中的 “throw myExp(1);” 语句将被编译器最终翻译成的样子。实际上在多数情况下，<code>__CxxRTThrowExp</code> 函数即我们前面曾多次提到的“异常处理器”，异常捕获和栈回退等各项重要工作都由它来完成。</p>
<p><code>__CxxRTThrowExp</code> 首先接收（并保存）<code>EXCEPTION</code> 对象；然后从 <code>TLS：Current ExpHdl</code> 处找到与当前函数对应的 piHandler、nStep 等异常处理相关数据；并按照前文所述的机制完成异常捕获和栈回退。由此完成了包括“抛出”-&gt;“捕获”-&gt;“回退”等步骤的整套异常处理机制。</p>
<h2 id="Windows-中的结构化异常处理"><a class="header-anchor" href="#Windows-中的结构化异常处理"></a>Windows 中的结构化异常处理</h2>
<p>Microsoft Windows 带有一种名为“结构化异常处理”的机制，非常著名的“内存访问违例”出错对话框就是该机制的一种体现。Windows 结构化异常处理与前文讨论的 C++ 异常处理机制有惊人的相似之处，同样使用类似的链式结构实现。对于 Windows 下的应用程序，只需使用 SetUnhandledExceptionFilter API 注册异常处理器；用 FS:[0] 替代前文所述的 TLS: Current ExpHdl 等很少的改动，即可将此两种错误处理机制合而为一。这样做的优势十分明显：</p>
<ul>
<li>由于可直接借助操作系统提供的机制，所以简化了 C++ 异常处理器的实现。</li>
<li>使“catch (…)” 块得以捕获操作系统产生的异常（如：“内存访问违例”等等）。</li>
<li>使操作系统的异常处理机制能够捕获所有 C++ 异常。</li>
</ul>
<p>实际上，大多数 Windows 下的 C++ 编译器的异常机制均使用这种方式实现。</p>
<h2 id="异常处理机制的开销分析"><a class="header-anchor" href="#异常处理机制的开销分析"></a>异常处理机制的开销分析</h2>
<p>至此，我们已完整地阐述了整套 C++ 异常处理机制的实现原理。我在本文的开头曾提到，作为一名 C++ 程序员，了解其某一特性的实现原理主要是为了避免错误地使用该特性。要达到这个目的，还要在了解实现原理的基础上进行一些额外的开销分析工作：</p>
<table>
<thead>
<tr>
<th>特性</th>
<th>时间开销</th>
<th>空间开销</th>
</tr>
</thead>
<tbody>
<tr>
<td>EHDL</td>
<td>无运行时开销</td>
<td>每“C++函数”一个 EHDL 对象，其中的 tblTryBlocks[] 成员仅在函数中包含至少一个 try 块时使用。典型情况下小于 64 字节。</td>
</tr>
<tr>
<td>C++栈框架</td>
<td>极高的 O(1) 效率，每次调用时进行3次额外的整形赋值和一次 TLS 访问。</td>
<td>每 调用两个指针和一个整形开销。典型情况下小于 16 字节。</td>
</tr>
<tr>
<td>step 跟踪</td>
<td>极高的 O(1) 效率每次进出 try 块或对象构造/析构一次整形立即数赋值。</td>
<td>无（已记入 C++ 栈框架中的相应项目）。</td>
</tr>
<tr>
<td>异常的抛出、捕获和栈回退</td>
<td>异常的抛出是一次 O(1) 级操作。在单个函数中进行捕获和栈回退也均为 O(1) 操作。<br/><br/>但异常捕获的总体成本为 O(m)，其中 m 等于当前函数调用栈中，从抛出异常的位置到达匹配 catch 块之间所经过的函数调用中，包含 try 块（即：定义了有效 tblTryBlocks[]）的函数个数。<br/><br/>栈回退的总成本为 O(n)，其中 n 等于当前函数调用栈中，从抛出异常的位置到达匹配 catch 块之间所经过的函数调用数。</td>
<td>在异常处理结束前，需保存异常对象及其析构函数指针和相应的 type_info 信息。<br/><br/>具体根据对象尺寸、编译器选项（是否开启 RTTI）及异常捕获器的参数传递方式（传值或传址）等因素有较大变化。典型情况下小于 256 字节。</td>
</tr>
</tbody>
</table>
<p>可以看出，在没有抛出异常时，C++ 的异常处理机制是十分有效的。在有异常被抛出后，可能会依当前函数调用栈的情形进行若干次整形比较（try块表匹配）操作，但这通常不会超过几十次。对于大多数 15 年前的 CPU 来说，整形比较也只需 1 时钟周期，所以异常捕获的效率还是很高的。栈回退的效率则与 return 语句基本相当。</p>
<p>考虑到即使是传统的函数调用、错误处理和逐级返回机制也不是没有代价的。这些开销在绝大多数情形下仍可以接受。空间开销方面，每“C++ 函数”一个 EHDL 结构体的引入在某些极端情形下会明显增加目标文件尺寸和内存开销。但是典型情况下，它们的影响并不大，但也没有小到可以完全忽略的程度。如果正在为一个资源严格受限的环境开发应用程序，你可能需要考虑关闭异常处理和 RTTI 机制以节约存储空间。</p>
<p>以上讨论的是一种典型的异常机制的实现方式，各具体编译器厂商可能有自己的优化和改进方案，但总体的出入不会很大。</p>
<h2 id="小节"><a class="header-anchor" href="#小节"></a>小节</h2>
<p>异常处理是 C++ 中十分有用的崭新特性之一。在绝大多数情况下，它们都有着优异的表现和令人满意的时空效率。异常处理本质上是另一种返回机制。但无论从软件工程、模块设计、编码习惯还是时空效率等角度来说，除了在有充分文档说明的前提下，偶尔可用来替代替代传统的 setjmp/longjmp 功能外，应保证只将其用于程序的错误处理机制中。<br>
此外，由于长跳转的使用既易于出错，又难于理解和维护。在编码过程中也应当尽量避免使用。关于异常的一般性使用说明，请参考：<a href="http://baiy.cn/doc/cpp/index.htm#%E4%BB%A3%E7%A0%81%E9%A3%8E%E6%A0%BC%E4%B8%8E%E7%89%88%E5%BC%8F_%E5%BC%82%E5%B8%B8">代码风格与版式：异常</a>。</p>
<p></p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/analysis-about-cpp-exception-implementation/">http://xnerv.wang/analysis-about-cpp-exception-implementation/</a></strong><br>
转载自：<a href="http://baiy.cn/doc/cpp/inside_exception.htm">C++异常机制的实现方式和开销分析</a></p>
]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>编程语言</tag>
        <tag>C++</tag>
        <tag>C++异常</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL - 常用SQL语句的MDL加锁源码分析（转载）</title>
    <url>/analysis-of-mdl-source-code-for-common-sql-statements/</url>
    <content><![CDATA[<section class="post">
<h2 id="前言"><a class="header-anchor" href="#前言"></a>前言</h2>
<p>MySQL5.5版本开始引入了MDL锁用来保护元数据信息，让MySQL能够在并发环境下多DDL、DML同时操作下保持元数据的一致性。本文用MySQL5.7源码分析了常用SQL语句的MDL加锁实现。</p>
<h4 id="MDL锁粒度"><a class="header-anchor" href="#MDL锁粒度"></a>MDL锁粒度</h4>
<p>MDL_key由namespace、db_name、name组成。</p>
<p>namespace包含：</p>
<ul>
<li>
<p>GLOBAL。用于global read lock，例如FLUSH TABLES WITH READ LOCK。</p>
</li>
<li>
<p>TABLESPACE/SCHEMA。用于保护tablespace/schema。</p>
</li>
<li>
<p>FUNCTION/PROCEDURE/TRIGGER/EVENT。用于保护function/procedure/trigger/event。</p>
</li>
<li>
<p>COMMIT。主要用于global read lock后，阻塞事务提交。（在DML的commit阶段也会获取COMMIT锁）</p>
</li>
<li>
<p>USER_LEVEL_LOCK。用于<a href="https://dev.mysql.com/doc/internals/en/user-level-locks.html">user level lock函数</a>的实现，GET_LOCK(str,timeout)， RELEASE_LOCK(str)。</p>
</li>
<li>
<p>LOCKING_SERVICE。用于<a href="https://dev.mysql.com/doc/refman/5.7/en/locking-service.html">locking service</a>的实现。</p>
</li>
</ul>
<span id="more"></span>
<h3 id="MDL锁类型"><a class="header-anchor" href="#MDL锁类型"></a>MDL锁类型</h3>
<ul>
<li>
<p>MDL_INTENTION_EXCLUSIVE(IX) 意向排他锁，锁定一个范围，用在GLOBAL/SCHEMA/COMMIT粒度。</p>
</li>
<li>
<p>MDL_SHARED(S) 用在只访问元数据信息，不访问数据。例如CREATE TABLE t LIKE t1;</p>
</li>
<li>
<p>MDL_SHARED_HIGH_PRIO(SH) 也是用于只访问元数据信息，但是优先级比排他锁高，用于访问information_schema的表。例如：select * from information_schema.tables;</p>
</li>
<li>
<p>MDL_SHARED_READ(SR) 访问表结构并且读表数据，例如：SELECT * FROM t1; LOCK TABLE t1 READ LOCAL;</p>
</li>
<li>
<p>MDL_SHARED_WRITE(SW) 访问表结构且写表数据， 例如：INSERT/DELETE/UPDATE t1 … ;SELECT * FROM t1 FOR UPDATE;LOCK TALE t1 WRITE</p>
</li>
<li>
<p>MDL_SHARED_WRITE_LOW_PRIO(SWLP) 优先级低于MDL_SHARED_READ_ONLY。语句INSER/DELETE/UPDATE LOW_PRIORITY t1 …; LOCK TABLE t1 WRITE LOW_PRIORITY。</p>
</li>
<li>
<p>MDL_SHARED_UPGRADABLE(SU) 可升级锁，允许并发update/read表数据。持有该锁可以同时读取表metadata和表数据，但不能修改数据。可以升级到SNW、X锁。用在alter table的第一阶段，使alter table的时候不阻塞DML，防止其他DDL。（是mysql 5.6引入的新的metadata lock，在alter table/create index/drop index会加该锁，可以说是为了online ddl才引入的。特点是允许DML，防止DDL。）</p>
</li>
<li>
<p>MDL_SHARED_READ_ONLY(SRO) 持有该锁可读取表数据，同时阻塞所有表结构和表数据的修改操作，用于LOCK TABLE t1 READ。</p>
</li>
<li>
<p>MDL_SHARED_NO_WRITE(SNW) 持有该锁可以读取表metadata和表数据，同时阻塞所有的表数据修改操作，允许读。可以升级到X锁。用在ALTER TABLE第一阶段，拷贝原始表数据到新表，允许读但不允许更新。</p>
</li>
<li>
<p>MDL_SHARED_NO_READ_WRITE(SNRW) 可升级锁，允许其他连接读取表结构但不可以读取数据，阻塞所有表数据的读写操作，允许INFORMATION_SCHEMA访问和SHOW语句。持有该锁的的连接可以读取表结构，修改和读取表数据。可升级为X锁。使用在LOCK TABLE WRITE语句。</p>
</li>
<li>
<p>MDL_EXCLUSIVE(X) 排他锁，持有该锁连接可以修改表结构和表数据，使用在CREATE/DROP/RENAME/ALTER TABLE 语句。</p>
</li>
</ul>
<h3 id="MDL锁持有时间"><a class="header-anchor" href="#MDL锁持有时间"></a>MDL锁持有时间</h3>
<ul>
<li>
<p>MDL_STATEMENT 语句中持有，语句结束自动释放</p>
</li>
<li>
<p>MDL_TRANSACTION 事务中持有，事务结束时释放</p>
</li>
<li>
<p>MDL_EXPLICIT 需要显示释放</p>
</li>
</ul>
<h3 id="MDL锁兼容性"><a class="header-anchor" href="#MDL锁兼容性"></a>MDL锁兼容性</h3>
<p>Scope锁活跃锁和请求锁兼容性矩阵如下。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">         | Type of active   |</span><br><span class="line">Request  |   scoped lock    |</span><br><span class="line">type     | IS(*)  IX   S  X |</span><br><span class="line">---------+------------------+</span><br><span class="line">IS       |  +      +   +  + |</span><br><span class="line">IX       |  +      +   -  - |</span><br><span class="line">S        |  +      -   +  - |</span><br><span class="line">X        |  +      -   -  - |</span><br><span class="line"></span><br><span class="line">+号表示请求的锁可以满足。</span><br><span class="line">-号表示请求的锁无法满足需要等待。</span><br></pre></td></tr></table></figure>
<p>Scope锁等待锁和请求锁优先级矩阵</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">         |    Pending      |</span><br><span class="line">Request  |  scoped lock    |</span><br><span class="line">type     | IS(*)  IX  S  X |</span><br><span class="line">---------+-----------------+</span><br><span class="line">IS       |  +      +  +  + |</span><br><span class="line">IX       |  +      +  -  - |</span><br><span class="line">S        |  +      +  +  - |</span><br><span class="line">X        |  +      +  +  + |</span><br><span class="line">+号表示请求的锁可以满足。</span><br><span class="line">-号表示请求的锁无法满足需要等待。</span><br></pre></td></tr></table></figure>
<p>object上已持有锁和请求锁的兼容性矩阵如下。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Request   |  Granted requests for lock                  |</span><br><span class="line"> type     | S  SH  SR  SW  SWLP  SU  SRO  SNW  SNRW  X  |</span><br><span class="line">----------+---------------------------------------------+</span><br><span class="line">S         | +   +   +   +    +    +   +    +    +    -  |</span><br><span class="line">SH        | +   +   +   +    +    +   +    +    +    -  |</span><br><span class="line">SR        | +   +   +   +    +    +   +    +    -    -  |</span><br><span class="line">SW        | +   +   +   +    +    +   -    -    -    -  |</span><br><span class="line">SWLP      | +   +   +   +    +    +   -    -    -    -  |</span><br><span class="line">SU        | +   +   +   +    +    -   +    -    -    -  |</span><br><span class="line">SRO       | +   +   +   -    -    +   +    +    -    -  |</span><br><span class="line">SNW       | +   +   +   -    -    -   +    -    -    -  |</span><br><span class="line">SNRW      | +   +   -   -    -    -   -    -    -    -  |</span><br><span class="line">X         | -   -   -   -    -    -   -    -    -    -  |</span><br></pre></td></tr></table></figure>
<p>object上等待锁和请求锁的优先级矩阵如下。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Request   |         Pending requests for lock          |</span><br><span class="line"> type     | S  SH  SR  SW  SWLP  SU  SRO  SNW  SNRW  X |</span><br><span class="line">----------+--------------------------------------------+</span><br><span class="line">S         | +   +   +   +    +    +   +    +     +   - |</span><br><span class="line">SH        | +   +   +   +    +    +   +    +     +   + |</span><br><span class="line">SR        | +   +   +   +    +    +   +    +     -   - |</span><br><span class="line">SW        | +   +   +   +    +    +   +    -     -   - |</span><br><span class="line">SWLP      | +   +   +   +    +    +   -    -     -   - |</span><br><span class="line">SU        | +   +   +   +    +    +   +    +     +   - |</span><br><span class="line">SRO       | +   +   +   -    +    +   +    +     -   - |</span><br><span class="line">SNW       | +   +   +   +    +    +   +    +     +   - |</span><br><span class="line">SNRW      | +   +   +   +    +    +   +    +     +   - |</span><br><span class="line">X         | +   +   +   +    +    +   +    +     +   + |</span><br></pre></td></tr></table></figure>
<h3 id="常用语句MDL锁加锁分析"><a class="header-anchor" href="#常用语句MDL锁加锁分析"></a>常用语句MDL锁加锁分析</h3>
<p>使用performance_schema可以辅助分析加锁。利用下面语句打开MDL锁分析，可以看到在只有当前session访问的时候，SELECT语句对metadata_locks表加了TRANSACTION周期的SHARED_READ锁，即锁粒度、时间范围和锁类型分别为：TABLE, TRANSACTION, SHARED_READ，在代码位置sql_parse.cc:5996初始化锁。后面的锁分析也按照锁粒度-时间范围-锁类型介绍。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">UPDATE performance_schema.setup_consumers SET ENABLED = &#x27;YES&#x27; WHERE NAME =&#x27;global_instrumentation&#x27;;</span><br><span class="line">UPDATE performance_schema.setup_instruments SET ENABLED = &#x27;YES&#x27; WHERE NAME =&#x27;wait/lock/metadata/sql/mdl&#x27;;</span><br><span class="line">select * from performance_schema.metadata_locks\G</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">          OBJECT_TYPE: TABLE</span><br><span class="line">        OBJECT_SCHEMA: performance_schema</span><br><span class="line">          OBJECT_NAME: metadata_locks</span><br><span class="line">OBJECT_INSTANCE_BEGIN: 46995934864720</span><br><span class="line">            LOCK_TYPE: SHARED_READ</span><br><span class="line">        LOCK_DURATION: TRANSACTION</span><br><span class="line">          LOCK_STATUS: GRANTED</span><br><span class="line">               SOURCE: sql_parse.cc:5996</span><br><span class="line">      OWNER_THREAD_ID: 26</span><br><span class="line">       OWNER_EVENT_ID: 163</span><br></pre></td></tr></table></figure>
<p>使用performance_schema很难完整分析语句执行中所有的加锁过程，可以借助gdb分析，在 MDL_context::acquire_lock设置断点。</p>
<p>下面会结合performance_schema和gdb分析常用语句的MDL加锁源码实现。</p>
<h4 id="FLUSH-TABLES-WITH-READ-LOCK"><a class="header-anchor" href="#FLUSH-TABLES-WITH-READ-LOCK"></a>FLUSH TABLES WITH READ LOCK</h4>
<p>语句执行会加锁GLOBAL-EXPLICIT-SHARED和COMMIT-EXPLICIT-SHARED。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">select * from performance_schema.metadata_locks\G</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">          OBJECT_TYPE: GLOBAL</span><br><span class="line">        OBJECT_SCHEMA: NULL</span><br><span class="line">          OBJECT_NAME: NULL</span><br><span class="line">OBJECT_INSTANCE_BEGIN: 46996001973424</span><br><span class="line">            LOCK_TYPE: SHARED</span><br><span class="line">        LOCK_DURATION: EXPLICIT</span><br><span class="line">          LOCK_STATUS: GRANTED</span><br><span class="line">               SOURCE: lock.cc:1110</span><br><span class="line">      OWNER_THREAD_ID: 27</span><br><span class="line">       OWNER_EVENT_ID: 92</span><br><span class="line">*************************** 2. row ***************************</span><br><span class="line">          OBJECT_TYPE: COMMIT</span><br><span class="line">        OBJECT_SCHEMA: NULL</span><br><span class="line">          OBJECT_NAME: NULL</span><br><span class="line">OBJECT_INSTANCE_BEGIN: 46996001973616</span><br><span class="line">            LOCK_TYPE: SHARED</span><br><span class="line">        LOCK_DURATION: EXPLICIT</span><br><span class="line">          LOCK_STATUS: GRANTED</span><br><span class="line">               SOURCE: lock.cc:1194</span><br><span class="line">      OWNER_THREAD_ID: 27</span><br><span class="line">       OWNER_EVENT_ID: 375</span><br></pre></td></tr></table></figure>
<p>相关源码实现剖析。当FLUSH语句是FLUSH TABLES WITH READ LOCK的时候，lex-&gt;type会添加REFRESH_TABLES和REFRESH_READ_LOCK标记，当没有指定表即进入reload_acl_and_cache函数，通过调用lock_global_read_lock和make_global_read_lock_block_commit加对应锁，通过对应的锁来阻止元数据修改和表数据更改。DDL语句执行时会请求GLOBAL的INTENTION_EXCLUSIVE锁，事务提交和外部XA需要记录binlog的语句执行会请求COMMIT的INTENTION_EXCLUSIVE锁。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">sql/sql_yacc.yy</span><br><span class="line">flush_options:</span><br><span class="line">          table_or_tables</span><br><span class="line">          &#123;</span><br><span class="line">            Lex-&gt;type|= REFRESH_TABLES;</span><br><span class="line">            <span class="comment">/*</span></span><br><span class="line"><span class="comment">              Set type of metadata and table locks for</span></span><br><span class="line"><span class="comment">              FLUSH TABLES table_list [WITH READ LOCK].</span></span><br><span class="line"><span class="comment">            */</span></span><br><span class="line">            YYPS-&gt;m_lock_type= TL_READ_NO_INSERT;</span><br><span class="line">            YYPS-&gt;m_mdl_type= MDL_SHARED_HIGH_PRIO;</span><br><span class="line">          &#125;</span><br><span class="line">          opt_table_list &#123;&#125;</span><br><span class="line">          opt_flush_lock &#123;&#125;</span><br><span class="line">        | flush_options_list</span><br><span class="line">        ;</span><br><span class="line"></span><br><span class="line">opt_flush_lock:</span><br><span class="line">          <span class="comment">/* empty */</span> &#123;&#125;</span><br><span class="line">        | WITH READ_SYM LOCK_SYM</span><br><span class="line">          &#123;</span><br><span class="line">            TABLE_LIST *tables= Lex-&gt;query_tables;</span><br><span class="line">            Lex-&gt;type|= REFRESH_READ_LOCK;</span><br><span class="line"></span><br><span class="line">sql/sql_parse.cc</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">case</span> SQLCOM_FLUSH:</span><br><span class="line">    <span class="keyword">if</span> (first_table &amp;&amp; lex-&gt;type &amp; REFRESH_READ_LOCK)<span class="comment">//当指定表的时候，对指定表加锁。</span></span><br><span class="line">    &#123;</span><br><span class="line">      <span class="keyword">if</span> (<span class="built_in">flush_tables_with_read_lock</span>(thd, all_tables))</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">if</span> (!<span class="built_in">reload_acl_and_cache</span>(thd, lex-&gt;type, first_table, &amp;write_to_binlog))</span><br><span class="line"></span><br><span class="line">sql/sql_reload.cc</span><br><span class="line">reload_acl_and_cache</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">if</span> (options &amp; (REFRESH_TABLES | REFRESH_READ_LOCK))</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">if</span> ((options &amp; REFRESH_READ_LOCK) &amp;&amp; thd)</span><br><span class="line">    &#123;</span><br><span class="line">      ...</span><br><span class="line">      <span class="keyword">if</span> (thd-&gt;global_read_lock.<span class="built_in">lock_global_read_lock</span>(thd))<span class="comment">//当未指定表的时候，加全局锁</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">      ...</span><br><span class="line">      <span class="keyword">if</span> (thd-&gt;global_read_lock.<span class="built_in">make_global_read_lock_block_commit</span>(thd))<span class="comment">//当未指定表的时候，加COMMIT锁</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//对GLOBAL加EXPLICIT的S锁。</span></span><br><span class="line">sql/lock.<span class="function">cc</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">Global_read_lock::lock_global_read_lock</span><span class="params">(THD *thd)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="built_in">MDL_REQUEST_INIT</span>(&amp;mdl_request,</span><br><span class="line">                 MDL_key::GLOBAL, <span class="string">&quot;&quot;</span>, <span class="string">&quot;&quot;</span>, MDL_SHARED, MDL_EXPLICIT);</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//对COMMIT加EXPLICIT的S锁。</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">Global_read_lock::make_global_read_lock_block_commit</span><span class="params">(THD *thd)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="built_in">MDL_REQUEST_INIT</span>(&amp;mdl_request,</span><br><span class="line">                 MDL_key::COMMIT, <span class="string">&quot;&quot;</span>, <span class="string">&quot;&quot;</span>, MDL_SHARED, MDL_EXPLICIT);</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">sql/handler.cc</span><br><span class="line">事务提交和外部XA事务的commit\rollback\prepare均需要加COMMIT的IX锁.</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">ha_commit_trans</span><span class="params">(THD *thd, <span class="type">bool</span> all, <span class="type">bool</span> ignore_global_read_lock)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">if</span> (rw_trans &amp;&amp; !ignore_global_read_lock) <span class="comment">//对于内部表slave status table的更新可以忽略global read lock</span></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="built_in">MDL_REQUEST_INIT</span>(&amp;mdl_request,</span><br><span class="line">                 MDL_key::COMMIT, <span class="string">&quot;&quot;</span>, <span class="string">&quot;&quot;</span>, MDL_INTENTION_EXCLUSIVE,</span><br><span class="line">                 MDL_EXPLICIT);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">DBUG_PRINT</span>(<span class="string">&quot;debug&quot;</span>, (<span class="string">&quot;Acquire MDL commit lock&quot;</span>));</span><br><span class="line">    <span class="keyword">if</span> (thd-&gt;mdl_context.<span class="built_in">acquire_lock</span>(&amp;mdl_request,</span><br><span class="line">                                  thd-&gt;variables.lock_wait_timeout))</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br><span class="line">sql/xa.<span class="function">cc</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">Sql_cmd_xa_commit::trans_xa_commit</span><span class="params">(THD *thd)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  MDL_request mdl_request;</span><br><span class="line">  <span class="built_in">MDL_REQUEST_INIT</span>(&amp;mdl_request,</span><br><span class="line">                   MDL_key::COMMIT, <span class="string">&quot;&quot;</span>, <span class="string">&quot;&quot;</span>, MDL_INTENTION_EXCLUSIVE,</span><br><span class="line">                   MDL_STATEMENT);</span><br><span class="line">  <span class="keyword">if</span> (thd-&gt;mdl_context.<span class="built_in">acquire_lock</span>(&amp;mdl_request,</span><br><span class="line">                                    thd-&gt;variables.lock_wait_timeout))</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">Sql_cmd_xa_rollback::trans_xa_rollback</span><span class="params">(THD *thd)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  MDL_request mdl_request;</span><br><span class="line">  <span class="built_in">MDL_REQUEST_INIT</span>(&amp;mdl_request,</span><br><span class="line">                   MDL_key::COMMIT, <span class="string">&quot;&quot;</span>, <span class="string">&quot;&quot;</span>, MDL_INTENTION_EXCLUSIVE,</span><br><span class="line">                   MDL_STATEMENT);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">Sql_cmd_xa_prepare::trans_xa_prepare</span><span class="params">(THD *thd)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  MDL_request mdl_request;</span><br><span class="line">  <span class="built_in">MDL_REQUEST_INIT</span>(&amp;mdl_request,</span><br><span class="line">                   MDL_key::COMMIT, <span class="string">&quot;&quot;</span>, <span class="string">&quot;&quot;</span>, MDL_INTENTION_EXCLUSIVE,</span><br><span class="line">                   MDL_STATEMENT);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//写入语句的执行和DDL执行需要GLOBAL的IX锁，这与S锁不兼容。</span></span><br><span class="line">sql/sql_base.<span class="function">cc</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">open_table</span><span class="params">(THD *thd, TABLE_LIST *table_list, Open_table_context *ot_ctx)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (table_list-&gt;mdl_request.<span class="built_in">is_write_lock_request</span>() &amp;&amp;</span><br><span class="line">  &#123;</span><br><span class="line">    MDL_request protection_request;</span><br><span class="line">    MDL_deadlock_handler <span class="built_in">mdl_deadlock_handler</span>(ot_ctx);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (thd-&gt;global_read_lock.<span class="built_in">can_acquire_protection</span>())</span><br><span class="line">      <span class="built_in">DBUG_RETURN</span>(TRUE);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">MDL_REQUEST_INIT</span>(&amp;protection_request,</span><br><span class="line">                     MDL_key::GLOBAL, <span class="string">&quot;&quot;</span>, <span class="string">&quot;&quot;</span>, MDL_INTENTION_EXCLUSIVE,</span><br><span class="line">                     MDL_STATEMENT);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">bool</span></span><br><span class="line"><span class="built_in">lock_table_names</span>(THD *thd,</span><br><span class="line">                 TABLE_LIST *tables_start, TABLE_LIST *tables_end,</span><br><span class="line">                 ulong lock_wait_timeout, uint flags)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">if</span> (need_global_read_lock_protection)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">      Protect this statement against concurrent global read lock</span></span><br><span class="line"><span class="comment">      by acquiring global intention exclusive lock with statement</span></span><br><span class="line"><span class="comment">      duration.</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="keyword">if</span> (thd-&gt;global_read_lock.<span class="built_in">can_acquire_protection</span>())</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    <span class="built_in">MDL_REQUEST_INIT</span>(&amp;global_request,</span><br><span class="line">                     MDL_key::GLOBAL, <span class="string">&quot;&quot;</span>, <span class="string">&quot;&quot;</span>, MDL_INTENTION_EXCLUSIVE,</span><br><span class="line">                     MDL_STATEMENT);</span><br><span class="line">    mdl_requests.<span class="built_in">push_front</span>(&amp;global_request);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="LOCK-TABLE-t-READ-LOCAL"><a class="header-anchor" href="#LOCK-TABLE-t-READ-LOCAL"></a>LOCK TABLE t READ [LOCAL]</h4>
<p>LOCK TABLE t READ LOCAL会加锁TABLE-TRANSACTION-SHARED_READ。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">select * from performance_schema.metadata_locks\G</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">          OBJECT_TYPE: TABLE</span><br><span class="line">        OBJECT_SCHEMA: test</span><br><span class="line">          OBJECT_NAME: t</span><br><span class="line">            LOCK_TYPE: SHARED_READ</span><br><span class="line">        LOCK_DURATION: TRANSACTION</span><br><span class="line">          LOCK_STATUS: GRANTED</span><br><span class="line">               SOURCE: sql_parse.cc:5996</span><br></pre></td></tr></table></figure>
<p>LOCK TABLE t READ会加锁TABLE-TRANSACTION-SHARED_READ_ONLY。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">select * from performance_schema.metadata_locks\G</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">          OBJECT_TYPE: TABLE</span><br><span class="line">        OBJECT_SCHEMA: test</span><br><span class="line">          OBJECT_NAME: t</span><br><span class="line">            LOCK_TYPE: SHARED_READ_ONLY</span><br><span class="line">        LOCK_DURATION: TRANSACTION</span><br><span class="line">          LOCK_STATUS: GRANTED</span><br><span class="line">               SOURCE: sql_parse.cc:5996</span><br></pre></td></tr></table></figure>
<p>这两个的区别是对于MyISAM引擎，LOCAL方式的加锁与insert写入不冲突，而没有LOCAL的时候SHARED_READ_ONLY会阻塞写入。不过对于InnoDB引擎两种方式是一样的，带有LOCAL的语句执行后面会升级为SHARED_READ_ONLY。</p>
<p>源码分析</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">table_lock:</span><br><span class="line">          table_ident opt_table_alias lock_option</span><br><span class="line">          &#123;</span><br><span class="line">            thr_lock_type lock_type= (thr_lock_type) $<span class="number">3</span>;</span><br><span class="line">            enum_mdl_type mdl_lock_type;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (lock_type &gt;= TL_WRITE_ALLOW_WRITE)</span><br><span class="line">            &#123;</span><br><span class="line">              <span class="comment">/* LOCK TABLE ... WRITE/LOW_PRIORITY WRITE */</span></span><br><span class="line">              mdl_lock_type= MDL_SHARED_NO_READ_WRITE;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (lock_type == TL_READ)</span><br><span class="line">            &#123;</span><br><span class="line">              <span class="comment">/* LOCK TABLE ... READ LOCAL */</span></span><br><span class="line">              mdl_lock_type= MDL_SHARED_READ;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">            &#123;</span><br><span class="line">              <span class="comment">/* LOCK TABLE ... READ */</span></span><br><span class="line">              mdl_lock_type= MDL_SHARED_READ_ONLY;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (!Select-&gt;<span class="built_in">add_table_to_list</span>(YYTHD, $<span class="number">1</span>, $<span class="number">2</span>, <span class="number">0</span>, lock_type,</span><br><span class="line">                                           mdl_lock_type))</span><br><span class="line">              MYSQL_YYABORT;</span><br><span class="line">          &#125;</span><br><span class="line"></span><br><span class="line">lock_option:</span><br><span class="line">          READ_SYM               &#123; $= TL_READ_NO_INSERT; &#125;</span><br><span class="line">        | WRITE_SYM              &#123; $= TL_WRITE_DEFAULT; &#125;</span><br><span class="line">        | LOW_PRIORITY WRITE_SYM</span><br><span class="line">          &#123;</span><br><span class="line">            $= TL_WRITE_LOW_PRIORITY;</span><br><span class="line">            <span class="built_in">push_deprecated_warn</span>(YYTHD, <span class="string">&quot;LOW_PRIORITY WRITE&quot;</span>, <span class="string">&quot;WRITE&quot;</span>);</span><br><span class="line">          &#125;</span><br><span class="line">        | READ_SYM LOCAL_SYM     &#123; $= TL_READ; &#125;</span><br><span class="line">        ;</span><br><span class="line"></span><br><span class="line">sql/sql_parse.<span class="function">cc</span></span><br><span class="line"><span class="function">TABLE_LIST *<span class="title">st_select_lex::add_table_to_list</span><span class="params">(THD *thd,</span></span></span><br><span class="line"><span class="params"><span class="function">               Table_ident *table,</span></span></span><br><span class="line"><span class="params"><span class="function">               LEX_STRING *alias,</span></span></span><br><span class="line"><span class="params"><span class="function">               ulong table_options,</span></span></span><br><span class="line"><span class="params"><span class="function">               thr_lock_type lock_type,</span></span></span><br><span class="line"><span class="params"><span class="function">               enum_mdl_type mdl_type,</span></span></span><br><span class="line"><span class="params"><span class="function">               List&lt;Index_hint&gt; *index_hints_arg,</span></span></span><br><span class="line"><span class="params"><span class="function">                                             List&lt;String&gt; *partition_names,</span></span></span><br><span class="line"><span class="params"><span class="function">                                             LEX_STRING *option)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="comment">// Pure table aliases do not need to be locked:</span></span><br><span class="line">  <span class="keyword">if</span> (!<span class="built_in">MY_TEST</span>(table_options &amp; TL_OPTION_ALIAS))</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="built_in">MDL_REQUEST_INIT</span>(&amp; ptr-&gt;mdl_request,</span><br><span class="line">                     MDL_key::TABLE, ptr-&gt;db, ptr-&gt;table_name, mdl_type,</span><br><span class="line">                     MDL_TRANSACTION);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//对于Innodb引擎</span></span><br><span class="line"><span class="function"><span class="type">static</span> <span class="type">bool</span> <span class="title">lock_tables_open_and_lock_tables</span><span class="params">(THD *thd, TABLE_LIST *tables)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">if</span> (table-&gt;lock_type == TL_READ &amp;&amp;</span><br><span class="line">           ! table-&gt;prelocking_placeholder &amp;&amp;</span><br><span class="line">           table-&gt;table-&gt;file-&gt;<span class="built_in">ha_table_flags</span>() &amp; HA_NO_READ_LOCAL_LOCK)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">      In case when LOCK TABLE ... READ LOCAL was issued for table with</span></span><br><span class="line"><span class="comment">      storage engine which doesn&#x27;t support READ LOCAL option and doesn&#x27;t</span></span><br><span class="line"><span class="comment">      use THR_LOCK locks we need to upgrade weak SR metadata lock acquired</span></span><br><span class="line"><span class="comment">      in open_tables() to stronger SRO metadata lock.</span></span><br><span class="line"><span class="comment">      This is not needed for tables used through stored routines or</span></span><br><span class="line"><span class="comment">      triggers as we always acquire SRO (or even stronger SNRW) metadata</span></span><br><span class="line"><span class="comment">      lock for them.</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="type">bool</span> result= thd-&gt;mdl_context.<span class="built_in">upgrade_shared_lock</span>(</span><br><span class="line">                                    table-&gt;table-&gt;mdl_ticket,</span><br><span class="line">                                    MDL_SHARED_READ_ONLY,</span><br><span class="line">                                    thd-&gt;variables.lock_wait_timeout);</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="LOCK-TABLE-t-WITH-WRITE"><a class="header-anchor" href="#LOCK-TABLE-t-WITH-WRITE"></a>LOCK TABLE t WITH WRITE</h4>
<p>LOCK TABLE t WITH WRITE会加锁：GLOBAL-STATEMENT-INTENTION_EXCLUSIVE，SCHEMA-TRANSACTION-INTENTION_EXCLUSIVE，TABLE-TRANSACTION-SHARED_NO_READ_WRITE。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">select OBJECT_TYPE,OBJECT_SCHEMA,OBJECT_NAME,LOCK_TYPE,LOCK_DURATION,SOURCE from performance_schema.metadata_locks\G</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">          OBJECT_TYPE: GLOBAL</span><br><span class="line">        OBJECT_SCHEMA: NULL</span><br><span class="line">          OBJECT_NAME: NULL</span><br><span class="line">            LOCK_TYPE: INTENTION_EXCLUSIVE</span><br><span class="line">        LOCK_DURATION: STATEMENT</span><br><span class="line">               SOURCE: sql_base.cc:5497</span><br><span class="line">*************************** 2. row ***************************</span><br><span class="line">          OBJECT_TYPE: SCHEMA</span><br><span class="line">        OBJECT_SCHEMA: test</span><br><span class="line">          OBJECT_NAME: NULL</span><br><span class="line">            LOCK_TYPE: INTENTION_EXCLUSIVE</span><br><span class="line">        LOCK_DURATION: TRANSACTION</span><br><span class="line">               SOURCE: sql_base.cc:5482</span><br><span class="line">*************************** 3. row ***************************</span><br><span class="line">          OBJECT_TYPE: TABLE</span><br><span class="line">        OBJECT_SCHEMA: test</span><br><span class="line">          OBJECT_NAME: ti</span><br><span class="line">            LOCK_TYPE: SHARED_NO_READ_WRITE</span><br><span class="line">        LOCK_DURATION: TRANSACTION</span><br><span class="line">               SOURCE: sql_parse.cc:5996</span><br></pre></td></tr></table></figure>
<p>相关源码</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span></span></span><br><span class="line"><span class="function"><span class="title">lock_table_names</span><span class="params">(THD *thd,</span></span></span><br><span class="line"><span class="params"><span class="function">                 TABLE_LIST *tables_start, TABLE_LIST *tables_end,</span></span></span><br><span class="line"><span class="params"><span class="function">                 ulong lock_wait_timeout, uint flags)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">while</span> ((table= it++))</span><br><span class="line">  &#123;</span><br><span class="line">    MDL_request *schema_request= <span class="built_in">new</span> (thd-&gt;mem_root) MDL_request;</span><br><span class="line">    <span class="keyword">if</span> (schema_request == <span class="literal">NULL</span>)</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    <span class="built_in">MDL_REQUEST_INIT</span>(schema_request,</span><br><span class="line">                     MDL_key::SCHEMA, table-&gt;db, <span class="string">&quot;&quot;</span>,</span><br><span class="line">                     MDL_INTENTION_EXCLUSIVE,</span><br><span class="line">                     MDL_TRANSACTION);</span><br><span class="line">    mdl_requests.<span class="built_in">push_front</span>(schema_request);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (need_global_read_lock_protection)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">      Protect this statement against concurrent global read lock</span></span><br><span class="line"><span class="comment">      by acquiring global intention exclusive lock with statement</span></span><br><span class="line"><span class="comment">      duration.</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="keyword">if</span> (thd-&gt;global_read_lock.<span class="built_in">can_acquire_protection</span>())</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    <span class="built_in">MDL_REQUEST_INIT</span>(&amp;global_request,</span><br><span class="line">                     MDL_key::GLOBAL, <span class="string">&quot;&quot;</span>, <span class="string">&quot;&quot;</span>, MDL_INTENTION_EXCLUSIVE,</span><br><span class="line">                     MDL_STATEMENT);</span><br><span class="line">    mdl_requests.<span class="built_in">push_front</span>(&amp;global_request);</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// Phase 3: Acquire the locks which have been requested so far.</span></span><br><span class="line">  <span class="keyword">if</span> (thd-&gt;mdl_context.<span class="built_in">acquire_locks</span>(&amp;mdl_requests, lock_wait_timeout))</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">在open_table中也会请求锁。</span><br><span class="line"></span><br><span class="line">SHARED_NO_READ_WRITE的加锁源码参考LOCK TABLE WITH READ的源码分析。</span><br></pre></td></tr></table></figure>
<h4 id="SELECT查询语句的执行"><a class="header-anchor" href="#SELECT查询语句的执行"></a>SELECT查询语句的执行</h4>
<p>SELECT语句的执行加锁TABLE-TRANSACTION-SHARED_READ锁。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">select * from performance_schema.metadata_locks\G</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">          OBJECT_TYPE: TABLE</span><br><span class="line">        OBJECT_SCHEMA: test</span><br><span class="line">          OBJECT_NAME: t1</span><br><span class="line">            LOCK_TYPE: SHARED_READ</span><br><span class="line">        LOCK_DURATION: TRANSACTION</span><br><span class="line">          LOCK_STATUS: GRANTED</span><br><span class="line">               SOURCE: sql_parse.cc:5996</span><br></pre></td></tr></table></figure>
<p>源码分析：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Yacc_state</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">reset</span><span class="params">()</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    yacc_yyss= <span class="literal">NULL</span>;</span><br><span class="line">    yacc_yyvs= <span class="literal">NULL</span>;</span><br><span class="line">    yacc_yyls= <span class="literal">NULL</span>;</span><br><span class="line">    m_lock_type= TL_READ_DEFAULT;</span><br><span class="line">    m_mdl_type= MDL_SHARED_READ;</span><br><span class="line">    m_ha_rkey_mode= HA_READ_KEY_EXACT;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">调用add_table_to_list初始化锁，调用open_table_get_mdl_lock获取锁。</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">static</span> <span class="type">bool</span></span></span><br><span class="line"><span class="function"><span class="title">open_table_get_mdl_lock</span><span class="params">(THD *thd, Open_table_context *ot_ctx,</span></span></span><br><span class="line"><span class="params"><span class="function">                        TABLE_LIST *table_list, uint flags,</span></span></span><br><span class="line"><span class="params"><span class="function">                        MDL_ticket **mdl_ticket)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="type">bool</span> result= thd-&gt;mdl_context.<span class="built_in">acquire_lock</span>(mdl_request,</span><br><span class="line">                                           ot_ctx-&gt;<span class="built_in">get_timeout</span>());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="INSERT-UPDATE-DELETE语句"><a class="header-anchor" href="#INSERT-UPDATE-DELETE语句"></a>INSERT/UPDATE/DELETE语句</h4>
<p>在open table阶段会获取GLOBAL-STATEMENT-INTENTION_EXCLUSIVE，TABLE-TRANSACTION-SHARED_WRITE。</p>
<p>在commit阶段获取COMMIT-MDL_EXPLICIT-INTENTION_EXCLUSIVE锁。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">select OBJECT_TYPE,OBJECT_SCHEMA,OBJECT_NAME,LOCK_TYPE,LOCK_DURATION,SOURCE from performance_schema.metadata_locks\G</span><br><span class="line">OBJECT_TYPE: GLOBAL</span><br><span class="line">OBJECT_SCHEMA: NULL</span><br><span class="line">OBJECT_NAME: NULL</span><br><span class="line">  LOCK_TYPE: INTENTION_EXCLUSIVE</span><br><span class="line">LOCK_DURATION: STATEMENT</span><br><span class="line">     SOURCE: sql_base.cc:3190</span><br><span class="line">*************************** 2. row ***************************</span><br><span class="line">OBJECT_TYPE: TABLE</span><br><span class="line">OBJECT_SCHEMA: test</span><br><span class="line">OBJECT_NAME: ti</span><br><span class="line">  LOCK_TYPE: SHARED_WRITE</span><br><span class="line">LOCK_DURATION: TRANSACTION</span><br><span class="line">     SOURCE: sql_parse.cc:5996</span><br><span class="line">*************************** 3. row ***************************</span><br><span class="line">OBJECT_TYPE: COMMIT</span><br><span class="line">OBJECT_SCHEMA: NULL</span><br><span class="line">OBJECT_NAME: NULL</span><br><span class="line">  LOCK_TYPE: INTENTION_EXCLUSIVE</span><br><span class="line">LOCK_DURATION: EXPLICIT</span><br><span class="line">     SOURCE: handler.cc:1758</span><br></pre></td></tr></table></figure>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">sql/sql_yacc.yy</span><br><span class="line">insert_stmt:</span><br><span class="line">          INSERT                       <span class="comment">/* #1 */</span></span><br><span class="line">          insert_lock_option           <span class="comment">/* #2 */</span></span><br><span class="line"></span><br><span class="line">          insert_lock_option:</span><br><span class="line">                    <span class="comment">/* empty */</span>   &#123; $= TL_WRITE_CONCURRENT_DEFAULT; &#125;</span><br><span class="line">                  | LOW_PRIORITY  &#123; $= TL_WRITE_LOW_PRIORITY; &#125;</span><br><span class="line">                  | DELAYED_SYM</span><br><span class="line">                  &#123;</span><br><span class="line">                    $= TL_WRITE_CONCURRENT_DEFAULT;</span><br><span class="line"></span><br><span class="line">                    <span class="built_in">push_warning_printf</span>(YYTHD, Sql_condition::SL_WARNING,</span><br><span class="line">                                        ER_WARN_LEGACY_SYNTAX_CONVERTED,</span><br><span class="line">                                        <span class="built_in">ER</span>(ER_WARN_LEGACY_SYNTAX_CONVERTED),</span><br><span class="line">                                        <span class="string">&quot;INSERT DELAYED&quot;</span>, <span class="string">&quot;INSERT&quot;</span>);</span><br><span class="line">                  &#125;</span><br><span class="line">                  | HIGH_PRIORITY &#123; $= TL_WRITE; &#125;</span><br><span class="line">                  ;</span><br><span class="line"></span><br><span class="line"><span class="comment">//DELETE语句</span></span><br><span class="line">delete_stmt:</span><br><span class="line">          DELETE_SYM</span><br><span class="line">          opt_delete_options</span><br><span class="line"></span><br><span class="line"><span class="comment">//UPDATE</span></span><br><span class="line">update_stmt:</span><br><span class="line">  UPDATE_SYM            <span class="comment">/* #1 */</span></span><br><span class="line">  opt_low_priority      <span class="comment">/* #2 */</span></span><br><span class="line">  opt_ignore            <span class="comment">/* #3 */</span></span><br><span class="line">  join_table_list       <span class="comment">/* #4 */</span></span><br><span class="line">  SET                   <span class="comment">/* #5 */</span></span><br><span class="line">  update_list           <span class="comment">/* #6 */</span></span><br><span class="line"></span><br><span class="line">opt_low_priority:</span><br><span class="line">          <span class="comment">/* empty */</span> &#123; $= TL_WRITE_DEFAULT; &#125;</span><br><span class="line">        | LOW_PRIORITY &#123; $= TL_WRITE_LOW_PRIORITY; &#125;</span><br><span class="line">        ;</span><br><span class="line"></span><br><span class="line">opt_delete_options:</span><br><span class="line">          <span class="comment">/* empty */</span>                          &#123; $= <span class="number">0</span>; &#125;</span><br><span class="line">        | opt_delete_option opt_delete_options &#123; $= $<span class="number">1</span> | $<span class="number">2</span>; &#125;</span><br><span class="line">        ;</span><br><span class="line"></span><br><span class="line">opt_delete_option:</span><br><span class="line">          QUICK        &#123; $= DELETE_QUICK; &#125;</span><br><span class="line">        | LOW_PRIORITY &#123; $= DELETE_LOW_PRIORITY; &#125;</span><br><span class="line">        | IGNORE_SYM   &#123; $= DELETE_IGNORE; &#125;</span><br><span class="line">        ;</span><br><span class="line"></span><br><span class="line">sql/parse_tree_nodes.<span class="function">cc</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">PT_delete::add_table</span><span class="params">(Parse_context *pc, Table_ident *table)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="type">const</span> enum_mdl_type mdl_type=</span><br><span class="line">  (opt_delete_options &amp; DELETE_LOW_PRIORITY) ? MDL_SHARED_WRITE_LOW_PRIO</span><br><span class="line">                                             : MDL_SHARED_WRITE;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">PT_insert::contextualize</span><span class="params">(Parse_context *pc)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (!pc-&gt;select-&gt;<span class="built_in">add_table_to_list</span>(pc-&gt;thd, table_ident, <span class="literal">NULL</span>,</span><br><span class="line">                                   TL_OPTION_UPDATING,</span><br><span class="line">                                   yyps-&gt;m_lock_type,</span><br><span class="line">                                   yyps-&gt;m_mdl_type,</span><br><span class="line">                                   <span class="literal">NULL</span>,</span><br><span class="line">                                   opt_use_partition))</span><br><span class="line">   pc-&gt;select-&gt;<span class="built_in">set_lock_for_tables</span>(lock_option);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">PT_update::contextualize</span><span class="params">(Parse_context *pc)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  pc-&gt;select-&gt;<span class="built_in">set_lock_for_tables</span>(opt_low_priority);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">st_select_lex::set_lock_for_tables</span><span class="params">(thr_lock_type lock_type)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="type">bool</span> for_update= lock_type &gt;= TL_READ_NO_INSERT;</span><br><span class="line">  enum_mdl_type mdl_type= <span class="built_in">mdl_type_for_dml</span>(lock_type);</span><br><span class="line">  ...</span><br><span class="line">  tables-&gt;mdl_request.<span class="built_in">set_type</span>(mdl_type);</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="keyword">enum</span> enum_mdl_type <span class="title">mdl_type_for_dml</span><span class="params">(<span class="keyword">enum</span> thr_lock_type lock_type)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">return</span> lock_type &gt;= TL_WRITE_ALLOW_WRITE ?</span><br><span class="line">         (lock_type == TL_WRITE_LOW_PRIORITY ?</span><br><span class="line">          MDL_SHARED_WRITE_LOW_PRIO : MDL_SHARED_WRITE) :</span><br><span class="line">         MDL_SHARED_READ;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">最终调用open\_table加锁</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">open_table</span><span class="params">(THD *thd, TABLE_LIST *table_list, Open_table_context *ot_ctx)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (table_list-&gt;mdl_request.<span class="built_in">is_write_lock_request</span>() &amp;&amp;</span><br><span class="line">     ...</span><br><span class="line">  &#123;</span><br><span class="line">     <span class="built_in">MDL_REQUEST_INIT</span>(&amp;protection_request,</span><br><span class="line">                  MDL_key::GLOBAL, <span class="string">&quot;&quot;</span>, <span class="string">&quot;&quot;</span>, MDL_INTENTION_EXCLUSIVE,</span><br><span class="line">                  MDL_STATEMENT);</span><br><span class="line">     <span class="type">bool</span> result= thd-&gt;mdl_context.<span class="built_in">acquire_lock</span>(&amp;protection_request,</span><br><span class="line">                                                ot_ctx-&gt;<span class="built_in">get_timeout</span>());</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">if</span> (<span class="built_in">open_table_get_mdl_lock</span>(thd, ot_ctx, table_list, flags, &amp;mdl_ticket) ||</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">在commit阶段调用ha_commit_trans函数时加COMMIT的INTENTION_EXCLUSIVE锁，源码如FLUSH TABLES WITH READ LOCK所述。</span><br></pre></td></tr></table></figure>
<p>如果INSERT/UPDATE/DELETE LOW_PRIORITY语句TABLE上加MDL_SHARED_WRITE_LOW_PRIO锁。</p>
<h4 id="ALTER-TABLE-ALGORITHM-COPY-INPLACE"><a class="header-anchor" href="#ALTER-TABLE-ALGORITHM-COPY-INPLACE"></a>ALTER TABLE ALGORITHM=COPY[INPLACE]</h4>
<p>ALTER TABLE ALGORITHM=COPY</p>
<p>COPY方式ALTER TABLE在open_table阶段加GLOBAL-STATEMENT-INTENTION_EXCLUSIVE锁，SCHEMA-TRANSACTION-INTENTION_EXCLUSIVE锁，TABLE-TRANSACTION-SHARED_UPGRADABLE锁。</p>
<p>在拷贝数据前将TABLE-TRANSACTION-SHARED_UPGRADABLE锁升级到SHARED_NO_WRITE。</p>
<p>拷贝完在交换表阶段将SHARED_NO_WRITE锁升级到EXCLUSIVE锁。</p>
<p>源码解析：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">GLOBAL、SCHEMA锁初始化位置和LOCK TABLE WRITE位置一致都是在lock_table_names函数中。在open_table中也会请求锁。</span><br><span class="line"></span><br><span class="line">sql/sql_yacc.yy</span><br><span class="line">alter:</span><br><span class="line">          ALTER TABLE_SYM table_ident</span><br><span class="line">          &#123;</span><br><span class="line">            THD *thd= YYTHD;</span><br><span class="line">            LEX *lex= thd-&gt;lex;</span><br><span class="line">            lex-&gt;name.str= <span class="number">0</span>;</span><br><span class="line">            lex-&gt;name.length= <span class="number">0</span>;</span><br><span class="line">            lex-&gt;sql_command= SQLCOM_ALTER_TABLE;</span><br><span class="line">            lex-&gt;duplicates= DUP_ERROR;</span><br><span class="line">            <span class="keyword">if</span> (!lex-&gt;select_lex-&gt;<span class="built_in">add_table_to_list</span>(thd, $<span class="number">3</span>, <span class="literal">NULL</span>,</span><br><span class="line">                                                    TL_OPTION_UPDATING,</span><br><span class="line">                                                    TL_READ_NO_INSERT,</span><br><span class="line">                                                    MDL_SHARED_UPGRADABLE))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">mysql_alter_table</span><span class="params">(THD *thd, <span class="type">const</span> <span class="type">char</span> *new_db, <span class="type">const</span> <span class="type">char</span> *new_name,</span></span></span><br><span class="line"><span class="params"><span class="function">                       HA_CREATE_INFO *create_info,</span></span></span><br><span class="line"><span class="params"><span class="function">                       TABLE_LIST *table_list,</span></span></span><br><span class="line"><span class="params"><span class="function">                       Alter_info *alter_info)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="comment">//升级锁</span></span><br><span class="line">  <span class="keyword">if</span> (thd-&gt;mdl_context.<span class="built_in">upgrade_shared_lock</span>(mdl_ticket, MDL_SHARED_NO_WRITE,</span><br><span class="line">                                           thd-&gt;variables.lock_wait_timeout)</span><br><span class="line">      || <span class="built_in">lock_tables</span>(thd, table_list, alter_ctx.tables_opened, <span class="number">0</span>))</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">if</span> (<span class="built_in">wait_while_table_is_used</span>(thd, table, HA_EXTRA_PREPARE_FOR_RENAME))</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">wait_while_table_is_used</span><span class="params">(THD *thd, TABLE *table,</span></span></span><br><span class="line"><span class="params"><span class="function">                              <span class="keyword">enum</span> ha_extra_function function)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="built_in">DBUG_ENTER</span>(<span class="string">&quot;wait_while_table_is_used&quot;</span>);</span><br><span class="line">  <span class="built_in">DBUG_PRINT</span>(<span class="string">&quot;enter&quot;</span>, (<span class="string">&quot;table: &#x27;%s&#x27;  share: 0x%lx  db_stat: %u  version: %lu&quot;</span>,</span><br><span class="line">                       table-&gt;s-&gt;table_name.str, (ulong) table-&gt;s,</span><br><span class="line">                       table-&gt;db_stat, table-&gt;s-&gt;version));</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (thd-&gt;mdl_context.<span class="built_in">upgrade_shared_lock</span>(</span><br><span class="line">             table-&gt;mdl_ticket, MDL_EXCLUSIVE,</span><br><span class="line">             thd-&gt;variables.lock_wait_timeout))</span><br></pre></td></tr></table></figure>
<p>ALTER TABLE INPLACE的加锁：</p>
<p>INPLACE方式在打开表的时候也是加GLOBAL-STATEMENT-INTENTION_EXCLUSIVE锁，SCHEMA-TRANSACTION-INTENTION_EXCLUSIVE锁，TABLE-TRANSACTION-SHARED_UPGRADABLE锁。</p>
<p>在prepare前将TABLE-TRANSACTION-SHARED_UPGRADABLE升级为TABLE-TRANSACTION-EXCLUSIVE锁。</p>
<p>在prepare后会再将EXCLUSIVE根据不同引擎支持情况降级为SHARED_NO_WRITE(不允许其他线程写入)或者SHARED_UPGRADABLE锁（其他线程可以读写，InnoDB引擎）。</p>
<p>在commit前，TABLE上的锁会再次升级到EXCLUSIVE锁。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">sql/sql_table.<span class="function">cc</span></span><br><span class="line"><span class="function"><span class="type">static</span> <span class="type">bool</span> <span class="title">mysql_inplace_alter_table</span><span class="params">(THD *thd,</span></span></span><br><span class="line"><span class="params"><span class="function">                                      TABLE_LIST *table_list,</span></span></span><br><span class="line"><span class="params"><span class="function">                                      TABLE *table,</span></span></span><br><span class="line"><span class="params"><span class="function">                                      TABLE *altered_table,</span></span></span><br><span class="line"><span class="params"><span class="function">                                      Alter_inplace_info *ha_alter_info,</span></span></span><br><span class="line"><span class="params"><span class="function">                                      enum_alter_inplace_result inplace_supported,</span></span></span><br><span class="line"><span class="params"><span class="function">                                      MDL_request *target_mdl_request,</span></span></span><br><span class="line"><span class="params"><span class="function">                                      Alter_table_ctx *alter_ctx)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">if</span> (inplace_supported == HA_ALTER_INPLACE_SHARED_LOCK_AFTER_PREPARE ||</span><br><span class="line">           inplace_supported == HA_ALTER_INPLACE_NO_LOCK_AFTER_PREPARE)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">      Storage engine has requested exclusive lock only for prepare phase</span></span><br><span class="line"><span class="comment">      and we are not under LOCK TABLES.</span></span><br><span class="line"><span class="comment">      Don&#x27;t mark TABLE_SHARE as old in this case, as this won&#x27;t allow opening</span></span><br><span class="line"><span class="comment">      of table by other threads during main phase of in-place ALTER TABLE.</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="keyword">if</span> (thd-&gt;mdl_context.<span class="built_in">upgrade_shared_lock</span>(table-&gt;mdl_ticket, MDL_EXCLUSIVE,</span><br><span class="line">                                             thd-&gt;variables.lock_wait_timeout))</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">if</span> (table-&gt;file-&gt;<span class="built_in">ha_prepare_inplace_alter_table</span>(altered_table,</span><br><span class="line">                                                ha_alter_info))</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">if</span> ((inplace_supported == HA_ALTER_INPLACE_SHARED_LOCK_AFTER_PREPARE ||</span><br><span class="line">     inplace_supported == HA_ALTER_INPLACE_NO_LOCK_AFTER_PREPARE) &amp;&amp;</span><br><span class="line">    !(thd-&gt;locked_tables_mode == LTM_LOCK_TABLES ||</span><br><span class="line">      thd-&gt;locked_tables_mode == LTM_PRELOCKED_UNDER_LOCK_TABLES) &amp;&amp;</span><br><span class="line">    (alter_info-&gt;requested_lock != Alter_info::ALTER_TABLE_LOCK_EXCLUSIVE))</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="comment">/* If storage engine or user requested shared lock downgrade to SNW. */</span></span><br><span class="line">    <span class="keyword">if</span> (inplace_supported == HA_ALTER_INPLACE_SHARED_LOCK_AFTER_PREPARE ||</span><br><span class="line">        alter_info-&gt;requested_lock == Alter_info::ALTER_TABLE_LOCK_SHARED)</span><br><span class="line">      table-&gt;mdl_ticket-&gt;<span class="built_in">downgrade_lock</span>(MDL_SHARED_NO_WRITE);</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">      <span class="built_in">DBUG_ASSERT</span>(inplace_supported == HA_ALTER_INPLACE_NO_LOCK_AFTER_PREPARE);</span><br><span class="line">      table-&gt;mdl_ticket-&gt;<span class="built_in">downgrade_lock</span>(MDL_SHARED_UPGRADABLE);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// Upgrade to EXCLUSIVE before commit.</span></span><br><span class="line">  <span class="keyword">if</span> (<span class="built_in">wait_while_table_is_used</span>(thd, table, HA_EXTRA_PREPARE_FOR_RENAME))</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">if</span> (table-&gt;file-&gt;<span class="built_in">ha_commit_inplace_alter_table</span>(altered_table,</span><br><span class="line">                                               ha_alter_info,</span><br><span class="line">                                               <span class="literal">true</span>))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="CREATE-TABLE-加锁"><a class="header-anchor" href="#CREATE-TABLE-加锁"></a>CREATE TABLE 加锁</h4>
<p>CREATE TABLE先加锁GLOBAL-STATEMENT-INTENTION_EXCLUSIVE，SCHEMA-MDL_TRANSACTION-INTENTION_EXCLUSIVE，TABLE-TRANSACTION-SHARED。</p>
<p>表不存在则升级表上的SHARED锁到EXCLUSIVE。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">open_table</span><span class="params">(THD *thd, TABLE_LIST *table_list, Open_table_context *ot_ctx)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">if</span> (!exists)</span><br><span class="line">  &#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="type">bool</span> wait_result= thd-&gt;mdl_context.<span class="built_in">upgrade_shared_lock</span>(</span><br><span class="line">                         table_list-&gt;mdl_request.ticket,</span><br><span class="line">                         MDL_EXCLUSIVE,</span><br><span class="line">                         thd-&gt;variables.lock_wait_timeout);</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="DROP-TABLE-加锁"><a class="header-anchor" href="#DROP-TABLE-加锁"></a>DROP TABLE 加锁</h3>
<p>drop table语句执行加锁GLOBAL-STATEMENT-INTENTION_EXCLUSIVE，SCHEMA-MDL_TRANSACTION-INTENTION_EXCLUSIVE，TABLE-EXCLUSIVE。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">drop:</span><br><span class="line">          DROP opt_temporary table_or_tables if_exists</span><br><span class="line">          &#123;</span><br><span class="line">            LEX *lex=Lex;</span><br><span class="line">            lex-&gt;sql_command = SQLCOM_DROP_TABLE;</span><br><span class="line">            lex-&gt;drop_temporary= $<span class="number">2</span>;</span><br><span class="line">            lex-&gt;drop_if_exists= $<span class="number">4</span>;</span><br><span class="line">            YYPS-&gt;m_lock_type= TL_UNLOCK;</span><br><span class="line">            YYPS-&gt;m_mdl_type= MDL_EXCLUSIVE;</span><br><span class="line">          &#125;</span><br></pre></td></tr></table></figure>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/analysis-of-mdl-source-code-for-common-sql-statements/">http://xnerv.wang/analysis-of-mdl-source-code-for-common-sql-statements/</a></strong><br>
转载自：<a href="http://mysql.taobao.org/monthly/2018/02/01/">常用SQL语句的MDL加锁源码分析</a></p>
]]></content>
      <categories>
        <category>DBMS</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>DBMS</tag>
        <tag>MySQL</tag>
        <tag>MDL</tag>
      </tags>
  </entry>
  <entry>
    <title>UNIX/LINUX 平台可执行文件格式分析（转载）</title>
    <url>/analysis-of-unix-linux-platform-executable-file-format/</url>
    <content><![CDATA[<h2 id="可执行文件格式综述"><a class="header-anchor" href="#可执行文件格式综述"></a>可执行文件格式综述</h2>
<p>相对于其它文件类型，可执行文件可能是一个操作系统中最重要的文件类型，因为它们是完成操作的真正执行者。可执行文件的大小、运行速度、资源占用情况以及可扩展性、可移植性等与文件格式的定义和文件加载过程紧密相关。研究可执行文件的格式对编写高性能程序和一些黑客技术的运用都是非常有意义的。</p>
<p>不管何种可执行文件格式，一些基本的要素是必须的，显而易见的，文件中应包含代码和数据。因为文件可能引用外部文件定义的符号（变量和函数），因此重定位信息和符号信息也是需要的。一些辅助信息是可选的，如调试信息、硬件信息等。基本上任意一种可执行文件格式都是按区间保存上述信息，称为段（Segment）或节（Section）。不同的文件格式中段和节的含义可能有细微区别，但根据上下文关系可以很清楚的理解，这不是关键问题。最后，可执行文件通常都有一个文件头部以描述本文件的总体结构。</p>
<p>相对可执行文件有三个重要的概念：编译（compile）、连接（link，也可称为链接、联接）、加载（load）。源程序文件被编译成目标文件，多个目标文件被连接成一个最终的可执行文件，可执行文件被加载到内存中运行。因为本文重点是讨论可执行文件格式，因此加载过程也相对重点讨论。下面是LINUX平台下ELF文件加载过程的一个简单描述。</p>
<span id="more"></span>
<ol>
<li>
<p>内核首先读ELF文件的头部，然后根据头部的数据指示分别读入各种数据结构，找到标记为可加载（loadable）的段，并调用函数 mmap()把段内容加载到内存中。在加载之前，内核把段的标记直接传递给 mmap()，段的标记指示该段在内存中是否可读、可写，可执行。显然，文本段是只读可执行，而数据段是可读可写。这种方式是利用了现代操作系统和处理器对内存的保护功能。著名的Shellcode（ <a href="#artrelatedtopics">参考资料 17</a>）的编写技巧则是突破此保护功能的一个实际例子。</p>
</li>
<li>
<p>内核分析出ELF文件标记为 PT_INTERP 的段中所对应的动态连接器名称，并加载动态连接器。现代 LINUX 系统的动态连接器通常是 /lib/ld-linux.so.2，相关细节在后面有详细描述。</p>
</li>
<li>
<p>内核在新进程的堆栈中设置一些标记-值对，以指示动态连接器的相关操作。</p>
</li>
<li>
<p>内核把控制传递给动态连接器。</p>
</li>
<li>
<p>动态连接器检查程序对外部文件（共享库）的依赖性，并在需要时对其进行加载。</p>
</li>
<li>
<p>动态连接器对程序的外部引用进行重定位，通俗的讲，就是告诉程序其引用的外部变量/函数的地址，此地址位于共享库被加载在内存的区间内。动态连接还有一个延迟（Lazy）定位的特性，即只在&quot;真正&quot;需要引用符号时才重定位，这对提高程序运行效率有极大帮助。</p>
</li>
<li>
<p>动态连接器执行在ELF文件中标记为 .init 的节的代码，进行程序运行的初始化。在早期系统中，初始化代码对应函数 <code>_init(void)</code>(函数名强制固定)，在现代系统中，则对应形式为</p>
</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void</span><br><span class="line">__attribute((constructor))</span><br><span class="line">init_function(void)</span><br><span class="line">&#123;</span><br><span class="line">……</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中函数名为任意。</p>
<p>8：动态连接器把控制传递给程序，从 ELF 文件头部中定义的程序进入点开始执行。在 a.out 格式和ELF格式中，程序进入点的值是显式存在的，在 COFF 格式中则是由规范隐含定义。</p>
<p>从上面的描述可以看出，加载文件最重要的是完成两件事情：加载程序段和数据段到内存；进行外部定义符号的重定位。重定位是程序连接中一个重要概念。我们知道，一个可执行程序通常是由一个含有 main() 的主程序文件、若干目标文件、若干共享库（Shared Libraries）组成。（注：采用一些特别的技巧，也可编写没有 main 函数的程序，请参阅 <a href="#artrelatedtopics">参考资料 2</a>）一个 C 程序可能引用共享库定义的变量或函数，换句话说就是程序运行时必须知道这些变量/函数的地址。在静态连接中，程序所有需要使用的外部定义都完全包含在可执行程序中，而动态连接则只在可执行文件中设置相关外部定义的一些引用信息，真正的重定位是在程序运行之时。静态连接方式有两个大问题：如果库中变量或函数有任何变化都必须重新编译连接程序；如果多个程序引用同样的变量/函数，则此变量/函数会在文件/内存中出现多次，浪费硬盘/内存空间。比较两种连接方式生成的可执行文件的大小，可以看出有明显的区别。</p>
<h2 id="a-out-文件格式分析"><a class="header-anchor" href="#a-out-文件格式分析"></a>a.out 文件格式分析</h2>
<p>a.out 格式在不同的机器平台和不同的 UNIX 操作系统上有轻微的不同，例如在 MC680x0 平台上有 6 个 section。下面我们讨论的是最&quot;标准&quot;的格式。</p>
<p>a.out 文件包含 7 个 section，格式如下：</p>
<table>
<thead>
<tr>
<th>exec header（执行头部，也可理解为文件头部）</th>
</tr>
</thead>
<tbody>
<tr>
<td>text segment（文本段）</td>
</tr>
<tr>
<td>data segment(数据段)</td>
</tr>
<tr>
<td>text relocations(文本重定位段)</td>
</tr>
<tr>
<td>data relocations（数据重定位段）</td>
</tr>
<tr>
<td>symbol table（符号表）</td>
</tr>
<tr>
<td>string table（字符串表）</td>
</tr>
</tbody>
</table>
<p>执行头部的数据结构：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">exec</span> &#123;</span></span><br><span class="line">        <span class="type">unsigned</span> <span class="type">long</span>   a_midmag;    <span class="comment">/* 魔数和其它信息 */</span></span><br><span class="line">        <span class="type">unsigned</span> <span class="type">long</span>   a_text;      <span class="comment">/* 文本段的长度 */</span></span><br><span class="line">        <span class="type">unsigned</span> <span class="type">long</span>   a_data;      <span class="comment">/* 数据段的长度 */</span></span><br><span class="line">        <span class="type">unsigned</span> <span class="type">long</span>   a_bss;       <span class="comment">/* BSS段的长度 */</span></span><br><span class="line">        <span class="type">unsigned</span> <span class="type">long</span>   a_syms;      <span class="comment">/* 符号表的长度 */</span></span><br><span class="line">        <span class="type">unsigned</span> <span class="type">long</span>   a_entry;     <span class="comment">/* 程序进入点 */</span></span><br><span class="line">        <span class="type">unsigned</span> <span class="type">long</span>   a_trsize;    <span class="comment">/* 文本重定位表的长度 */</span></span><br><span class="line">        <span class="type">unsigned</span> <span class="type">long</span>   a_drsize;    <span class="comment">/* 数据重定位表的长度 */</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>文件头部主要描述了各个 section 的长度，比较重要的字段是 a_entry（程序进入点），代表了系统在加载程序并初试化各种环境后开始执行程序代码的入口。这个字段在后面讨论的 ELF 文件头部中也有出现。由 a.out 格式和头部数据结构我们可以看出，a.out 的格式非常紧凑，只包含了程序运行所必须的信息（文本、数据、BSS），而且每个 section 的顺序是固定的。这种结构缺乏扩展性，如不能包含&quot;现代&quot;可执行文件中常见的调试信息，最初的 UNIX 黑客对 a.out 文件调试使用的工具是 adb，而 adb 是一种机器语言调试器！</p>
<p>a.out 文件中包含符号表和两个重定位表，这三个表的内容在连接目标文件以生成可执行文件时起作用。在最终可执行的 a.out 文件中，这三个表的长度都为 0。a.out 文件在连接时就把所有外部定义包含在可执行程序中，如果从程序设计的角度来看，这是一种硬编码方式，或者可称为模块之间是强藕和的。在后面的讨论中，我们将会具体看到ELF格式和动态连接机制是如何对此进行改进的。</p>
<p>a.out 是早期UNIX系统使用的可执行文件格式，由<code>AT&amp;T</code>设计，现在基本上已被 ELF 文件格式代替。a.out 的设计比较简单，但其设计思想明显的被后续的可执行文件格式所继承和发扬。可以参阅 <a href="#artrelatedtopics">参考资料 16</a> 和阅读 <a href="#artrelatedtopics">参考资料 15</a> 源代码加深对 a.out 格式的理解。 <a href="#artrelatedtopics">参考资料 12</a> 讨论了如何在&quot;现代&quot;的红帽LINUX运行 a.out 格式文件。</p>
<h2 id="COFF-文件格式分析"><a class="header-anchor" href="#COFF-文件格式分析"></a>COFF 文件格式分析</h2>
<p>COFF 格式比 a.out 格式要复杂一些，最重要的是包含一个节段表(section table)，因此除了 .text，.data，和 .bss 区段以外，还可以包含其它的区段。另外也多了一个可选的头部，不同的操作系统可一对此头部做特定的定义。</p>
<p>COFF 文件格式如下：</p>
<table>
<thead>
<tr>
<th>File Header(文件头部)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Optional Header(可选文件头部)</td>
</tr>
<tr>
<td>Section 1 Header(节头部)</td>
</tr>
<tr>
<td>………</td>
</tr>
<tr>
<td>Section n Header(节头部)</td>
</tr>
<tr>
<td>Raw Data for Section 1(节数据)</td>
</tr>
<tr>
<td>Raw Data for Section n(节数据)</td>
</tr>
<tr>
<td>Relocation Info for Sect. 1(节重定位数据)</td>
</tr>
<tr>
<td>Relocation Info for Sect. n(节重定位数据)</td>
</tr>
<tr>
<td>Line Numbers for Sect. 1(节行号数据)</td>
</tr>
<tr>
<td>Line Numbers for Sect. n(节行号数据)</td>
</tr>
<tr>
<td>Symbol table(符号表)</td>
</tr>
<tr>
<td>String table(字符串表)</td>
</tr>
</tbody>
</table>
<p>文件头部的数据结构：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">filehdr</span></span></span><br><span class="line"><span class="class">   &#123;</span></span><br><span class="line">        <span class="type">unsigned</span> <span class="type">short</span>  f_magic;    <span class="comment">/* 魔数 */</span></span><br><span class="line">       <span class="type">unsigned</span> <span class="type">short</span>  f_nscns;    <span class="comment">/* 节个数 */</span></span><br><span class="line">       <span class="type">long</span>            f_timdat;   <span class="comment">/* 文件建立时间 */</span></span><br><span class="line">       <span class="type">long</span>            f_symptr;   <span class="comment">/* 符号表相对文件的偏移量 */</span></span><br><span class="line">       <span class="type">long</span>            f_nsyms;    <span class="comment">/* 符号表条目个数 */</span></span><br><span class="line">       <span class="type">unsigned</span> <span class="type">short</span>  f_opthdr;   <span class="comment">/* 可选头部长度 */</span></span><br><span class="line">       <span class="type">unsigned</span> <span class="type">short</span>  f_flags;    <span class="comment">/* 标志 */</span></span><br><span class="line">   &#125;;</span><br></pre></td></tr></table></figure>
<p>COFF 文件头部中魔数与其它两种格式的意义不太一样，它是表示针对的机器类型，例如 0x014c 相对于 I386 平台，而 0x268 相对于 Motorola 68000系列等。当 COFF 文件为可执行文件时，字段 f_flags 的值为 F_EXEC（0X00002），同时也表示此文件没有未解析的符号，换句话说，也就是重定位在连接时就已经完成。由此也可以看出，原始的 COFF 格式不支持动态连接。为了解决这个问题以及增加一些新的特性，一些操作系统对 COFF 格式进行了扩展。Microsoft 设计了名为 PE（Portable Executable）的文件格式，主要扩展是在 COFF 文件头部之上增加了一些专用头部，具体细节请参阅 <a href="#artrelatedtopics">参考资料 18</a>，某些 UNIX 系统也对 COFF 格式进行了扩展，如 XCOFF（extended common object file format）格式，支持动态连接，请参阅 <a href="#artrelatedtopics">参考资料 5</a>。</p>
<p>紧接文件头部的是可选头部，COFF 文件格式规范中规定可选头部的长度可以为 0，但在 LINUX 系统下可选头部是必须存在的。下面是 LINUX 下可选头部的数据结构：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">        <span class="type">char</span>   magic[<span class="number">2</span>];                <span class="comment">/* 魔数 */</span></span><br><span class="line">        <span class="type">char</span>   vstamp[<span class="number">2</span>];               <span class="comment">/* 版本号 */</span></span><br><span class="line">        <span class="type">char</span>   tsize[<span class="number">4</span>];                <span class="comment">/* 文本段长度 */</span></span><br><span class="line">        <span class="type">char</span>   dsize[<span class="number">4</span>];                <span class="comment">/* 已初始化数据段长度 */</span></span><br><span class="line">        <span class="type">char</span>   bsize[<span class="number">4</span>];                <span class="comment">/* 未初始化数据段长度 */</span></span><br><span class="line">        <span class="type">char</span>   entry[<span class="number">4</span>];                <span class="comment">/* 程序进入点 */</span></span><br><span class="line">        <span class="type">char</span>   text_start[<span class="number">4</span>];       <span class="comment">/* 文本段基地址 */</span></span><br><span class="line">        <span class="type">char</span>   data_start[<span class="number">4</span>];       <span class="comment">/* 数据段基地址 */</span></span><br><span class="line">&#125;</span><br><span class="line">COFF_AOUTHDR;</span><br></pre></td></tr></table></figure>
<p>字段 magic 为 0413 时表示 COFF 文件是可执行的，注意到可选头部中显式定义了程序进入点，标准的 COFF 文件没有明确的定义程序进入点的值，通常是从 .text 节开始执行，但这种设计并不好。</p>
<p>前面我们提到，COFF 格式比 a.out 格式多了一个节段表，一个节头条目描述一个节数据的细节，因此 COFF 格式能包含更多的节，或者说可以根据实际需要，增加特定的节，具体表现在 COFF 格式本身的定义以及稍早提及的 COFF 格式扩展。我个人认为，节段表的出现可能是 COFF 格式相对 a.out 格式最大的进步。下面我们将简单描述 COFF 文件中节的数据结构，因为节的意义更多体现在程序的编译和连接上，所以本文不对其做更多的描述。此外，ELF 格式和 COFF格式对节的定义非常相似，在随后的 ELF 格式分析中，我们将省略相关讨论。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">COFF_scnhdr</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">        <span class="type">char</span>    s_name[<span class="number">8</span>];                  <span class="comment">/* 节名称 */</span></span><br><span class="line">        <span class="type">char</span>    s_paddr[<span class="number">4</span>];             <span class="comment">/* 物理地址 */</span></span><br><span class="line">        <span class="type">char</span>    s_vaddr[<span class="number">4</span>];             <span class="comment">/* 虚拟地址 */</span></span><br><span class="line">        <span class="type">char</span>    s_size[<span class="number">4</span>];                  <span class="comment">/* 节长度 */</span></span><br><span class="line">        <span class="type">char</span>    s_scnptr[<span class="number">4</span>];                <span class="comment">/* 节数据相对文件的偏移量 */</span></span><br><span class="line">        <span class="type">char</span>    s_relptr[<span class="number">4</span>];                <span class="comment">/* 节重定位信息偏移量 */</span></span><br><span class="line">        <span class="type">char</span>    s_lnnoptr[<span class="number">4</span>];               <span class="comment">/* 节行信息偏移量 */</span></span><br><span class="line">        <span class="type">char</span>    s_nreloc[<span class="number">2</span>];                <span class="comment">/* 节重定位条目数 */</span></span><br><span class="line">        <span class="type">char</span>    s_nlnno[<span class="number">2</span>];             <span class="comment">/* 节行信息条目数 */</span></span><br><span class="line">        <span class="type">char</span>    s_flags[<span class="number">4</span>];             <span class="comment">/* 段标记 */</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>有一点需要注意：LINUX系统中头文件coff.h中对字段s_paddr的注释是&quot;physical address&quot;，但似乎应该理解为&quot;节被加载到内存中所占用的空间长度&quot;。字段s_flags标记该节的类型，如文本段、数据段、BSS段等。在COFF的节中也出现了行信息，行信息描述了二进制代码与源代码的行号之间的对映关系，在调试时很有用。</p>
<p><a href="#artrelatedtopics">参考资料 19</a>是一份对COFF格式详细描述的中文资料，更详细的内容请参阅 <a href="#artrelatedtopics">参考资料 20</a>。</p>
<h2 id="ELF文件格式分析"><a class="header-anchor" href="#ELF文件格式分析"></a>ELF文件格式分析</h2>
<p>ELF文件有三种类型： 可重定位文件：也就是通常称的目标文件，后缀为.o。 共享文件：也就是通常称的库文件，<a href="http://xn--siqw5lms6b.so">后缀为.so</a>。 可执行文件：本文主要讨论的文件格式，总的来说，可执行文件的格式与上述两种文件的格式之间的区别主要在于观察的角度不同：一种称为连接视图（Linking View），一种称为执行视图（Execution View）。</p>
<p>首先看看ELF文件的总体布局：</p>
<table>
<thead>
<tr>
<th>ELF header(ELF头部)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Program header table(程序头表)</td>
</tr>
<tr>
<td>Segment1（段1）</td>
</tr>
<tr>
<td>Segment2（段2）</td>
</tr>
<tr>
<td>………</td>
</tr>
<tr>
<td>Sengmentn（段n）</td>
</tr>
<tr>
<td>Setion header table(节头表，可选)</td>
</tr>
</tbody>
</table>
<p>段由若干个节(Section)构成,节头表对每一个节的信息有相关描述。对可执行程序而言，节头表是可选的。 <a href="#artrelatedtopics">参考资料 1</a>中作者谈到把节头表的所有数据全部设置为0，程序也能正确运行！ELF头部是一个关于本文件的路线图（road map），从总体上描述文件的结构。下面是ELF头部的数据结构：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">        <span class="type">unsigned</span> <span class="type">char</span> e_ident[EI_NIDENT];     <span class="comment">/* 魔数和相关信息 */</span></span><br><span class="line">        Elf32_Half    e_type;                 <span class="comment">/* 目标文件类型 */</span></span><br><span class="line">        Elf32_Half    e_machine;              <span class="comment">/* 硬件体系 */</span></span><br><span class="line">        Elf32_Word    e_version;              <span class="comment">/* 目标文件版本 */</span></span><br><span class="line">        Elf32_Addr    e_entry;                <span class="comment">/* 程序进入点 */</span></span><br><span class="line">        Elf32_Off     e_phoff;                <span class="comment">/* 程序头部偏移量 */</span></span><br><span class="line">        Elf32_Off     e_shoff;                <span class="comment">/* 节头部偏移量 */</span></span><br><span class="line">        Elf32_Word    e_flags;                <span class="comment">/* 处理器特定标志 */</span></span><br><span class="line">        Elf32_Half    e_ehsize;               <span class="comment">/* ELF头部长度 */</span></span><br><span class="line">        Elf32_Half    e_phentsize;            <span class="comment">/* 程序头部中一个条目的长度 */</span></span><br><span class="line">        Elf32_Half    e_phnum;                <span class="comment">/* 程序头部条目个数  */</span></span><br><span class="line">        Elf32_Half    e_shentsize;            <span class="comment">/* 节头部中一个条目的长度 */</span></span><br><span class="line">        Elf32_Half    e_shnum;                <span class="comment">/* 节头部条目个数 */</span></span><br><span class="line">        Elf32_Half    e_shstrndx;             <span class="comment">/* 节头部字符表索引 */</span></span><br><span class="line">&#125; Elf32_Ehdr;</span><br></pre></td></tr></table></figure>
<p>下面我们对ELF头表中一些重要的字段作出相关说明，完整的ELF定义请参阅 <a href="#artrelatedtopics">参考资料6</a>和 <a href="#artrelatedtopics">参考资料 7</a>。</p>
<p>e_ident[0]-e_ident[3]包含了ELF文件的魔数，依次是0x7f、‘E’、‘L’、‘F’。注意，任何一个ELF文件必须包含此魔数。 <a href="#artrelatedtopics">参考资料 3</a>中讨论了利用程序、工具、/Proc文件系统等多种查看ELF魔数的方法。e_ident[4]表示硬件系统的位数，1代表32位，2代表64位。e_ident[5]表示数据编码方式，1代表小印第安排序（最大有意义的字节占有最低的地址），2代表大印第安排序（最大有意义的字节占有最高的地址）。e_ident[6]指定ELF头部的版本，当前必须为1。e_ident[7]到e_ident[14]是填充符，通常是0。ELF格式规范中定义这几个字节是被忽略的，但实际上是这几个字节完全可以可被利用。如病毒Lin/Glaurung.676/666（ <a href="#artrelatedtopics">参考资料 1</a>）设置e_ident[7]为0x21,表示本文件已被感染；或者存放可执行代码（ <a href="#artrelatedtopics">参考资料 2</a>）。ELF头部中大多数字段都是对子头部数据的描述，其意义相对比较简单。值得注意的是某些病毒可能修改字段e_entry（程序进入点）的值，以指向病毒代码，例如上面提到的病毒Lin/Glaurung.676/666。</p>
<p>一个实际可执行文件的文件头部形式如下：（利用命令readelf）</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">ELF Header:</span><br><span class="line">Magic:   <span class="number">7f</span> <span class="number">45</span> <span class="number">4</span>c <span class="number">46</span> <span class="number">01</span> <span class="number">01</span> <span class="number">01</span> <span class="number">00</span> <span class="number">00</span> <span class="number">00</span> <span class="number">00</span> <span class="number">00</span> <span class="number">00</span> <span class="number">00</span> <span class="number">00</span> <span class="number">00</span></span><br><span class="line">Class:                             ELF32</span><br><span class="line">Data:                              <span class="number">2&#x27;</span>s complement, little endian</span><br><span class="line">Version:                           <span class="number">1</span> (current)</span><br><span class="line">OS/ABI:                            UNIX - System V</span><br><span class="line">ABI Version:                       <span class="number">0</span></span><br><span class="line">Type:                              EXEC (Executable file)</span><br><span class="line">Machine:                           Intel <span class="number">80386</span></span><br><span class="line">Version:                           <span class="number">0x1</span></span><br><span class="line">Entry point address:               <span class="number">0x80483cc</span></span><br><span class="line">Start of program headers:          <span class="number">52</span> (bytes into file)</span><br><span class="line">Start of section headers:          <span class="number">14936</span> (bytes into file)</span><br><span class="line">Flags:                             <span class="number">0x0</span></span><br><span class="line">Size of this header:               <span class="number">52</span> (bytes)</span><br><span class="line">Size of program headers:           <span class="number">32</span> (bytes)</span><br><span class="line">Number of program headers:         <span class="number">6</span></span><br><span class="line">Size of section headers:           <span class="number">40</span> (bytes)</span><br><span class="line">Number of section headers:         <span class="number">34</span></span><br><span class="line">Section header <span class="built_in">string</span> table index: <span class="number">31</span></span><br></pre></td></tr></table></figure>
<p>紧接ELF头部的是程序头表，它是一个结构数组，包含了ELF头表中字段e_phnum定义的条目，结构描述一个段或其他系统准备执行该程序所需要的信息。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">      Elf32_Word  p_type;               <span class="comment">/* 段类型 */</span></span><br><span class="line">      Elf32_Off   p_offset;             <span class="comment">/* 段位置相对于文件开始处的偏移量 */</span></span><br><span class="line">      Elf32_Addr  p_vaddr;              <span class="comment">/* 段在内存中的地址 */</span></span><br><span class="line">      Elf32_Addr  p_paddr;              <span class="comment">/* 段的物理地址 */</span></span><br><span class="line">      Elf32_Word  p_filesz;             <span class="comment">/* 段在文件中的长度 */</span></span><br><span class="line">      Elf32_Word  p_memsz;              <span class="comment">/* 段在内存中的长度 */</span></span><br><span class="line">      Elf32_Word  p_flags;              <span class="comment">/* 段的标记 */</span></span><br><span class="line">      Elf32_Word  p_align;              <span class="comment">/* 段在内存中对齐标记 */</span></span><br><span class="line">  &#125; Elf32_Phdr;</span><br></pre></td></tr></table></figure>
<p>在详细讨论可执行文件程序头表之前，首先查看一个实际文件的输出：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Program Headers:</span><br><span class="line">Type           Offset   VirtAddr   PhysAddr   FileSiz MemSiz  Flg Align</span><br><span class="line">PHDR           0x000034 0x08048034 0x08048034 0x000c0 0x000c0 R E 0x4</span><br><span class="line">INTERP         0x0000f4 0x080480f4 0x080480f4 0x00013 0x00013 R   0x1</span><br><span class="line">      [Requesting program interpreter: /lib/ld-linux.so.2]</span><br><span class="line">    LOAD           0x000000 0x08048000 0x08048000 0x00684 0x00684 R E 0x1000</span><br><span class="line">    LOAD           0x000684 0x08049684 0x08049684 0x00118 0x00130 RW  0x1000</span><br><span class="line">    DYNAMIC        0x000690 0x08049690 0x08049690 0x000c8 0x000c8 RW  0x4</span><br><span class="line">    NOTE           0x000108 0x08048108 0x08048108 0x00020 0x00020 R   0x4</span><br><span class="line">    Section to Segment mapping:</span><br><span class="line">  Segment Sections...</span><br><span class="line">   00</span><br><span class="line">   01     .interp</span><br><span class="line">   02     .interp .note.ABI-tag .<span class="built_in">hash</span> .dynsym .dynstr .gnu.version</span><br><span class="line">           .gnu.version_r .rel.dyn .rel.plt .init .plt .text .fini .rodata .eh_frame</span><br><span class="line">   03     .data .dynamic .ctors .dtors .jcr .got .bss</span><br><span class="line">   04     .dynamic</span><br><span class="line">05     .note.ABI-tag</span><br><span class="line">Section Headers:</span><br><span class="line">  [Nr] Name              Type            Addr     Off    Size   ES Flg Lk Inf Al</span><br><span class="line">  [ 0]                   NULL            00000000 000000 000000 00      0   0  0</span><br><span class="line">  [ 1] .interp           PROGBITS        080480f4 0000f4 000013 00   A  0   0  1</span><br><span class="line">  [ 2] .note.ABI-tag     NOTE            08048108 000108 000020 00   A  0   0  4</span><br><span class="line">  [ 3] .<span class="built_in">hash</span>             HASH            08048128 000128 000040 04   A  4   0  4</span><br><span class="line">  [ 4] .dynsym           DYNSYM          08048168 000168 0000b0 10   A  5   1  4</span><br><span class="line">  [ 5] .dynstr           STRTAB          08048218 000218 00007b 00   A  0   0  1</span><br><span class="line">  [ 6] .gnu.version      VERSYM          08048294 000294 000016 02   A  4   0  2</span><br><span class="line">  [ 7] .gnu.version_r    VERNEED         080482ac 0002ac 000030 00   A  5   1  4</span><br><span class="line">  [ 8] .rel.dyn          REL             080482dc 0002dc 000008 08   A  4   0  4</span><br><span class="line">  [ 9] .rel.plt          REL             080482e4 0002e4 000040 08   A  4   b  4</span><br><span class="line">  [10] .init             PROGBITS        08048324 000324 000017 00  AX  0   0  4</span><br><span class="line">  [11] .plt              PROGBITS        0804833c 00033c 000090 04  AX  0   0  4</span><br><span class="line">  [12] .text             PROGBITS        080483cc 0003cc 0001f8 00  AX  0   0  4</span><br><span class="line">  [13] .fini             PROGBITS        080485c4 0005c4 00001b 00  AX  0   0  4</span><br><span class="line">  [14] .rodata           PROGBITS        080485e0 0005e0 00009f 00   A  0   0 32</span><br><span class="line">  [15] .eh_frame         PROGBITS        08048680 000680 000004 00   A  0   0  4</span><br><span class="line">  [16] .data             PROGBITS        08049684 000684 00000c 00  WA  0   0  4</span><br><span class="line">  [17] .dynamic          DYNAMIC         08049690 000690 0000c8 08  WA  5   0  4</span><br><span class="line">  [18] .ctors            PROGBITS        08049758 000758 000008 00  WA  0   0  4</span><br><span class="line">  [19] .dtors            PROGBITS        08049760 000760 000008 00  WA  0   0  4</span><br><span class="line">  [20] .jcr              PROGBITS        08049768 000768 000004 00  WA  0   0  4</span><br><span class="line">  [21] .got              PROGBITS        0804976c 00076c 000030 04  WA  0   0  4</span><br><span class="line">  [22] .bss              NOBITS          0804979c 00079c 000018 00  WA  0   0  4</span><br><span class="line">  [23] .comment          PROGBITS        00000000 00079c 000132 00      0   0  1</span><br><span class="line">  [24] .debug_aranges    PROGBITS        00000000 0008d0 000098 00      0   0  8</span><br><span class="line">  [25] .debug_pubnames   PROGBITS        00000000 000968 000040 00      0   0  1</span><br><span class="line">  [26] .debug_info       PROGBITS        00000000 0009a8 001cc6 00      0   0  1</span><br><span class="line">  [27] .debug_abbrev     PROGBITS        00000000 00266e 0002cc 00      0   0  1</span><br><span class="line">  [28] .debug_line       PROGBITS        00000000 00293a 0003dc 00      0   0  1</span><br><span class="line">  [29] .debug_frame      PROGBITS        00000000 002d18 000048 00      0   0  4</span><br><span class="line">  [30] .debug_str        PROGBITS        00000000 002d60 000bcd 01  MS  0   0  1</span><br><span class="line">  [31] .shstrtab         STRTAB          00000000 00392d 00012b 00      0   0  1</span><br><span class="line">  [32] .symtab           SYMTAB          00000000 003fa8 000740 10     33  56  4</span><br><span class="line">  [33] .strtab           STRTAB          00000000 0046e8 000467 00      0   0  1</span><br></pre></td></tr></table></figure>
<p>对一个ELF可执行程序而言，一个基本的段是标记p_type为PT_INTERP的段，它表明了运行此程序所需要的程序解释器（/lib/ld-linux.so.2），实际上也就是动态连接器（dynamic linker）。最重要的段是标记p_type为PT_LOAD的段，它表明了为运行程序而需要加载到内存的数据。查看上面实际输入，可以看见有两个可LOAD段，第一个为只读可执行（FLg为R E）,第二个为可读可写（Flg为RW）。段1包含了文本节.text，注意到ELF文件头部中程序进入点的值为0x80483cc，正好是指向节.text在内存中的地址。段二包含了数据节.data，此数据节中数据是可读可写的，相对的只读数据节.rodata包含在段1中。ELF格式可以比COFF格式包含更多的调试信息，如上面所列出的形式为.debug_xxx的节。在I386平台LINUX系统下，用命令file查看一个ELF可执行程序的可能输出是：a.out: ELF 32-bit LSB executable, Intel 80386, version 1 (SYSV), for GNU/Linux 2.2.5, dynamically linked (uses shared libs), not stripped。</p>
<p>ELF文件中包含了动态连接器的全路径，内核定位&quot;正确&quot;的动态连接器在内存中的地址是&quot;正确&quot;运行可执行文件的保证， <a href="#artrelatedtopics">参考资料 13</a>讨论了如何通过查找动态连接器在内存中的地址以达到颠覆（Subversiver）动态连接机制的方法。</p>
<p>最后我们讨论ELF文件的动态连接机制。每一个外部定义的符号在全局偏移表(Global Offset Table GOT)中有相应的条目,如果符号是函数则在过程连接表(Procedure Linkage Table PLT)中也有相应的条目，且一个PLT条目对应一个GOT条目。对外部定义函数解析可能是整个ELF文件规范中最复杂的，下面是函数符号解析过程的一个描述。</p>
<ol>
<li>
<p>代码中调用外部函数func,语句形式为call 0xaabbccdd,地址0xaabbccdd实际上就是符号func在PLT表中对应的条目地址（假设地址为标号.PLT2）。</p>
</li>
<li>
<p>PLT表的形式如下</p>
</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">.PLT0: pushl   4(%ebx)    /* GOT表的地址保存在寄存器ebx中 */</span><br><span class="line">jmp     *8(%ebx)</span><br><span class="line">nop; nop</span><br><span class="line">nop; nop</span><br><span class="line">.PLT1:  jmp     *name1@GOT(%ebx)</span><br><span class="line">pushl   <span class="variable">$offset</span></span><br><span class="line">jmp     .PLT0@PC</span><br><span class="line">.PLT2:  jmp     *func@GOT(%ebx)</span><br><span class="line">pushl   <span class="variable">$offset</span></span><br><span class="line">jmp     .PLT0@PC</span><br></pre></td></tr></table></figure>
<ol start="3">
<li>
<p>查看标号.PLT2的语句,实际上是跳转到符号func在GOT表中对应的条目。</p>
</li>
<li>
<p>在符号没有重定位前，GOT表中此符号对应的地址为标号.PLT2的下一条语句，即是pushl $offset，其中$offset是符号func的重定位偏移量。注意到这是一个二次跳转。</p>
</li>
<li>
<p>在符号func的重定位偏移量压栈后,控制跳到PLT表的第一条目，把GOT[1]的内容压栈，并跳转到GOT[2]对应的地址。</p>
</li>
<li>
<p>GOT[2]对应的实际上是动态符号解析函数的代码，在对符号func的地址解析后，会把func在内存中的地址设置到GOT表中此符号对应的条目中。</p>
</li>
<li>
<p>当第二次调用此符号时，GOT表中对应的条目已经包含了此符号的地址，就可直接调用而不需要利用PLT表进行跳转。</p>
</li>
</ol>
<p>动态连接是比较复杂的，但为了获得灵活性的代价通常就是复杂性。其最终目的是把GOT表中条目的值修改为符号的真实地址，这也可解释节.got包含在可读可写段中。</p>
<p>动态连接是一个非常重要的进步，这意味着库文件可以被升级、移动到其他目录等等而不需要重新编译程序（当然，这不意味库可以任意修改，如函数入参的个数、数据类型应保持兼容性）。从很大程度上说，动态连接机制是ELF格式代替a.out格式的决定性原因。如果说面对对象的编程本质是面对接口（interface）的编程，那么动态连接机制则是这种思想的地一个非常典型的应用，具体的讲，动态连接机制与设计模式中的桥接（BRIDGE）方法比较类似，而它的LAZY特性则与代理（PROXY）方法非常相似。动态连接操作的细节描述请参阅 <a href="#artrelatedtopics">参考资料 8，9，10，11</a>。通过阅读命令readelf、objdump 的源代码以及 <a href="#artrelatedtopics">参考资料 14</a>中所提及的相关软件源代码，可以对ELF文件的格式有更彻底的了解。</p>
<h2 id="总结"><a class="header-anchor" href="#总结"></a>总结</h2>
<p>不同时期的可执行文件格式深刻的反映了技术进步的过程，技术进步通常是针对解决存在的问题和适应新的环境。早期的UNIX系统使用a.out格式，随着操作系统和硬件系统的进步，a.out格式的局限性越来越明显。新的可执行文件格式COFF在UNIX System VR3中出现，COFF格式相对a.out格式最大变化是多了一个节头表（section head table），能够在包含基础的文本段、数据段、BSS段之外包含更多的段，但是COFF对动态连接和C++程序的支持仍然比较困难。为了解决上述问题，UNIX系统实验室(UNIX SYSTEM Laboratories USL) 开发出ELF文件格式，它被作为应用程序二进制接口（Application binary Interface ABI）的一部分，其目的是替代传统的a.out格式。例如，ELF文件格式中引入初始化段.init和结束段.fini（分别对应构造函数和析构函数）则主要是为了支持C++程序。1994年6月ELF格式出现在LINUX系统上，现在ELF格式作为UNIX/LINUX最主要的可执行文件格式。当然我们完全有理由相信，在将来还会有新的可执行文件格式出现。</p>
<p>上述三种可执行文件格式都很好的体现了设计思想中分层的概念，由一个总的头部刻画了文件的基本要素，再由若干子头部/条目刻画了文件的若干细节。比较一下可执行文件格式和以太数据包中以太头、IP头、TCP头的设计，我想我们能很好的感受分层这一重要的设计思想。 <a href="#artrelatedtopics">参考资料 21</a>从全局的角度讨论了各种文件的格式，并提出一个比较夸张的结论：Everything Is Byte!</p>
<p>最后的题外话：大多数资料中对a.out格式的评价较低，常见的词语有黑暗年代（dark ages）、丑陋（ugly）等等，当然，从现代的观点来看，的确是比较简单，但是如果没有曾经的简单何来今天的精巧？正如我们今天可以评价石器时代的技术是ugly,那么将来的人们也可以嘲讽今天的技术是非常ugly。我想我们也许应该用更平和的心态来对曾经的技术有一个公正的评价。</p>
<h2 id="参考资料"><a class="header-anchor" href="#参考资料"></a>参考资料</h2>
<p>（原文中未提供参考资料的链接）</p>
<hr>
<p><a href="https://stackoverflow.com/a/38117710/2258530">What’s the difference of section and segment in ELF file format</a></p>
<div class="post-text" itemprop="text">
<p><strong>Section is static, segment is dynamic</strong></p>
<p>The quote is correct, but to actually understand it the difference, you should try to understand the fields of the section header and program header (segment) entries, and how they are be used by the linker (sections) and operating system (segment).</p>
<p>Particularly important informations are (besides lengths):</p>
<ul>
<li>section: tell the linker if a section is either:
<ul>
<li>raw data to be loaded into memory, e.g. <code>.data</code>, <code>.text</code>, etc.</li>
<li>or formatted metadata about other sections, that will be used by the linker, but disappear at runtime e.g. <code>.symtab</code>, <code>.srttab</code>, <code>.rela.text</code></li>
</ul>
</li>
<li>segment: tells the operating system:
<ul>
<li>where should a segment be loaded into virtual memory</li>
<li>what permissions the segments have (read, write, execute). Remember that this can be efficiently enforced by the processor: <a href="https://stackoverflow.com/questions/18431261/how-does-x86-paging-work">How does x86 paging work?</a></li>
</ul>
</li>
</ul>
<p>I have written a tutorial that covers that in more detail at: <a href="http://www.cirosantilli.com/elf-hello-world/">http://www.cirosantilli.com/elf-hello-world/</a></p>
<p><strong>Does a segment contain one or more sections?</strong></p>
<p>Yes, and it is the linker that puts sections into segments.</p>
<p>In Binutils, how sections are put into segments by <code>ld</code> is determined by a text file called a <em>linker script</em>. Docs: <a href="https://sourceware.org/binutils/docs/ld/Scripts.html">https://sourceware.org/binutils/docs/ld/Scripts.html</a></p>
<p>You can get the default one with <code>ld --verbose</code>, and set a custom one with <code>-T</code>.</p>
<p>For example, my default Ubuntu 17.04 linker script contains:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">.text           :</span><br><span class="line">&#123;</span><br><span class="line">  *(.text.unlikely .text.*_unlikely .text.unlikely.*)</span><br><span class="line">  *(.text.exit .text.exit.*)</span><br><span class="line">  *(.text.startup .text.startup.*)</span><br><span class="line">  *(.text.hot .text.hot.*)</span><br><span class="line">  *(.text .stub .text.* .gnu.linkonce.t.*)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>which tells the linker to put sections named <code>.text.unlikely</code>, <code>.text.*_unlikely</code>, <code>.text.exit</code>, etc. in the <code>.text</code> segment.</p>
<p>OS development is a case where custom scripts are useful, minimal example: <a href="https://github.com/cirosantilli/x86-bare-metal-examples/blob/d217b180be4220a0b4a453f31275d38e697a99e0/linker.ld">https://github.com/cirosantilli/x86-bare-metal-examples/blob/d217b180be4220a0b4a453f31275d38e697a99e0/linker.ld</a></p>
<p>Once the executable is linked, it is only possible to know which section went to which segment if the linker stores the optional section header in the executable: <a href="https://stackoverflow.com/questions/23018496/where-is-the-section-to-segment-mapping-stored-in-elf-files">Where is the “Section to segment mapping” stored in ELF files?</a></p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/analysis-of-unix-linux-platform-executable-file-format/">http://xnerv.wang/analysis-of-unix-linux-platform-executable-file-format/</a></strong><br>
转载自：<a href="https://www.ibm.com/developerworks/cn/linux/l-excutff/">UNIX/LINUX 平台可执行文件格式分析</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Linux</tag>
        <tag>COFF</tag>
        <tag>linker</tag>
      </tags>
  </entry>
  <entry>
    <title>多版本并发控制(MVCC)在分布式系统中的应用（转载）</title>
    <url>/application-of-mvcc-in-distributed-system/</url>
    <content><![CDATA[<h2 id="问题"><a class="header-anchor" href="#问题"></a>问题</h2>
<p>最近项目中遇到了一个分布式系统的并发控制问题。该问题可以抽象为：某分布式系统由一个数据中心D和若干业务处理中心L1，L2 … Ln组成；D本质上是一个key-value存储，它对外提供基于HTTP协议的CRUD操作接口。L的业务逻辑可以抽象为下面3个步骤：</p>
<ol>
<li>read: 根据keySet {k1, … kn}从D获取keyValueSet {k1:v1, … kn:vn}</li>
<li>do: 根据keyValueSet进行业务处理，得到需要更新的数据集keyValueSet’ {k1′:v1′, … km’:vm’} (<strong>注</strong>：读取的keySet和更新的keySet’可能不同)</li>
<li>update: 把keyValueSet’更新到D （<strong>注</strong>：D保证在一次调用更新多个key的原子性）</li>
</ol>
<p>在没有事务支持的情况下，多个L进行并发处理可能会导致数据一致性问题。比如，考虑L1和L2的如下执行顺序：</p>
<ol>
<li>L1从D读取key:123对应的值100</li>
<li>L2从D读取key:123对应的100</li>
<li>L1将key:123更新为100 + 1</li>
<li>L2将key:123更新为100 + 2</li>
</ol>
<p>如果L1和L2串行执行，key:123对应的值将为103，但上面并发执行中L1的执行效果完全被L2所覆盖，实际key:123所对应的值变成了102。</p>
<span id="more"></span>
<h2 id="解决方案1：基于锁的事务"><a class="header-anchor" href="#解决方案1：基于锁的事务"></a>解决方案1：基于锁的事务</h2>
<p>为了让L的处理具有可串行化特性(Serializability)，一种最直接的解决方案就是考虑为D加上基于锁的简单事务。让L在进行业务处理前先锁定D，完成以后释放锁。另外，为了防止持有锁的L由于某种原因长时间未提交事务，D还需要具有超时机制，当L尝试提交一个已超时的事务时会得到一个错误响应。</p>
<p><img src="http://images.cnblogs.com/cnblogs_com/weidagang2046/362318/o_conditional_update_1.PNG" alt=""><img src="https://coolshell.cn/wp-content/uploads/2012/03/0915536496-0.png" alt="0915536496-0"></p>
<p>本方案的优点是实现简单，缺点是锁定了整个数据集，粒度太大；时间上包含了L的整个处理时间，跨度太长。虽然我们可以考虑把锁定粒度降低到数据项级别，按key进行锁定，但这又会带来其他的问题。由于更新的keySet’可能是事先不确定的，所以可能无法在开始事务时锁定所有的key；如果分阶段来锁定需要的key，又可能出现死锁(Deadlock)问题。另外，按key锁定在有锁争用的情况下并不能解决锁定时间太长的问题。所以，按key锁定仍然存在重要的不足之处。</p>
<h2 id="解决方案2：多版本并发控制"><a class="header-anchor" href="#解决方案2：多版本并发控制"></a>解决方案2：多版本并发控制</h2>
<p>为了实现可串行化，同时避免锁机制存在的各种问题，我们可以采用基于多版本并发控制（Multiversion concurrency control，MVCC）思想的无锁事务机制。人们一般把基于锁的并发控制机制称成为悲观机制，而把MVCC机制称为乐观机制。这是因为锁机制是一种预防性的，读会阻塞写，写也会阻塞读，当锁定粒度较大，时间较长时并发性能就不会太好；而MVCC是一种后验性的，读不阻塞写，写也不阻塞读，等到提交的时候才检验是否有冲突，由于没有锁，所以读写不会相互阻塞，从而大大提升了并发性能。我们可以借用源代码版本控制来理解MVCC，每个人都可以自由地阅读和修改本地的代码，相互之间不会阻塞，只在提交的时候版本控制器会检查冲突，并提示merge。目前，Oracle、PostgreSQL和MySQL都已支持基于MVCC的并发机制，但具体实现各有不同。</p>
<p>MVCC的一种简单实现是基于CAS（Compare-and-swap）思想的有条件更新（Conditional Update）。普通的update参数只包含了一个keyValueSet’，Conditional Update在此基础上加上了一组更新条件conditionSet { … data[keyx]=valuex, … }，即只有在D满足更新条件的情况下才将数据更新为keyValueSet’；否则，返回错误信息。这样，L就形成了如下图所示的Try/Conditional Update/(Try again)的处理模式：</p>
<p><img src="http://images.cnblogs.com/cnblogs_com/weidagang2046/362318/o_mvcc_2.png" alt=""><img src="https://coolshell.cn/wp-content/uploads/2012/03/0915535U3-1.png" alt="0915535U3-1"></p>
<p>虽然对单个L来讲不能保证每次都成功更新，但从整个系统来看，总是有任务能够顺利进行。这种方案利用Conditional Update避免了大粒度和长时间的锁定，当各个业务之间资源争用不大的情况下，并发性能很好。不过，由于Conditional Update需要更多的参数，如果condition中value的长度很长，那么每次网络传送的数据量就会比较大，从而导致性能下降。特别是当需要更新的keyValueSet’很小，而condition很大时，就显得非常不经济。</p>
<p>为了避免condition太大所带来的性能问题，可以为每条数据项增加一个int型的版本号字段，由D维护该版本号，每次数据有更新就增加版本号；L在进行Conditional Update时，通过版本号取代具体的值。</p>
<p><img src="http://images.cnblogs.com/cnblogs_com/weidagang2046/362318/o_mvcc_3.png" alt=""><img src="https://coolshell.cn/wp-content/uploads/2012/03/0915533324-2.png" alt="0915533324-2"></p>
<p>另一个问题是上面的解决方案假设了D是可以支持Conditional Update的；那么，如果D是一个不支持Conditional Update的第三方的key-value存储怎么办呢？这时，我们可以在L和D之间增加一个P作为代理，所有的CRUD操作都必须经过P，让P来进行条件检查，而实际的数据操作放在D。这种方式实现了条件检查和数据操作的分离，但同时降低了性能，需要在P中增加cache，提升性能。由于P是D的唯一客户端；所以，P的cache管理是非常简单的，不必像多客户端情形担心缓存的失效。不过，实际上，据我所知redis和Amazon SimpleDB都已经有了Conditional Update的支持。</p>
<h2 id="悲观锁和MVCC对比"><a class="header-anchor" href="#悲观锁和MVCC对比"></a>悲观锁和MVCC对比</h2>
<p>上面介绍了悲观锁和MVCC的基本原理，但是对于它们分别适用于什么场合，不同的场合下两种机制优劣具体表现在什么地方还不是很清楚。这里我就对一些典型的应用场景进行简单的分析。需要注意的是下面的分析不针对分布式，悲观锁和MVCC两种机制在分布式系统、单数据库系统、甚至到内存变量各个层次都存在。</p>
<h3 id="场景1：对读的响应速度要求高"><a class="header-anchor" href="#场景1：对读的响应速度要求高"></a>场景1：对读的响应速度要求高</h3>
<p>有一类系统更新特别频繁，并且对读的响应速度要求很高，如股票交易系统。在悲观锁机制下，写会阻塞读，那么当有写操作时，读操作的响应速度就会受到影响；而MVCC不存在读写锁，读操作是不受任何阻塞的，所以读的响应速度会更快更稳定。</p>
<h3 id="场景2：读远多于写"><a class="header-anchor" href="#场景2：读远多于写"></a>场景2：读远多于写</h3>
<p>对于许多系统来讲，读操作的比例往往远大于写操作，特别是某些海量并发读的系统。在悲观锁机制下，当有写操作占用锁，就会有大量的读操作被阻塞，影响并发性能；而MVCC可以保持比较高且稳定的读并发能力。</p>
<h3 id="场景3：写操作冲突频繁"><a class="header-anchor" href="#场景3：写操作冲突频繁"></a>场景3：写操作冲突频繁</h3>
<p>如果系统中写操作的比例很高，且冲突频繁，这时就需要仔细评估。假设两个有冲突的业务L1和L2，它们在单独执行是分别耗时t1，t2。在悲观锁机制下，它们的总时间大约等于串行执行的时间：</p>
<p>T = t1 + t2</p>
<p>而在MVCC下，假设L1在L2之前更新，L2需要retry一次，它们的总时间大约等于L2执行两次的时间（这里假设L2的两次执行耗时相等，更好的情况是，如果第1次能缓存下部分有效结果，第二次执行L2耗时是可能减小的）：</p>
<p>T’ = 2 * t2</p>
<p>这时关键是要评估retry的代价，如果retry的代价很低，比如，对某个计数器递增，又或者第二次执行可以比第一次快很多，这时采用MVCC机制就比较适合。反之，如果retry的代价很大，比如，报表统计运算需要算几小时甚至一天那就应该采用锁机制避免retry。</p>
<p>从上面的分析，我们可以简单的得出这样的结论：对读的响应速度和并发性要求比较高的场景适合MVCC；而retry代价越大的场景越适合悲观锁机制。</p>
<h2 id="总结"><a class="header-anchor" href="#总结"></a>总结</h2>
<p>本文介绍了一种基于多版本并发控制（MVCC）思想的Conditional Update解决分布式系统并发控制问题的方法。和基于悲观锁的方法相比，该方法避免了大粒度和长时间的锁定，能更好地适应对读的响应速度和并发性要求高的场景。</p>
<h2 id="参考"><a class="header-anchor" href="#参考"></a>参考</h2>
<ul>
<li><a href="http://en.wikipedia.org/wiki/Serializability">Wikipedia – Serializability</a></li>
<li><a href="http://en.wikipedia.org/wiki/Compare-and-swap">Wikipedia – Compare-and-swap</a></li>
<li><a href="http://en.wikipedia.org/wiki/Multiversion_concurrency_control">Wikipedia – Multiversion concurrency control</a></li>
<li><a href="http://blogs.msdn.com/b/oldnewthing/archive/2011/04/12/10152296.aspx">Lock-free algorithms: The try/commit/(try again) pattern</a></li>
<li><a href="http://aws.amazon.com/simpledb/faqs/#Does_Amazon_SimpleDB_support_transactions">Amazon SimpleDB FAQs – Does Amazon SimpleDB support transactions?</a></li>
<li><a href="http://redis.io/topics/transactions">redis – Transactions</a></li>
<li><a href="http://simpledbm.googlecode.com/files/mvcc-survey-1.0.pdf">A Quick Survey of MultiVersion Concurrency Algorithms</a></li>
<li><a href="http://www.cnblogs.com/jobs/archive/2007/11/13/957446.html">非阻塞算法思想在关系数据库应用程序开发中的使用</a></li>
</ul>
<h4 id="友情推荐"><a class="header-anchor" href="#友情推荐"></a>友情推荐</h4>
<p>本文的图是用我自己开发的<a href="http://textdiagram.sinaapp.com">TextDiagram</a>工具画的，欢迎试用！如果您喜欢，请推荐给朋友，谢谢！</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/application-of-mvcc-in-distributed-system/">http://xnerv.wang/application-of-mvcc-in-distributed-system/</a></strong><br>
转载自：<a href="https://coolshell.cn/articles/6790.html">多版本并发控制(MVCC)在分布式系统中的应用</a></p>
]]></content>
      <categories>
        <category>分布式及存储</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>分布式及存储</tag>
        <tag>MVCC</tag>
      </tags>
  </entry>
  <entry>
    <title>浅析 Bigtable 和 LevelDB 的实现（转载）</title>
    <url>/bigtable-leveldb/</url>
    <content><![CDATA[<p>在 2006 年的 OSDI 上，Google 发布了名为 <a href="https://static.googleusercontent.com/media/research.google.com/en//archive/bigtable-osdi06.pdf">Bigtable: A Distributed Storage System for Structured Data</a> 的论文，其中描述了一个用于管理结构化数据的分布式存储系统 - Bigtable 的数据模型、接口以及实现等内容。</p>
<p><img src="/assets/bigtable-leveldb/2017-08-12-leveldb-logo.png-1000width" alt="leveldb-logo"></p>
<p>本文会先对 Bigtable 一文中描述的分布式存储系统进行简单的描述，然后对 Google 开源的 KV 存储数据库 <a href="https://github.com/google/leveldb">LevelDB</a> 进行分析；LevelDB 可以理解为单点的 Bigtable 的系统，虽然其中没有 Bigtable 中与 tablet 管理以及一些分布式相关的逻辑，不过我们可以通过对 LevelDB 源代码的阅读增加对 Bigtable 的理解。</p>
<span id="more"></span>
<h2 id="Bigtable"><a class="header-anchor" href="#Bigtable"></a><a href="#bigtable"></a>Bigtable</h2>
<p>Bigtable 是一个用于管理<strong>结构化数据</strong>的分布式存储系统，它有非常优秀的扩展性，可以同时处理上千台机器中的 PB 级别的数据；Google 中的很多项目，包括 Web 索引都使用 Bigtable 来存储海量的数据；Bigtable 的论文中声称它实现了四个目标：</p>
<p><img src="/assets/bigtable-leveldb/2017-08-12-Goals-of-Bigtable.jpg-1000width" alt="Goals-of-Bigtable"></p>
<p>在作者看来这些目标看看就好，其实并没有什么太大的意义，所有的项目都会对外宣称它们达到了高性能、高可用性等等特性，我们需要关注的是 Bigtable 到底是如何实现的。</p>
<h3 id="数据模型"><a class="header-anchor" href="#数据模型"></a><a href="#%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B"></a>数据模型</h3>
<p>Bigtable 与数据库在很多方面都非常相似，但是它提供了与数据库不同的接口，它并没有支持全部的关系型数据模型，反而使用了简单的数据模型，使数据可以被更灵活的控制和管理。</p>
<p>在实现中，Bigtable 其实就是一个稀疏的、分布式的、多维持久有序哈希。</p>
<blockquote>
<p>A Bigtable is a sparse, distributed, persistent multi-dimensional sorted map.</p>
</blockquote>
<p>它的定义其实也就决定了其数据模型非常简单并且易于实现，我们使用 <code>row</code>、<code>column</code> 和 <code>timestamp</code> 三个字段作为这个哈希的键，值就是一个字节数组，也可以理解为字符串。</p>
<p><img src="/assets/bigtable-leveldb/2017-08-12-Bigtable-DataModel-Row-Column-Timestamp-Value.jpg-1000width" alt="Bigtable-DataModel-Row-Column-Timestamp-Value"></p>
<p>这里最重要的就是 <code>row</code> 的值，它的长度最大可以为 64KB，对于同一 <code>row</code> 下数据的读写都可以看做是原子的；因为 Bigtable 是按照 <code>row</code> 的值使用字典顺序进行排序的，每一段 <code>row</code> 的范围都会被 Bigtable 进行分区，并交给一个 tablet 进行处理。</p>
<h3 id="实现"><a class="header-anchor" href="#实现"></a><a href="#%E5%AE%9E%E7%8E%B0"></a>实现</h3>
<p>在这一节中，我们将介绍 Bigtable 论文对于其本身实现的描述，其中包含很多内容：tablet 的组织形式、tablet 的管理、读写请求的处理以及数据的压缩等几个部分。</p>
<h4 id="tablet-的组织形式"><a class="header-anchor" href="#tablet-的组织形式"></a><a href="#tablet-%E7%9A%84%E7%BB%84%E7%BB%87%E5%BD%A2%E5%BC%8F"></a>tablet 的组织形式</h4>
<p>我们使用类似 B+ 树的三层结构来存储 tablet 的位置信息，第一层是一个单独的 <a href="https://static.googleusercontent.com/media/research.google.com/en//archive/chubby-osdi06.pdf">Chubby</a> 文件，其中保存了根 tablet 的位置。</p>
<blockquote>
<p>Chubby 是一个分布式锁服务，我们可能会在后面的文章中介绍它。</p>
</blockquote>
<p><img src="/assets/bigtable-leveldb/2017-08-12-Tablet-Location-Hierarchy.jpg-1000width" alt="Tablet-Location-Hierarchy"></p>
<p>每一个 METADATA tablet 包括根节点上的 tablet 都存储了 tablet 的位置和该 tablet 中 key 的最小值和最大值；每一个 METADATA 行大约在内存中存储了 1KB 的数据，如果每一个 METADATA tablet 的大小都为 128MB，那么整个三层结构可以存储 2^61 字节的数据。</p>
<h4 id="tablet-的管理"><a class="header-anchor" href="#tablet-的管理"></a><a href="#tablet-%E7%9A%84%E7%AE%A1%E7%90%86"></a>tablet 的管理</h4>
<p>既然在整个 Bigtable 中有着海量的 tablet 服务器以及数据的分片 tablet，那么 Bigtable 是如何管理海量的数据呢？Bigtable 与很多的分布式系统一样，使用一个主服务器将 tablet 分派给不同的服务器节点。</p>
<p><img src="/assets/bigtable-leveldb/2017-08-12-Master-Manage-Tablet-Servers-And-Tablets.jpg-1000width" alt="Master-Manage-Tablet-Servers-And-Tablets"></p>
<p>为了减轻主服务器的负载，所有的客户端仅仅通过 Master 获取 tablet 服务器的位置信息，它并不会在每次读写时都请求 Master 节点，而是直接与 tablet 服务器相连，同时客户端本身也会保存一份 tablet 服务器位置的缓存以减少与 Master 通信的次数和频率。</p>
<h4 id="读写请求的处理"><a class="header-anchor" href="#读写请求的处理"></a><a href="#%E8%AF%BB%E5%86%99%E8%AF%B7%E6%B1%82%E7%9A%84%E5%A4%84%E7%90%86"></a>读写请求的处理</h4>
<p>从读写请求的处理，我们其实可以看出整个 Bigtable 中的各个部分是如何协作的，包括日志、memtable 以及 SSTable 文件。</p>
<p><img src="/assets/bigtable-leveldb/2017-08-12-Tablet-Serving.jpg-1000width" alt="Tablet-Serving"></p>
<p>当有客户端向 tablet 服务器发送写操作时，它会先向 tablet 服务器中的日志追加一条记录，在日志成功追加之后再向 memtable 中插入该条记录；这与现在大多的数据库的实现完全相同，通过顺序写向日志追加记录，然后再向数据库随机写，因为随机写的耗时远远大于追加内容，如果直接进行随机写，可能由于发生设备故障造成数据丢失。</p>
<p>当 tablet 服务器接收到读操作时，它会在 memtable 和 SSTable 上进行合并查找，因为 memtable 和 SSTable 中对于键值的存储都是字典顺序的，所以整个读操作的执行会非常快。</p>
<h4 id="表的压缩"><a class="header-anchor" href="#表的压缩"></a><a href="#%E8%A1%A8%E7%9A%84%E5%8E%8B%E7%BC%A9"></a>表的压缩</h4>
<p>随着写操作的进行，memtable 会随着事件的推移逐渐增大，当 memtable 的大小超过一定的阈值时，就会将当前的 memtable 冻结，并且创建一个新的 memtable，被冻结的 memtable 会被转换为一个 SSTable 并且写入到 GFS 系统中，这种压缩方式也被称作 <em>Minor Compaction</em>。</p>
<p><img src="/assets/bigtable-leveldb/2017-08-12-Minor-Compaction.jpg-1000width" alt="Minor-Compaction"></p>
<p>每一个 Minor Compaction 都能够创建一个新的 SSTable，它能够有效地降低内存的占用并且降低服务进程异常退出后，过大的日志导致的过长的恢复时间。既然有用于压缩 memtable 中数据的 Minor Compaction，那么就一定有一个对应的 Major Compaction 操作。</p>
<p><img src="/assets/bigtable-leveldb/2017-08-12-Major-Compaction.jpg-1000width" alt="Major-Compaction"></p>
<p>Bigtable 会在<strong>后台周期性</strong>地进行 <em>Major Compaction</em>，将 memtable 中的数据和一部分的 SSTable 作为输入，将其中的键值进行归并排序，生成新的 SSTable 并移除原有的 memtable 和 SSTable，新生成的 SSTable 中包含前两者的全部数据和信息，并且将其中一部分标记未删除的信息彻底清除。</p>
<h4 id="小结"><a class="header-anchor" href="#小结"></a><a href="#%E5%B0%8F%E7%BB%93"></a>小结</h4>
<p>到这里为止，对于 Google 的 Bigtable 论文的介绍就差不多完成了，当然本文只介绍了其中的一部分内容，关于压缩算法的实现细节、缓存以及提交日志的实现等问题我们都没有涉及，想要了解更多相关信息的读者，这里强烈推荐去看一遍 Bigtable 这篇论文的原文 <a href="https://static.googleusercontent.com/media/research.google.com/en//archive/bigtable-osdi06.pdf">Bigtable: A Distributed Storage System for Structured Data</a> 以增强对其实现的理解。</p>
<h2 id="LevelDB"><a class="header-anchor" href="#LevelDB"></a><a href="#leveldb"></a>LevelDB</h2>
<p>文章前面对于 Bigtable 的介绍其实都是对 <a href="https://github.com/google/leveldb">LevelDB</a> 这部分内容所做的铺垫，当然这并不是说前面的内容就不重要，LevelDB 是对 Bigtable 论文中描述的键值存储系统的单机版的实现，它提供了一个极其高速的键值存储系统，并且由 Bigtable 的作者 <a href="https://research.google.com/pubs/jeff.html">Jeff Dean</a> 和 <a href="https://research.google.com/pubs/SanjayGhemawat.html">Sanjay Ghemawat</a> 共同完成，可以说高度复刻了 Bigtable 论文中对于其实现的描述。</p>
<p>因为 Bigtable 只是一篇论文，同时又因为其实现依赖于 Google 的一些不开源的基础服务：GFS、Chubby 等等，我们很难接触到它的源代码，不过我们可以通过 LevelDB 更好地了解这篇论文中提到的诸多内容和思量。</p>
<h3 id="概述"><a class="header-anchor" href="#概述"></a><a href="#%E6%A6%82%E8%BF%B0"></a>概述</h3>
<p>LevelDB 作为一个键值存储的『仓库』，它提供了一组非常简单的增删改查接口：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">DB</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Status <span class="title">Put</span><span class="params">(<span class="type">const</span> WriteOptions&amp; options, <span class="type">const</span> Slice&amp; key, <span class="type">const</span> Slice&amp; value)</span> </span>= <span class="number">0</span>;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Status <span class="title">Delete</span><span class="params">(<span class="type">const</span> WriteOptions&amp; options, <span class="type">const</span> Slice&amp; key)</span> </span>= <span class="number">0</span>;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Status <span class="title">Write</span><span class="params">(<span class="type">const</span> WriteOptions&amp; options, WriteBatch* updates)</span> </span>= <span class="number">0</span>;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Status <span class="title">Get</span><span class="params">(<span class="type">const</span> ReadOptions&amp; options, <span class="type">const</span> Slice&amp; key, std::string* value)</span> </span>= <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>Put</code> 方法在内部最终会调用 <code>Write</code> 方法，只是在上层为调用者提供了两个不同的选择。</p>
</blockquote>
<p><code>Get</code> 和 <code>Put</code> 是 LevelDB 为上层提供的用于读写的接口，如果我们能够对读写的过程有一个非常清晰的认知，那么理解 LevelDB 的实现就不是那么困难了。</p>
<p>在这一节中，我们将先通过对读写操作的分析了解整个工程中的一些实现，并在遇到问题和新的概念时进行解释，我们会在这个过程中一步一步介绍 LevelDB 中一些重要模块的实现以达到掌握它的原理的目标。</p>
<h3 id="从写操作开始："><a class="header-anchor" href="#从写操作开始："></a><a href="#%E4%BB%8E%E5%86%99%E6%93%8D%E4%BD%9C%E5%BC%80%E5%A7%8B"></a>从写操作开始：</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">Status <span class="title">DB::Put</span><span class="params">(<span class="type">const</span> WriteOptions&amp; opt, <span class="type">const</span> Slice&amp; key, <span class="type">const</span> Slice&amp; value)</span> </span>&#123;</span><br><span class="line">  WriteBatch batch;</span><br><span class="line">  batch.<span class="built_in">Put</span>(key, value);</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">Write</span>(opt, &amp;batch);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">Status <span class="title">DBImpl::Write</span><span class="params">(<span class="type">const</span> WriteOptions&amp; options, WriteBatch* my_batch)</span> </span>&#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>正如上面所介绍的，<code>DB::Put</code> 方法将传入的参数封装成了一个 <code>WritaBatch</code>，然后仍然会执行 <code>DBImpl::Write</code> 方法向数据库中写入数据；写入方法 <code>DBImpl::Write</code> 其实是一个是非常复杂的过程，包含了很多对上下文状态的判断，我们先来看一个写操作的整体逻辑：</p>
<p><img src="/assets/bigtable-leveldb/2017-08-12-LevelDB-Put.jpg-1000width" alt="LevelDB-Put"></p>
<p>从总体上看，LevelDB 在对数据库执行写操作时，会有三个步骤：</p>
<ol>
<li>调用 <code>MakeRoomForWrite</code> 方法为即将进行的写入提供足够的空间；
<ul>
<li>在这个过程中，由于 memtable 中空间的不足可能会冻结当前的 memtable，发生 Minor Compaction 并创建一个新的 <code>MemTable</code> 对象；</li>
<li>在某些条件满足时，也可能发生 Major Compaction，对数据库中的 SSTable 进行压缩；</li>
</ul>
</li>
<li>通过 <code>AddRecord</code> 方法向日志中追加一条写操作的记录；</li>
<li>再向日志成功写入记录后，我们使用 <code>InsertInto</code> 直接插入 memtable 中，完成整个写操作的流程；</li>
</ol>
<p>在这里，我们并不会提供 LevelDB 对于 <code>Put</code> 方法实现的全部代码，只会展示一份精简后的代码，帮助我们大致了解一下整个写操作的流程：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">Status <span class="title">DBImpl::Write</span><span class="params">(<span class="type">const</span> WriteOptions&amp; options, WriteBatch* my_batch)</span> </span>&#123;</span><br><span class="line">  <span class="function">Writer <span class="title">w</span><span class="params">(&amp;mutex_)</span></span>;</span><br><span class="line">  w.batch = my_batch;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">MakeRoomForWrite</span>(my_batch == <span class="literal">NULL</span>);</span><br><span class="line"></span><br><span class="line">  <span class="type">uint64_t</span> last_sequence = versions_-&gt;<span class="built_in">LastSequence</span>();</span><br><span class="line">  Writer* last_writer = &amp;w;</span><br><span class="line">  WriteBatch* updates = <span class="built_in">BuildBatchGroup</span>(&amp;last_writer);</span><br><span class="line">  WriteBatchInternal::<span class="built_in">SetSequence</span>(updates, last_sequence + <span class="number">1</span>);</span><br><span class="line">  last_sequence += WriteBatchInternal::<span class="built_in">Count</span>(updates);</span><br><span class="line"></span><br><span class="line">  log_-&gt;<span class="built_in">AddRecord</span>(WriteBatchInternal::<span class="built_in">Contents</span>(updates));</span><br><span class="line">  WriteBatchInternal::<span class="built_in">InsertInto</span>(updates, mem_);</span><br><span class="line"></span><br><span class="line">  versions_-&gt;<span class="built_in">SetLastSequence</span>(last_sequence);</span><br><span class="line">  <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="不可变的-memtable"><a class="header-anchor" href="#不可变的-memtable"></a><a href="#%E4%B8%8D%E5%8F%AF%E5%8F%98%E7%9A%84-memtable"></a>不可变的 memtable</h4>
<p>在写操作的实现代码 <code>DBImpl::Put</code> 中，写操作的准备过程 <code>MakeRoomForWrite</code> 是我们需要注意的一个方法：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">Status <span class="title">DBImpl::MakeRoomForWrite</span><span class="params">(<span class="type">bool</span> force)</span> </span>&#123;</span><br><span class="line">  <span class="type">uint64_t</span> new_log_number = versions_-&gt;<span class="built_in">NewFileNumber</span>();</span><br><span class="line">  WritableFile* lfile = <span class="literal">NULL</span>;</span><br><span class="line">  env_-&gt;<span class="built_in">NewWritableFile</span>(<span class="built_in">LogFileName</span>(dbname_, new_log_number), &amp;lfile);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">delete</span> log_;</span><br><span class="line">  <span class="keyword">delete</span> logfile_;</span><br><span class="line">  logfile_ = lfile;</span><br><span class="line">  logfile_number_ = new_log_number;</span><br><span class="line">  log_ = <span class="keyword">new</span> log::<span class="built_in">Writer</span>(lfile);</span><br><span class="line">  imm_ = mem_;</span><br><span class="line">  has_imm_.<span class="built_in">Release_Store</span>(imm_);</span><br><span class="line">  mem_ = <span class="keyword">new</span> <span class="built_in">MemTable</span>(internal_comparator_);</span><br><span class="line">  mem_-&gt;<span class="built_in">Ref</span>();</span><br><span class="line">  <span class="built_in">MaybeScheduleCompaction</span>();</span><br><span class="line">  <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当 LevelDB 中的 memtable 已经被数据填满导致内存已经快不够用的时候，我们会开始对 memtable 中的数据进行冻结并创建一个新的 <code>MemTable</code> 对象。</p>
<p><img src="/assets/bigtable-leveldb/2017-08-12-Immutable-MemTable.jpg-1000width" alt="Immutable-MemTable"></p>
<p>你可以看到，与 Bigtable 中论文不同的是，LevelDB 中引入了一个不可变的 memtable 结构 imm，它的结构与 memtable 完全相同，只是其中的所有数据都是不可变的。</p>
<p><img src="/assets/bigtable-leveldb/2017-08-12-LevelDB-Serving.jpg-1000width" alt="LevelDB-Serving"></p>
<p>在切换到新的 memtable 之后，还可能会执行 <code>MaybeScheduleCompaction</code> 来触发一次 Minor Compaction 将 imm 中数据固化成数据库中的 SSTable；imm 的引入能够解决由于 memtable 中数据过大导致压缩时不可写入数据的问题。</p>
<p>引入 imm 后，如果 memtable 中的数据过多，我们可以直接将 memtable 指针赋值给 imm，然后创建一个新的 MemTable 实例，这样就可以继续接受外界的写操作，不再需要等待 Minor Compaction 的结束了。</p>
<h4 id="日志记录的格式"><a class="header-anchor" href="#日志记录的格式"></a><a href="#%E6%97%A5%E5%BF%97%E8%AE%B0%E5%BD%95%E7%9A%84%E6%A0%BC%E5%BC%8F"></a>日志记录的格式</h4>
<p>作为一个持久存储的 KV 数据库，LevelDB 一定要有日志模块以支持错误发生时恢复数据，我们想要深入了解 LevelDB 的实现，那么日志的格式是一定绕不开的问题；这里并不打算展示用于追加日志的方法 <code>AddRecord</code> 的实现，因为方法中只是实现了对表头和字符串的拼接。</p>
<p>日志在 LevelDB 是以块的形式存储的，每一个块的长度都是 32KB，<strong>固定的块长度</strong>也就决定了日志可能存放在块中的任意位置，LevelDB 中通过引入一位 <code>RecordType</code> 来表示当前记录在块中的位置：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">enum</span> <span class="title class_">RecordType</span> &#123;</span><br><span class="line">  <span class="comment">// Zero is reserved for preallocated files</span></span><br><span class="line">  kZeroType = <span class="number">0</span>,</span><br><span class="line">  kFullType = <span class="number">1</span>,</span><br><span class="line">  <span class="comment">// For fragments</span></span><br><span class="line">  kFirstType = <span class="number">2</span>,</span><br><span class="line">  kMiddleType = <span class="number">3</span>,</span><br><span class="line">  kLastType = <span class="number">4</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>日志记录的类型存储在该条记录的头部，其中还存储了 4 字节日志的 CRC 校验、记录的长度等信息：</p>
<p><img src="/assets/bigtable-leveldb/2017-08-12-LevelDB-log-format-and-recordtype.jpg-1000width" alt="LevelDB-log-format-and-recordtype"></p>
<p>上图中一共包含 4 个块，其中存储着 6 条日志记录，我们可以通过 <code>RecordType</code> 对每一条日志记录或者日志记录的一部分进行标记，并在日志需要使用时通过该信息重新构造出这条日志记录。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">virtual</span> Status <span class="title">Sync</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  Status s = <span class="built_in">SyncDirIfManifest</span>();</span><br><span class="line">  <span class="keyword">if</span> (<span class="built_in">fflush_unlocked</span>(file_) != <span class="number">0</span> ||</span><br><span class="line">      <span class="built_in">fdatasync</span>(<span class="built_in">fileno</span>(file_)) != <span class="number">0</span>) &#123;</span><br><span class="line">    s = Status::<span class="built_in">IOError</span>(filename_, <span class="built_in">strerror</span>(errno));</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> s;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>因为向日志中写新记录都是顺序写的，所以它写入的速度非常快，当在内存中写入完成时，也会直接将缓冲区的这部分的内容 <code>fflush</code> 到磁盘上，实现对记录的持久化，用于之后的错误恢复等操作。</p>
<h4 id="记录的插入"><a class="header-anchor" href="#记录的插入"></a><a href="#%E8%AE%B0%E5%BD%95%E7%9A%84%E6%8F%92%E5%85%A5"></a>记录的插入</h4>
<p>当一条数据的记录写入日志时，这条记录仍然无法被查询，只有当该数据写入 memtable 后才可以被查询，而这也是这一节将要介绍的内容，无论是数据的插入还是数据的删除都会向 memtable 中添加一条记录。</p>
<p><img src="/assets/bigtable-leveldb/2017-08-12-LevelDB-Memtable-Key-Value-Format.jpg-1000width" alt="LevelDB-Memtable-Key-Value-Format"></p>
<p>添加和删除的记录的区别就是它们使用了不用的 <code>ValueType</code> 标记，插入的数据会将其设置为 <code>kTypeValue</code>，删除的操作会标记为 <code>kTypeDeletion</code>；但是它们实际上都向 memtable 中插入了一条数据。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">Put</span><span class="params">(<span class="type">const</span> Slice&amp; key, <span class="type">const</span> Slice&amp; value)</span> </span>&#123;</span><br><span class="line">  mem_-&gt;<span class="built_in">Add</span>(sequence_, kTypeValue, key, value);</span><br><span class="line">  sequence_++;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">Delete</span><span class="params">(<span class="type">const</span> Slice&amp; key)</span> </span>&#123;</span><br><span class="line">  mem_-&gt;<span class="built_in">Add</span>(sequence_, kTypeDeletion, key, <span class="built_in">Slice</span>());</span><br><span class="line">  sequence_++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>我们可以看到它们都调用了 memtable 的 <code>Add</code> 方法，向其内部的数据结构 skiplist 以上图展示的格式插入数据，这条数据中既包含了该记录的键值、序列号以及这条记录的种类，这些字段会在拼接后存入 skiplist；既然我们并没有在 memtable 中对数据进行删除，那么我们是如何保证每次取到的数据都是最新的呢？首先，在 skiplist 中，我们使用了自己定义的一个 <code>comparator</code>：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">InternalKeyComparator::Compare</span><span class="params">(<span class="type">const</span> Slice&amp; akey, <span class="type">const</span> Slice&amp; bkey)</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> r = user_comparator_-&gt;<span class="built_in">Compare</span>(<span class="built_in">ExtractUserKey</span>(akey), <span class="built_in">ExtractUserKey</span>(bkey));</span><br><span class="line">  <span class="keyword">if</span> (r == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">uint64_t</span> anum = <span class="built_in">DecodeFixed64</span>(akey.<span class="built_in">data</span>() + akey.<span class="built_in">size</span>() - <span class="number">8</span>);</span><br><span class="line">    <span class="type">const</span> <span class="type">uint64_t</span> bnum = <span class="built_in">DecodeFixed64</span>(bkey.<span class="built_in">data</span>() + bkey.<span class="built_in">size</span>() - <span class="number">8</span>);</span><br><span class="line">    <span class="keyword">if</span> (anum &gt; bnum) &#123;</span><br><span class="line">      r = <span class="number">-1</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (anum &lt; bnum) &#123;</span><br><span class="line">      r = +<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> r;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>比较的两个 key 中的数据可能包含的内容都不完全相同，有的会包含键值、序列号等全部信息，但是例如从 <code>Get</code> 方法调用过来的 key 中可能就只包含键的长度、键值和序列号了，但是这并不影响这里对数据的提取，因为我们只从每个 key 的头部提取信息，所以无论是完整的 key/value 还是单独的 key，我们都不会取到 key 之外的任何数据。</p>
</blockquote>
<p>该方法分别从两个不同的 key 中取出键和序列号，然后对它们进行比较；比较的过程就是使用 <code>InternalKeyComparator</code> 比较器，它通过 <code>user_key</code> 和 <code>sequence_number</code> 进行排序，其中 <code>user_key</code> 按照递增的顺序排序、<code>sequence_number</code> 按照递减的顺序排序，因为随着数据的插入序列号是不断递增的，所以我们可以保证先取到的都是最新的数据或者删除信息。</p>
<p><img src="/assets/bigtable-leveldb/2017-08-12-LevelDB-MemTable-SkipList.jpg-1000width" alt="LevelDB-MemTable-SkipList"></p>
<p>在序列号的帮助下，我们并不需要对历史数据进行删除，同时也能加快写操作的速度，提升 LevelDB 的写性能。</p>
<h3 id="数据的读取"><a class="header-anchor" href="#数据的读取"></a><a href="#%E6%95%B0%E6%8D%AE%E7%9A%84%E8%AF%BB%E5%8F%96"></a>数据的读取</h3>
<p>从 LevelDB 中读取数据其实并不复杂，memtable 和 imm 更像是两级缓存，它们在内存中提供了更快的访问速度，如果能直接从内存中的这两处直接获取到响应的值，那么它们一定是最新的数据。</p>
<blockquote>
<p>LevelDB 总会将新的键值对写在最前面，并在数据压缩时删除历史数据。</p>
</blockquote>
<p><img src="/assets/bigtable-leveldb/2017-08-12-LevelDB-Read-Processes.jpg-1000width" alt="LevelDB-Read-Processes"></p>
<p>数据的读取是按照 MemTable、Immutable MemTable 以及不同层级的 SSTable 的顺序进行的，前两者都是在内存中，后面不同层级的 SSTable 都是以 <code>*.ldb</code> 文件的形式持久存储在磁盘上，而正是因为有着不同层级的 SSTable，所以我们的数据库的名字叫做 LevelDB。</p>
<p>精简后的读操作方法的实现代码是这样的，方法的脉络非常清晰，作者相信这里也不需要过多的解释：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">Status <span class="title">DBImpl::Get</span><span class="params">(<span class="type">const</span> ReadOptions&amp; options, <span class="type">const</span> Slice&amp; key, std::string* value)</span> </span>&#123;</span><br><span class="line">  <span class="function">LookupKey <span class="title">lkey</span><span class="params">(key, versions_-&gt;LastSequence())</span></span>;</span><br><span class="line">  <span class="keyword">if</span> (mem_-&gt;<span class="built_in">Get</span>(lkey, value, <span class="literal">NULL</span>)) &#123;</span><br><span class="line">    <span class="comment">// Done</span></span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (imm_ != <span class="literal">NULL</span> &amp;&amp; imm_-&gt;<span class="built_in">Get</span>(lkey, value, <span class="literal">NULL</span>)) &#123;</span><br><span class="line">    <span class="comment">// Done</span></span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    versions_-&gt;<span class="built_in">current</span>()-&gt;<span class="built_in">Get</span>(options, lkey, value, <span class="literal">NULL</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">MaybeScheduleCompaction</span>();</span><br><span class="line">  <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当 LevelDB 在 memtable 和 imm 中查询到结果时，如果查询到了数据并不一定表示当前的值一定存在，它仍然需要判断 <code>ValueType</code> 来确定当前记录是否被删除。</p>
<h4 id="多层级的-SSTable"><a class="header-anchor" href="#多层级的-SSTable"></a><a href="#%E5%A4%9A%E5%B1%82%E7%BA%A7%E7%9A%84-sstable"></a>多层级的 SSTable</h4>
<p>当 LevelDB 在内存中没有找到对应的数据时，它才会到磁盘中多个层级的 SSTable 中进行查找，这个过程就稍微有一点复杂了，LevelDB 会在多个层级中逐级进行查找，并且不会跳过其中的任何层级；在查找的过程就涉及到一个非常重要的数据结构 <code>FileMetaData</code>：</p>
<p><img src="/assets/bigtable-leveldb/2017-08-12-FileMetaData.jpg-1000width" alt="FileMetaData"></p>
<p><code>FileMetaData</code> 中包含了整个文件的全部信息，其中包括键的最大值和最小值、允许查找的次数、文件被引用的次数、文件的大小以及文件号，因为所有的 <code>SSTable</code> 都是以固定的形式存储在同一目录下的，所以我们可以通过文件号轻松查找到对应的文件。</p>
<p><img src="/assets/bigtable-leveldb/2017-08-12-LevelDB-Level0-Layer.jpg-1000width" alt="LevelDB-Level0-Laye"></p>
<p>查找的顺序就是从低到高了，LevelDB 首先会在 Level0 中查找对应的键。但是，与其他层级不同，Level0 中多个 SSTable 的键的范围有重合部分的，在查找对应值的过程中，会依次查找 Level0 中固定的 4 个 SSTable。</p>
<p><img src="/assets/bigtable-leveldb/2017-08-12-LevelDB-LevelN-Layers.jpg-1000width" alt="LevelDB-LevelN-Layers"></p>
<p>但是当涉及到更高层级的 SSTable 时，因为同一层级的 SSTable 都是没有重叠部分的，所以我们在查找时可以利用已知的 SSTable 中的极值信息 <code>smallest/largest</code> 快速查找到对应的 SSTable，再判断当前的 SSTable 是否包含查询的 key，如果不存在，就继续查找下一个层级直到最后的一个层级 <code>kNumLevels</code>（默认为 7 级）或者查询到了对应的值。</p>
<h4 id="SSTable-的『合并』"><a class="header-anchor" href="#SSTable-的『合并』"></a><a href="#sstable-%E7%9A%84%E5%90%88%E5%B9%B6"></a>SSTable 的『合并』</h4>
<p>既然 LevelDB 中的数据是通过多个层级的 SSTable 组织的，那么它是如何对不同层级中的 SSTable 进行合并和压缩的呢；与 Bigtable 论文中描述的两种 Compaction 几乎完全相同，LevelDB 对这两种压缩的方式都进行了实现。</p>
<p>无论是读操作还是写操作，在执行的过程中都可能调用 <code>MaybeScheduleCompaction</code> 来尝试对数据库中的 SSTable 进行合并，当合并的条件满足时，最终都会执行 <code>BackgroundCompaction</code> 方法在后台完成这个步骤。</p>
<p><img src="/assets/bigtable-leveldb/2017-08-12-LevelDB-BackgroundCompaction-Processes.jpg-1000width" alt="LevelDB-BackgroundCompaction-Processes"></p>
<p>这种合并分为两种情况，一种是 Minor Compaction，即内存中的数据超过了 memtable 大小的最大限制，改 memtable 被冻结为不可变的 imm，然后执行方法 <code>CompactMemTable()</code> 对内存表进行压缩。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">DBImpl::CompactMemTable</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  VersionEdit edit;</span><br><span class="line">  Version* base = versions_-&gt;<span class="built_in">current</span>();</span><br><span class="line">  <span class="built_in">WriteLevel0Table</span>(imm_, &amp;edit, base);</span><br><span class="line">  versions_-&gt;<span class="built_in">LogAndApply</span>(&amp;edit, &amp;mutex_);</span><br><span class="line">  <span class="built_in">DeleteObsoleteFiles</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>CompactMemTable</code> 会执行 <code>WriteLevel0Table</code> 将当前的 imm 转换成一个 Level0 的 SSTable 文件，同时由于 Level0 层级的文件变多，可能会继续触发一个新的 Major Compaction，在这里我们就需要在这里选择需要压缩的合适的层级：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">Status <span class="title">DBImpl::WriteLevel0Table</span><span class="params">(MemTable* mem, VersionEdit* edit, Version* base)</span> </span>&#123;</span><br><span class="line">  FileMetaData meta;</span><br><span class="line">  meta.number = versions_-&gt;<span class="built_in">NewFileNumber</span>();</span><br><span class="line">  Iterator* iter = mem-&gt;<span class="built_in">NewIterator</span>();</span><br><span class="line">  <span class="built_in">BuildTable</span>(dbname_, env_, options_, table_cache_, iter, &amp;meta);</span><br><span class="line"></span><br><span class="line">  <span class="type">const</span> Slice min_user_key = meta.smallest.<span class="built_in">user_key</span>();</span><br><span class="line">  <span class="type">const</span> Slice max_user_key = meta.largest.<span class="built_in">user_key</span>();</span><br><span class="line">  <span class="type">int</span> level = base-&gt;<span class="built_in">PickLevelForMemTableOutput</span>(min_user_key, max_user_key);</span><br><span class="line">  edit-&gt;<span class="built_in">AddFile</span>(level, meta.number, meta.file_size, meta.smallest, meta.largest);</span><br><span class="line">  <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>所有对当前 SSTable 数据的修改由一个统一的 <code>VersionEdit</code> 对象记录和管理，我们会在后面介绍这个对象的作用和实现，如果成功写入了就会返回这个文件的元数据 <code>FileMetaData</code>，最后调用 <code>VersionSet</code> 的方法 <code>LogAndApply</code> 将文件中的全部变化如实记录下来，最后做一些数据的清理工作。</p>
<p>当然如果是 Major Compaction 就稍微有一些复杂了，不过整理后的 <code>BackgroundCompaction</code> 方法的逻辑非常清晰：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">DBImpl::BackgroundCompaction</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (imm_ != <span class="literal">NULL</span>) &#123;</span><br><span class="line">    <span class="built_in">CompactMemTable</span>();</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  Compaction* c = versions_-&gt;<span class="built_in">PickCompaction</span>();</span><br><span class="line">  CompactionState* compact = <span class="keyword">new</span> <span class="built_in">CompactionState</span>(c);</span><br><span class="line">  <span class="built_in">DoCompactionWork</span>(compact);</span><br><span class="line">  <span class="built_in">CleanupCompaction</span>(compact);</span><br><span class="line">  <span class="built_in">DeleteObsoleteFiles</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>我们从当前的 <code>VersionSet</code> 中找到需要压缩的文件信息，将它们打包存入一个 <code>Compaction</code> 对象，该对象需要选择两个层级的 SSTable，低层级的表很好选择，只需要选择大小超过限制的或者查询次数太多的 SSTable；当我们选择了低层级的一个 SSTable 后，就在更高的层级选择与该 SSTable 有重叠键的 SSTable 就可以了，通过 <code>FileMetaData</code> 中数据的帮助我们可以很快找到待压缩的全部数据。</p>
<blockquote>
<p>查询次数太多的意思就是，当客户端调用多次 <code>Get</code> 方法时，如果这次 <code>Get</code> 方法在某个层级的 SSTable 中找到了对应的键，那么就算做上一层级中包含该键的 SSTable 的一次查找，也就是这次查找由于不同层级键的覆盖范围造成了更多的耗时，每个 SSTable 在创建之后的 <code>allowed_seeks</code> 都为 100 次，当 <code>allowed_seeks &lt; 0</code> 时就会触发该文件的与更高层级和合并，以减少以后查询的查找次数。</p>
</blockquote>
<p><img src="/assets/bigtable-leveldb/2017-08-12-LevelDB-Pick-Compactions.jpg-1000width" alt="LevelDB-Pick-Compactions"></p>
<p>LevelDB 中的 <code>DoCompactionWork</code> 方法会对所有传入的 SSTable 中的键值使用归并排序进行合并，最后会在高高层级（图中为 Level2）中生成一个新的 SSTable。</p>
<p><img src="/assets/bigtable-leveldb/2017-08-12-LevelDB-After-Compactions.jpg-1000width" alt="LevelDB-After-Compactions"></p>
<p>这样下一次查询 17~40 之间的值时就可以减少一次对 SSTable 中数据的二分查找以及读取文件的时间，提升读写的性能。</p>
<h4 id="存储-db-状态的-VersionSet"><a class="header-anchor" href="#存储-db-状态的-VersionSet"></a><a href="#%E5%AD%98%E5%82%A8-db-%E7%8A%B6%E6%80%81%E7%9A%84-versionset"></a>存储 db 状态的 VersionSet</h4>
<p>LevelDB 中的所有状态其实都是被一个 <code>VersionSet</code> 结构所存储的，一个 <code>VersionSet</code> 包含一组 <code>Version</code> 结构体，所有的 <code>Version</code> 包括历史版本都是通过双向链表连接起来的，但是只有一个版本是当前版本。</p>
<p><img src="/assets/bigtable-leveldb/2017-08-12-VersionSet-Version-And-VersionEdit.jpg-1000width" alt="VersionSet-Version-And-VersionEdit"></p>
<p>当 LevelDB 中的 SSTable 发生变动时，它会生成一个 <code>VersionEdit</code> 结构，最终执行 <code>LogAndApply</code> 方法：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">Status <span class="title">VersionSet::LogAndApply</span><span class="params">(VersionEdit* edit, port::Mutex* mu)</span> </span>&#123;</span><br><span class="line">  Version* v = <span class="keyword">new</span> <span class="built_in">Version</span>(<span class="keyword">this</span>);</span><br><span class="line">  <span class="function">Builder <span class="title">builder</span><span class="params">(<span class="keyword">this</span>, current_)</span></span>;</span><br><span class="line">  builder.<span class="built_in">Apply</span>(edit);</span><br><span class="line">  builder.<span class="built_in">SaveTo</span>(v);</span><br><span class="line"></span><br><span class="line">  std::string new_manifest_file;</span><br><span class="line">  new_manifest_file = <span class="built_in">DescriptorFileName</span>(dbname_, manifest_file_number_);</span><br><span class="line">  env_-&gt;<span class="built_in">NewWritableFile</span>(new_manifest_file, &amp;descriptor_file_);</span><br><span class="line"></span><br><span class="line">  std::string record;</span><br><span class="line">  edit-&gt;<span class="built_in">EncodeTo</span>(&amp;record);</span><br><span class="line">  descriptor_log_-&gt;<span class="built_in">AddRecord</span>(record);</span><br><span class="line">  descriptor_file_-&gt;<span class="built_in">Sync</span>();</span><br><span class="line"></span><br><span class="line">  <span class="built_in">SetCurrentFile</span>(env_, dbname_, manifest_file_number_);</span><br><span class="line">  <span class="built_in">AppendVersion</span>(v);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该方法的主要工作是使用当前版本和 <code>VersionEdit</code> 创建一个新的版本对象，然后将 <code>Version</code> 的变更追加到 MANIFEST 日志中，并且改变数据库中全局当前版本信息。</p>
<blockquote>
<p>MANIFEST 文件中记录了 LevelDB 中所有层级中的表、每一个 SSTable 的 Key 范围和其他重要的元数据，它以日志的格式存储，所有对文件的增删操作都会追加到这个日志中。</p>
</blockquote>
<h4 id="SSTable-的格式"><a class="header-anchor" href="#SSTable-的格式"></a><a href="#sstable-%E7%9A%84%E6%A0%BC%E5%BC%8F"></a>SSTable 的格式</h4>
<p>SSTable 中其实存储的不只是数据，其中还保存了一些元数据、索引等信息，用于加速读写操作的速度，虽然在 Bigtable 的论文中并没有给出 SSTable 的数据格式，不过在 LevelDB 的实现中，我们可以发现 SSTable 是以这种格式存储数据的：</p>
<p><img src="/assets/bigtable-leveldb/2017-08-12-SSTable-Format.jpg-1000width" alt="SSTable-Format"></p>
<p>当 LevelDB 读取 SSTable 存在的 <code>ldb</code> 文件时，会先读取文件中的 <code>Footer</code> 信息。</p>
<p><img src="/assets/bigtable-leveldb/2017-08-12-SSTable-Footer.jpg-1000width" alt="SSTable-Foote"></p>
<p>整个 <code>Footer</code> 在文件中占用 48 个字节，我们能在其中拿到 MetaIndex 块和 Index 块的位置，再通过其中的索引继而找到对应值存在的位置。</p>
<p><code>TableBuilder::Rep</code> 结构体中就包含了一个文件需要创建的全部信息，包括数据块、索引块等等：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">TableBuilder</span>::Rep &#123;</span><br><span class="line">  WritableFile* file;</span><br><span class="line">  <span class="type">uint64_t</span> offset;</span><br><span class="line">  BlockBuilder data_block;</span><br><span class="line">  BlockBuilder index_block;</span><br><span class="line">  std::string last_key;</span><br><span class="line">  <span class="type">int64_t</span> num_entries;</span><br><span class="line">  <span class="type">bool</span> closed;</span><br><span class="line">  FilterBlockBuilder* filter_block;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>到这里，我们就完成了对整个数据读取过程的解析了；对于读操作，我们可以理解为 LevelDB 在它内部的『多级缓存』中依次查找是否存在对应的键，如果存在就会直接返回，唯一与缓存不同可能就是，在数据『命中』后，它并不会把数据移动到更近的地方，而是会把数据移到更远的地方来减少下一次的访问时间，虽然这么听起来却是不可思议，不过仔细想一下确实是这样。</p>
<h2 id="小结-v2"><a class="header-anchor" href="#小结-v2"></a><a href="#%E5%B0%8F%E7%BB%93-1"></a>小结</h2>
<p>在这篇文章中，我们通过对 LevelDB 源代码中读写操作的分析，了解了整个框架的绝大部分实现细节，包括 LevelDB 中存储数据的格式、多级 SSTable、如何进行合并以及管理版本等信息，不过由于篇幅所限，对于其中的一些问题并没有展开详细地进行介绍和分析，例如错误恢复以及缓存等问题；但是对 LevelDB 源代码的阅读，加深了我们对 Bigtable 论文中描述的分布式 KV 存储数据库的理解。</p>
<p>LevelDB 的源代码非常易于阅读，也是学习 C++ 语言非常优秀的资源，如果对文章的内容有疑问，可以在博客下面留言。</p>
<h2 id="Reference"><a class="header-anchor" href="#Reference"></a><a href="#reference"></a>Reference</h2>
<ul>
<li><a href="https://static.googleusercontent.com/media/research.google.com/en//archive/bigtable-osdi06.pdf">Bigtable: A Distributed Storage System for Structured Data</a></li>
<li><a href="https://github.com/google/leveldb">LevelDB</a></li>
<li><a href="https://static.googleusercontent.com/media/research.google.com/en//archive/chubby-osdi06.pdf">The Chubby lock service for loosely-coupled distributed systems</a></li>
<li><a href="https://github.com/google/leveldb/blob/master/doc/impl.md">LevelDB · Impl</a></li>
<li><a href="http://bean-li.github.io/leveldb-sstable/">leveldb 中的 SSTable</a></li>
</ul>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/bigtable-leveldb/">http://xnerv.wang/bigtable-leveldb/</a></strong><br>
转载自：<a href="https://draveness.me/bigtable-leveldb">浅析 Bigtable 和 LevelDB 的实现</a></p>
]]></content>
      <categories>
        <category>分布式及存储</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>分布式及存储</tag>
        <tag>Bigtable</tag>
        <tag>LevelDB</tag>
      </tags>
  </entry>
  <entry>
    <title>比特币白皮书：一种点对点的电子现金系统（转载）</title>
    <url>/bitcoin-a-peer-to-peer-electronic-cash-system-cn/</url>
    <content><![CDATA[<p><strong>原文作者：<a href="http://8btc.com/article-25-1.html">中本聪</a>（Satoshi Nakamoto）</strong></p>
<p><strong>作者邮箱：Satoshin@gmx.com</strong></p>
<p><strong>执行翻译：<a href="http://8btc.com">8btc.com</a>  巴比特 <a href="http://www.8btc.com/author/1043736">QQagent</a></strong></p>
<blockquote>
<p>[摘要]：本文提出了一种完全通过点对点技术实现的电子现金系统，它使得在线支付能够直接由一方发起并支付给另外一方，中间不需要通过任何的金融机构。虽然数字签名（Digital signatures）部分解决了这个问题，但是如果仍然需要第三方的支持才能防止双重支付（double-spending）的话，那么这种系统也就失去了存在的价值。我们(we)在此提出一种解决方案，使现金系统在点对点的环境下运行，并防止双重支付问题。该网络通过随机散列（hashing）对全部交易加上时间戳（timestamps），将它们合并入一个不断延伸的基于随机散列的工作量证明（proof-of-work）的链条作为交易记录，除非重新完成全部的工作量证明，形成的交易记录将不可更改。最长的链条不仅将作为被观察到的事件序列（sequence）的证明，而且被看做是来自CPU计算能力最大的池（pool）。只要大多数的CPU计算能力都没有打算合作起来对全网进行攻击，那么诚实的节点将会生成最长的、超过攻击者的链条。这个系统本身需要的基础设施非常少。信息尽最大努力在全网传播即可，节点(nodes)可以随时离开和重新加入网络，并将最长的工作量证明链条作为在该节点离线期间发生的交易的证明。</p>
</blockquote>
<span id="more"></span>
<h2 id="1-简介"><a class="header-anchor" href="#1-简介"></a>1. 简介</h2>
<p>互联网上的贸易，几乎都需要借助金融机构作为可资信赖的第三方来处理电子支付信息。虽然这类系统在绝大多数情况下都运作良好，但是这类系统仍然内生性地受制于“基于信用的模式”(trust based model)的弱点。我们无法实现完全不可逆的交易，因为金融机构总是不可避免地会出面协调争端。而金融中介的存在，也会增加交易的成本，并且限制了实际可行的最小交易规模，也限制了日常的小额支付交易。并且潜在的损失还在于，很多商品和服务本身是无法退货的，如果缺乏不可逆的支付手段，互联网的贸易就大大受限。因为有潜在的退款的可能，就需要交易双方拥有信任。而商家也必须提防自己的客户，因此会向客户索取完全不必要的个人信息。而实际的商业行为中，一定比例的欺诈性客户也被认为是不可避免的，相关损失视作销售费用处理。而在使用物理现金的情况下，这些销售费用和支付问题上的不确定性却是可以避免的，因为此时没有第三方信用中介的存在。<br>
所以，我们非常需要这样一种电子支付系统，它基于密码学原理而不基于信用，使得任何达成一致的双方，能够直接进行支付，从而不需要第三方中介的参与。杜绝回滚(reverse)支付交易的可能，这就可以保护特定的卖家免于欺诈；而对于想要保护买家的人来说，在此环境下设立通常的第三方担保机制也可谓轻松加愉快。在这篇论文中，我们(we)将提出一种通过点对点分布式的时间戳服务器来生成依照时间前后排列并加以记录的电子交易证明，从而解决双重支付问题。只要诚实的节点所控制的计算能力的总和，大于有合作关系的(cooperating)攻击者的计算能力的总和，该系统就是安全的。</p>
<h2 id="2-交易-Transactions"><a class="header-anchor" href="#2-交易-Transactions"></a>2. 交易(Transactions)</h2>
<p>我们定义，一枚电子货币（an electronic coin）是这样的一串数字签名：每一位所有者通过对前一次交易和下一位拥有者的公钥(Public key) 签署一个随机散列的数字签名，并将这个签名附加在这枚电子货币的末尾，电子货币就发送给了下一位所有者。而收款人通过对签名进行检验，就能够验证该链条的所有者。</p>
<p><img src="http://7fvhfe.com1.z0.glb.clouddn.com/wp-content/uploads/2013/11/11.png" alt="1"></p>
<p>该过程的问题在于，收款人将难以检验，之前的某位所有者，是否对这枚电子货币进行了双重支付。通常的解决方案，就是引入信得过的第三方权威，或者类似于造币厂(mint)的机构，来对每一笔交易进行检验，以防止双重支付。在每一笔交易结束后，这枚电子货币就要被造币厂回收，而造币厂将发行一枚新的电子货币；而只有造币厂直接发行的电子货币，才算作有效，这样就能够防止双重支付。可是该解决方案的问题在于，整个货币系统的命运完全依赖于运作造币厂的公司，因为每一笔交易都要经过该造币厂的确认，而该造币厂就好比是一家银行。<br>
我们需要收款人有某种方法，能够确保之前的所有者没有对更早发生的交易实施签名。从逻辑上看，为了达到目的，实际上我们需要关注的只是于本交易之前发生的交易，而不需要关注这笔交易发生之后是否会有双重支付的尝试。为了确保某一次交易是不存在的，那么唯一的方法就是获悉之前发生过的所有交易。在造币厂模型里面，造币厂获悉所有的交易，并且决定了交易完成的先后顺序。如果想要在电子系统中排除第三方中介机构，那么交易信息就应当被公开宣布（publicly announced）<a href="#footnote-1"><sup>[1]</sup></a> ，我们需要整个系统内的所有参与者，都有唯一公认的历史交易序列。收款人需要确保在交易期间绝大多数的节点都认同该交易是首次出现。</p>
<h2 id="3-时间戳服务器-Timestamp-server"><a class="header-anchor" href="#3-时间戳服务器-Timestamp-server"></a>3. 时间戳服务器(Timestamp server)</h2>
<p>本解决方案首先提出一个“时间戳服务器”。时间戳服务器通过对以区块(block)形式存在的一组数据实施随机散列而加上时间戳，并将该随机散列进行广播，就像在新闻或世界性新闻组网络（Usenet）的发帖一样<a href="#footnote-2"><sup>[2]</sup></a><a href="#footnote-3"><sup>[3]</sup></a><a href="#footnote-4"><sup>[4]</sup></a><a href="#footnote-5"><sup>[5]</sup></a> 。显然，该时间戳能够证实特定数据必然于某特定时间是的确存在的，因为只有在该时刻存在了才能获取相应的随机散列值。每个时间戳应当将前一个时间戳纳入其随机散列值中，每一个随后的时间戳都对之前的一个时间戳进行增强(reinforcing)，这样就形成了一个链条（Chain）。</p>
<p><img src="http://7fvhfe.com1.z0.glb.clouddn.com/wp-content/uploads/2013/11/21.png" alt="2"></p>
<h2 id="4-工作量证明（Proof-of-Work）"><a class="header-anchor" href="#4-工作量证明（Proof-of-Work）"></a>4. 工作量证明（Proof-of-Work）</h2>
<p>为了在点对点的基础上构建一组分散化的时间戳服务器，仅仅像报纸或世界性新闻网络组一样工作是不够的，我们还需要一个类似于亚当•柏克（Adam Back）提出的哈希现金（Hashcash）<a href="#footnote-6"><sup>[6]</sup></a> 。在进行随机散列运算时，工作量证明机制引入了对某一个特定值的扫描工作，比方说SHA-256下，随机散列值以一个或多个0开始。那么随着0的数目的上升, 找到这个解所需要的工作量将呈指数增长，而对结果进行检验则仅需要一次随机散列运算。</p>
<p>我们在区块中补增一个随机数(Nonce)，这个随机数要使得该给定区块的随机散列值出现了所需的那么多个0。我们通过反复尝试来找到这个随机数，直到找到为止，这样我们就构建了一个工作量证明机制。只要该CPU耗费的工作量能够满足该工作量证明机制，那么除非重新完成相当的工作量，该区块的信息就不可更改。由于之后的区块是链接在该区块之后的，所以想要更改该区块中的信息，就还需要重新完成之后所有区块的全部工作量。</p>
<p><img src="http://7fvhfe.com1.z0.glb.clouddn.com/wp-content/uploads/2013/11/31.png" alt="3"></p>
<p>同时，该工作量证明机制还解决了在集体投票表决时，谁是大多数的问题。如果决定大多数的方式是基于IP地址的，一IP地址一票，那么如果有人拥有分配大量IP地址的权力，则该机制就被破坏了。而工作量证明机制的本质则是一CPU一票。“大多数”的决定表达为最长的链，因为最长的链包含了最大的工作量。如果大多数的CPU为诚实的节点控制，那么诚实的链条将以最快的速度延长，并超越其他的竞争链条。如果想要对业已出现的区块进行修改，攻击者必须重新完成该区块的工作量外加该区块之后所有区块的工作量，并最终赶上和超越诚实节点的工作量。我们将在后文证明，设想一个较慢的攻击者试图赶上随后的区块，那么其成功概率将呈指数化递减。<br>
另一个问题是，硬件的运算速度在高速增长，而节点参与网络的程度则会有所起伏。为了解决这个问题，工作量证明的难度(the proof-of-work difficulty)将采用移动平均目标的方法来确定，即令难度指向令每小时生成区块的速度为某一个预定的平均数。如果区块生成的速度过快，那么难度就会提高。</p>
<h2 id="5-网络"><a class="header-anchor" href="#5-网络"></a>5. 网络</h2>
<p>运行该网络的步骤如下：</p>
<ul>
<li>
<ol>
<li>新的交易向全网进行广播；</li>
</ol>
</li>
<li>
<ol start="2">
<li>每一个节点都将收到的交易信息纳入一个区块中；</li>
</ol>
</li>
<li>
<ol start="3">
<li>每个节点都尝试在自己的区块中找到一个具有足够难度的工作量证明；</li>
</ol>
</li>
<li>
<ol start="4">
<li>当一个节点找到了一个工作量证明，它就向全网进行广播；</li>
</ol>
</li>
<li>
<ol start="5">
<li>当且仅当包含在该区块中的所有交易都是有效的且之前未存在过的，其他节点才认同该区块的有效性；</li>
</ol>
</li>
<li>
<ol start="6">
<li>其他节点表示他们接受该区块，而表示接受的方法，则是在跟随该区块的末尾，制造新的区块以延长该链条，而将被接受区块的随机散列值视为先于新区快的随机散列值。</li>
</ol>
</li>
</ul>
<p>节点始终都将最长的链条视为正确的链条，并持续工作和延长它。如果有两个节点同时广播不同版本的新区块，那么其他节点在接收到该区块的时间上将存在先后差别。当此情形，他们将在率先收到的区块基础上进行工作，但也会保留另外一个链条，以防后者变成最长的链条。该僵局（tie）的打破要等到下一个工作量证明被发现，而其中的一条链条被证实为是较长的一条，那么在另一条分支链条上工作的节点将转换阵营，开始在较长的链条上工作。<br>
所谓“新的交易要广播”，实际上不需要抵达全部的节点。只要交易信息能够抵达足够多的节点，那么他们将很快被整合进一个区块中。而区块的广播对被丢弃的信息是具有容错能力的。如果一个节点没有收到某特定区块，那么该节点将会发现自己缺失了某个区块，也就可以提出自己下载该区块的请求。</p>
<h2 id="6-激励"><a class="header-anchor" href="#6-激励"></a>6. 激励</h2>
<p>我们约定如此：每个区块的第一笔交易进行特殊化处理，该交易产生一枚由该区块创造者拥有的新的电子货币。这样就增加了节点支持该网络的激励，并在没有中央集权机构发行货币的情况下，提供了一种将电子货币分配到流通领域的一种方法。这种将一定数量新货币持续增添到货币系统中的方法，非常类似于耗费资源去挖掘金矿并将黄金注入到流通领域。此时，CPU的时间和电力消耗就是消耗的资源。<br>
另外一个激励的来源则是交易费（transaction fees）。如果某笔交易的输出值小于输入值，那么差额就是交易费，该交易费将被增加到该区块的激励中。只要既定数量的电子货币已经进入流通，那么激励机制就可以逐渐转换为完全依靠交易费，那么本货币系统就能够免于通货膨胀。<br>
激励系统也有助于鼓励节点保持诚实。如果有一个贪婪的攻击者能够调集比所有诚实节点加起来还要多的CPU计算力，那么他就面临一个选择：要么将其用于诚实工作产生新的电子货币，或者将其用于进行二次支付攻击。那么他就会发现，按照规则行事、诚实工作是更有利可图的。因为该等规则使得他能够拥有更多的电子货币，而不是破坏这个系统使得其自身财富的有效性受损。</p>
<h2 id="7-回收硬盘空间"><a class="header-anchor" href="#7-回收硬盘空间"></a>7. 回收硬盘空间</h2>
<p>如果最近的交易已经被纳入了足够多的区块之中，那么就可以丢弃该交易之前的数据，以回收硬盘空间。为了同时确保不损害区块的随机散列值，交易信息被随机散列时，被构建成一种Merkle树（Merkle tree）<a href="#footnote-7"><sup>[7]</sup></a> 的形态，使得只有根(root)被纳入了区块的随机散列值。通过将该树（tree）的分支拔除（stubbing）的方法，老区块就能被压缩。而内部的随机散列值是不必保存的。</p>
<p><img src="http://7fvhfe.com1.z0.glb.clouddn.com/wp-content/uploads/2013/11/41.png" alt="4"></p>
<p>不含交易信息的区块头（Block header）大小仅有80字节。如果我们设定区块生成的速率为每10分钟一个，那么每一年产生的数据位4.2MB。（80 bytes * 6 * 24 * 365 = 4.2MB）。2008年，PC系统通常的内存容量为2GB，按照摩尔定律的预言，即使将全部的区块头存储于内存之中都不是问题。</p>
<h2 id="8-简化的支付确认（Simplified-Payment-Verification）"><a class="header-anchor" href="#8-简化的支付确认（Simplified-Payment-Verification）"></a>8. 简化的支付确认（Simplified Payment Verification）</h2>
<p>在不运行完整网络节点的情况下，也能够对支付进行检验。一个用户需要保留最长的工作量证明链条的区块头的拷贝，它可以不断向网络发起询问，直到它确信自己拥有最长的链条，并能够通过merkle的分支通向它被加上时间戳并纳入区块的那次交易。节点想要自行检验该交易的有效性原本是不可能的，但通过追溯到链条的某个位置，它就能看到某个节点曾经接受过它，并且于其后追加的区块也进一步证明全网曾经接受了它。</p>
<p><img src="http://7fvhfe.com1.z0.glb.clouddn.com/wp-content/uploads/2013/11/5.png" alt="5"></p>
<p>当此情形，只要诚实的节点控制了网络，检验机制就是可靠的。但是，当全网被一个计算力占优的攻击者攻击时，将变得较为脆弱。因为网络节点能够自行确认交易的有效性，只要攻击者能够持续地保持计算力优势，简化的机制会被攻击者焊接的（fabricated）交易欺骗。那么一个可行的策略就是，只要他们发现了一个无效的区块，就立刻发出警报，收到警报的用户将立刻开始下载被警告有问题的区块或交易的完整信息，以便对信息的不一致进行判定。对于日常会发生大量收付的商业机构，可能仍会希望运行他们自己的完整节点，以保持较大的独立完全性和检验的快速性。</p>
<p><img src="http://7fvhfe.com1.z0.glb.clouddn.com/wp-content/uploads/2013/11/7.png" alt="7"></p>
<h2 id="9-价值的组合与分割（Combining-and-Splitting-Value）"><a class="header-anchor" href="#9-价值的组合与分割（Combining-and-Splitting-Value）"></a>9. 价值的组合与分割（Combining and Splitting Value）</h2>
<p>虽然可以单个单个地对电子货币进行处理，但是对于每一枚电子货币单独发起一次交易将是一种笨拙的办法。为了使得价值易于组合与分割，交易被设计为可以纳入多个输入和输出。一般而言是某次价值较大的前次交易构成的单一输入，或者由某几个价值较小的前次交易共同构成的并行输入，但是输出最多只有两个：一个用于支付，另一个用于找零（如有）。<br>
需要指出的是，当一笔交易依赖于之前的多笔交易时，这些交易又各自依赖于多笔交易，但这并不存在任何问题。因为这个工作机制并不需要展开检验之前发生的所有交易历史。</p>
<h2 id="10-隐私（Privacy）"><a class="header-anchor" href="#10-隐私（Privacy）"></a>10. 隐私（Privacy）</h2>
<p><img src="http://7fvhfe.com1.z0.glb.clouddn.com/wp-content/uploads/2013/11/6.png" alt="6"></p>
<p>传统的造币厂模型为交易的参与者提供了一定程度的隐私保护，因为试图向可信任的第三方索取交易信息是严格受限的。但是如果将交易信息向全网进行广播，就意味着这样的方法失效了。但是隐私依然可以得到保护：将公钥保持为匿名。公众得知的信息仅仅是有某个人将一定数量的货币发所给了另外一个人，但是难以将该交易同特定的人联系在一起，也就是说，公众难以确信，这些人究竟是谁。这同股票交易所发布的信息是类似的，股票交易发生的时间、交易量是记录在案且可供查询的，但是交易双方的身份信息却不予透露。<br>
作为额外的预防措施，使用者可以让每次交易都生成一个新的地址，以确保这些交易不被追溯到一个共同的所有者。但是由于并行输入的存在，一定程度上的追溯还是不可避免的，因为并行输入表明这些货币都属于同一个所有者。此时的风险在于，如果某个人的某一个公钥被确认属于他，那么就可以追溯出此人的其它很多交易。</p>
<h2 id="11-计算"><a class="header-anchor" href="#11-计算"></a>11. 计算</h2>
<p>设想如下场景：一个攻击者试图比诚实节点产生链条更快地制造替代性区块链。即便它达到了这一目的，但是整个系统也并非就此完全受制于攻击者的独断意志了，比方说凭空创造价值，或者掠夺本不属于攻击者的货币。这是因为节点将不会接受无效的交易，而诚实的节点永远不会接受一个包含了无效信息的区块。一个攻击者能做的，最多是更改他自己的交易信息，并试图拿回他刚刚付给别人的钱。<br>
诚实链条和攻击者链条之间的竞赛，可以用二叉树随机漫步（Binomial Random Walk)来描述。成功事件定义为诚实链条延长了一个区块，使其领先性+1，而失败事件则是攻击者的链条被延长了一个区块，使得差距-1。<br>
攻击者成功填补某一既定差距的可能性，可以近似地看做赌徒破产问题（Gambler’s Ruin problem）。假定一个赌徒拥有无限的透支信用，然后开始进行潜在次数为无穷的赌博，试图填补上自己的亏空。那么我们可以计算他填补上亏空的概率，也就是该攻击者赶上诚实链条，如下所示<a href="#footnote-8"><sup>[8]</sup></a> ：</p>
<p><img src="http://7fvhfe.com1.z0.glb.clouddn.com/wp-content/uploads/2013/11/pq.png" alt="pq"></p>
<p>假定p&gt;q，那么攻击成功的概率就因为区块数的增长而呈现指数化下降。由于概率是攻击者的敌人，如果他不能幸运且快速地获得成功，那么他获得成功的机会随着时间的流逝就变得愈发渺茫。那么我们考虑一个收款人需要等待多长时间，才能足够确信付款人已经难以更改交易了。我们假设付款人是一个支付攻击者，希望让收款人在一段时间内相信他已经付过款了，然后立即将支付的款项重新支付给自己。虽然收款人届时会发现这一点，但为时已晚。<br>
收款人生成了新的一对密钥组合，然后只预留一个较短的时间将公钥发送给付款人。这将可以防止以下情况：付款人预先准备好一个区块链然后持续地对此区块进行运算，直到运气让他的区块链超越了诚实链条，方才立即执行支付。当此情形，只要交易一旦发出，攻击者就开始秘密地准备一条包含了该交易替代版本的平行链条。<br>
然后收款人将等待交易出现在首个区块中，然后在等到z个区块链接其后。此时，他仍然不能确切知道攻击者已经进展了多少个区块，但是假设诚实区块将耗费平均预期时间以产生一个区块，那么攻击者的潜在进展就是一个泊松分布，分布的期望值为：</p>
<p><img src="http://7fvhfe.com1.z0.glb.clouddn.com/wp-content/uploads/2013/11/image022.png" alt="image022"></p>
<p>当此情形，为了计算攻击者追赶上的概率，我们将攻击者取得进展区块数量的泊松分布的概率密度，乘以在该数量下攻击者依然能够追赶上的概率。</p>
<p><img src="http://7fvhfe.com1.z0.glb.clouddn.com/wp-content/uploads/2013/11/pq2.png" alt="pq2"></p>
<p>化为如下形式，避免对无限数列求和：</p>
<p><img src="http://7fvhfe.com1.z0.glb.clouddn.com/wp-content/uploads/2013/11/pq3.png" alt="pq3"></p>
<p>写为如下C语言代码：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> double AttackerSuccessProbability(double q, int z)</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="type">double</span> p = <span class="number">1.0</span> - q;</span><br><span class="line"><span class="type">double</span> lambda = z * (q / p);</span><br><span class="line"><span class="type">double</span> sum = <span class="number">1.0</span>;</span><br><span class="line"><span class="type">int</span> i, k;</span><br><span class="line"><span class="keyword">for</span> (k = <span class="number">0</span>; k &lt;= z; k++)</span><br><span class="line">&#123;</span><br><span class="line"><span class="type">double</span> poisson = <span class="built_in">exp</span>(-lambda);</span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">1</span>; i &lt;= k; i++)</span><br><span class="line">poisson *= lambda / i;</span><br><span class="line">sum -= poisson * (<span class="number">1</span> - <span class="built_in">pow</span>(q / p, z - k));</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> sum;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>对其进行运算，我们可以得到如下的概率结果，发现概率对z值呈指数下降。</p>
<p>当q=0.1时</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">z=0 P=1.0000000</span><br><span class="line">z=1 P=0.2045873</span><br><span class="line">z=2 P=0.0509779</span><br><span class="line">z=3 P=0.0131722</span><br><span class="line">z=4 P=0.0034552</span><br><span class="line">z=5 P=0.0009137</span><br><span class="line">z=6 P=0.0002428</span><br><span class="line">z=7 P=0.0000647</span><br><span class="line">z=8 P=0.0000173</span><br><span class="line">z=9 P=0.0000046</span><br><span class="line">z=10 P=0.0000012</span><br></pre></td></tr></table></figure>
<p>当q=0.3时</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">z=0 P=1.0000000</span><br><span class="line">z=5 P=0.1773523</span><br><span class="line">z=10 P=0.0416605</span><br><span class="line">z=15 P=0.0101008</span><br><span class="line">z=20 P=0.0024804</span><br><span class="line">z=25 P=0.0006132</span><br><span class="line">z=30 P=0.0001522</span><br><span class="line">z=35 P=0.0000379</span><br><span class="line">z=40 P=0.0000095</span><br><span class="line">z=45 P=0.0000024</span><br><span class="line">z=50 P=0.0000006</span><br></pre></td></tr></table></figure>
<p>求解令<code>P&lt;0.1%</code>的z值：</p>
<p>为使<code>P&lt;0.001</code>，则</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">q=0.10 z=5</span><br><span class="line">q=0.15 z=8</span><br><span class="line">q=0.20 z=11</span><br><span class="line">q=0.25 z=15</span><br><span class="line">q=0.30 z=24</span><br><span class="line">q=0.35 z=41</span><br><span class="line">q=0.40 z=89</span><br><span class="line">q=0.45 z=340</span><br></pre></td></tr></table></figure>
<h2 id="12-结论"><a class="header-anchor" href="#12-结论"></a>12.结论</h2>
<p>我们在此提出了一种不需要信用中介的电子支付系统。我们首先讨论了通常的电子货币的电子签名原理，虽然这种系统为所有权提供了强有力的控制，但是不足以防止双重支付。为了解决这个问题，我们提出了一种采用工作量证明机制的点对点网络来记录交易的公开信息，只要诚实的节点能够控制绝大多数的CPU计算能力，就能使得攻击者事实上难以改变交易记录。该网络的强健之处在于它结构上的简洁性。节点之间的工作大部分是彼此独立的，只需要很少的协同。每个节点都不需要明确自己的身份，由于交易信息的流动路径并无任何要求，所以只需要尽其最大努力传播即可。节点可以随时离开网络，而想重新加入网络也非常容易，因为只需要补充接收离开期间的工作量证明链条即可。节点通过自己的CPU计算力进行投票，表决他们对有效区块的确认，他们不断延长有效的区块链来表达自己的确认，并拒绝在无效的区块之后延长区块以表示拒绝。本框架包含了一个P2P电子货币系统所需要的全部规则和激励措施。</p>
<h2 id="注释"><a class="header-anchor" href="#注释"></a>注释</h2>
<ol>
<li>W Dai（戴伟）,a scheme for a group of untraceable digital pseudonyms to pay each other with money and to enforce contracts amongst themselves without outside help（一种能够借助电子假名在群体内部相互支付并迫使个体遵守规则且不需要外界协助的电子现金机制）, “B-money”, <a href="http://www.weidai.com/bmoney.txt">http://www.weidai.com/bmoney.txt</a>, 1998(#refmark-1)</li>
<li>H. Massias, X.S. Avila, and J.-J. Quisquater, “Design of a secure timestamping service with minimal trust requirements,”（在最小化信任的基础上设计一种时间戳服务器） In 20th Symposium on Information Theory in the Benelux, May 1999.(#refmark-2)</li>
<li>S. Haber, W.S. Stornetta, “How to time-stamp a digital document,” （怎样为电子文件添加时间戳）In Journal of Cryptology, vol 3, No.2, pages 99-111, 1991.(#refmark-3)</li>
<li>D. Bayer, S. Haber, W.S. Stornetta, “Improving the efficiency and reliability of digital time-stamping,”（提升电子时间戳的效率和可靠性） In Sequences II: Methods in Communication, Security and Computer Science, pages 329-334, 1993.(#refmark-4)</li>
<li>S. Haber, W.S. Stornetta, “Secure names for bit-strings,”（比特字串的安全命名） In Proceedings of the 4th ACM Conference on Computer and Communications Security, pages 28-35, April 1997. on Computer and Communications Security, pages 28-35, April 1997.(#refmark-5)</li>
<li>A. Back, “Hashcash – a denial of service counter-measure,”（哈希现金——拒绝服务式攻击的克制方法）<a href="http://www.hashcash.org/papers/hashcash.pdf">http://www.hashcash.org/papers/hashcash.pdf</a>, 2002.(#refmark-6)</li>
<li>R.C. Merkle, “Protocols for public key cryptosystems,” （公钥密码系统的协议）In Proc. 1980 Symposium on Security and Privacy, IEEE Computer Society, pages 122-133, April 1980.<br>
S. Haber, W.S. Stornetta, “Secure names for bit-strings,”（比特字串安全命名） In Proceedings of the 4th ACM Conference on Computer and Communications Security, pages 28-35, April 1997. on Computer and Communications Security, pages 28-35, April 1997.<br>
H. Massias, X.S. Avila, and J.-J. Quisquater, “Design of a secure timestamping service with minimal trust requirements,”（在最小化信任的条件下设计一种时间戳服务器） In 20th Symposium on Information Theory in the Benelux, May 1999.(#refmark-7)</li>
<li>W. Feller, “An introduction to probability theory and its applications,” （概率学理论与应用导论）1957(#refmark-8)</li>
</ol>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/bitcoin-a-peer-to-peer-electronic-cash-system-cn/">http://xnerv.wang/bitcoin-a-peer-to-peer-electronic-cash-system-cn/</a></strong><br>
转载自：<a href="http://www.8btc.com/wiki/bitcoin-a-peer-to-peer-electronic-cash-system">比特币白皮书：一种点对点的电子现金系统</a></p>
]]></content>
      <categories>
        <category>区块链与比特币</category>
      </categories>
      <tags>
        <tag>区块链与比特币</tag>
        <tag>区块链</tag>
        <tag>比特币</tag>
      </tags>
  </entry>
  <entry>
    <title>缓存更新的套路（转载）</title>
    <url>/cache-update-routines/</url>
    <content><![CDATA[<p><img src="https://coolshell.cn/wp-content/uploads/2016/07/cache-300x158.png" alt="cache"></p>
<p>看到好些人在写更新缓存数据代码时，<strong>先删除缓存，然后再更新数据库</strong>，而后续的操作会把数据再装载的缓存中。<strong>然而，这个是逻辑是错误的</strong>。试想，两个并发操作，一个是更新操作，另一个是查询操作，更新操作删除缓存后，查询操作没有命中缓存，先把老数据读出来后放到缓存中，然后更新操作更新了数据库。于是，在缓存中的数据还是老的数据，导致缓存中的数据是脏的，而且还一直这样脏下去了。</p>
<p>我不知道为什么这么多人用的都是这个逻辑，当我在微博上发了这个贴以后，我发现好些人给了好多非常复杂和诡异的方案，所以，我想写这篇文章说一下几个缓存更新的Design Pattern（让我们多一些套路吧）。</p>
<p>这里，我们先不讨论更新缓存和更新数据这两个事是一个事务的事，或是会有失败的可能，我们先假设更新数据库和更新缓存都可以成功的情况（我们先把成功的代码逻辑先写对）。</p>
<p>更新缓存的的Design Pattern有四种：Cache aside, Read through, Write through, Write behind caching，我们下面一一来看一下这四种Pattern。</p>
<span id="more"></span>
<h2 id="Cache-Aside-Pattern"><a class="header-anchor" href="#Cache-Aside-Pattern"></a>Cache Aside Pattern</h2>
<p>这是最常用最常用的pattern了。其具体逻辑如下：</p>
<ul>
<li>
<p><strong>失效</strong>：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。</p>
</li>
<li>
<p><strong>命中</strong>：应用程序从cache中取数据，取到后返回。</p>
</li>
<li>
<p><strong>更新</strong>：先把数据存到数据库中，成功后，再让缓存失效。</p>
</li>
</ul>
<p><img src="https://coolshell.cn/wp-content/uploads/2016/07/Cache-Aside-Design-Pattern-Flow-Diagram-e1470471723210.png" alt="Cache-Aside-Design-Pattern-Flow-Diagram"></p>
<p><img src="https://coolshell.cn/wp-content/uploads/2016/07/Updating-Data-using-the-Cache-Aside-Pattern-Flow-Diagram-1-e1470471761402.png" alt="Updating-Data-using-the-Cache-Aside-Pattern-Flow-Diagram-1"></p>
<p>注意，我们的更新是先更新数据库，成功后，让缓存失效。那么，这种方式是否可以没有文章前面提到过的那个问题呢？我们可以脑补一下。</p>
<p>一个是查询操作，一个是更新操作的并发，首先，没有了删除cache数据的操作了，而是先更新了数据库中的数据，此时，缓存依然有效，所以，并发的查询操作拿的是没有更新的数据，但是，更新操作马上让缓存的失效了，后续的查询操作再把数据从数据库中拉出来。而不会像文章开头的那个逻辑产生的问题，后续的查询操作一直都在取老的数据。</p>
<p>这是标准的design pattern，包括Facebook的论文《<a href="https://www.usenix.org/system/files/conference/nsdi13/nsdi13-final170_update.pdf">Scaling Memcache at Facebook</a>》也使用了这个策略。为什么不是写完数据库后更新缓存？你可以看一下Quora上的这个问答《<a href="https://www.quora.com/Why-does-Facebook-use-delete-to-remove-the-key-value-pair-in-Memcached-instead-of-updating-the-Memcached-during-write-request-to-the-backend">Why does Facebook use delete to remove the key-value pair in Memcached instead of updating the Memcached during write request to the backend?</a>》，主要是怕两个并发的写操作导致脏数据。</p>
<p>那么，是不是Cache Aside这个就不会有并发问题了？不是的，比如，一个是读操作，但是没有命中缓存，然后就到数据库中取数据，此时来了一个写操作，写完数据库后，让缓存失效，然后，之前的那个读操作再把老的数据放进去，所以，会造成脏数据。</p>
<p>但，这个case理论上会出现，不过，实际上出现的概率可能非常低，因为这个条件需要发生在读缓存时缓存失效，而且并发着有一个写操作。而实际上数据库的写操作会比读操作慢得多，而且还要锁表，而读操作必需在写操作前进入数据库操作，而又要晚于写操作更新缓存，所有的这些条件都具备的概率基本并不大。</p>
<p><strong>所以，这也就是Quora上的那个答案里说的，要么通过2PC或是Paxos协议保证一致性，要么就是拼命的降低并发时脏数据的概率，而Facebook使用了这个降低概率的玩法，因为2PC太慢，而Paxos太复杂。当然，最好还是为缓存设置上过期时间。</strong></p>
<h2 id="Read-Write-Through-Pattern"><a class="header-anchor" href="#Read-Write-Through-Pattern"></a>Read/Write Through Pattern</h2>
<p>我们可以看到，在上面的Cache Aside套路中，我们的应用代码需要维护两个数据存储，一个是缓存（Cache），一个是数据库（Repository）。所以，应用程序比较啰嗦。而Read/Write Through套路是把更新数据库（Repository）的操作由缓存自己代理了，所以，对于应用层来说，就简单很多了。<strong>可以理解为，应用认为后端就是一个单一的存储，而存储自己维护自己的Cache。</strong></p>
<h3 id="Read-Through"><a class="header-anchor" href="#Read-Through"></a>Read Through</h3>
<p>Read Through 套路就是在查询操作中更新缓存，也就是说，当缓存失效的时候（过期或LRU换出），Cache Aside是由调用方负责把数据加载入缓存，而Read Through则用缓存服务自己来加载，从而对应用方是透明的。</p>
<h3 id="Write-Through"><a class="header-anchor" href="#Write-Through"></a>Write Through</h3>
<p>Write Through 套路和Read Through相仿，不过是在更新数据时发生。当有数据更新的时候，如果没有命中缓存，直接更新数据库，然后返回。如果命中了缓存，则更新缓存，然后再由Cache自己更新数据库（这是一个同步操作）</p>
<p>下图自来Wikipedia的<a href="https://en.wikipedia.org/wiki/Cache_(computing)">Cache词条</a>。其中的Memory你可以理解为就是我们例子里的数据库。</p>
<p><img src="https://coolshell.cn/wp-content/uploads/2016/07/460px-Write-through_with_no-write-allocation.svg_.png" alt="Write-through_with_no-write-allocation"></p>
<h2 id="Write-Behind-Caching-Pattern"><a class="header-anchor" href="#Write-Behind-Caching-Pattern"></a>Write Behind Caching Pattern</h2>
<p>Write Behind 又叫 Write Back。**一些了解Linux操作系统内核的同学对write back应该非常熟悉，这不就是Linux文件系统的Page Cache的算法吗？是的，你看基础这玩意全都是相通的。**所以，基础很重要，我已经不是一次说过基础很重要这事了。</p>
<p>Write Back套路，一句说就是，在更新数据的时候，只更新缓存，不更新数据库，而我们的缓存会异步地批量更新数据库。这个设计的好处就是让数据的I/O操作飞快无比（因为直接操作内存嘛 ），因为异步，write backg还可以合并对同一个数据的多次操作，所以性能的提高是相当可观的。</p>
<p>但是，其带来的问题是，数据不是强一致性的，而且可能会丢失（我们知道Unix/Linux非正常关机会导致数据丢失，就是因为这个事）。在软件设计上，我们基本上不可能做出一个没有缺陷的设计，就像算法设计中的时间换空间，空间换时间一个道理，有时候，强一致性和高性能，高可用和高性性是有冲突的。软件设计从来都是取舍Trade-Off。</p>
<p>另外，Write Back实现逻辑比较复杂，因为他需要track有哪数据是被更新了的，需要刷到持久层上。操作系统的write back会在仅当这个cache需要失效的时候，才会被真正持久起来，比如，内存不够了，或是进程退出了等情况，这又叫lazy write。</p>
<p>在wikipedia上有一张write back的流程图，基本逻辑如下：</p>
<p><img src="https://coolshell.cn/wp-content/uploads/2016/07/Write-back_with_write-allocation.png" alt="Write-back_with_write-allocation"></p>
<h2 id="再多唠叨一些"><a class="header-anchor" href="#再多唠叨一些"></a>再多唠叨一些</h2>
<p>1）上面讲的这些Design Pattern，其实并不是软件架构里的mysql数据库和memcache/redis的更新策略，这些东西都是计算机体系结构里的设计，比如CPU的缓存，硬盘文件系统中的缓存，硬盘上的缓存，数据库中的缓存。<strong>基本上来说，这些缓存更新的设计模式都是非常老古董的，而且历经长时间考验的策略</strong>，所以这也就是，工程学上所谓的Best Practice，遵从就好了。</p>
<p>2）有时候，我们觉得能做宏观的系统架构的人一定是很有经验的，其实，宏观系统架构中的很多设计都来源于这些微观的东西。比如，云计算中的很多虚拟化技术的原理，和传统的虚拟内存不是很像么？Unix下的那些I/O模型，也放大到了架构里的同步异步的模型，还有Unix发明的管道不就是数据流式计算架构吗？TCP的好些设计也用在不同系统间的通讯中，仔细看看这些微观层面，你会发现有很多设计都非常精妙……所以，<strong>请允许我在这里放句观点鲜明的话——如果你要做好架构，首先你得把计算机体系结构以及很多老古董的基础技术吃透了</strong>。</p>
<p>3）在软件开发或设计中，我非常建议在之前先去参考一下已有的设计和思路，<strong>看看相应的guideline，best practice或design pattern，吃透了已有的这些东西，再决定是否要重新发明轮子</strong>。千万不要似是而非地，想当然的做软件设计。</p>
<p>4）上面，我们没有考虑缓存（Cache）和持久层（Repository）的整体事务的问题。比如，更新Cache成功，更新数据库失败了怎么吗？或是反过来。关于这个事，如果你需要强一致性，你需要使用“两阶段提交协议”——prepare, commit/rollback，比如Java 7 的<a href="http://docs.oracle.com/javaee/7/api/javax/transaction/xa/XAResource.html">XAResource</a>，还有MySQL 5.7的 <a href="http://dev.mysql.com/doc/refman/5.7/en/xa.html">XA Transaction</a>，有些cache也支持XA，比如<a href="http://www.ehcache.org/documentation/3.0/xa.html">EhCache</a>。当然，XA这样的强一致性的玩法会导致性能下降，关于分布式的事务的相关话题，你可以看看《<a href="https://coolshell.cn/articles/10910.html">分布式系统的事务处理</a>》一文。</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/cache-update-routines/">http://xnerv.wang/cache-update-routines/</a></strong><br>
转载自：<a href="https://coolshell.cn/articles/17416.html">缓存更新的套路</a></p>
]]></content>
      <categories>
        <category>分布式及存储</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>分布式及存储</tag>
        <tag>缓存</tag>
      </tags>
  </entry>
  <entry>
    <title>(MSDN) Comparing Memory Allocation Methods</title>
    <url>/comparing-memory-allocation-methods/</url>
    <content><![CDATA[<p>The following is a brief comparison of the various memory allocation methods:</p>
<ul>
<li><a href="https://msdn.microsoft.com/en-us/library/windows/desktop/ms692727(v=vs.85).aspx"><strong>CoTaskMemAlloc</strong></a></li>
<li><a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366574(v=vs.85).aspx"><strong>GlobalAlloc</strong></a></li>
<li><a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366597(v=vs.85).aspx"><strong>HeapAlloc</strong></a></li>
<li><a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366723(v=vs.85).aspx"><strong>LocalAlloc</strong></a></li>
<li><strong>malloc</strong></li>
<li><strong>new</strong></li>
<li><a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366887(v=vs.85).aspx"><strong>VirtualAlloc</strong></a></li>
</ul>
<p>Although the <a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366574(v=vs.85).aspx"><strong>GlobalAlloc</strong></a>, <a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366723(v=vs.85).aspx"><strong>LocalAlloc</strong></a>, and <a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366597(v=vs.85).aspx"><strong>HeapAlloc</strong></a> functions ultimately allocate memory from the same heap, each provides a slightly different set of functionality. For example, <strong>HeapAlloc</strong> can be instructed to raise an exception if memory could not be allocated, a capability not available with <strong>LocalAlloc</strong>. <strong>LocalAlloc</strong> supports allocation of handles which permit the underlying memory to be moved by a reallocation without changing the handle value, a capability not available with <strong>HeapAlloc</strong>.</p>
<span id="more"></span>
<p>Starting with 32-bit Windows, <a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366574(v=vs.85).aspx"><strong>GlobalAlloc</strong></a> and <a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366723(v=vs.85).aspx"><strong>LocalAlloc</strong></a> are implemented as wrapper functions that call <a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366597(v=vs.85).aspx"><strong>HeapAlloc</strong></a> using a handle to the process’s default heap. Therefore, <strong>GlobalAlloc</strong> and <strong>LocalAlloc</strong> have greater overhead than <strong>HeapAlloc</strong>.</p>
<p>Because the different heap allocators provide distinctive functionality by using different mechanisms, you must free memory with the correct function. For example, memory allocated with <a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366597(v=vs.85).aspx"><strong>HeapAlloc</strong></a> must be freed with <a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366701(v=vs.85).aspx"><strong>HeapFree</strong></a> and not <a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366730(v=vs.85).aspx"><strong>LocalFree</strong></a> or <a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366579(v=vs.85).aspx"><strong>GlobalFree</strong></a>. Memory allocated with <a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366574(v=vs.85).aspx"><strong>GlobalAlloc</strong></a> or <a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366723(v=vs.85).aspx"><strong>LocalAlloc</strong></a> must be queried, validated, and released with the corresponding global or local function.</p>
<p>The <a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366887(v=vs.85).aspx"><strong>VirtualAlloc</strong></a> function allows you to specify additional options for memory allocation. However, its allocations use a page granularity, so using <strong>VirtualAlloc</strong> can result in higher memory usage.</p>
<p>The <strong>malloc</strong> function has the disadvantage of being run-time dependent. The <strong>new</strong> operator has the disadvantage of being compiler dependent and language dependent.</p>
<p>The <a href="https://msdn.microsoft.com/en-us/library/windows/desktop/ms692727(v=vs.85).aspx"><strong>CoTaskMemAlloc</strong></a> function has the advantage of working well in either C, C++, or Visual Basic. It is also the only way to share memory in a COM-based application, since MIDL uses <strong>CoTaskMemAlloc</strong> and <a href="https://msdn.microsoft.com/en-us/library/windows/desktop/ms680722(v=vs.85).aspx"><strong>CoTaskMemFree</strong></a> to marshal memory.</p>
<h2 id="a-id-related-topics-a-Related-topics"><a class="header-anchor" href="#a-id-related-topics-a-Related-topics"></a><a id="related_topics"></a>Related topics</h2>
<p><a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366596(v=vs.85).aspx">Global and Local Functions</a><br>
<a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366711(v=vs.85).aspx">Heap Functions</a><br>
<a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366916(v=vs.85).aspx">Virtual Memory Functions</a></p>
<hr>
<p><strong>Article link: <a href="http://xnerv.wang/comparing-memory-allocation-methods/">http://xnerv.wang/comparing-memory-allocation-methods/</a></strong><br>
Reprinted from: <a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366533">(MSDN) Comparing Memory Allocation Methods</a></p>
]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Windows</tag>
        <tag>Heap</tag>
        <tag>MSDN</tag>
      </tags>
  </entry>
  <entry>
    <title>编译Windows版的Seafile客户端</title>
    <url>/compile-windows-seafile-client/</url>
    <content><![CDATA[<p>Seafile是国内少有的做的还不错的开源产品之一。相信很多朋友都经历过几年前的各大云盘厂商大战然后纷纷衰落的这个过程。金山快盘应该是我用过的个人觉得最好的一款云盘了，和Windows GUI的集成也非常完美。可惜现如今各大云盘不是停止运营了就是今非昔比了。因此与其每天提心吊胆地担心自己宝贵的“资源”是不是会被某度网盘封杀，作为码农的我们何不自己动手来搭建一个私有云盘。Seafile的UI是基于Qt，考虑到可移植性和跨平台兼容性，虽然不能像金山快盘那样拥有一些Windows上的特效，例如在托盘上查看当前在上传/下载哪些文件，以及上传/下载的进度。但优势是多平台，在Linux、安卓，iOS上都有相应的客户端。</p>
<p>Seafile官网只提供了Linux版本客户端的编译方法，并没有提供Windows版本的步骤。搜索了官方论坛，虽然有不少人提问问过，但是官方并没有给出回答。只能说国内的开源的文档还需要进一步完善，遮遮掩掩不算是真正的开源。<a href="http://www.ilovecpp.com/2018/06/25/seafile-compile/">搭建seafile windows客户端的交叉编译环境</a>这篇文章给出了一种基于MinGW在Fedora上交叉编译Windows版本Seafile的方法。我曾尝试过在Ubuntu 18.04上重复这个步骤，但是因为一些packages的原因没能成功。不同的Linux发行版之间的package有一些区别。我也曾尝试过在Windows上的MinGW上交叉编译，但有一些packages死活找不到在Windows MinGW上对应的版本，而且编译时也有一些错误（Windows上的MinGW好像是跑在Cygwin上面的，也就是说Cygwin上的packages可能不全或者跟Fedora上有一些不同）。最终由于时间关系，我放弃了去弄清楚其中的原因，而是采用在Ubuntu上用docker安装Fedora镜像这种类似作弊的方法来重现这篇文章中的步骤。</p>
<span id="more"></span>
<p>基于<a href="http://www.ilovecpp.com/2018/06/25/seafile-compile/">搭建seafile windows客户端的交叉编译环境</a>这篇文章，我写了一些脚本来自动化整个编译流程以及打包流程，这些脚本我都放到了GitHub上：<a href="https://github.com/xnervwang/SeafileClientBuildTools">xnervwang/SeafileClientBuildTools</a>。脚本分成两种，一种是在Host环境（例如我的Ubuntu）上执行的，一种是在docker实例中执行的。先介绍一下各个脚本的作用：</p>
<ul>
<li>
<p><code>InitDockerVerification.sh</code>：这个脚本是在Host环境中执行的。会根据<code>Dockerfile</code>创建相应的Fedora docker image，并且在当前的Host目录创建三个文件夹：build, ms-build, ms-build64，分别用于存放编译出来的Linux版本的Seafile客户端，32位Windows客户端，64位Windows客户端。build, ms-build, ms-build64这三个目录会通过docker volume映射到docker实例内，从而便于docker实例和Host共享目录。</p>
</li>
<li>
<p><code>Dockerfile</code>：<code>InitDockerVerification.sh</code>在创建docker image时会使用该文件。这个<code>Dockerfile</code>指定docker镜像在创建时，会git clone我的git repo <a href="https://github.com/xnervwang/SeafileClientBuildTools">xnervwang/SeafileClientBuildTools</a>，然后运行其中的<code>InstallDevPackagesFedora.sh</code>安装编译所需要的一些packages。然后基于该docker镜像创建的docker实例会自动执行<code>DockerEntry.sh</code>。</p>
</li>
<li>
<p><code>RunDockerVerification.sh</code>：创建docker实例并启动。</p>
</li>
<li>
<p><code>DockerEntry.sh</code>：这个脚本被docker实例在启动时执行，会先更新本地的git repo，然后执行<code>OneKey.sh</code>。<code>OneKey.sh</code>会编译Linux版本的Seafile客户端，32位Windows客户端，64位Windows客户端。然后调用<code>ResolveDllDeps.py</code>这个脚本分别对三种客户端进行打包，打包后的产物分别位于build, ms-build, ms-build64这三个目录内。</p>
</li>
<li>
<p><code>ResolveDllDeps.py</code>：这是我写的一个比较有意思的脚本。可以自动递归分析binary所依赖的所有.so动态链接库文件，然后将这些.so文件都复制到打包目录中，从而便于发布。需要注意的是编译出来的Seafile客户端还依赖于qt5/plugins/imageformats和qt5/plugins/platforms这两个插件目录，但是我的这个脚本却无法从Seafile客户端的可执行文件推导出这样的依赖关系。我推测可能这两个插件目录中的插件是通过dlopen的方式动态加载的，因此不能通过静态分析获得依赖关系。所以我将这连个目录中的.so也加入到了第一级的binary列表中。</p>
</li>
<li>
<p><code>Makefile</code>：这个是在docker实例中，在<code>DockerEntry.sh</code>执行编译时所使用的的Makefile。</p>
</li>
<li>
<p><code>Toolchain-cross-linux.i686.cmake/Toolchain-cross-linux.x86_64.cmake</code>：MinGW编译工具所使用的配置文件，分别用于32位/64位Windows客户端。</p>
</li>
<li>
<p><code>DropDockerVerification.sh</code>：删除docker实例和相关的生成目录。</p>
</li>
</ul>
<p>因此，基本的使用方法就是，首先基于<a href="https://docs.docker.com/install/linux/docker-ce/ubuntu/">docker官方文档</a>安装docker环境，然后git clone我的git repo，然后先执行<code>InitDockerVerification.sh</code>环境，然后以后就可以每次通过执行<code>RunDockerVerification.sh</code>来获取编译后的客户端，分别位于Host机器的build, ms-build, ms-build64这三个目录内。</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/compile-windows-seafile-client/">http://xnerv.wang/compile-windows-seafile-client/</a></strong></p>
]]></content>
      <categories>
        <category>分布式及存储</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>Windows</tag>
        <tag>分布式及存储</tag>
        <tag>Seafile</tag>
        <tag>MinGW</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>【协程原理】 - 协程不过是用户态的线程（转载）</title>
    <url>/coroutine-is-a-type-of-user-mode-thread/</url>
    <content><![CDATA[<p>笔者最美好的记忆来自于早年在6502 cpu的cc800上写汇编的年代， 那个时代的计算机甚至没有操作系统，也没有实模式等保护机制。在6502上写汇编应用其实非常简单，系统会把bin文件加载到一个固定的内存地址中，cpu会固定地从一个特定的位置开始执行。然后cpu就按照你提供的机器指令开始一条一条的执行。在高级语言中的“函数调用”的概念，在汇编里主要体现为两个寄存器。寄存器是cpu内部临时保存数据的区域，相当于高级语言里的变量。但是有一个寄存器是特殊的，它存放了cpu当前正在执行的指令的内存地址(Instruction Register)。一个高级语言中的函数一般会被编译成指令存放在一段连续的内存空间中（data segment）。那么所谓函数执行到了第几行这样的信息其实就是保存在这个Instruction Register中的。另外一个很特殊的寄存器是Stack Register，它其中存放的内存地址指向的内存区域用于函数之间传递参数和返回值，以及存放一个函数内的局部变量。如果不考虑现代计算机cpu中各种各样其他存放中间结果的寄存器，理论上保存了Instruction Register（执行到哪儿了）和Stack Register（堆栈上的变量）就保存了一个函数的当前执行状态，分别是函数当前执行到了哪，以及这个函数局部变量所代表的当前state。</p>
<span id="more"></span>
<p>事实上，操作系统的几个关键切换也是这么来完成的。操作系统提供了两个执行态，一个是用户态，一般我们的代码都是执行在用户态的。另外一个是内核态，像驱动程序之类的代码会用各种方式被加载到操作系统内部执行在内核之中。内核态里的代码可以完全控制CPU的I/O中断，从而可以和外部设备交互。用户态的代码属于受限代码，必须把I/O请求通过syscall交由运行在内核态的操作系统来完成。当一个cpu的核在执行用户态代码时，其寄存器里存放的状态是你的应用的代码的状态，但是应用要进行I/O操作的时候，cpu要被切换到内核的代码里去执行内核态的代码。这里就需要进行一次context switch，所谓context switch其实原理不会比把寄存器的值存到内存的一个地方，等回来的时候再把内存中临时保存的值加载回寄存器复杂多少。</p>
<p>操作系统还有一个需要进行context switch的地方，那就是在协程与协程之间。操作系统在执行一个ELF或者PE的可执行文件的时候，对于这个可执行文件内的汇编代码来说，整个内存寻址空间是独立的。也就是1.exe的执行状态完全无法感知到2.exe的执行状态的内存。也就是现代操作系统的虚拟内存空间。有cpu在两个进程之间切换状态的时候，需要把内存的映射关系调整过来，否则虚拟内存的地址是无法对应到正确的物理地址的。一个进程内的两个线成切换的时候，要稍微简单一些，只需要把当前线成正在执行的位置和栈做切换就可以了。</p>
<p>无论是操作系统做user/kernel的switch，还是process/process，thread/thread的switch，其实现方式都是大同小异的。通过把“当前执行状态”这样的一个抽象概念落实为一个具体的数据结构存储起来，然后指挥cpu在不同的场合加载不同的数据恢复不同的“当前执行状态”。</p>
<p>在高级语言中，一个函数正在执行的位置以及其状态，内部都可以有一个抽象的表达方式。有的高级语言直接被编译成原生的机器码，那么其执行状态的表述就和操作系统的context switch的context非常类似。有的高级语言自身执行在一个虚拟机之上，那么其context的表述可能是虚拟机的instruction register和stack register，而不是80x86这样原生的机器的物理寄存器。但是原理是非常类似的。</p>
<p>取决于语言设计者的觉悟，有的语言会把这种表达执行状态的能力直接提供出来，让一个函数在执行过程中可以把当前状态保存，然后把执行权交给另外一个函数执行，等那个函数放弃执行权回来的时候再把保存的状态恢复。这也就是所谓的协程（co-routine）。协程与线程的区别在于，协程的context switch是在完全在用户态，由语言的runtime或者是库来完成的。而线程的context switch则是操作系统来完成的。</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/coroutine-is-a-type-of-user-mode-thread/">http://xnerv.wang/coroutine-is-a-type-of-user-mode-thread/</a></strong><br>
转载自：<a href="https://segmentfault.com/a/1190000000663472">【协程原理】 - 协程不过是用户态的线程</a></p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>操作系统</tag>
        <tag>协程</tag>
        <tag>线程</tag>
      </tags>
  </entry>
  <entry>
    <title>一些基础的C++豆知识</title>
    <url>/cpp-bean-knowledge/</url>
    <content><![CDATA[<h2 id="基础语法"><a class="header-anchor" href="#基础语法"></a>基础语法</h2>
<ul>
<li>由于C++的枚举不像C#中的枚举，其枚举类型名并不是标识符的一部分，因此经常可能发生命名冲突的问题，解决的方法有四个：在枚举元素名称前加限定前缀（如enum EnumFruit { EnumFruit_apple = 1 };），将枚举类型放在一个同名的命名空间中，或将枚举作为类的嵌套类型，或者使用C++11的enum class（<a href="https://stackoverflow.com/questions/14041711/whats-an-enum-class-and-why-should-i-care?noredirect=1&amp;lq=1">What’s an enum class and why should I care?</a>）。</li>
<li>struct和class的默认类继承方式都是private，这与struct的成员默认继承方式是public是不同的。</li>
<li><code>#include_next &lt;filename.h&gt;</code>，include位于搜索路径中位于当前文件之后的文件filename.h。</li>
<li>在vc中，inlucde的路径的反斜杠不需要转义，如<code>#include &quot;..\..\..\Global\Data\GlobalPreferencesMgr.h&quot;</code>。</li>
<li>对于namespace中的函数或class的前置声明，必须同样也包括在相同的namespace中，而不能用class ::std::A这种写法。（<a href="https://stackoverflow.com/questions/2059665/why-cant-i-forward-declare-a-class-in-a-namespace-like-this">Why can’t I forward-declare a class in a namespace like this?</a>）</li>
<li>没有<code>&amp;&amp;=</code>，只有<code>&amp;=</code>。</li>
<li>（-1 || 0） == 1，请想想为什么。</li>
</ul>
<span id="more"></span>
<h3 id="位移"><a class="header-anchor" href="#位移"></a>位移</h3>
<ul>
<li>在C语言中，涉及位移的运算符有2个，&gt;&gt;表示右移，&lt;&lt;则表示左移。<br>
而汇编指令中，SHL和SHR表示逻辑左移和逻辑右移，SAR和SAL表示算术左移和算术右移。<br>
其中，逻辑左移和算术左移都是寄存器二进制位整体向左移动，并在右边补0。<br>
而右移则不同，逻辑右移是整体向右移，并在左边补0，而算术左移则是根据原符号位的值补与其相同的值。</li>
<li>那么如何在C语言中分别实现逻辑和算术位移呢？根据C标准，如果在位移运算符左边的变量是有符号数，如int,char,short等，编译产生的汇编指令是算术位移指令，如果该变量是无符号数，如unsigned int,unsigned char等，编译产生的汇编指令则是逻辑位移指令。</li>
<li>虽然intel平台上都是little-endian字节序，如果看作左边是低端地址右边是高端地址，则左移似乎丢弃低端bits。其实，对于C语言，在移位逻辑上要看作是big-endian，例如0x1001，左边是高位，左移是丢弃高位bits。</li>
</ul>
<h2 id="变量"><a class="header-anchor" href="#变量"></a>变量</h2>
<ul>
<li>
<p>如果反码范围是-127~127，则0有00000000和10000000两种表示方法。补码由于负数是在反码的基础上+1，因此-128占用了10000000，因此补码的负数能多表示一个。</p>
</li>
<li>
<p>64位系统vc的long仍然只有4 bytes，64位gcc则是8 bytes。主要是由于64位Linux用的是LP64位数据模型，而64位Windows用的是LLP64位数据模型。（<a href="https://stackoverflow.com/questions/384502/what-is-the-bit-size-of-long-on-64-bit-windows">What is the bit size of long on 64-bit Windows?</a>）</p>
</li>
<li>
<p>注意1.f也是一种合法的写法，与1.0f是等价的。（<a href="https://stackoverflow.com/questions/15048165/what-is-the-difference-between-1-0f-and-1-f">What is the difference between “1.0f” and “1.f”?</a>）</p>
</li>
<li>
<p>当一个struct定义了构造函数，或者用新的C++11语法直接赋予成员默认值后（<a href="https://stackoverflow.com/questions/27352021/c11-member-initializer-list-vs-in-class-initializer">C++11 member initializer list vs in-class initializer?</a>），就不能用new A{1, 2, “a”}这样的“集合初始化”语法了，必须提供构造函数。（<a href="https://stackoverflow.com/questions/16983539/why-can-i-not-brace-initialize-a-struct-derived-from-another-struct">Why can I not brace initialize a struct derived from another struct?</a>）</p>
</li>
<li>
<p>全局变量可以用函数进行初始化，但注意static成员的初始化顺序不一定是按照定义的顺序进行的。（<a href="https://stackoverflow.com/questions/6337426/may-i-initialize-a-global-variable-with-the-result-of-a-function-call">May I initialize a global variable with the result of a function call?</a>）</p>
</li>
<li>
<p>字面常量（literal constant）根据平台的不同，有可能存储在text段，也可能存储在data段或其它地方，但具有static生命周期。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">char *b;</span><br><span class="line">&#123;</span><br><span class="line">  char *a = &quot;abc&quot;;</span><br><span class="line">  b = a;</span><br><span class="line">&#125;</span><br><span class="line">// b仍然是有效指针</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>string类采用了Copy-On-Write，将str b赋值给str a之后，如果a不修改，则a和b其实用的是同样的char*内存。所以这也是一个警示，string的c_str()地址是可能变化的，不应该去依赖这个地址。</p>
</li>
<li>
<p>string本身是没有encoding的，取决于输入的字符串的encoding（<a href="https://stackoverflow.com/questions/1010783/what-encoding-does-stdstring-c-str-use">What encoding does std::string.c_str() use?</a>）。而字符串encoding一般由</p>
</li>
<li>
<p><a href="http://stackoverflow.com/questions/32872465/const-char-value-lifetime">const char * value lifetime</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">const char **p = nullptr;</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">    const char *t = &quot;test&quot;;</span><br><span class="line">    p = &amp;t;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">cout &lt;&lt; *p;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>&quot;test&quot;是字面常量，和global或static变量具有类似的生命周期。</p>
<h3 id="变量修饰关键字"><a class="header-anchor" href="#变量修饰关键字"></a>变量修饰关键字</h3>
<ul>
<li>const是限制指针还是限制指向的变量，关键看const是在星号*的左边还是右边。。如<code>const int *cptr</code>和<code>int const *cptr</code>是限制int，说明指向的是一个常亮。<code>int *const cptr</code>是一个常量指针，不能再指向其它int变量。（更简单直观的看法是，看const的右边是什么，<code>*cptr</code>是原变量本身，而cptr是指针）</li>
<li><code>const int *</code>指针不能赋值给<code>int *</code>指针，因为一个是指向const int类型，一个是指向int类型。而<code>int * const</code>指针可以赋值给<code>int *</code>指针，因为两者都是指向int变量，指向同类型变量的指针之间的相互赋值，是不受指针本身是否为const的影响的。</li>
<li>对于<code>func(const char*)</code>，正如上面一条所说的，可以将char*实参传递过来。但是对于<code>fun(const char*&amp; p)</code>这种加了引用的函数，不能将<code>char*</code>的指针传给它，而必须传<code>const char*</code>指针，因为引用必须引用相同的类型，一个<code>const char*</code>的引用不能去引用一个<code>char*</code>的变量。</li>
<li>auto这个关键字用于声明变量的生存期为自动，即将不在任何类、结构、枚举、联合和函数中定义的变量视为全局变量，而在函数中定义的变量视为局部变量。它是存储类型标识符，表明变量（自动）具有本地范围。块范围的变量声明（如for循环体内的变量声明）默认为auto存储类型。</li>
<li>mutable关键是为了针对const而提出来的关键字。extern关键字则是针对static（C语言）提出来的关键字。register关键字是针对volatile提出来的关键字。<a href="https://blog.csdn.net/hanchaoman/article/details/41116251">volatile与const一样需要弄清楚修饰的是变量本身还是指针，以及哪一级的指针</a>。</li>
<li>const int &amp;a =100是正确的，但去掉const就是错误的。</li>
</ul>
<h3 id="浮点数"><a class="header-anchor" href="#浮点数"></a>浮点数</h3>
<ul>
<li>浮点数是不能用 unsigned来规范的。unsigned 的意思就是把内存中的数据第一位也用来表示数据，而不用于表示符号位。而浮点数规定内存中数据的第一位必须是符号位（<a href="https://en.wikipedia.org/wiki/Double-precision_floating-point_format">Double-precision floating-point format</a>）。因此两者之间是互相矛盾的，这也就是为什么浮点数不会有unsigned类型。在某些编译器下unsigned float 和 unsigned double会被自动转换成unsigned int类型，而不报错。这时sizeof(unsigned float)和sizeof(unsigned double)的值是4。</li>
<li>定点数的优点是很简单，大部分运算实现起来和整数一样或者略有变化，但是缺点则是表示范围，而且在表示很小的数的时候，大部分位都是0，精度很差，不能充分运用存储单元。浮点数就是设计来克服这个缺点的，它相当于一个定点数加上一个阶码，阶码表示将这个定点数的小数点移动若干位。由于可以用阶码移动小数点，因此称为浮点数。（<a href="https://zhihu.com/question/19848808/answer/120393769">为什么叫浮点数?</a>）</li>
<li>类型float和double通过==,&gt;,&lt;等比较不会引起编译错误，但是非常可能得到错误的结果。这是因为它们的内存分布不同，不可以直接比较。正确的方法是转换为同一类型后比较两者差值，如果结果小于规定的小值，则视为相等。</li>
</ul>
<h3 id="数组"><a class="header-anchor" href="#数组"></a>数组</h3>
<ul>
<li>对于数组char buff[] = “hello”，将buff 和 &amp;buff 用指针形式输出，结果是一样的。（<a href="https://stackoverflow.com/questions/7707190/address-of-array-difference-between-having-an-ampersand-and-no-ampersand">Address of array - difference between having an ampersand and no ampersand</a>）</li>
<li><a href="https://stackoverflow.com/questions/201101/how-to-initialize-all-members-of-an-array-to-the-same-value">How to initialize all members of an array to the same value?</a><br>
int array[100] = {0};可以将100个元素都设置成0，但int array[100] = {-1};只能将第一个元素设置成-1，声誉99个元素则设置成0。</li>
<li>不能将一个char[100]的实参传给一个char*&amp;的形参，因为对于引用，必须是类型严格相同的。char[100]跟char*虽然可以相互转换，但编译时类型并不相同。可以将形参改成int (&amp;arr)[100]这样。</li>
<li><code>char * arr[n] = &#123; &quot;aaa&quot;, &quot;bbb&quot; &#125;</code>是对的，是char<em>的数组，每一个char</em>指向一个字符串常量。而<code>char ** arr = &#123; &quot;aaa&quot;, &quot;bbb&quot; &#125;</code>是语法错误的，这是指向char*数组的二维指针，所以必须先<code>arr = new char*[n]</code>。</li>
<li>当数组定义时没有指定大小，当初始化采用列表初始化了，那么数组的大小由初始化时列表元素个数决定。如果明确指定了数组大小，当在初始化时指定的元素个数超过这个大小就会产生错误。如果初始化时指定的的元素个数比数组大小少，剩下的元素都回被初始化为0。字符数组可以方便地采用字符串直接初始化。因此，<code>int a[10] = &#123;0&#125;</code>这种写法，其实本来是将第一个元素置为0，但后续所有元素都会被默认置为0。</li>
</ul>
<h2 id="new-delete-malloc-free"><a class="header-anchor" href="#new-delete-malloc-free"></a>new/delete/malloc/free</h2>
<ul>
<li><a href="https://kelvinh.github.io/blog/2014/04/19/research-on-operator-new-and-delete/">深入探究C++的new/delete操作符</a><br>
new/new[]调用的是operator new/new[]，前者是C++关键字，而后者其实就是（全局或class内的）操作符重载。所谓的placement new其实就是operator new/new[]的重载版本，我们也可以自定义提供了更多参数的placement new版本如operator(size_t size, P2, P3, P4)，然后通过new(P2, P3, P4)这样的语法进行调用。</li>
<li>calloc返回的是一个数组，而malloc返回的是一个对象。calloc的效率一般是比较低的。calloc相当于malloc后再加memset。关于realloc，原来的指针会被Free，申请可能不成功，会返回NULL。新增区域内的初始值则不确定。alloca是在栈(stack)上申请空间，用完马上就释放。某些系统在函数已被调用后不能增加栈帧长度，于是也就不能支持alloca函数。</li>
</ul>
<h3 id="cookie信息"><a class="header-anchor" href="#cookie信息"></a>cookie信息</h3>
<ul>
<li>当我们使用 operator new 为一个自定义类型对象分配内存时，实际上我们得到的内存要比实际对象的内存大一些，这些内存除了要存储对象数据外，还需要记录这片内存的大小，此方法称为 cookie。这一点上的实现依据不同的编译器不同。（例如 MFC 选择在所分配内存的头部存储对象实际数据，而后面的部分存储边界标志和内存大小信息。g++ 则采用在所分配内存的头4个字节存储相关信息，而后面的内存存储对象实际数据。）当我们使用 delete operator 进行内存释放操作时，delete operator 就可以根据这些信息正确的释放指针所指向的内存块。</li>
<li>以上论述的是对于单个对象的内存分配/释放，当我们为数组分配/释放内存时，虽然我们仍然使用 new operator 和 delete operator，但是其内部行为却有不同：new operator 调用了operator new 的数组版的兄弟－ operator new[]，而后针对每一个数组成员调用构造函数。而 delete operator 先对每一个数组成员调用析构函数，而后调用 operator delete[] 来释放内存。需要注意的是，当我们创建或释放由自定义数据类型所构成的数组时，编译器为了能够标识出在 operator delete[] 中所需释放的内存块的大小，也使用了编译器相关的 cookie 技术。</li>
<li>根据Inside The C++ Object Model上所言，现在的编译器大多使用两种方法， 一种是cookie, 一个记录分配空间大小的内存小块绑定在分配内存的地址头部。二是使用表来对分配了的指针进行管理，每一个分配了空间的指针都在表中对应着分配空间的大小。</li>
</ul>
<h2 id="指针"><a class="header-anchor" href="#指针"></a>指针</h2>
<ul>
<li>ANSI规定不能对void<em>指针做++/+=等操作，但GNU将void</em>的这些操作当作和char*一样。（<a href="https://stackoverflow.com/questions/6449935/increment-void-pointer-by-one-byte-by-two">Increment void pointer by one byte? by two?</a>）</li>
<li>定义指向public成员函数的指针变量的一般形式为<code>数据类型名 (类名::*指针变量名)(参数表列)</code>。使指针变量指向一个公用成员函数的一般形式为<code>指针变量名=&amp;类名::成员函数名</code>。对于普通函数，函数名本身加不加&amp;都能表示函数指针，但是成员函数则必须加&amp;才能取地址。</li>
<li>在C语言里，一个指针可以指向一个函数。这个指针也有两个属性，但一个是函数的入口地址，另一个是函数的返值类型。但是C里面函数指针的形参列表可以不写出（obsolescent），而C++中则强制要求写出。（<a href="https://stackoverflow.com/questions/20835534/function-pointer-without-arguments-types">Function pointer without arguments types?</a>）</li>
</ul>
<h2 id="函数"><a class="header-anchor" href="#函数"></a>函数</h2>
<ul>
<li>
<p>默认值可以是全局变量、全局常量，甚至是一个函数。但不可以是局部变量。因为默认参数的调用是在编译时确定的，而局部变量位置与默认值在编译时无法确定。</p>
</li>
<li>
<p>当一个stack上的数组如char arr[5]作为参数传递给一个函数void func(char* p)或void func(char p[5])时，就降级为一个指针，sizeof只能取到指针本身的大小。要记得sizeof是一个编译器的行为，对于函数而言，有可能被多处调用到，传递来不同大小的数组，因此不可能在编译器完成sizeof。（<a href="https://stackoverflow.com/questions/2950332/why-does-a-c-array-have-a-wrong-sizeof-value-when-its-passed-to-a-function">Why does a C-Array have a wrong sizeof() value when it’s passed to a function?</a>）如果要保留数组类型，则要声明函数为void func(char (&amp;a)[5])。（<a href="https://stackoverflow.com/questions/1328223/when-a-function-has-a-specific-size-array-parameter-why-is-it-replaced-with-a-p">When a function has a specific-size array parameter, why is it replaced with a pointer?</a>）</p>
</li>
<li>
<p>数组的长度与参数声明无关。因此，下列三个声明是等价的：</p>
<pre><code><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void putValues(int*);</span><br><span class="line">void putValues(int[]);</span><br><span class="line">void putValues(int[10]);</span><br></pre></td></tr></table></figure>
</code></pre>
</li>
</ul>
<p>数组长度不是参数类型的一部分。函数不知道传递给它的数组的实际长度，编译器也不知道，当编译器对实参类型进行参数类型检查时，并不检查数组的长度。</p>
<ul>
<li>一个返回void的函数，可以在内部return另一个返回void的函数。</li>
<li>参数默认值可以写在函数声明处，也可以写在函数定义处，但是不能两处同时写，即使两处写的默认值是一样的。但是不同的cpp在声明一个外部函数时，应该可以使用不同的函数参数默认值声明，虽然在同一个cpp中不能看见有两次同一个函数的声明，即使是同样的默认值。这说明，无论是函数的声明还是定义，无论默认值是否相同，同一个函数的默认值定义不能出现两次。</li>
<li>string, char*参数都可以用字符串常量作为默认值，说明一个类A的对象，并且支持类型B到A的隐式转换，就可以用B的一个实例b作为参数默认值。（<a href="https://stackoverflow.com/questions/12121645/how-to-set-default-parameter-as-class-object-in-c">How to set default parameter as class object in c++?</a>）</li>
<li><a href="http://bbs.csdn.net/topics/300003660">如何定义一个函数指针，指向一个带有默认值参数的函数?</a><br>
结论是做不到，只能用类似functor或者std::function等来<a href="https://zh.wikipedia.org/wiki/%E6%9F%AF%E9%87%8C%E5%8C%96">科里化</a>其中的一个或部分参数值。</li>
<li>普通的函数不需要通过&amp;来取地址，但是成员方法取地址则必须加上&amp;。（<a href="https://stackoverflow.com/questions/18312186/if-ampersands-arent-needed-for-function-pointers-why-does-boostbind-require">If ampersands aren’t needed for function pointers, why does boost::bind require one?</a>）</li>
</ul>
<h3 id="内联函数"><a class="header-anchor" href="#内联函数"></a>内联函数</h3>
<ul>
<li>inline关键字更主要的含义是允许一个函数在不同的编译单元（cpp）同时存在实现，这和在h文件的class定义中直接实现一个方法，而不是将方法的实现放到cpp中，本质上是样的。至于是否会用内联代码代替函数调用，则是由编译器自身决定的。（<a href="https://stackoverflow.com/questions/1809679/difference-between-implementing-a-class-inside-a-h-file-or-in-a-cpp-file">Difference between implementing a class inside a .h file or in a .cpp file</a>）</li>
<li>在cpp中定义inline函数（即使在头文件中再次用inline声明了这个函数），对于其它的cpp而言是没有inline效果的。因为对于编译器而言，每个cpp都是独立的编译单元，因此一个cpp是不能inline另一个cpp中定义实现的inline函数的。（<a href="https://stackoverflow.com/questions/3992980/c-inline-member-function-in-cpp-file">C++ inline member function in .cpp file</a>）</li>
</ul>
<h3 id="构造函数"><a class="header-anchor" href="#构造函数"></a>构造函数</h3>
<ul>
<li>
<p>explicit关键字用于取消构造函数的隐式转换，对有多个参数的构造函数使用explicit是个语法错误。即用explict修饰的构造函数有且只能有一个参数。</p>
</li>
<li>
<p>在构造函数里调用另一个构造函数的关键是让第二个构造函数在第一次分配好的内存上执行，而不是分配新的内存，这个可以用标准库的placement new做到。</p>
<pre><code>  <figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">A</span>()</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">new</span>(<span class="keyword">this</span>)<span class="built_in">A</span>(<span class="number">11</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</code></pre>
</li>
</ul>
<p>注： 若构造函数调用自身，则会出现无限递归调用。</p>
<ul>
<li>成员初始化列表不能对基类成员变量赋值，而应该通过调用基类的构造函数达成目标。</li>
<li>C++初始化类成员时，是按照声明的顺序初始化的，而不是按照出现在初始化列表中的顺序。（<a href="https://stackoverflow.com/a/4037283/2258530">Order of execution in constructor initialization list</a>）</li>
<li>删除一个强转成void*的对象指针，会释放内存，但不会调用其析构函数。<a href="https://stackoverflow.com/questions/941832/is-it-safe-to-delete-a-void-pointer">Is it safe to delete a void pointer?</a></li>
<li>不要在有虚表的类的构造函数和析构函数中调用虚函数，会调用到基类的函数。（[Calling virtual functions inside constructors(<a href="https://stackoverflow.com/questions/962132/calling-virtual-functions-inside-constructors">https://stackoverflow.com/questions/962132/calling-virtual-functions-inside-constructors</a>)]，<a href="https://stackoverflow.com/questions/962132/calling-virtual-functions-inside-constructors">https://stackoverflow.com/questions/962132/calling-virtual-functions-inside-constructors</a>）</li>
<li><a href="http://stackoverflow.com/questions/3899223/what-is-a-non-trivial-constructor-in-c">What is a non-trivial constructor in C++?</a><br>
也就是说，trivial构造函数即没有定义构造函数。但没有自定义任何构造函数（包括拷贝构造函数）时，应该会由编译器自动生成trivial构造函数（其实就是什么都不做，进行对象的拷贝赋值时，直接进行memory copy）。如果只定义了一个带参数的构造函数的话，则不会再生成默认的构造函数。
<blockquote>
<p>If you define a constructor yourself, it is considered non-trivial, even if it doesn’t do anything, so a trivial constructor must be implicitly defined by the compiler.<br>
For a default constructor and destructor being “trivial” means literally “do nothing at all”. For copy-constructor and copy-assignment operator, being “trivial” means literally “be equivalent to simple raw memory copying” (like copy with memcpy).</p>
</blockquote>
</li>
</ul>
<h3 id="成员函数隐藏"><a class="header-anchor" href="#成员函数隐藏"></a>成员函数隐藏</h3>
<ul>
<li><a href="https://stackoverflow.com/questions/11923890/reason-for-c-member-function-hiding">Reason for C++ member function hiding</a><br>
当编译器于某一层找到能用（不一定最好，也许需要强制转换参数类型）的方法时，就不会继续再向上一层（父类）查找。不仅仅是类与类之间，嵌套的namespace也存在这个现象。</li>
</ul>
<h3 id="哑元函数"><a class="header-anchor" href="#哑元函数"></a>哑元函数</h3>
<ul>
<li>C++的哑元参数是指operator ++(int)这种。某个参数如果在子程序或函数中没有用到，那就被称为哑元。函数的形参又称“哑元”，实参又称“实元”。</li>
<li>。友元关系不能被继承。（<a href="https://stackoverflow.com/questions/3561648/why-does-c-not-allow-inherited-friendship">Why does C++ not allow inherited friendship?</a>）</li>
<li>至少在gcc里，<code>int a; string b; 1 == 1 ? a : b;</code>这种写法是可以的，但如果将这个表达式进行cout，就会编译报错提示两边类型不一直的。（<a href="https://stackoverflow.com/questions/8535226/return-type-of-ternary-conditional-operator">Return type of ‘?:’ (ternary conditional operator)</a>）</li>
</ul>
<h2 id="库函数"><a class="header-anchor" href="#库函数"></a>库函数</h2>
<ul>
<li><code>memmove</code>和<code>memcpy</code>的区别，在于前者当<code>src &lt; dest</code>并且两者区间有重叠时，会改用从后向前复制。memmove函数为什么要先判断重叠，而不是直接从尾部向头部复制？因为当dst的头部和src的尾部覆盖时，从尾部开始复制是正确的。但是当dst的尾部和src的头部覆盖时，从头部开始复制才是正确的。所以要区分处理。</li>
<li><code>memccpy</code>用来拷贝src所指的内存内容前n个字节到dest所指的地址上。与<code>memcpy</code>不同的是，<code>memccpy</code>如果在src中遇到某个特定值(int c)立即停止复制。</li>
<li><code>strtok</code>是一个线程不安全的函数，因为它使用了静态分配的空间来存储被分割的字符串位置（C库还有其它使用了静态空间的线程不安全函数）。运用<code>strtok</code>来判断ip或者mac的时候务必要先用其他的方法判断’.‘或’:'的个数，因为用<code>strtok</code>截断的话，比如：&quot;192…168.0…8…&quot;这个字符串，<code>strtok</code>只会截取四次，中间的…无论多少都会被当作一个key。而这个函数的线程安全版本在linux中是<code>strtok_r</code>，在vc中则是<code>strtok_s</code>。</li>
<li>sprintf和vsprintf的区别，以及snprintf和vsnprintf的区别，在于后者接收的是va_list，而前者是不变参数列表，后者几乎不会被直接使用，而是在不定参数的函数内部调用，作为一种“转发”。</li>
<li><a href="https://stackoverflow.com/questions/1376085/c-safe-to-use-longjmp-and-setjmp">在C++中用longjmp，可能导致析构函数不被调用。</a></li>
<li><a href="http://blog.think-async.com/2010/04/bind-illustrated.html">std::bind是基于functor仿函数实现的</a>，也就是函数对象实现存储固定的参数值。</li>
</ul>
<h2 id="C-的4种cast操作"><a class="header-anchor" href="#C-的4种cast操作"></a>C++的4种cast操作</h2>
<ul>
<li>
<p><code>static_cast/dynamic_cast/reinterpret_cast</code>不能将一个<code>const T*</code>转为<code>T*</code>，当然如果是将<code>const T</code>转化<code>T</code>是可以的。只有<code>const_cast</code>能将<code>const T*</code>转为<code>T*</code>。</p>
</li>
<li>
<p><code>reinterpret_cast</code>转换后的bits是不变的，因此在将double=1.0转变为int时，显然<code>reinterpret_cast</code>会得到诡异的结果。</p>
</li>
<li>
<p><code>rtti</code>包括<code>typeid(type_info)</code>和<code>dynamic_cast</code>两者，都需要虚表的支持。如果是没有虚函数的类，则<code>dynamic_cast</code>就只能从下往上安全转换了。此外，<code>dynamic_cast</code>只能对指针（引用）操作。<code>static_cast</code>是C++里面的类型安全转换，这个转换不允许将毫无关系的两个数据类型的指针互相转化。例如不能把<code>int**</code>转成<code>void**</code>，因为<code>int*</code>和<code>void*</code>没有关系，但是可以将<code>int*</code>转成<code>void*</code>。</p>
</li>
<li>
<p>综上所述，C风格的强制转换=<code>static_cast + reinterpret_cast</code>。对于有虚表的类的指针，<code>reinterpret_cast</code>由于不会调整this指针，也不会将vptr指针进行上溯或下溯，因此将会造成不可预期的结果。</p>
</li>
<li>
<p><code>static_cast</code>可以将<code>void*</code>转换为<code>A*</code>，但是不能量<code>B*</code>转换为<code>A*</code>。</p>
</li>
<li>
<p><code>bad_cast</code>这个关键字和<code>bad_typeid</code>类似，是<code>dynamic_cast</code>转换失败时（一般是错误地想把基类转换为子类时，此时转换结果为空指针），会抛出的异常。</p>
</li>
<li>
<p><code>const_cast</code>：允许添加或删除表达式类型的<code>const</code>或<code>volatile</code>关键字.</p>
</li>
<li>
<p><code>dynamic_cast</code>：仅适用于多态类型的向下转换，被转换的类型必须是一个指向含有虚函数的类类型的指针，否则会编译错误。</p>
</li>
<li>
<p><code>reinterpret_cast</code>：从位的角度来看待一个对象，从而允许将一个东西看成是完全不同的另一个东西，最强的一种转换。这个操作符能够在非相关的类型之间转换。操作结果只是简单的从一个指针到别的指针的值的二进制拷贝。在类型之间指向的内容不做任何类型的检查和转换。例如将一个double转化为int，<code>reinterpret_cast</code>仅仅复制bits，导致转化的值无意义。而<code>static_cast</code>就能得到正确的退一法值。</p>
</li>
<li>
<p>只有<a href="https://stackoverflow.com/questions/27309604/do-constant-and-reinterpret-cast-happen-at-compile-time">dynamic_cast是运行期行为</a>，其它三种cast都是编译器行为。</p>
</li>
<li>
<p><a href="http://stackoverflow.com/questions/18359780/how-is-dynamic-cast-implemented">How is dynamic_cast implemented</a><br>
<code>dynamic_cast</code> can know this by keeping this knowledge around.<br>
When the compiler generates code it keeps around the data about the class hierarchies in some sort of table that <code>dynamic_cast</code> can look up later. That table can be attached to the vtable pointer for easy lookup by the <code>dynamic_cast</code> implementation. The data neeeded for <code>typeid</code> for those classes can also be stored along with those.</p>
</li>
<li>
<p><a href="https://stackoverflow.com/questions/20798214/how-dynamic-cast-works-internally">How dynamic_cast works internally?</a><br>
Formally, of course, it’s implementation defined, but in practice, there will be an additional pointer in the vtable, which points to a description of the object, probably as a DAG of objects which contain pointers to the various children (derived classes) and information regarding their type (a pointer to a  type_info, perhaps).</p>
<blockquote>
<p>The compiler then generates code which walks the different paths in the graph until it either finds the targeted type, or has visited all of the nodes. If it finds the targeted type, the node will also contain the necessary information as to how to convert the pointer.</p>
<p>One additional point occurs to me. Even if the generated code finds a match, it may have to continue navigating in order to ensure that it isn’t ambiguous.</p>
</blockquote>
</li>
<li>
<p>dynamic_cast失败时，<a href="https://stackoverflow.com/questions/41213505/when-does-dynamic-cast-return-0-and-when-throws-exception-cpp?rq=1">有时是返回null，有时是抛出异常</a>。原因在于C++没有null reference，所以只能throw exception。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">Base* b1 = <span class="keyword">new</span> Derived;</span><br><span class="line">Derived* pd1 = <span class="built_in">dynamic_cast</span>&lt;Derived *&gt;(b1);  <span class="comment">// fails: returns &#x27;NULL&#x27;</span></span><br><span class="line">Derived d1 = <span class="built_in">dynamic_cast</span>&lt;Derived &amp;*&gt;(b1);  <span class="comment">// fails: exception thrown</span></span><br></pre></td></tr></table></figure>
<ul>
<li><a href="https://stackoverflow.com/questions/10151834/why-cant-i-static-cast-between-char-and-unsigned-char">Why can’t I static_cast between char * and unsigned char *?</a><br>
不同的两种类型的指针相互之间不能用static_cast转换，而必须用reinterprete_cast。而普通指针和void*之间则可以用static_cast相互转换。</li>
</ul>
</li>
</ul>
<h2 id="sizeof"><a class="header-anchor" href="#sizeof"></a>sizeof</h2>
<ul>
<li><a href="http://blog.csdn.net/freefalcon/article/details/54839">sizeof，终极无惑（上）</a></li>
</ul>
<blockquote>
<p>sizeof有三种语法形式，如下：</p>
<ol>
<li>sizeof( object ); // sizeof( 对象 );</li>
<li>sizeof( type_name ); // sizeof( 类型 );</li>
<li>sizeof object; // sizeof 对象;</li>
<li>size_t sz = sizeof( foo() ); // foo() 的返回值类型为char，所以sz = sizeof( char )，foo()并不会被调用。但是foo不能返回为void。<br>
c99标准支持对VLA取sizeof。</li>
</ol>
</blockquote>
<ul>
<li><a href="http://www.spongeliu.com/218.html">结构体的sizeof到底多大？</a></li>
</ul>
<blockquote>
<p>在VC中规定， 结构体变量的首地址能够被其最宽基本类型成员的大小所整除；而在gcc中规定对齐模数最大只能是4，也就是说，即使结构体中有double类型，对齐模数还是4。</p>
</blockquote>
<ul>
<li>
<p>sizeof也是运算符，虽然不能被重载。<br>
不能重载的运算符只有5个（<a href="https://www.quora.com/Which-operator-cannot-be-overloaded-in-C++-and-why">Which operator cannot be overloaded in C++ and why?</a>）：</p>
<pre><code>  - (成员访问运算符)
  .*  (成员指针访问运算符)
  ::  (域运算符)
  sizeof  (长度运算符)
  ?:  (条件运算符）
</code></pre>
</li>
<li>
<p><a href="http://www.spongeliu.com/260.html">为什么C++中空类和空结构体大小为1？</a></p>
</li>
</ul>
<blockquote>
<p>这是因为，C++标准中规定，“no object shall have the same address in memory as any other variable” ，就是任何不同的对象不能拥有相同的内存地址。 如果空类大小为0，若我们声明一个这个类的对象数组，那么数组中的每个对象都拥有了相同的地址，这显然是违背标准的。<br>
基本上所有的指针运算都依赖于sizeof T。</p>
</blockquote>
<h2 id="typedef"><a class="header-anchor" href="#typedef"></a>typedef</h2>
<ul>
<li>typdef定义的struct/class如何前置声明？</li>
</ul>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">my_time_t</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="type">int</span> hour, minute, second;</span><br><span class="line">&#125; MY_TIME;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">my_time_t</span>;</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">my_time_t</span> <span class="title">MY_TIME</span>;</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">func</span><span class="params">(MY_TIME* mt)</span> &#123;&#125;</span><br></pre></td></tr></table></figure>
<p>其实typedef作为一种类似宏的声明，在没有include头文件的情况下要想使用只能重新typedef。</p>
<ul>
<li><code>#define</code>没有作用域的限制，只要是之前预定义过的宏，在以后的程序中都可以使用。而typedef有自己的作用域。（<a href="https://stackoverflow.com/questions/2427739/please-explain-syntax-rules-and-scope-for-typedef">Please explain syntax rules and scope for “typedef”</a>）</li>
<li>typedef会影响模板参数T的匹配吗？对于func(int, int32_t)和func(int, int)，会优先匹配哪个？实验发现编译错误：func重定义。一个int实参不能传给unsigned&amp;的形参，但typedef可以。以上都表明typedef有点类似define。但是，ifdef/ifndef不能检查typedef。</li>
<li><code>typedef register int FAST_COUNTER;</code>，这种写法是错误的，编译通不过。问题出在你不能在声明中有多个存储类关键字（storage class specifier）。因为符号typedef已经占据了存储类关键字的位置， typedef声明中不能用register（或任何其它存储类关键字如static）。此外，由于存储类关键字本身并不是类型type的一部分，因此不允许其出现在typedef语句中也是合理的。（<a href="https://stackoverflow.com/questions/2218435/why-typedef-can-not-be-used-with-static">Why typedef can not be used with static?</a>）</li>
<li><code>typedef struct tagNode *pNode; struct tagNode  &#123; &#125;;</code>，在这个例子中，你用typedef给一个还未完全声明的类型起新名字。C语言编译器支持这种做法。</li>
<li><code>typedef struct tagNode &#123; &#125; *pNode;</code>，定义了一种新的类型pNode，等于一个结构体指针类型。</li>
<li><code>typedef char *pStr1; #define pStr2 char *; pStr2 s3, s4;  pStr2 s3, s4;</code>，在上述的变量定义中，s1、s2、s3都被定义为<code>char *</code>，而s4则定义成了<code>char</code>，不是我们所预期的指针变量，根本原因就在于#define只是简单的字符串替换而typedef则是为一个类型起新名字。</li>
<li>typedef也有一个特别的长处：它符合范围规则（scope），使用typedef定义的变量类型其作用范围限制在所定义的函数或者文件内（取决于此变量定义的位置），而宏定义则没有这种特性。但typedef定义的类型不能用#ifdef 、#ifndef去检测。</li>
<li>typedef是一个语句，后面要加分号；。而define是预处理宏，不能加分号。</li>
<li><code>typedef char Line[81];</code>，<code>定义了一种新的类型Line，等于char[81]，不能错误地写作``typedef char[81] Line;</code>。此外，最好用<code>typedef struct Line &#123; char line[81]; &#125; Line;</code></li>
<li><code>typedef char * pstr;</code>，定义了一种新的类型pstr，等于<code>char*</code>。按照顺序，<code>const pstr</code>被解释为<code>char * const</code>（一个指向 char 的常量指针），而不是<code>const char *</code>（指向常量 char 的指针）。这个问题很容易解决：<code>typedef const char * cpstr;</code>。</li>
</ul>
<h2 id="cdecl和stdcall"><a class="header-anchor" href="#cdecl和stdcall"></a>cdecl和stdcall</h2>
<p>实际上<code>__cdecl</code>和<code>__stdcall</code>函数参数都是从右到左入栈，它们的区别在于由谁来清栈，<code>__cdecl</code>由外部调用函数清栈，而<code>__stdcall</code>由被调用函数本身清栈， 显然对于可变参数的函数，函数本身没法知道外部函数调用它时传了多少参数（也许有人说例如printf，分析format string不就可以知道传了哪些参数了，但实际上，caller在调用printf时，可以额外多传一些没有用到的参数啊），所以没法支持被调用函数本身清栈（<code>__stdcall</code>）， 所以可变参数只能用__cdecll。<br>
另外还要理解函数参数传递过程中堆栈是如何生长和变化的，从堆栈低地址到高地址，依次存储 被调用函数局部变量，上一函数堆栈桢基址，函数返回地址，参数1， 参数2， 参数3…</p>
<h2 id="多态、继承"><a class="header-anchor" href="#多态、继承"></a>多态、继承</h2>
<ul>
<li>C++的派生类在重写virtual函数时，访问修饰符可以和基类不同，但是要注意派生类中对基类方法的重载将会导致罕见的<a href="http://www.cplusplus.com/forum/general/35681/">“隐藏”问题</a>，<a href="https://stackoverflow.com/questions/19736281/what-are-the-differences-between-overriding-virtual-functions-and-hiding-non-vir">无论这个函数是不是虚函数</a>。</li>
<li>重载方法（包括运算符重载）时是可以改变返回值类型的，因为返回值类型不是函数签名的一部分。</li>
<li>当有虚函数时，应该把析构函数声明为虚析构函数，否则通过基类指针释放派生类对象时，有可能会存在内存泄漏（object的空间本身应该无论如何是可以释放掉的，只是基类的析构函数由于没有被调用，可能会泄露基类对象本身拥有的一些其它内存或资源）。</li>
<li>三种继承方式下基类的私有成员对派生类都不可见，而公共成员和保护成员对派生类的方法而言都可以访问。三者的区别是，公共继承时基类的公共成员和保护成员对派生类而言仍然是公共成员和保护成员，私有继承时基类的公共成员和保护成员都成为派生类的私有成员，保护继承时基类的公共成员和保护成员都成为派生类的保护成员（而对于外界，无论是哪种继承方式，保护成员和私有成员都是不可见的）。</li>
<li>在protected和private继承时，基类指针不能指向派生类对象。简单的说这两种继承方式并不是所谓的is-a关系。详细一点讲,用了这两种继承方式后,子类对象中的继承方法都是在main中不能访问的，如果允许基类指针指向子类对象,就会出错了。当然你也可以用(Base*)进行强制转化。</li>
<li>C++的默认继承方式是private继承。</li>
</ul>
<h2 id="模板"><a class="header-anchor" href="#模板"></a>模板</h2>
<h3 id="函数模板的偏特化"><a class="header-anchor" href="#函数模板的偏特化"></a>函数模板的偏特化</h3>
<p>严格的来说，函数模板并不支持偏特化，但由于可以对函数进行重载，所以可以达到类似于类模板偏特化的效果。<br>
<code>template &lt;class T&gt; void f(T);  (a)</code><br>
根据重载规则，对（a）进行重载<br>
<code>template &lt; class T&gt; void f(T*);  (b)</code><br>
如果将（a）称为基模板，那么（b）称为对基模板（a）的重载，而非对（a）的偏特化。C++的标准委员会仍在对下一个版本中是否允许函数模板的偏特化进行讨论。</p>
<h3 id="C-traits"><a class="header-anchor" href="#C-traits"></a>C++ traits</h3>
<p>C++ traits是利用模板特化编译器来完成一定功能的技巧，本质是“利用类型固有的特性，判断类型是否具有特定的特性”，例如简单的例子（利用偏特化）：</p>
  <figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">is_void</span></span><br><span class="line">&#123; <span class="type">static</span> <span class="type">const</span> <span class="type">bool</span> value = <span class="literal">false</span>; &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">is_void</span>&lt;<span class="type">void</span>&gt;</span><br><span class="line">&#123; <span class="type">static</span> <span class="type">const</span> <span class="type">bool</span> value = <span class="literal">true</span>; &#125;</span><br></pre></td></tr></table></figure>
<h2 id="STL"><a class="header-anchor" href="#STL"></a>STL</h2>
<ul>
<li>C++语言中的<code>std::remove(vec.begin(), vec.end(), 5);</code>并非是删除容器里变所有值等于5的数，而是用类似LeetCode中的<a href="https://leetcode.com/problems/remove-element/">27. Remove Element</a>的算法，将后面的元素向前复制移动。因此vector的长度并不会改变，需要和<code>erase</code>方法结合使用：<code>vec.erase(std::remove(vec.begin(), vec.end(), 5), vec.end());</code>。</li>
<li>vector为了防止大量分配连续内存的开销，保持一块默认的尺寸的内存，clear只是清数据了，未清内存，因为vector的capacity容量未变化，系统维护一个的默认值。有什么方法可以释放掉vector中占用的全部内存呢？根据<a href="https://stackoverflow.com/questions/10464992/c-delete-vector-objects-free-memory">StackOverflow上的方法</a>，可以用<code>vector&lt; T &gt; vtTemp; veTemp.swap(vt);</code>。</li>
<li>multimap/multiset不支持下标运算，可能是因为<a href="https://stackoverflow.com/questions/27837132/why-is-there-no-operator-for-stdmultimap">[]运算符可能有多个元素匹配</a>。</li>
<li>const map不支持下标操作，根据<a href="https://stackoverflow.com/questions/5134614/c-const-map-element-access">StackOverflow的说法</a>，[]运算符在key不存在时会插入新的元素，不符合const的语境。</li>
<li>stl的deque,queue,stack,heap：deque和vector、list一样是一种基础数据结构。然后stack，queue，priority_queue则是可以使用某个基础数据机构作为底层存储的二级数据结构。而heap本身不能持有数据存储，只能将某个基础数据结构对象作为托管的数据存储。</li>
<li>STL的模板参数T类型也可以带const修饰符。</li>
<li>STL中有bitset这种数据结构。</li>
</ul>
<h2 id="编译器优化"><a class="header-anchor" href="#编译器优化"></a>编译器优化</h2>
<ul>
<li><a href="http://stackoverflow.com/questions/7570152/object-returned-from-function-and-copy-constructor">Object returned from function and copy constructor</a></li>
</ul>
<blockquote>
<p>That is called <a href="https://en.wikipedia.org/wiki/Return_value_optimization">Named Return Value Optimization and copy elision</a>, and basically means that the compiler has figured out that the copy can be avoided by carefully placing the temporary and the object in the same memory location.<br>
By default there would be three objects in that piece of code, temp inside fun, the return value and ob inside main, and as many as two copies, but by carefully placing temp in the same memory location as the returned object inside fun and placing ob in the same memory address the two copies can be optimized away.<br>
Ref to <a href="http://definedbehavior.blogspot.sg/2011/08/value-semantics-nrvo.html">Value semantics: NRVO</a>, and <a href="http://definedbehavior.blogspot.sg/2011/08/value-semantics-copy-elision.html">Value semantics: Copy elision</a>.</p>
</blockquote>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/cpp-bean-knowledge/">http://xnerv.wang/cpp-bean-knowledge/</a></strong></p>
]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>编程语言</tag>
        <tag>原创</tag>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>DDL commands in Transactions in SQL Server versus Oracle（转载）</title>
    <url>/ddl-commands-in-transactions-in-sql-server-versus-oracle/</url>
    <content><![CDATA[<h2 id="Problem"><a class="header-anchor" href="#Problem"></a>Problem</h2>
<p>Transactions are widely used in database development, especially when a database supports an application where a lot of correlated changes are needed. A transaction is a group of SQL statements that are all committed together (all changes done by these statements become a permanent part of the database) or none of these statements are committed (all these changes are rolled back). More often statements included in transaction are DML (Data Manipulation Language) statements, such as INSERT, UPDATE, DELETE and so on. But what about DDL (Data Definition Language) statements? Is it possible to include DDL commands such as CREATE, ALTER, DROP, etc., in a transaction? In this tip we are going to answer these questions for both - MS SQL Server and Oracle databases.</p>
<h2 id="Solution"><a class="header-anchor" href="#Solution"></a>Solution</h2>
<p>The approaches to use DDL commands within transactions are quite different in Microsoft SQL Server vs. Oracle. Let’s discuss this for each RDBMS separately.</p>
<span id="more"></span>
<h3 id="DDL-and-Transactions-in-Microsoft-SQL-Server"><a class="header-anchor" href="#DDL-and-Transactions-in-Microsoft-SQL-Server"></a>DDL and Transactions in Microsoft SQL Server</h3>
<p>Generally it is possible to include DDL statements in one transaction in Microsoft SQL Server. However, there are exceptions: some DDL statements are not allowed in transactions, for example CREATE/ALTER/DROP DATABASE commands, CREATE/ALTER/DROP FULLTEXT INDEX and so on. When including DDL statements in a transaction, like DML commands they all are either committed or rolled back. This means that it is possible to ROLLBACK a created table or ROLLBACK truncated data. Let’s prepare a database for testing and see an example:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">USE master</span><br><span class="line">GO</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> DATABASE TestDB</span><br><span class="line">GO</span><br><span class="line"></span><br><span class="line">USE TestDB</span><br><span class="line">GO</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> TableA</span><br><span class="line">(</span><br><span class="line"> ID <span class="type">INT</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">PRIMARY</span> KEY,</span><br><span class="line"> <span class="keyword">Value</span> <span class="type">CHAR</span>(<span class="number">1</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> TableA(ID, <span class="keyword">Value</span>)</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="number">1</span>,<span class="string">&#x27;A&#x27;</span>),(<span class="number">2</span>,<span class="string">&#x27;B&#x27;</span>),(<span class="number">3</span>, <span class="string">&#x27;C&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> TableB</span><br><span class="line">(</span><br><span class="line"> ID <span class="type">INT</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">PRIMARY</span> KEY,</span><br><span class="line"> <span class="keyword">Value</span> <span class="type">CHAR</span>(<span class="number">1</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> TableB(ID, <span class="keyword">Value</span>)</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="number">1</span>,<span class="string">&#x27;X&#x27;</span>),(<span class="number">2</span>,<span class="string">&#x27;Y&#x27;</span>),(<span class="number">3</span>, <span class="string">&#x27;Z&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>We have two tables with data in our TestDB database. Now let’s start a transaction and do some DDL changes in the TestDB database:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">USE TestDB</span><br><span class="line">GO</span><br><span class="line"></span><br><span class="line"><span class="keyword">BEGIN</span> TRANSACTION</span><br><span class="line"></span><br><span class="line"> <span class="keyword">TRUNCATE</span> <span class="keyword">TABLE</span> TableA</span><br><span class="line"></span><br><span class="line"> <span class="keyword">DROP</span> <span class="keyword">TABLE</span> TableB</span><br><span class="line"></span><br><span class="line"> <span class="keyword">CREATE</span> <span class="keyword">TABLE</span> TableC(ID <span class="type">INT</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">ROLLBACK</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> TableA</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> TableB</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> TableC</span><br></pre></td></tr></table></figure>
<p>We can see that after the rollback there is no TableC in the database:</p>
<center>
<img src="/assets/ddl-commands-in-transactions-in-sql-server-versus-oracle/1.jpg" alt="t-sql statement output"/>
</center>
<p>TableA and TableB exist and contain data:</p>
<center>
<img src="/assets/ddl-commands-in-transactions-in-sql-server-versus-oracle/2.jpg" alt="t-sql results"/>
</center>
<p>This means that all these changes made by the DDL commands, that are included in the transaction, have been rolled back. So, we can include DDL commands (with some exceptions) in transactions in MS SQL Server.</p>
<h3 id="DDL-and-Transactions-in-Oracle"><a class="header-anchor" href="#DDL-and-Transactions-in-Oracle"></a>DDL and Transactions in Oracle</h3>
<p>Unlike SQL Server, transactions in Oracle are always implicit. This means that a logical transaction starts in the event of a data change in the database. The other big difference from SQL Server is that in Oracle DDL commands automatically commit transactions (xnerv: So it’s not weird that Oracle bought MySQL since InnoDB has the same behavior… Just a joke : ). Every new database connection opens a new transaction and an explicit COMMIT command is needed to make them a permanent part of database (as mentioned above DDL commands automatically COMMIT a transaction and in this case an explicit COMMIT is not needed). Commands issued after a COMMIT open a new transaction and so on. Let’s look at an example:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> TableA (<span class="keyword">Value</span> <span class="type">INT</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> TableA(<span class="keyword">Value</span>) <span class="keyword">VALUES</span>(<span class="number">1</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> TableA(<span class="keyword">Value</span>) <span class="keyword">VALUES</span>(<span class="number">2</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> TableA(<span class="keyword">Value</span>) <span class="keyword">VALUES</span>(<span class="number">3</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> V$TRANSACTION <span class="keyword">WHERE</span> STATUS<span class="operator">=</span><span class="string">&#x27;ACTIVE&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">COMMIT</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> V$TRANSACTION <span class="keyword">WHERE</span> STATUS<span class="operator">=</span><span class="string">&#x27;ACTIVE&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p>In this example TableA is created and after that 3 rows are inserted. We can see that there is one active transaction after the INSERT statements and after the COMMIT there are no active transactions:</p>
<center>
<img src="/assets/ddl-commands-in-transactions-in-sql-server-versus-oracle/3.jpg" alt="oracle results"/>
</center>
<p>In the next script we’ll issue a DELETE command and after that we create a new table. After creating TableB, we delete one more row from TableA and then issue a ROLLBACK command:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">DELETE</span> <span class="keyword">FROM</span> TableA <span class="keyword">WHERE</span> <span class="keyword">Value</span><span class="operator">=</span><span class="number">2</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> V$TRANSACTION <span class="keyword">WHERE</span> STATUS<span class="operator">=</span><span class="string">&#x27;ACTIVE&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> TableB (<span class="keyword">Value</span> <span class="type">INT</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">DELETE</span> <span class="keyword">FROM</span> TableA <span class="keyword">WHERE</span> <span class="keyword">Value</span><span class="operator">=</span><span class="number">3</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">ROLLBACK</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> V$TRANSACTION <span class="keyword">WHERE</span> STATUS<span class="operator">=</span><span class="string">&#x27;ACTIVE&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> TableA;</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> TableB;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> V$TRANSACTION <span class="keyword">WHERE</span> STATUS<span class="operator">=</span><span class="string">&#x27;ACTIVE&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p>As a result, we can see that although a ROLLBACK is issued, TableB is created and the row with Value=2 from TableA is deleted. The reason is that the CREATE TABLE command which is a DDL command commits the transaction. However, the second DELETE statement has been rolled back, because it is issued after the DDL and before the ROLLBACK command.</p>
<center>
<img src="/assets/ddl-commands-in-transactions-in-sql-server-versus-oracle/4.jpg" alt="oracle results"/>
</center>
<p>So, now it becomes obvious that DDL commands in Oracle cannot be rolled back and included in one transaction.</p>
<h3 id="Create-multiple-tables-in-a-single-transaction-in-Oracle"><a class="header-anchor" href="#Create-multiple-tables-in-a-single-transaction-in-Oracle"></a>Create multiple tables in a single transaction in Oracle</h3>
<p>Sometimes it is necessary to create more than one table in a single transaction. So, how can we solve this problem in Oracle? We can do that by using a CREATE SCHEMA statement. This statement allows us to include multiple CREATE TABLE or CREATE VIEW statements as well as multiple GRANT statements in a single transaction in your own schema. If all statements in the CREATE SCHEMA are executed successfully the transaction is committed. In case of an error, all commands included in the CREATE SCHEMA statement are rolled back. It is important to note that CREATE SCHEMA statement does not create a schema. It’s used to create tables, views or grant privileges in one transaction. In the example below, we are using the CREATE SCHEMA statement to create two tables in one transaction. Before executing this statement it is essential to make sure that you are creating objects in your own schema and have necessary permissions to issue the statements:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> SCHEMA <span class="keyword">AUTHORIZATION</span> MyUser</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> TableC (<span class="keyword">Value</span> <span class="type">INT</span>)</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> TableD (<span class="keyword">Value</span> <span class="type">INT</span>);</span><br></pre></td></tr></table></figure>
<p>Two tables has been successfully created:</p>
<center>
<img src="/assets/ddl-commands-in-transactions-in-sql-server-versus-oracle/5.jpg" alt="oracle create schema"/>
</center>
<p>In the next example we are trying to create two tables:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> SCHEMA <span class="keyword">AUTHORIZATION</span> MyUser</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> TableC (<span class="keyword">Value</span> <span class="type">INT</span>)</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> TableE (<span class="keyword">Value</span> <span class="type">INT</span>);</span><br></pre></td></tr></table></figure>
<p>The transaction is rolled back (because TableC already exists), therefore TableE has not been created:</p>
<center>
<img src="/assets/ddl-commands-in-transactions-in-sql-server-versus-oracle/6.jpg" alt="oracle create schema"/>
</center>
<h2 id="Conclusion"><a class="header-anchor" href="#Conclusion"></a>Conclusion</h2>
<p>In conclusion, the SQL Server and Oracle database engines manage transactions and DDL commands differently. As we can see in this tip SQL Server allows us to include multiple DDL commands in a single transaction in contrast to Oracle. The latter commits transactions when a DDL command is issued, so it is not possible to combine DDL statements in one transaction. However, in Oracle it is possible to issue multiple table and view creation statements, as well as multiple grant statements in a single transaction by using the CREATE SCHEMA statement.</p>
<h2 id="Next-Steps"><a class="header-anchor" href="#Next-Steps"></a>Next Steps</h2>
<p>Check out this related information:</p>
<ul>
<li><a href="https://msdn.microsoft.com/en-us/library/ms174377.aspx">https://msdn.microsoft.com/en-us/library/ms174377.aspx</a></li>
<li><a href="https://msdn.microsoft.com/en-us/library/ms188929.aspx">https://msdn.microsoft.com/en-us/library/ms188929.aspx</a></li>
<li><a href="https://msdn.microsoft.com/en-us/library/ff848799.aspx">https://msdn.microsoft.com/en-us/library/ff848799.aspx</a></li>
<li><a href="https://msdn.microsoft.com/en-us/library/ms191544.aspx">https://msdn.microsoft.com/en-us/library/ms191544.aspx</a></li>
<li><a href="https://docs.oracle.com/cd/B19306_01/appdev.102/b14261/sqloperations.htm#i7105">https://docs.oracle.com/cd/B19306_01/appdev.102/b14261/sqloperations.htm#i7105</a></li>
<li><a href="https://docs.oracle.com/database/121/CNCPT/transact.htm#CNCPT89320">https://docs.oracle.com/database/121/CNCPT/transact.htm#CNCPT89320</a></li>
<li><a href="https://docs.oracle.com/cd/B19306_01/server.102/b14200/statements_6014.htm">https://docs.oracle.com/cd/B19306_01/server.102/b14200/statements_6014.htm</a></li>
</ul>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/ddl-commands-in-transactions-in-sql-server-versus-oracle/">http://xnerv.wang/ddl-commands-in-transactions-in-sql-server-versus-oracle/</a></strong><br>
转载自：<a href="https://www.mssqltips.com/sqlservertip/4591/ddl-commands-in-transactions-in-sql-server-versus-oracle/">DDL commands in Transactions in SQL Server versus Oracle</a></p>
]]></content>
      <categories>
        <category>DBMS</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>DBMS</tag>
        <tag>SQL Server</tag>
        <tag>Oracle</tag>
        <tag>Transaction</tag>
      </tags>
  </entry>
  <entry>
    <title>在调试器中看阿里的软件兵团（转载）</title>
    <url>/debugging-alibaba-softwares/</url>
    <content><![CDATA[<p>摘要：为了抢占用户桌面，很多客户端软件都是主动送上门的，不需要花钱购买。可能只要你一个认可，就在电脑上安家落户。住下来之后，有些软件偶尔动动，但也有些高调强势，让你不得不注意到它，本文要谈的就是这样的软件。</p>
<span id="more"></span>
<h2 id="谁在消耗电池？"><a class="header-anchor" href="#谁在消耗电池？"></a>谁在消耗电池？</h2>
<p>人们对手机、笔记本电脑等移动设备的依赖越来越大。一旦电池用尽而又不能立刻充电，便可能把人急得双脚跳。面对类似情况，为了让笔记本电池多支撑一会儿，我会采取两项省电措施：一是把屏幕调暗，二是杀掉特别费电的软件。第一项容易理解，略去不谈。第二项的关键是如何找到高功耗软件。一种简单的方法是调出任务管理器，通过View菜单（Windows 8之前）或者在列表的标题行（Windows 8/8.1）调出图1所示的“选择列”对话框，然后将Page faults（缺页异常总次数）和PF Delta（自上次更新后缺页异常的新增次数，默认为每秒更新一次）两项选中。接下来分别按Page faults、PF Delta和CPU使用率指标对进程排序，找出这几项指标高的进程。</p>
<center>
<img src="/assets/debugging-alibaba-softwares/1.jpg" alt="图1  任务管理器的选择列对话框" title="图1  任务管理器的选择列对话框" />
</center>
<p>为何选择Page faults来衡量软件对功耗的影响？虽然今天的计算机都配备了比较多的物理内存，但仍离不开虚拟内存技术，把暂时不用的数据放在外存中，当CPU访问这样的数据时，会报告缺页异常，让操作系统的内存管理器将数据从外存中读到物理内存，这个操作通常被称为Page In。物理内存是以页为单位来管理的，因此每次Page In的数据至少是一个页，通常为4KB。访问外存意味着系统总线和硬盘等存储设备的运作，在时间和功耗方面都是较大的开销，因此，Page faults常成为系统调优的一个重要指标。</p>
<p>正是使用以上方法查找高耗电高软件时，Alipay引起了我的注意。图2是当时的屏幕截图，可以看到，任务管理器中的各个进程（任务）是按Page faults总数排列的，而位列前三的分别是AlipaySecSvc、AlipayBsm和TaobaoProtect，全是Alipay软件成员。它们导致的Page faults总数分别为四亿五千多万次、一亿三千多万次和八千多万次。假定每次Page fault触发的Page In数据都是4KB，那么它们促使系统Page In的数据量分别为大约1.8TB、500GB和300GB。</p>
<p>另外，从PF Delta列来看，排名第一的AlipaySecSvc进程在最近一秒内就触发了2906次缺页异常。</p>
<p>坦率说，这样的结果让我惊叹不已。通常排在前列的都是安全软件。而自从我的机器上有了Alipay软件后，它们总是可以轻松超越杀毒软件。图2中，第6名是系统窗口合成器，第4、5、7名都是安全软件。</p>
<center>
<img src="/assets/debugging-alibaba-softwares/2.jpg" alt="图2  Alipay三个进程的Page faults总数垄断前三名" title="图2  Alipay三个进程的Page faults总数垄断前三名" />
</center>
<p>因为处理每次Page fault时要执行比较复杂的逻辑，所以高Page faults也常意味着较高的CPU使用率。在图2中，AlipaySecSvc进程使用的CPU总时间高达1小时20分32秒。今天的CPU速度惊人，很多“分量”轻的软件运行一天可能也用不上CPU几秒钟（大多被挂起）。尽管AlipaySecSvc的名字中也包含安全字样（Sec），但其CPU总时间如此高也着实离谱。简而言之，这个进程的分量重得惊人。</p>
<h2 id="AlipaySecSvc"><a class="header-anchor" href="#AlipaySecSvc"></a>AlipaySecSvc</h2>
<p>那么，如此重的AlipaySecSvc进程是做什么的呢？好奇心和职业精神都驱使我深入了解这个进程。打开系统服务控制台，找到AlipaySecSvc服务，查看其属性（如图3），可以看到它的全称（Alipay security service）、官方身份和在磁盘上的位置信息。</p>
<center>
<img src="/assets/debugging-alibaba-softwares/3.jpg" alt="图3  AlipaySecSvc的服务属性" title="图3  AlipaySecSvc的服务属性" />
</center>
<p>根据图3中路径信息，可以在磁盘上找到Alipay目录（如图4），其下有三个子目录。根据布局可以推测，我的机器上已安装了Alipay的三个组件，分别是AliEditPlus、AlipayDHC和SafeTransaction，引起我们注意的AlipaySecSvc是AliEditPlus的一部分。看来，AliEditPlus绝不是孤军奋战，一个兵团已在我的电脑上安营扎寨了。</p>
<center>
<img src="/assets/debugging-alibaba-softwares/4.jpg" alt="图4  Alipay软件的磁盘布局" title="图4  Alipay软件的磁盘布局" />
</center>
<p>图3中的描述信息声明了AlipaySecSvc服务的重要性，但同时也说明了它的职权范围是“电子支付”。既然如此，当用户未做支付操作时，AlipaySecSvc应该尽可能保持安静。但事实上，它却始终忙碌着，甚至连浏览器进程没有启动时也是如此，这便不正常了。</p>
<h2 id="上调试器"><a class="header-anchor" href="#上调试器"></a>上调试器</h2>
<p>不轻信，不迷信，还是请出WinDBG来看分明。以管理员身份运行WinDBG，赐予其系统级的督察权利，然后将其附加到AlipaySecSvc进程。</p>
<p>接下来的目标是寻找这个进程躁动的原因。如何做呢？有多种方法，例如以前介绍过的使用<code>~*e .ttime</code>命令观察每个线程的执行时间，再例如使用~* k命令显示每个线程的栈回溯，寻找线索。对于眼下的问题，这两种方法也都有效。但为了避免陈词滥调，这次我打算介绍种新方法。</p>
<p>简单说，就是让被调试对象在调试器里跑一跑，让其“自露马脚”。套用赵本山的话就是“有病没病走两步”。轻扣键盘，发出g命令，恢复AlipaySecSvc运行，端起茶杯，等待WinDBG报告“蛛丝马迹”。</p>
<p>手里的茶杯还没放下，WinDBG便有所发现。屏幕上出现如下信息。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">**(27bc.1b30): Unknown exception – code 000006ba (first chance)**</span><br></pre></td></tr></table></figure>
<p>看来是有真的异常（Windows系统的结构化异常SEH）发生。继续观察，WinDBG连续输出这样的信息，间隔不到一秒。根据经验，这个信息很有价值，可以作为突破口。轻按Ctrl+Break再将AlipaySecSvc断下，然后通过菜单Debug→Event Filters调出图5所示的调试事件过滤器对话框。</p>
<center>
<img src="/assets/debugging-alibaba-softwares/5.jpg" alt="图5  WinDBG的调试事件过滤器对话框" title="图5  WinDBG的调试事件过滤器对话框" />
</center>
<p>因为信息输出的6ba异常不在WinDBG的常见异常列表中，所以点击Add按钮增加一个代码为0x6ba的异常。之后选中新增的项目，再点击Command按钮调出图6所示的过滤器关联命令对话框，并输入：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">**.echo ********bang******;? @$tid;.ttime**</span><br></pre></td></tr></table></figure>
<center>
<img src="/assets/debugging-alibaba-softwares/6.jpg" alt="图6  过滤器命令" title="图6  过滤器命令" />
</center>
<p>执行如上操作，再恢复AlipaySecSvc运行，让其再走些步。这时我们看到屏幕上持续输出信息，如图7所示（此图为后补，与图1不属同一次调试）。</p>
<center>
<img src="/assets/debugging-alibaba-softwares/7.jpg" alt="图7  持续不断的6ba异常" title="图7  持续不断的6ba异常" />
</center>
<p>在软件世界，一次异常就是一起爆炸事件。如此连续不断的爆炸必然会让CPU负担很重。</p>
<h2 id="6ba异常"><a class="header-anchor" href="#6ba异常"></a>6ba异常</h2>
<p>接下来的问题是为什么有如此多的6ba异常呢？Ctrl+Break断下，执行命令sxe 6ba告诉WinDBG再有6ba异常发生时立刻停下来。恢复运行后，果然很快又停下，位置正是6ba异常的发生现场：</p>
<center>
<img src="/assets/debugging-alibaba-softwares/6ba.jpg" />
</center>
<p>看来是有人调用了著名的RaiseException API发起软件异常。是发生了什么矛盾，以至于要引爆炸弹呢？k一下看缘由吧，结果如图8所示。</p>
<p>细看图8，关注本专栏的读者一定可以看出个“破绽”，符号不精确。是的，诚然老雷偷懒了，没有使用PDB号，只用了导出符号。但对于我们的分析，这样的信息足够了。因为其中包含了以下重要内容：</p>
<ul>
<li>AlipaySecSvc服务调用了WTSEnumerate­Sessions API。</li>
<li>WTSEnumerateSessionsW函数（WTS­Enumerate­Sessions API的Unicode版本实现）使用了RPC机制在做远程调用。</li>
<li>RPC机制的运行时模块（rpcrpt4）检测到不正常情况，“大为关火”，抛出了异常。</li>
</ul>
<p>有了这些信息，已没必要探究RPC检测到了何种意外，因为我们有了如下结论：AlipaySecSvc服务调用了一个依赖RPC机制的沉重API，而且API执行不顺利，导致了异常。</p>
<p>根据前面的监视结果（见图7），6ba异常是反复发生的，说明这个沉重的过程也是在循环进行。对wtsapi32!WTSEnumerateSessionsW设置断点，果然反复命中，还不止一个线程命中断点，居然有多个线程在调用这个沉重的API和触发异常。从其中的线程ID来看，也有两个（6960和1032）。综合前面的分析，可以对AlipaySecSvc服务进程的躁动原因做出初步诊断：多个线程循环调用沉重的WTSEnumerateSessions API，而且执行时触发异常。</p>
<center>
<img src="/assets/debugging-alibaba-softwares/8.jpg" alt="图8  追索爆炸原因" title="图8  追索爆炸原因" />
</center>
<p>对于性能问题，也可用WPT帮忙。它的全称是Windows Performance Toolkit，曾用名xPerf。安装完成后，先启动WPR（Windows Performance Recorder），让其开启系统中早已埋伏好的ETW（Event Tracing for Windows）事件，重现问题后，停止录制，WPR会把收集到的事件整理到一个庞大的etl文件中。最后再使用WPA（Windows Performance Analyzer）打开etl文件进行分析。</p>
<p>详细介绍WPA的用法超出了本文的范围，这里只做简述。</p>
<p>图9是使用WPA分析CPU占用情况的截图。重点看右侧的采样数据。画面以曲线图为核心分三个部分，下面的表格是详细数据，左上角是进程、模块列表，可选择其中的一个或多个，每个对应一条曲线。我们故意屏蔽了其他进程，只显示AlipaySecSvc的曲线。</p>
<p>每个尖峰代表一次较重的负载（占用CPU较多）。尖峰反复出现说明这些负载是周期性的，与我们前面分析的在循环中反复调用沉重API的结论完全一致。尖峰的幅度不很一致，是因为有多个线程在执行重负荷，发生和叠加的时机不同。</p>
<p>再观察图9中的详细数据，可以看到进程内部模块和函数一级的信息。WPA已根据模块的样本点数做过排序（点数越多，意味着占用CPU越多），内核模块排名第一，说明AlipaySecSvc进程做了多次系统调用，进一步还可发现有一个线程反复分配大堆块和调用NtQuerySystemInformation。</p>
<p>展开函数一级的信息，可以看到占用CPU较多的函数。例如在kernel32.dll模块下，Process32­NextW赫然在列。这告诉我们，AlipaySecSvc除了调用沉重的WTSEnumerate­Sessions API外，还调用了另一个沉重的API Process32­Next。前者枚举系统中的所有登录会话，而后者枚举会话中的进程。据此，我们可以推测，AlipaySecSvc的循环中，先是枚举会话，然后再枚举会话中的每个进程。笔者多年前就分析过Process32Next API，得到的结论是，这个API与缺页异常密切相关，几乎每次调用，都会触发数百次的缺页异常。而我们正分析的AlipaySecSvc进程，有两个线程在以循环的方式反复调用这个API，其结果就是本文开头说的累计缺页异常数排名第一。</p>
<center>
<img src="/assets/debugging-alibaba-softwares/9.jpg" alt="图9  使用WPA分析CPU占用情况" title="图9  使用WPA分析CPU占用情况" />
</center>
<h2 id="API的分量"><a class="header-anchor" href="#API的分量"></a>API的分量</h2>
<p>使用同样的方法分析缺页异常总数排名第二和第三的Alipaybsm（Browser Safe Monitor）以及TaobaoProtect，结果与此相似，或许它们三兄弟在共享循环调用沉重API的经典代码吧，也可能它们都出自一位同行之手。</p>
<p>普通世界中的商品都明确标识重量。这个基本属性非常重要，尤其在今天的网购时代，买家可能根据重量判断货物的质量，卖家很可能根据重量计算运输（快递）成本。但在软件世界中，标记代码的重量还没有任何规范，甚至尚无测量代码重量的标准方法。更严重的是，很多程序员同行会认为，代码有什么重量呢？</p>
<p>如果说为所有普通函数标记重量还为时过早，那么给操作系统的标准API标识重量该排上议事日程了。这不仅必要而且可行。例如用可能引发的系统调用次数、跨进程调用的次数、触发缺页异常的次数等指标来衡量API的重量。标记之后，程序员就有所依据，避免频繁调用太重的API，尤其不要在当前没有明确任务的进程中调用这些沉重的API，以免白白消耗电池，让用户反感。</p>
<p>话说回来，关键问题还在于写代码的程序员，即使标记重量了，程序员可能也置之不理。不标记重量，有经验的程序员也心中有数。退一步讲，本文讨论的问题，只要打开任务管理器就能察觉，挂一下WinDBG更容易发现，运行WPT也可以发现，但为什么问题就这样发生了呢？</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/debugging-alibaba-softwares/">http://xnerv.wang/debugging-alibaba-softwares/</a></strong><br>
转载自：<a href="http://www.csdn.net/article/2014-09-16/2821705">在调试器中看阿里的软件兵团</a></p>
]]></content>
      <categories>
        <category>WinDbg</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Windows</tag>
        <tag>WinDbg</tag>
      </tags>
  </entry>
  <entry>
    <title>在调试器里看百度云管家（转载）</title>
    <url>/debugging-baidu-pan/</url>
    <content><![CDATA[<p>因为太了解软件，我很慎重在自己的电脑上安装新软件。大约半年前，有朋友通过百度云盘向我传递dump文件。点击链接下载时失败，提示超过了普通方式允许的上限，必须安装百度云盘客户端软件。于是我的电脑新增了一个软件，名曰“百度云管家”。第一次看到这个名字，就觉得很奇怪，云的家在服务器上，为什么一个终端应用程序叫云管家呢？</p>
<p>过了一段时间，我慢慢意识到，原来这位云管家管的不是云的家，而是我（用户电脑）的家。名字的含义或曰：“我是百度云，来管你的家”。</p>
<p>为什么这么认为呢？最初的原因是我发现这个管家特别忙碌，即使当我根本没有使用百度云。更让我跌破眼镜的是，即使我把网线拔掉、关闭无线，它依然忙碌。这些反常的表现让我不得不留意它了。多少次，我打开任务管理器，看它忙碌的身影。多少次，我想大声对它说：“管家大哥，你歇歇，告诉我你在忙啥？”</p>
<h2 id="怎一个忙字了得"><a class="header-anchor" href="#怎一个忙字了得"></a>怎一个忙字了得</h2>
<center>
<img src="http://ipad-cms.csdn.net/cms/attachment/201606/574e591fb2de5.png" alt="图1 任务管理器中缺页异常排名第一" title="图1 任务管理器中缺页异常排名第一" />
</center>
<p>起初是在任务管理器中发现百度云管家（以下简称其“管家程序”）很忙。图1是我某次看见它忙时做的截图。在这个截图中，系统中一共运行了175个进程，任务列表是按缺页异常总数（Page Faults）排名，管家程序排名第一位，而且遥遥领先，把一向排名靠前的McAfee安全软件（第二名和第三名）远远抛在后头（相差一个数量级）。顺便说下，排在第4位的BaiduProtect是管家程序的同门兄弟，以后台服务方式运行，权限更高。</p>
<p>在Page Faults右侧的那一列是PF Delta，代表最近一秒钟新增的缺页异常个数，管家程序新增4千多个，但这并不是我看到的最高值，有时是7000多。再往右的一列是CPU净时间，即CPU执行管家程序的累计时间，14分37秒。这个数值也算较高了，因为系统中CPU频率高达2.6 GHz，速度很快，排在后面的很多程序（图1中未显示出）的累计时间还不到1秒。排在第二名的安全软件CPU累计时间是1小时55分42秒，比管家程序还高很多。如果把缺页异常总数除以CPU净时间，便得到缺页异常与CPU净时间的比率。这个比率反应了CPU执行程序时触发缺页异常的频繁程度，不妨将其称为缺页异常净频率。为排名前两位的两个程序计算这个指标，其结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">0:000&gt; ?? 215415833/(14*60+37)</span><br><span class="line">int 0n245628</span><br><span class="line">0:000&gt; ?? 34064443/(115*60+42)</span><br><span class="line">int 0n4907</span><br></pre></td></tr></table></figure>
<p>可以看出管家程序触发缺页异常的净频率高得惊人，达到24万多次。这意味着CPU平均执行这个程序1秒钟就触发24万多个缺页异常。这也意味着，CPU花在这个程序上的时间有很多都用在了处理缺页异常上。</p>
<center>
<img src="http://ipad-cms.csdn.net/cms/attachment/201606/574e592fbc565.png" alt="图2 使用Process Explorer观察线程信息" title="图2 使用Process Explorer观察线程信息" />
</center>
<p>图2是使用Mark Russinovich先生的Process Explorer来观察管家程序的截图，显示的是管家程序的线程信息。</p>
<p>可以看到，管家程序有四个很活跃的线程，它们的CPU占用率都超过了0.1%。图2中第1列是线程ID，第2列是CPU占用率，第3列是Cycles Delta，即最近一秒钟CPU执行这个线程所用的时钟个数。从Windows Vista开始，NT内核会读取现代处理器的性能计数器来统计CPU花在每个线程上的时钟个数。根据图2，最近1秒里，管家程序的前4个线程使用的CPU时钟数分别为1千4百万、1千5百万、3千2百万和1亿零5百万。</p>
<p>图2下方是排名第一的8864号线程的更多数据，其中的Kernel和User分别是内核态净时间（23秒多）和用户态净时间（1分23秒多）。Context Switches是用户态和内核态之间切换的次数，高达3千1百多万次。左下角的Cycles是CPU执行该线程时所用的总时钟个数，7万多亿个。今天的x86处理器使用的超标量架构有4个发射端口，每次可以发出四条指令乱序执行，这意味着每个时钟周期可能执行多达四条指令。对于比较差的情况，平均每条指令所用的时钟周期（即所谓的CPI指标，Cycles Per Instruction）可能为3。按CPI为3来折算一下，CPU在这个线程上执行的指令数多达2万多亿条。2万多亿条指令是什么概念呢？曾经轰动信息产业的著名CIH病毒，总指令数只有几百条。即使按1千条来说，那么2万多亿条指令相当于把CIH病毒执行了20多亿次。</p>
<center>
<img src="http://ipad-cms.csdn.net/cms/attachment/201606/574e593cd1a60.png" alt="图3 VTune显示的线程信息" title="图3 VTune显示的线程信息" />
</center>
<p>图3是使用Intel的著名调优工具VTune分析管家程序时得到的线程信息。每行代表一个线程。需要说明的是，因为图2与图3是针对管家程序的不同运行实例，所以无法用线程ID把两个线程对应起来。但观察到的结论是一致的，从VTune视图来看，也是有四个线程很繁忙，而且有很频繁的线程上下文切换。VTune视图给我们的另一个信息是，有多个线程的执行过程都很有规律，尤其是第四个，每隔大约1秒（横轴为时间，单位为秒）有个尖峰，这说明该线程很可能是受定时器触发来工作的。</p>
<h2 id="上调试器"><a class="header-anchor" href="#上调试器"></a>上调试器</h2>
<p>上面使用多个工具观察管家程序得到的结论都是它很忙碌。但不是很清楚到底是在忙什么？熟悉我的朋友一定想到了要上调试器。诚然，要想深刻认识软件，没有比调试器更有力的工具了。唤出WinDBG，附加到管家进程，一切顺利，先执行lm浏览模块信息（图4）。</p>
<center>
<img src="http://ipad-cms.csdn.net/cms/attachment/201606/574e5949abed1.png" alt="图4 模块列表（部分结果）" title="图4 模块列表（部分结果）" />
</center>
<p>图4中，第一行是EXE主模块，接下来的kernelbasis、kernel和kernelpromote三个模块的名字中都含有kernel字样，第一次看到这些名字让我一惊，以为与系统的kernel32和kernelbase模块有关，后来确认这是云管家自己的模块，我不禁好奇，这么高大上的名字，不知道出自哪位同行的妙想。</p>
<p>顺便说一下，图4中以Yun开头的YunDb和YunLogic模块也是管家程序的重要模块，后文会提到。</p>
<p>观察EXE模块的详细信息（图5），可以看到目前使用的是2016年3月的版本，这比我最初分析过的版本要新很多。</p>
<center>
<img src="http://ipad-cms.csdn.net/cms/attachment/201606/574e5958021a0.png" alt="图5 主模块的版本信息" title="图5 主模块的版本信息" />
</center>
<center>
<img src="http://ipad-cms.csdn.net/cms/attachment/201606/574e596776b51.png" alt="图6 自动更新模块" title="图6 自动更新模块" />
</center>
<p>在已经卸载的模块列表（图6）中，可以看到一个名为AutoUpdateUtil.dll的模块多次出现，它应该是用来做自动更新的。</p>
<p>大致了解模块信息后，执行<sub>*观察线程信息。哇，一共40多个线程。执行</sub>*e .echo <strong>_</strong>*<strong>_</strong>; ? @$tid;.ttime观察线程的执行时间信息，可以看到有几个线程的CPU累计时间都超过了秒级。这与前面使用Process Explorer看到的结果一致。</p>
<h2 id="反调试与反反调试"><a class="header-anchor" href="#反调试与反反调试"></a>反调试与反反调试</h2>
<p>做了以上观察后，执行g命令，希望让管家程序走走看。但是意外出现了，WinDBG很快收到了进程退出事件。第一次看到这一幕时，不禁愕然。凭借多年经验，我意识到这次的对手不一般，也是懂调试的，检测到调试器后，主动退出了。“你上调试器，我不跑了，死给你看。”</p>
<p>管家程序的这招反调试让我刷新了对百度同行的认识。但我并没有被这招吓到，反而兴趣更高了。不禁让我想起曾经在国内某公司的一次交流，在我演讲之后，一位同行提问，“看过了你写的《软件调试》，是否有计划写一本如何反调试的？”</p>
<p>调试是软件世界里的逃生通道，我真的不愿意写反调试的书。<br>
但被逼到这里，只好出几招了。首先需要知道管家程序检测调试器的方法。先退出调试器，触发管家程序重新执行，并再附加WinDBG，然后执行x kernelbase!_debug_列出Windows系统的调试API。其中的IsDebuggerPresent是用来检测是否在被调试的最简单方法，对其设置断点，而后执行g恢复管家程序执行。</p>
<p>刹那之间，断点果然命中，k命令观察，真的是上文曾提到的Yun字辈模块之一YunLogic在调用这个检测调试器的API（图7）。</p>
<center>
<img src="http://ipad-cms.csdn.net/cms/attachment/201606/574e597724b6b.png" alt="图7 检测调试器" title="图7 检测调试器" />
</center>
<p>使用u命令观察IsDebuggerPresent函数，很短。其原理我在《软件调试》中有详细介绍，先通过TEB取得PEB，再访问PEB中的BeingDebugged字段。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">KERNELBASE!IsDebuggerPresent:</span><br><span class="line">76153789 64a118000000    mov     eax,dword ptr fs:[00000018h] fs:0053:00000018=7efdd000</span><br><span class="line">7615378f 8b4030          mov     eax,dword ptr [eax+30h]</span><br><span class="line">76153792 0fb64002        movzx   eax,byte ptr [eax+2]</span><br><span class="line">76153796 c3              ret</span><br></pre></td></tr></table></figure>
<p>单步跟踪到ret指令，看EAX寄存器果然为1，代表调试器存在。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">0:000&gt; r eax</span><br><span class="line">eax=00000001</span><br></pre></td></tr></table></figure>
<p>如果把这个结果返回给管家程序，那么它就发现被调试了，继而就会开始退出。于是，执行r eax=0，“狸猫换太子”。<br>
这样篡改IsDebuggerPresent的结果后，再g恢复执行，发现断点再次命中，看来是“骗过”管家一次，它又一次做检查。<br>
每次修改返回值太麻烦了。执行a命令开始交互式汇编（图8）。</p>
<center>
<img src="http://ipad-cms.csdn.net/cms/attachment/201606/574e59817c73f.png" alt="图8 WinDBG的交互式汇编支持" title="图8 WinDBG的交互式汇编支持" />
</center>
<p>WinDBG的汇编环境虽然简陋，但也足够用了，输入以下两行x86汇编后，直接按回车键结束汇编。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Mov eax, 0</span><br><span class="line">Ret</span><br></pre></td></tr></table></figure>
<p>再观察IsDebuggerPresent API，现在变成了下面这样：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">KERNELBASE!IsDebuggerPresent:</span><br><span class="line">76153789 b800000000      mov     eax,0</span><br><span class="line">7615378e c3              ret</span><br></pre></td></tr></table></figure>
<p>也就是永远返回假。这样偷梁换柱之后，先bd * 禁止断点，然后再执行g命令恢复管家执行。这下它不退出了，因为它以为调试器不在。</p>
<p>原来管家程序的反调试设施如此单薄。看了它的模块架构，其实有一种更简单有效的反调试方法，不过老雷不想说，因为我一向不赞成反调试。</p>
<h2 id="折腾堆"><a class="header-anchor" href="#折腾堆"></a>折腾堆</h2>
<p>解除了管家程序的反调试保护之后，可以进一步寻找它忙碌的原因了。经过一番勘察，我发现管家程序忙碌的第一个原因是非常频繁地分配和释放内存。长话短说，在WinDBG中设置如下断点来监视从堆上的内存分配。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bp ntdll!RtlAllocateHeap+5 &quot;.echo **allocating heap;r $t1=@$t1+1; ? @$t1; kv;.if(poi(ebp+10)&gt;10000)&#123;&#125;.else&#123;gc;&#125;&quot;</span><br></pre></td></tr></table></figure>
<p>先解释一下上面的断点命令，地址部分加5是为了越过函数开头的序言部分，以保证后面获取到参数值是准确的。双引号中包含了多条命令，先是显示提示信息，然后使用一个准变量来统计断点命中次数并打印出来，之后的kv是显示栈回溯，而后判断第三个参数所代表的分配大小是否超过1MB，如果超过则中断，不然则gc继续执行。</p>
<p>设好以上断点，恢复目标执行，发现大量信息喷涌而出，如图9所示。</p>
<center>
<img src="http://ipad-cms.csdn.net/cms/attachment/201606/574e598fd8959.png" alt="图9 频繁的内存分配" title="图9 频繁的内存分配" />
</center>
<p>等待5分钟左右，没有自动中断，说明没有发生参数超过1MB的调用，手工中断下来，可以看到$t1的累计值高达6万多次。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">0:043&gt; ? @$t1</span><br><span class="line">Evaluate expression: 61434 = 0000effa</span><br></pre></td></tr></table></figure>
<p>如果再设置如下断点监视释放堆块的行为，那么即使过了十几分钟之后，t1的值仍然不大。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bp ntdll!RtlFreeHeap+0x5 &quot;.echo **Releasing heap;r $t1=@$t1-1; ? @$t1; kv; gc&quot;</span><br></pre></td></tr></table></figure>
<p>这说明很多内存块是分配了后，很快又释放掉了。有经验的程序员知道，从堆上分配内存是开销比较大的操作，好的程序应该尽可能减少从堆上分配内存的次数，分配好了的堆快如果将来还可能使用，那么最好重复使用，不要释放了又分配，分配了又释放。</p>
<h2 id="枚举进程"><a class="header-anchor" href="#枚举进程"></a>枚举进程</h2>
<p>管家程序的更大问题是频繁调用很重的系统API。执行如下命令对系统的CreateToolhelp32Snapshot API设置断点。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bp kernel32!CreateToolhelp32Snapshot &quot;.echo creating snapshot;? @$tid;r $t8=@$t8+1;? @$t8;kv;gc&quot;</span><br></pre></td></tr></table></figure>
<p>禁止其他断点后，恢复目标执行，会发现这个断点命中的也很频繁。一分钟调用了100多次，大约每秒钟调用两次，如图10所示。</p>
<center>
<img src="http://ipad-cms.csdn.net/cms/attachment/201606/574e59a4c4dfb.png" alt="图10 频繁调用CreateToolhelp32Snapshot API" title="图10 频繁调用CreateToolhelp32Snapshot API" />
</center>
<p>熟悉Windows操作系统开发的朋友知道，CreateToolhelp32Snapshot的用途是对指定进程或者系统中的所有进程抓取快照。其函数原型为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bp kernel32!CreateToolhelp32Snapshot &quot;.echo creating snapshot;? @$tid;r $t8=@$t8+1;? @$t8;kv;gc&quot;</span><br></pre></td></tr></table></figure>
<p>参考图10中的kv命令结果，可以看到dwFlags参数为2，代表TH32CS_SNAPPROCESS，意为包含系统中的所有进程。</p>
<p>把上述断点中的gc去掉，不要自动恢复执行，断点命中后，一边观察任务管理器窗口，一边执行gu命令，执行完这个API后中断，可以发现每调用CreateToolhelp32Snapshot一次大约触发60多个缺页异常。</p>
<p>CreateToolhelp32Snapshot返回的是一个句柄，通常拿到这个句柄后再反复调用Process32Next API来获取每个进程的信息。设置如下断点：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">HANDLE WINAPI CreateToolhelp32Snapshot(</span><br><span class="line">  _In_ DWORD dwFlags,</span><br><span class="line">  _In_ DWORD th32ProcessID</span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<p>恢复管家程序执行，可以看到以上断点果然反复命中，如图11所示。</p>
<center>
<img src="http://ipad-cms.csdn.net/cms/attachment/201606/574e59db9694d.png" alt="图11 反复调用Process32NextW API" title="图11 反复调用Process32NextW API" />
</center>
<p>根据老雷的试验观察，每调用一次Process32NextW API，大约会触发8次缺页异常。管家程序每调用好一次CreateToolhelp32Snapshot后，会调用165次Process32NextW，那么这两项导致的缺页异常总数加起来便是1300多次，即：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bp kernel32!Process32NextW &quot;.echo enumerating each process;r $t9=@$t9+1;? @$t9;gc&quot;</span><br></pre></td></tr></table></figure>
<p>管家程序每秒钟会做两轮以上循环，于是便是2千多次了。值得说明的是，这个很重的循环操作发生在一个线程中，即前文所说图3中很有规律的第4个线程。有读者可能会问，如果每秒循环两次，那么图3中的尖峰应该是间隔半秒啊？其实不然，因为这个线程是连续循环两次。也就是每次唤醒后，连续做两次拍照和枚举，然后休息不到1秒再做两轮循环，如此往复。执行.ttime观察这个线程的执行时间，可以看到它的执行时间很长。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">0:017&gt; .ttime</span><br><span class="line">Created: Mon May  2 09:56:18.377 2016 (UTC + 8:00)</span><br><span class="line">Kernel:  0 days 0:02:45.579</span><br><span class="line">User:    0 days 0:00:24.679</span><br></pre></td></tr></table></figure>
<p>执行~17n命令把这个线程临时挂起，恢复管家程序，再观察任务管理器，发现PF Delta（每秒钟新增的缺页异常）指标立刻降下来了，只有不到十次了。看来导致管家程序那么多的缺页异常的主要原因在于这个枚举系统进程的线程。它忙着给系统里的所有进程拍照，然后再一个个看过来。重要的是，这样的工作不是做一次，而是每秒来两轮，风雨无阻、孜孜不倦，时时刻刻关心着系统里运行着的其它进程，好辛劳的管家啊。<br>
软件的历史不长，但软件的孩提时代已经过去了，因为今天的软件已经丧失了曾经拥有的简单和纯真，变得复杂、贪婪和狡黠。</p>
<p>一年多之前，我曾写过一篇《<a href="http://www.csdn.net/article/1970-01-01/2821705">在调试器里看阿里的软件兵团</a>》，批评了支付宝客户端软件中的性能问题，文章发表后，很高兴看到阿里的同行不断改进，今天已经不再有当时的问题了（图1中还可以看到淘宝的TBSecSvc进程，排名已经比较靠后）。不知百度的同行看过此文有何感想？作为一款客户端软件，能帮助用户管家是好想法，但是管家毕竟是仆人，有事时应该尽心给主人办事，没事时应该安安静静休息，不要肆意挥霍主人家的东西。</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/debugging-baidu-pan/">http://xnerv.wang/debugging-baidu-pan/</a></strong><br>
转载自：<a href="http://geek.csdn.net/news/detail/79743">在调试器里看百度云管家</a></p>
]]></content>
      <categories>
        <category>WinDbg</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Windows</tag>
        <tag>WinDbg</tag>
      </tags>
  </entry>
  <entry>
    <title>Disabling ROW and PAGE Level Locks in SQL Server（转载）</title>
    <url>/disabling-row-and-page-level-locks-in-sql-server/</url>
    <content><![CDATA[<p>Today I want to talk about another very interesting topic in SQL Server: disabling Row and Page Level Locks in SQL Server. Every time that you rebuild an Index in SQL Server, you can use the <strong>ALLOW_ROW_LOCKS</strong> and <strong>ALLOW_PAGE_LOCKS</strong> options to specify that SQL Server should acquire Row and Page Level Locks when accessing your data for reading and writing. Let’s look at what happens internally when we disable these locks.</p>
<span id="more"></span>
<h2 id="Disable-Row-Level-Locks"><a class="header-anchor" href="#Disable-Row-Level-Locks"></a>Disable Row Level Locks</h2>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- Disable row level locks</span></span><br><span class="line"><span class="keyword">ALTER</span> INDEX idx_ci <span class="keyword">ON</span> Foo REBUILD</span><br><span class="line"><span class="keyword">WITH</span> (ALLOW_ROW_LOCKS <span class="operator">=</span> OFF)</span><br><span class="line">GO</span><br></pre></td></tr></table></figure>
<p>As you know from the <a href="/why-do-we-need-intent-locks-in-sql-server/">Locking Hierarchy</a>, SQL Server acquires locks at the table level, the page level, and the row level. Now let’s run a simple SELECT statement in an explicit transaction and let’s hold the Shared Locks until the end of the transaction with the query hint <strong>HOLDLOCK</strong>.</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- SQL Server acquires in Repeatable Read a Shared Lock on the Page Level,</span></span><br><span class="line"><span class="comment">-- because Shared Row Locks are not possible anymore.</span></span><br><span class="line"><span class="keyword">BEGIN</span> TRANSACTION</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> Foo <span class="keyword">WITH</span> (HOLDLOCK)</span><br><span class="line"><span class="keyword">WHERE</span> ID <span class="operator">=</span> <span class="number">5000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> sys.dm_tran_locks</span><br><span class="line"><span class="keyword">WHERE</span> request_session_id <span class="operator">=</span> @<span class="variable">@SPID</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ROLLBACK</span></span><br><span class="line">GO</span><br></pre></td></tr></table></figure>
<p>When you look into the Lock Manager during that transaction, you can see that SQL Server has only acquired the IS Lock at the Table level, and a Shared Lock at the Page level. There are no Row Level locks anymore!</p>
<p><img src="http://www.sqlpassion.at/wp-content/uploads/2016/10/Picture1-2.png" alt="There are no row locks anymore!" title="There are no row locks anymore!"></p>
<p>The acquired locks are now more restrictive, because normally SQL Server acquires an IS lock at the page level and a Shared Lock on the row itself. The same concept applies when you change your data through a transaction:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- SQL Server acquires for an UPDATE statement an Exclusive Lock on the Page Level,</span></span><br><span class="line"><span class="comment">-- because Exclusive Row Locks are not possible anymore.</span></span><br><span class="line"><span class="keyword">BEGIN</span> TRANSACTION</span><br><span class="line"></span><br><span class="line"><span class="keyword">UPDATE</span> Foo</span><br><span class="line"><span class="keyword">SET</span> Col2 <span class="operator">=</span> REPLICATE(<span class="string">&#x27;y&#x27;</span>, <span class="number">100</span>)</span><br><span class="line"><span class="keyword">WHERE</span> ID <span class="operator">=</span> <span class="number">5000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> sys.dm_tran_locks</span><br><span class="line"><span class="keyword">WHERE</span> request_session_id <span class="operator">=</span> @<span class="variable">@SPID</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ROLLBACK</span></span><br><span class="line">GO</span><br></pre></td></tr></table></figure>
<p>In that case you again end up with an Exclusive Lock at the Page Level instead of an IX lock.</p>
<h2 id="Disable-Page-Level-Locks"><a class="header-anchor" href="#Disable-Page-Level-Locks"></a>Disable Page Level Locks</h2>
<p>Next let’s disable Page Level Locks:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- Disable Page level locks</span></span><br><span class="line"><span class="keyword">ALTER</span> INDEX idx_ci <span class="keyword">ON</span> Foo REBUILD</span><br><span class="line"><span class="keyword">WITH</span> (ALLOW_PAGE_LOCKS <span class="operator">=</span> OFF)</span><br><span class="line">GO</span><br></pre></td></tr></table></figure>
<p>The first thing that I want to show you here is that an Index Reorganize operation is dependent on Page Level locks. Therefore a simple Reorganize of that index will fail:</p>
<p><span style="color: red"><b>The index “idx_ci” on table “Foo” cannot be reorganized because page level locking is disabled.</b></span></p>
<p>Now let’s run our SELECT statement again but this time with the query hint <strong>HOLDLOCK</strong>:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- There is no IS lock on the Page anymore.</span></span><br><span class="line"><span class="keyword">BEGIN</span> TRANSACTION</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> Foo <span class="keyword">WITH</span> (HOLDLOCK)</span><br><span class="line"><span class="keyword">WHERE</span> ID <span class="operator">=</span> <span class="number">5000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> sys.dm_tran_locks</span><br><span class="line"><span class="keyword">WHERE</span> request_session_id <span class="operator">=</span> @<span class="variable">@SPID</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ROLLBACK</span></span><br><span class="line">GO</span><br></pre></td></tr></table></figure>
<p>When you look again into the Lock Manager you can see that the IS lock at the Page level disappeared. We only have an IS lock at the Table level, and the S Lock on the row.</p>
<p><img src="http://www.sqlpassion.at/wp-content/uploads/2016/10/Picture2-2.png" alt="And now we have no page locks anymore!" title="And now we have no page locks anymore!"></p>
<p>Let’s try to change a record again:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- There is no IX lock on the Page anymore.</span></span><br><span class="line"><span class="keyword">BEGIN</span> TRANSACTION</span><br><span class="line"></span><br><span class="line"><span class="keyword">UPDATE</span> Foo</span><br><span class="line"><span class="keyword">SET</span> Col2 <span class="operator">=</span> REPLICATE(<span class="string">&#x27;y&#x27;</span>, <span class="number">100</span>)</span><br><span class="line"><span class="keyword">WHERE</span> ID <span class="operator">=</span> <span class="number">5000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> sys.dm_tran_locks</span><br><span class="line"><span class="keyword">WHERE</span> request_session_id <span class="operator">=</span> @<span class="variable">@SPID</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ROLLBACK</span></span><br><span class="line">GO</span><br></pre></td></tr></table></figure>
<p>The same thing has happened as previously: SQL Server has only acquired the IX Lock at the Table level, and the X Lock on the row. There is no lock at the Page level anymore…</p>
<p><img src="http://www.sqlpassion.at/wp-content/uploads/2016/10/Picture3-1.png" alt="The IX lock on the page is gone..." title="The IX lock on the page is gone..."></p>
<h2 id="Disable-Row-and-Page-Level-Locks"><a class="header-anchor" href="#Disable-Row-and-Page-Level-Locks"></a>Disable Row and Page Level Locks</h2>
<p>And now let’s go overboard, and we disable Row and Page level Locks for our Clustered Index:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- Disable Row and Page level locks</span></span><br><span class="line"><span class="keyword">ALTER</span> INDEX idx_ci <span class="keyword">ON</span> Foo REBUILD</span><br><span class="line"><span class="keyword">WITH</span> (ALLOW_ROW_LOCKS <span class="operator">=</span> OFF, ALLOW_PAGE_LOCKS <span class="operator">=</span> OFF)</span><br><span class="line">GO</span><br></pre></td></tr></table></figure>
<p>When you now read some data, SQL Server just acquires a Shared Lock at the Table level. Your whole table is read-only:</p>
<p><img src="http://www.sqlpassion.at/wp-content/uploads/2016/10/Picture4-1.png" alt="Great, our table is now read-only!" title="Great, our table is now read-only!"></p>
<p>And when you change a record without being able to acquire Page and Row level Locks, SQL Server acquires an X Lock on the whole table – ouch:</p>
<p><img src="http://www.sqlpassion.at/wp-content/uploads/2016/10/Picture5-1.png" alt="And finally we have exclusively locked our table..." title="And finally we have exclusively locked our table..."></p>
<h2 id="Summary"><a class="header-anchor" href="#Summary"></a>Summary</h2>
<p>The moral of this story/blog post? There is not really a good reason why you should disable Page and Row level Locks in SQL Server. Just work with the default Locking Strategy that SQL Server offers, because otherwise the locking that is employed will be too restrictive and the throughput of your workload will suffer…</p>
<p>Thanks for your time.</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/disabling-row-and-page-level-locks-in-sql-server/">http://xnerv.wang/disabling-row-and-page-level-locks-in-sql-server/</a></strong><br>
转载自：<a href="https://www.sqlpassion.at/archive/2016/10/31/disabling-row-and-page-level-locks-in-sql-server/">Disabling ROW and PAGE Level Locks in SQL Server</a></p>
]]></content>
      <categories>
        <category>DBMS</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>DBMS</tag>
        <tag>SQL Server</tag>
        <tag>Transaction</tag>
        <tag>Row Lock</tag>
        <tag>Page Lock</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式键值存储 Dynamo 的实现原理（转载）</title>
    <url>/dynamo-implement/</url>
    <content><![CDATA[<p>在最近的一周时间里，一直都在研究和阅读 Amazon 的一篇论文 <a href="http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf">Dynamo: Amazon’s Highly Available Key-value Store</a>，论文中描述了 Amazon 的高可用分布式键值存储服务 Dynamo 的实现原理。</p>
<p><img src="/assets/dynamo-implement/2017-10-24-dynamodb.png" alt="dynamodb"></p>
<p>之前在阅读 Google 的 <a href="https://static.googleusercontent.com/media/research.google.com/en//archive/bigtable-osdi06.pdf">Bigtable: A Distributed Storage System for Structured Data</a> 时写了一篇 <a href="https://draveness.me/bigtable-leveldb">浅析 Bigtable 和 LevelDB 的实现</a> 文章分析了 Bigtable 的单机版 LevelDB 的实现原理；在研究 Dynamo 时，作者发现 Dynamo 虽然和 Bigtable 同为 NoSQL，但是它们的实现却有着很大的不同，最主要的原因来自不同的应用场景和不同的目的。</p>
<span id="more"></span>
<h2 id="Bigtable-和-Dynamo"><a class="header-anchor" href="#Bigtable-和-Dynamo"></a><a href="#bigtable-%E5%92%8C-dynamo"></a>Bigtable 和 Dynamo</h2>
<p>Bigtable 和 Dynamo 两者分别是 Google 和 Amazon 两大巨头给出的存储海量数据的解决方法，作为 NoSQL 两者都具有分布式、容错以及可扩展的几大特性。</p>
<p><img src="/assets/dynamo-implement/2017-10-24-nosql-main-characteristics.png" alt="nosql-main-characteristics"></p>
<p>虽然两者都是 NoSQL，并且有着相似的特性，但是它们在侧重的方向上有非常明显的不同，从两个数据库论文的标题中，我们就能看到 Amazon 的 Dynamo 追求的是高可用性并且提供的是类似 MongoDB 的 Key-value 文档存储，而 Bigtable 中描述的数据库却可以用于结构化的数据存储。</p>
<p>由于 Bigtable 和 Dynamo 都属于同一个类别 - NoSQL，所以它们经常会被放在一起进行对比，这篇文章不仅会介绍 Dynamo 的设计理念以及架构等问题，还会就其中的部分问题与 Bigtable 中相对应的概念进行对比，这样能够让我们更加清楚地了解不同的数据库对不同问题，因设计理念的差异做出的权衡。</p>
<h2 id="架构"><a class="header-anchor" href="#架构"></a><a href="#%E6%9E%B6%E6%9E%84"></a>架构</h2>
<p>在数据库领域中尤其是分布式数据库，最重要的就是服务的架构，多数的分布式系统在设计时都会假设服务运行在廉价的节点上，并没有出众的性能和也不能提供稳定的服务，所以水平扩展和容错的能力是分布式数据库的标配；但是不同的分布式数据库选用了不同的架构来组织大量的节点。</p>
<p>很多的分布式服务例如 GFS 和 Bigtable 都使用了带有主节点的架构来维护整个系统中的元数据，包括节点的位置等信息，而 Dynamo 的实现不同于这些中心化的分布式服务，在 Dynamo 中所有的节点都有着完全相同的职责，会对外界提供同样的服务，所以在整个系统中并不会出现单点故障的问题。</p>
<p><img src="/assets/dynamo-implement/2017-10-24-dynamo-architecture.png" alt="dynamo-architecture"></p>
<p>去中心化的架构使得系统的水平扩展非常容易，节点可以在任何时候直接加入到整个 Dynamo 的集群中，并且只会造成集群中少量数据的迁移。</p>
<p>Bigtable 使用了中心化的架构，通过主节点来维护整个系统中全部的元数据信息，但是 Bigtable 本身其实并不会处理来自客户端的读写请求，所有请求都会由客户端直接和从节点通信，不过由于有了中心化的主节点，所以主节点一旦发生故障宕机就会造成服务的不可用，虽然 Bigtable 以及类似的服务通过其他方式解决这个问题，但是这个问题仍然是中心化的设计所造成的。</p>
<p><img src="/assets/dynamo-implement/2017-10-24-centralized-architecture.png" alt="centralized-architecture"></p>
<p>中心化或者去中心化并不是一个绝对好或者绝对坏的选择，选择中心化的解决方案能够降低系统实现的复杂度，而去中心化的方式能够避免单点故障，让系统能够更好更快地增加新的节点，提供优秀的水平扩展能力。</p>
<h2 id="分片和复制"><a class="header-anchor" href="#分片和复制"></a><a href="#%E5%88%86%E7%89%87%E5%92%8C%E5%A4%8D%E5%88%B6"></a>分片和复制</h2>
<p>Dynamo 在设计之初就定下了<strong>增量扩展</strong>（Incremental Scalability）的核心需求，这也就需要一种能够在一组节点中动态分片的机制，Dynamo 的分片策略依赖于_一致性哈希_，通过这种策略 Dynamo 能够将负载合理的分配到不同的存储节点上。</p>
<p>所有的键在存储之前都会通过哈希函数得到一个唯一的值，哈希函数的输出被看做是一个固定长度的环，也就是其输出的最大值和最小值是『连接』到一起的：</p>
<p><img src="/assets/dynamo-implement/2017-10-24-partition-in-dynamo.png" alt="partition-in-dynamo"></p>
<p>每一个节点都会被 Dynamo 在这个环中分配一个随机的位置，而这个节点会处理从哈希的输出在当前节点前的所有键；假设我们有一个键值对 <code>(draven, developer)</code>，<code>Hash(draven)</code> 的结果位于上图中的绿色区域，从环中的位置开始按照<strong>顺时针</strong>的顺序寻找，找到的以第一个节点 B 就会成为协调者（coordinator）负责处理当前的键值对，上图中的每一个节点都会负责与其颜色相同的部分。</p>
<p>由于 Dynamo 系统中的每一个节点在刚刚加入当前的集群时，会被分配一个随机的位置，所以由于算法的随机性可能会导致不同节点处理的范围有所不同，最终每一个节点的负载也并不相同；为了解决这个问题，Dynamo 使用了一致性哈希算法的变种，将同一个物理节点分配到环中的多个位置（标记），成为多个虚拟节点，但是在这种策略下，如果当前的 Dynamo 节点一天处理上百万的请求，那么新增节点为了不影响已有节点的性能，会在后台进行启动，整个过程大约会<strong>消耗一整天</strong>的时间，这其实是很难接受的，除此之外这种策略还会造成系统进行日常归档极其缓慢。</p>
<p><img src="/assets/dynamo-implement/2017-10-24-equal-size-partition-in-dynamo.png" alt="equal-size-partition-in-dynamo"></p>
<p>为了解决负载的不均衡的问题，除了上面使用虚拟节点的策略之外，Dynamo 论文中还提供了另外两种策略，其中性能相对较好的是将数据的哈希分成 Q 个大小相等的区域，S 个节点每一个处理 Q/S 个分区，当某一个节点因为故障或者其他原因需要退出集群时，会将它处理的数据分片随机分配给其它的节点，当有节点加入系统时，会从其它的节点中『接管』对应的数据分片。上图只是对这种策略下的分片情况简单展示，在真实环境中分片数 Q 的值远远大于节点数 S。</p>
<p>Dynamo 为了达到高可用性和持久性，防止由于节点宕机故障或者数据丢失，将同一份数据在协调者和随后的 <code>N-1</code> 个节点上备份了多次，N 是一个可以配置的值，在一般情况下都为 3。</p>
<p><img src="/assets/dynamo-implement/2017-10-24-replication-in-dynamo.png" alt="replication-in-dynamo"></p>
<p>也就是说，上图中黄色区域的值会存储在三个节点 A、B 和 C 中，绿色的区域会被 B、C、D 三个节点处理，从另一个角度来看，A 节点会处理范围在 <code>(C, A]</code> 之间的值，而 B 节点会处理从 <code>(D, B]</code> 区域内的值。</p>
<p><img src="/assets/dynamo-implement/2017-10-24-replication-range-in-dynamo.png" alt="replication-range-in-dynamo"></p>
<p>负责存储某一个特定键值对的节点列表叫做偏好列表（preference list），因为虚拟节点在环中会随机存在，为了保证出现节点故障时不会影响可用性和持久性，偏好列表中的全部节点必须都为<strong>不同的物理节点</strong>。</p>
<p>Bigtable 中对分片和复制的实现其实就与 Dynamo 中完全不同，这不仅是因为 Bigtable 的节点有主从之分，还因为 Bigtable 的设计理念与 Dynamo 完全不同。在 Bigtable 中，数据是按照键的顺序存储的，数据存储的单位都是 tablet，每一张表都由多个 tablet 组成，而每一个的 tablet 都有一个 tablet 服务器来处理，而 tablet 的位置都存储在 METADATA 表中。</p>
<p><img src="/assets/dynamo-implement/2017-10-24-partition-in-bigtable.png" alt="partition-in-bigtable"></p>
<p>在 Bigtable 中，所有的 tablet 都在 GFS 中以 SSTable 的格式存储起来，这些 SSTable 都被分成了固定大小的块在 chunkserver 上存储，而每一个块也都会在存储在多个 chunkserver 中。</p>
<h2 id="读写请求的执行"><a class="header-anchor" href="#读写请求的执行"></a><a href="#%E8%AF%BB%E5%86%99%E8%AF%B7%E6%B1%82%E7%9A%84%E6%89%A7%E8%A1%8C"></a>读写请求的执行</h2>
<p>Dynamo 集群中的任意节点都能够接受来自客户端的对于任意键的读写请求，所有的请求都通过 RPC 调用执行，客户端在选择节点时有两种不同的策略：一种是通过一个负载均衡器根据负载选择不同的节点，另一种是通过一个清楚当前集群分片的库直接请求相应的节点。</p>
<p><img src="/assets/dynamo-implement/2017-10-24-node-selecting-strategies.png" alt="node-selecting-strategies"></p>
<p>从上面我们就已经知道了处理读写请求的节点就叫做协调者（coordinator），前 N 个『健康』的节点会参与读写请求的处理；Dynamo 使用了 Quorum 一致性协议来保证系统中的一致性，协议中有两个可以配置的值：R 和 W，其中 R 是成功参与一个读请求的最小节点数，而 W 是成功参与写请求的最小节点数。</p>
<p><img src="/assets/dynamo-implement/2017-10-24-dynamo-read-write-operation.png" alt="dynamo-read-write-operation"></p>
<p>当 R = 2 时，所有的读请求必须等待两个节点成功返回对应键的结果，才认为当前的请求结束了，也就是说读请求的时间取决于返回最慢的节点，对于写请求来说也是完全相同的；当协调者接收到了来自客户端的写请求 <code>put()</code> 时，它会创建一个新的向量时钟（vector clock），然后将新版本的信息存储在本地，之后向偏好列表（preference list）中的前 <code>N-1</code> 个节点发送消息，直到其中的 <code>W-1</code> 个返回这次请求才成功结束，读请求 <code>get()</code> 与上述请求的唯一区别就是，如果协调者发现节点中的数据出现了冲突，就会对冲突尝试进行解决并将结果重新写回对应的节点。</p>
<h2 id="冲突和向量时钟"><a class="header-anchor" href="#冲突和向量时钟"></a><a href="#%E5%86%B2%E7%AA%81%E5%92%8C%E5%90%91%E9%87%8F%E6%97%B6%E9%92%9F"></a>冲突和向量时钟</h2>
<p>Dynamo 与目前的绝大多数分布式系统一样都提供了<strong>最终一致性</strong>，最终一致性能够允许我们异步的更新集群中的节点，<code>put()</code> 请求可能会在所有的节点后更新前就返回对应的结果了，在这时随后的 <code>get()</code> 就可能获取到过期的数据。</p>
<p><img src="/assets/dynamo-implement/2017-10-24-inconsistent-in-dynamo.png" alt="inconsistent-in-dynamo"></p>
<p>如果在系统中出现了节点故障宕机，那么数据的更新可能在一段时间内都不会到达失效的节点，这也是在使用 Dynamo 或者使用相似原理的系统时会遇到的问题，Amazon 中的很多应用虽然都能够忍受这种数据层面可能发生的不一致性，但是有些对业务数据一致性非常高的应用在选择 Dynamo 时就需要好好考虑了。</p>
<p>因为 Dynamo 在工作的过程中不同的节点可能会发生数据不一致的问题，这种问题肯定是需要解决的，Dynamo 能够确保<strong>一旦数据之间发生了冲突不会丢失</strong>，但是可能会有<strong>已被删除的数据重新出现</strong>的问题。</p>
<p>在多数情况下，Dynamo 中的最新版本的数据都会取代之前的版本，系统在这时可以通过语法调解（syntactic reconcile）数据库中的正确版本。但是版本也可能会出现分支，在这时，Dynamo 就会返回所有它无法处理的数据版本，由客户端在多个版本的数据中选择或者创建（collapse）合适的版本返回给 Dynamo，其实这个过程比较像出现冲突的 <code>git merge</code> 操作，git 没有办法判断当前的哪个版本是合适的，所以只能由开发者对分支之间的冲突进行处理。</p>
<p><img src="/assets/dynamo-implement/2017-10-24-version-evolution-in-dynamo.png" alt="version-evolution-in-dynamo"></p>
<p>上图中的每一个对象的版本 Dx 中存储着一个或多个向量时钟 <code>[Sn, N]</code>，每次 Dynamo 对数据进行写入时都会更新向量时钟的版本，节点 Sx 第一次写入时向量时钟为 <code>[Sx, 1]</code>，第二次为 <code>[Sx, 2]</code>，在这时假设节点 Sy 和 Sz 都不知道 Sx 已经对节点进行写入了，它们接收到了来自其他客户端的请求，在本地也对同样键做出了写入并分别生成了不同的时钟 <code>[Sy, 1]</code> 和 <code>[Sz, 1]</code>，当客户端再次使用 <code>get()</code> 请求时就会发现数据出现了冲突，由于 Dynamo 无法根据向量时钟自动解决，所以它需要手动合并三个不同的数据版本。</p>
<p>论文中对 24 小时内的请求进行了统计，其中 99.94% 的请求仅会返回一个版本，0.00057% 的请求会返回两个版本，0.00047 的请求会返回三个版本，0.000009% 的请求会返回四个版本，虽然论文中说：</p>
<blockquote>
<p>This shows that divergent versions are created rarely.</p>
</blockquote>
<p>但是作者仍然认为在海量的数据面前 99.94% 并不是一个特别高的百分比，处理分歧的数据版本仍然会带来额外的工作量和负担。虽然在这种情况下，数据库本身确实没有足够的信息来解决数据的不一致问题，也确实只能由客户端去解决冲突，但是这种将问题抛给上层去解决的方式并不友好，论文中也提到了 Amazon 中使用 Dynamo 的应用程序也都是能够适应并解决这些数据不一致的问题的，不过对于作者来说，仅仅这一个问题就成为不选择 Dynamo 的理由了。</p>
<h2 id="节点的增删"><a class="header-anchor" href="#节点的增删"></a><a href="#%E8%8A%82%E7%82%B9%E7%9A%84%E5%A2%9E%E5%88%A0"></a>节点的增删</h2>
<p>因为在分布式系统中节点的失效是非常常见的事情，而节点也很少会因为某些原因永久失效，往往大部分节点会临时宕机然后快速重新加入系统；由于这些原因，Dynamo 选择使用了显式的机制向系统中添加和移除节点。</p>
<p><img src="/assets/dynamo-implement/2017-10-24-ring-membership.png" alt="ring-membership"></p>
<p>添加节点时可以使用命令行工具或者浏览器连接 Dynamo 中的任意节点后触发一个成员变动的事件，这个事件会从当前的环中移除或者向环中添加一个新的节点，当节点的信息发生改变时，该节点会通过 Gossip 协议通知它所能通知的最多的节点。</p>
<p><img src="/assets/dynamo-implement/2017-10-24-gossip-protocol.png" alt="gossip-protoco"></p>
<p>在 Gossip 协议中，每次通讯的两个节点会对当前系统中的节点信息达成一致；通过节点之间互相传递成员信息，最终整个 Dyanmo 的集群中所有的节点都会就成员信息达成一致，如上图所示，”gossip” 首先会被 C 节点接收，然后它会传递给它能接触到的最多的节点 A、D、F、G 四个节点，然后 “gossip” 会进行二次传播传递给系统中的灰色节点，到此为止系统中的所有节点都得到了最新的 “gossip” 消息。</p>
<p>当我们向 Dynamo 中加入了新的节点时，会发生节点之间的分片转移，假设我们连接上了 Dynamo 数据库，然后添加了一个 X 节点，该节点被分配到了如下图所示的 A 和 B 节点之间。</p>
<p><img src="/assets/dynamo-implement/2017-10-24-adding-storage-node.png" alt="adding-storage-node"></p>
<p>新引入的节点 X 会从三个节点 C、D、E 中接受它们管理的分片的一部分，也就是上图中彩色的 <code>(E, A]</code>、<code>(A, B]</code> 和 <code>(B, X]</code> 三个部分，在 X 节点加入集群之前分别属于与其颜色相同的节点管理。</p>
<p>Dynamo 由于其去中心化的架构，节点增删的事件都需要通过 Gossip 协议进行传递，然而拥有主从节点之分的 Bigtable 就不需要上述的方式对集群中的节点进行增删了，它可以直接通过用于管理其他从节点的服务直接注册新的节点或者撤下已有的节点。</p>
<h2 id="副本同步"><a class="header-anchor" href="#副本同步"></a><a href="#%E5%89%AF%E6%9C%AC%E5%90%8C%E6%AD%A5"></a>副本同步</h2>
<p>在 Dynamo 运行的过程中，由于一些情况会造成不同节点中的数据不一致的问题，Dynamo 使用了反信息熵（anti-entropy）的策略保证所有的副本存储的信息都是同步的。</p>
<p>为了快速确认多个副本之间的数据的一致性并避免大量的数据传输，Dynamo 使用了 <a href="https://en.wikipedia.org/wiki/Merkle_tree">Merkle tree</a> 对不同节点中的数据进行快速验证。</p>
<p><img src="/assets/dynamo-implement/2017-10-24-merkle-hash-tree.png" alt="merkle-hash-tree"></p>
<p>在 Merkle 树中，所有父节点中的内容都是叶子节点的哈希，通过这种方式构建的树形结构能够保证整棵树不会被篡改，任何的改动都能被立刻发现。</p>
<p>Dynamo 中的每一个节点都为其持有的键的范围维护了一颗 Merkle 树，在验证两份节点中的数据是否相同时，只需要发送根节点中的哈希值，如果相同那么说明两棵树的内容全部相同，否则就会依次对比不同层级节点中的内容，直到找出不同的副本，这种做法虽然能够减少数据的传输并能够快速找到副本之间的不同，但是当有新的节点加入或者旧的节点退出时会导致大量的 Merkle 树重新计算。</p>
<h2 id="总结"><a class="header-anchor" href="#总结"></a><a href="#%E6%80%BB%E7%BB%93"></a>总结</h2>
<p>在 Dynamo 的论文公开之后，有一篇文章将 Dynamo 的设计称作 <a href="http://jsensarma.com/blog/?p=55">“A flawed architecture”</a>，这篇文章的作者在文中对 Dynamo 的实现进行了分析，主要对其最终一致性和 Quorom 机制进行了批评，它在 <a href="https://news.ycombinator.com/item?id=915212">HackerNews</a> 上也引起了广泛的讨论，帖子中的很多内容都值得一看，能够帮助我们了解 Dynamo 的设计原理，而 Amazon 的 CTO 对于这篇文章也发了一条 Twitter：</p>
<p><img src="/assets/dynamo-implement/2017-10-24-amazon-cto-twitter-about-dynamo.png" alt="amazon-cto-twitter-about-dynamo"></p>
<p>不管如何，Dynamo 作为支撑亚马逊业务的底层服务，其实现原理和思想对于整个社区都是非常有价值的，然而它使用的去中心化的策略也带了很多问题，虽然作者可能会因为这个原因在选择数据库时不会 Dynamo，不过相信它也是有合适的应用场景的。</p>
<h2 id="Reference"><a class="header-anchor" href="#Reference"></a><a href="#reference"></a>Reference</h2>
<ul>
<li><a href="http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf">Dynamo: Amazon’s Highly Available Key-value Store</a></li>
<li><a href="http://jsensarma.com/blog/?p=55">Dynamo: A flawed architecture – Part I</a></li>
<li><a href="http://jsensarma.com/blog/?p=64">Dynamo – Part I: a followup and re-rebuttals</a></li>
<li><a href="https://www.slideshare.net/GrishaWeintraub/presentation-46722530">Dynamo and BigTable - Review and Comparison</a></li>
<li><a href="http://vschart.com/compare/dynamo-db/vs/bigtable">DynamoDB vs. BigTable · vsChart</a></li>
<li><a href="https://en.wikipedia.org/wiki/Merkle_tree">Merkle tree</a></li>
<li><a href="https://link.springer.com/content/pdf/10.1007/3-540-48184-2_32.pdf">A Digital Signature Based on a Conventional Encryption Function</a></li>
<li><a href="http://www.raychase.net/2396">Dynamo 的实现技术和去中心化</a></li>
<li><a href="https://draveness.me/bigtable-leveldb">浅析 Bigtable 和 LevelDB 的实现</a></li>
</ul>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/dynamo-implement/">http://xnerv.wang/dynamo-implement/</a></strong><br>
转载自：<a href="https://draveness.me/dynamo">分布式键值存储 Dynamo 的实现原理</a></p>
]]></content>
      <categories>
        <category>分布式及存储</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>分布式及存储</tag>
        <tag>Dynamo</tag>
      </tags>
  </entry>
  <entry>
    <title>Everything You Always Wanted to Know About Fsync()（转载）</title>
    <url>/everything-you-always-wanted-to-know-about-fsync/</url>
    <content><![CDATA[<p>And then the developer wondered:</p>
<blockquote>
<p><em>is my file properly sync’ed on disk ?</em></p>
</blockquote>
<p>You probably know <strong>more or less</strong> how databases (or things that look like one) store their data on disk in a <strong>permanent</strong> and <strong>safe</strong> way. Or at least, you know the basic principles. Or not ?</p>
<span id="more"></span>
<h2 id="Being-on-AC-I-D"><a class="header-anchor" href="#Being-on-AC-I-D"></a>Being on AC(I)D</h2>
<p>There are a bunch of concepts that first must be understood: what is <strong>atomicity</strong>, <strong>consistency</strong>, and <strong>durability</strong> ? These concepts apply on databases (see <a href="http://en.wikipedia.org/wiki/ACID">ACID</a>), but also on the underlying filesystem.</p>
<ul>
<li><strong>Atomicity</strong>: a write operation is fully executed at once, and is not <strong>interleaved</strong> with another one (if, for example, someone else is writing to the same location)</li>
</ul>
<p>Atomicity is typically guaranteed in operations involving filename handling ; for example, for <a href="http://pubs.opengroup.org/onlinepubs/009695399/functions/rename.html">rename</a>, “<em>specification requires that the action of the function be atomic</em>” – that is, when renaming a file from the old name to the new one, at no circumstances should you ever see the two files at the same time.</p>
<ul>
<li><strong>Consistency</strong>: integrity of data must be maintained when executing an operation, even in a crash event – for example, a power outage in the middle of a <code>rename()</code> operation shall not leave the filesystem in a “weird” state, with the filename being unreachable because its metadata has been corrupted. (ie. either the operation is lost, or the operation is committed.)</li>
</ul>
<p>Consistency is guaranteed on the filesystem level ; but you also need to have the same guarantee if you build a database on disk, for example by serializing/locking certain operations on a working area, and committing the transaction by changing some kind of generation number.</p>
<ul>
<li><strong>Durability</strong>: the write operation is durable, that is, unplugging the power cord (or a kernel panic, a crash…) shall not lose any data (hitting the hard disk with a hammer is however not covered!)</li>
</ul>
<p>This is an important one – at a given point, you must ensure that the data is actually written on disk <em>physically</em>, preventing any loss of data in case of a sudden power outage, for example. This is absolutely critical when dealing with a client/server architecture: the client may have its connection or transaction aborted at any time without troubles (ie. the transaction will be retried later), but once the server acknowledges it, no event should ever cause it to be lost (think of responsibility in a commercial transaction, or a digital signature, for example). For this reason, having the data committed in the internal system or hard disk cache is NOT durable for obvious reasons (unless there is a guarantee that no such power outage could happen – if a battery is used on a RAID array, for example).</p>
<p>On POSIX systems, durability is achieved through sync operations (<code>fsync()</code>, <code>fdatasync()</code>, <code>aio_fsync()</code>): “<em>The fsync() function is intended to force a physical write of data from the buffer cache, and to assure that after a system crash or other failure that all data up to the time of the fsync() call is recorded on the disk.</em>”. [Note: The difference between fsync() and fdatasync() is that the later does not necessarily update the meta-data associated with a file – such as the “last modified” date – but only the file data.]</p>
<p>Now that these concepts are a bit clearer, let’s go back to our filesystem!</p>
<h2 id="Hey-What-is-a-File-By-The-Way"><a class="header-anchor" href="#Hey-What-is-a-File-By-The-Way"></a>Hey, What is a File, By The Way ?</h2>
<p>If we want to simplify the concept, let’s consider the filesystem on POSIX platforms as a very simple <em>flat</em> storage manager, allowing to read/write data blobs and basic properties (such as the modified time) indexed by an <em>integer</em> number (hint: they sometimes call that the <em>inode number</em>).</p>
<p>For example, you may want to read the file #4242’s data. And later, write some data on file #1234.</p>
<p>To have a more convenient way to handle files (because “I need to send you the presentation number 155324” would not be really convenient in the real world), we use the <strong>filename/directory</strong> concepts. A file has a name, and it is <em>contained</em> within a <em>directory structure</em>. You may put files and directories in a directory, building a hierarchical structure. But everything rely on our previous basic data blobs to store both filename and the associated index.</p>
<p>As an example, reading the file <code>foo/bar.txt</code> (ie. the file <code>bar.txt</code> within the <code>foo</code> directory) will require to access the data blob associated with the directory <code>foo</code>. After parsing this opaque data blob, the system will fetch the entry for <code>bar.txt</code>, and open the associated data blob. (And yes, there is obviously a root entry, storing references to first-level entries, allowing to access any file top-down)</p>
<p>If I now want to create a new file named <code>foo/baz.txt</code>, it will require the system to access the data blob associated with the directory <code>foo</code>, add an entry named <code>baz.txt</code> with a new allocated index for the upcoming file, and write the updated directory blob back, and from this point, write to the newly allocated blob. The operation therefore involves <strong>two</strong> data structures: the <strong>directory entry</strong>, and the <strong>file</strong> itself.</p>
<h2 id="Keeping-My-File-name-Safe"><a class="header-anchor" href="#Keeping-My-File-name-Safe"></a>Keeping My File(name) Safe</h2>
<p>Let’s go back to our database problem: what is the impact of having two data structures for our files ?</p>
<p><strong>Atomicity</strong> and <strong>consistency</strong> of filenames are handled for us by the filesystem, so this is not really a bother.</p>
<p>What about <strong>durability</strong> ?</p>
<p>We know that <code>fsync()</code> provides guarantees related to data and meta-data sync’ing. But if you look closer to the specification, the only data involved are the one related to the file itself – not its directory entry. The “metadata” concept involves modified time, access time etc. – <strong>not</strong> the <em>directory entry</em> itself.</p>
<p>It would be cumbersome for a filesystem to provide this guarantee, by the way: on POSIX systems, you can have an arbitrary number of directory links to a filename (or to another directory entry). The most common case is <em>one</em>, of course. But you may delete a file being used (the file entry will be removed by the system when the file is closed) – the very reason why erasing a log file which is flooding a filesystem is a futile and deadly action – in such case, the number of links will be zero. And you may also create as many <a href="http://pubs.opengroup.org/onlinepubs/009695399/functions/link.html">hard-links</a> as you want for a given file/directory entry.</p>
<p>Therefore, in theory, you may create a file, write some data, synchronize it, close the file, and see your <a href="http://upload.wikimedia.org/wikipedia/en/e/e0/Gollum.PNG">precious</a> file lost forever because of a power outage. Oh, the filesystem must guarantee consistency, of course, but not durability unless <em>explicitly</em> asked by the client – which means that a filesystem check may find your directory entry partially written, and decide to achieve consistency by taking the previous directory blob entry, <strong>wiping</strong> the unreferenced file entry (note: if you are “lucky” enough, the file will be expelled in <code>lost+found</code>)</p>
<p>The filesystem can, of course, decide to be gentle, and commit all filename operations when fsync’ing. It may also, such as for ext3, commit <a href="https://ext4.wiki.kernel.org/index.php/Ext3_Data%3DOrdered_vs_Data%3DWriteback_mode">everything</a> when fsync’ing a file – causing the <a href="http://lwn.net/Articles/328363/">infamous</a> and <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=421482">horrendous</a> lags in firefox or thunderbird.</p>
<p>But if you need to have <strong>guarantees</strong>, and not just <em>hope</em> the filesystem “<em>will be gentle</em>”, and do not want to “<em>trust the filesystem</em>” (yes, someone actually told me that: you need to “trust the filesystem” – I swear it), you have to actually make sure that your <strong>filename</strong> entry is properly sync’ed on disk following the POSIX specification.</p>
<p>Oh, and by the way: according to <a href="http://pubs.opengroup.org/onlinepubs/009695399/functions/fsync.html">POSIX</a>, <em>The fsync() function is intended to force a physical write of data from the buffer cache, and to assure that after a system crash or other failure that all data up to the time of the fsync() call is recorded on the disk.</em></p>
<p><em>But</em> things are sometimes a bit obscure on the implementation side :</p>
<p><a href="http://unixhelp.ed.ac.uk/CGI/man-cgi?fsync">Linux/ext3</a>: <em>If the underlying hard disk has write caching enabled, then the data may not really be on permanent storage when fsync() / fdatasync() return.</em> (do’h!)</p>
<p><a href="http://linux.die.net/man/2/fsync">Linux/ext4</a>: <em>The fsync() implementations in older kernels and lesser used filesystems does not know how to flush disk caches.</em> (do’h!) – issue adressed quite <a href="http://lwn.net/Articles/270891/">recently</a></p>
<p><a href="https://developer.apple.com/library/mac/documentation/Darwin/Reference/ManPages/man2/fsync.2.html">OSX</a>: <em>For applications that require tighter guarantees about the integrity of their data, Mac OS X provides the F_FULLFSYNC fcntl. The <code>F_FULLFSYNC</code> fcntl asks the drive to flush all buffered data to permanent storage</em> (hey, fsync was supposed to do that, no ? guys ?) <em>(Edit: no, fsync is actually not required to do that – thanks for the clarification Florent!)</em></p>
<p>But we may assume that on Linux with <a href="http://monolight.cc/2011/06/barriers-caches-filesystems/">ext4</a> (and OSX with proper flags ?) the system is properly propagating <a href="http://docs.fedoraproject.org/en-US/Fedora/14/html/Storage_Administration_Guide/writebarr.html">write barriers</a>.</p>
<p>On Windows, using <code>FlushFileBuffers()</code> is probably the way to go.</p>
<h2 id="Syncing-Filenames"><a class="header-anchor" href="#Syncing-Filenames"></a>Syncing Filenames</h2>
<p>I told you that a filesystem was actually a bunch of <em>flat</em> data blobs with associated metadata, and that a file had actually two parts: its directory entry (let’s assume there is only one directory entry for the sake of simplicity), and its actual data. We already know how to sync the later one ; do we have a way to do the same for the directory container itself ?</p>
<p>On POSIX, you may actually open a directory as if you were opening a file (hint: a directory is <em><a href="http://pubs.opengroup.org/onlinepubs/9699919799/basedefs/V1_chap03.html">a file that contains directory entries</a></em>). It means that <code>open()</code> <em>may</em> successfully open a directory entry. But on the other hand, you generally can not open a directory entry for writing (see POSIX <a href="http://pubs.opengroup.org/onlinepubs/009695299/functions/open.html">remark</a> regarding <code>EISDIR</code>: <em>The named file is a directory and oflag includes O_WRONLY or O_RDWR</em>), and this is perfectly logical: by directly writing to the internal directory entry, you may be able to mess up with the directory structure, ruining the filesystem <strong>consistency</strong>.</p>
<p>But can we fsync() written data using a file descriptor opened <em>only</em> for reading ? The question is… yes, or at least “<em>yes it should</em>” – even POSIX group had <em>editorial</em> inconsistencies regarding <a href="http://austingroupbugs.net/view.php?id=501">fdatasync</a> and <a href="http://austingroupbugs.net/view.php?id=671">aio_fsync()</a>, leading to incorrect <a href="http://cygwin.com/frysk/bugzilla/show_bug.cgi?id=15361">behavior</a> on various implementations. And the reason it should execute the operation is because requesting the completion of a write operation does not have to require actual write access – which have already been checked and enforced.</p>
<p>On Windows… err, there is no clear answer. You can not call <code>FlushFileBuffers()</code> on a directory handle as far as I can see.</p>
<p>Oh, a last funny note: how do you sync the <strong>content</strong> of a <em>symbolic link</em> (and its related meta-data), that is, the filename pointed by this link ? The answer is… you can’t. Nope. This is not possible with the current standard (hint: you can not <code>open()</code> a symbolic link). Which means that if you handle some kind of database generation update based on symbolic links (ie. changing a “last-version” symlink to the latest built generation file), you have zero guarantee over durability.</p>
<h2 id="Conclusion"><a class="header-anchor" href="#Conclusion"></a>Conclusion</h2>
<p>Does it means that we need to call <code>fsync()</code> <em>twice</em>, one on the file data, and one on its parent directory ? When you need to achieve <em>durability</em>, the answer is obviously <strong>yes</strong>. (Remember that file file/filename will be sync’ed on disk anyway by the operating system, so you do not actually need to do that for every single file – only for those you want to have a durability guarantee at a given time)</p>
<p>However, the question is causing some headache on the POSIX standard, and as a follow-up to the <a href="http://comments.gmane.org/gmane.comp.standards.posix.austin.general/6952">austin-group</a> (ie. POSIX mailing-list) discussion, an <a href="http://austingroupbugs.net/view.php?id=672">editorial clarification request</a> is still pending and is waiting for feedback from various implementors. (you may also have a look at the <a href="http://unix.derkeiler.com/Newsgroups/comp.unix.programmer/2013-03/msg00016.html">comp.unix.programmer discussion</a>)</p>
<p><strong>TL;DR</strong>: syncing a file is not as simple as it seems!</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/everything-you-always-wanted-to-know-about-fsync/">http://xnerv.wang/everything-you-always-wanted-to-know-about-fsync/</a></strong><br>
转载自：<a href="http://blog.httrack.com/blog/2013/11/15/everything-you-always-wanted-to-know-about-fsync/">Everything You Always Wanted to Know About Fsync()</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Linux</tag>
        <tag>Linux API</tag>
      </tags>
  </entry>
  <entry>
    <title>关于DLL的一些你不会想要知道的知识</title>
    <url>/everything-you-never-wanted-to-know-about-dlls-cn/</url>
    <content><![CDATA[<p>英文版本 <strong><a href="/everything-you-never-wanted-to-know-about-dlls/">Everything You Never Wanted To Know About DLLs</a></strong>.</p>
<hr>
<p>最近因为一些原因，我需要调研动态链接在Windows平台上的实现细节。这篇文章主要是总结我在这个问题上所学到的知识，用于我将来的回顾和参考，但同时我也希望这篇文章对其他人所有帮助，因为我将要总结的这些内容，你可能需要东找西找才能找到。</p>
<p>废话不多说，让我们开始这趟旅程吧：</p>
<span id="more"></span>
<h2 id="导出和导入"><a class="header-anchor" href="#导出和导入"></a>导出和导入</h2>
<p>Windows可执行文件加载器（Windows executable loader）负责在运行程序前完成所有动态加载和符号解析工作。链接器会分别计算出每一个可执行镜像（可执行镜像是一个DLL或者一个EXE文件）导出和导入了哪些函数，这个过程是通过检查可执行镜像的.edata段和.idata段来进行的。</p>
<p>关于.edata段和.idata段的详细信息，在<a href="http://msdn.microsoft.com/en-us/windows/hardware/gg463119">PE/COFF specification</a>这篇文档中有详细说明。</p>
<h3 id="edata段"><a class="header-anchor" href="#edata段"></a>.edata段</h3>
<p>.edata段记录了可执行镜像导出的符号（是的，EXE也可以导出符号）。主要包括：</p>
<ul>
<li>导出地址表（export address table）：一个长度为N的数组，保存了导出的函数/变量的地址（相对于可执行镜像起始地址的相关地址）。这张表的索引称之为序号（ordinals）。</li>
<li>导出名称地址表（export name pointer table）：一个长度为M的<a href="https://en.wikipedia.org/wiki/Parallel_array">并行数组</a>（译者记：其实就是两个大小一样的数组，一个保存key，一个保存对应的value），保存的是符号地址到导出名称的映射。这个平行数组是按照导出名称的字典序排序的，从而允许进行对一个给定的导出符号名称进行二分查找。</li>
<li>导出序号表（export ordinal table）：也是一个长度为M的并行数组，保存了序号到对应的导出名称的映射，其中导出名称对应的是导出名称地址表中的键key。</li>
</ul>
<p>（作为通过名称导入符号这一做法的另一种替代方法，也可以通过指定序号来导入一个符号。通过序号来导入符号的做法在运行时会稍微快一些，因为这种情况下动态链接器（dynamic linker）不需要进行查找（译者记：根据名称在导出名称地址表中找到名称对应的地址）。此外，如果导出符号的DLL并没有给某个导出项分配名称，那么通过序号来导入符号是唯一的可行之路。）</p>
<p>那么.edata段最初是怎样被创建的呢？主要有两种方法：</p>
<ol>
<li>
<p>最常见的一种情况，在编译生成一些目标文件（object files）时会创建.edata段。这些目标文件对应的源码中，定义了一些带<code>__declspec(dllimport)</code>修饰符的函数或者变量。于是编译器就会产生一个包含了这些导出项的.edata段。</p>
</li>
<li>
<p>另一种比较少见的情况，开发人员会写一个.def文件，指定那些函数需要被导出。将这个.def文件提供给<code>dll tool --output-exp</code>，就能产生一个导出文件（export file）。导出文件是一个仅包含.edata段的目标文件，导出了在.def文件中声明的符号（导出了一些未解析的引用，通常链接器会填写这些引用到一个实际的地址）。程序员在将这些目标文件链接成DLL的时候，必须对这些导出库（export library）进行命名。</p>
<p>对于以上两种情况，链接器在链接时都会从所有的目标（objects）中收集.edata段，用于给整个可执行镜像文件创建一个.edata段。最后一种可能的方式是.edata段可以被链接器自身所创建，不需要将.edata段放入到任何目标文件中：</p>
</li>
<li>
<p>链接器可以选择在链接时导出目标文件中的所有符号。例如，这是<a href="http://sourceware.org/binutils/docs/ld/WIN32.html">GNU ld的默认行为</a>（也可以通过–export-all-symbols显式地指定这种行为）。在这种情况下，由链接器来产生.edata段。（GNU ld也支持在命令行中指定一个.def文件，然后产生的.edata段就只会导出这个.def文件中声明的符号）。</p>
</li>
</ol>
<h3 id="idata段"><a class="header-anchor" href="#idata段"></a>.idata段</h3>
<p>.idata段记录了可执行镜像导入的符号信息。包括：<br>
对于导入符号涉及到的每一个可执行镜像：</p>
<ul>
<li>可执行镜像的文件名。被动态链接器用于在磁盘上查找该文件。</li>
<li>导入符号查找表（import lookup table）：一个长度为N的数组，每一项要么是一个序号，要么是一个指向导入名称字符串的指针。</li>
<li>导入符号地址表（import address table）：一个长度为N的指针数组。动态链接器会用从导入符号查找表中对应顺序的符号的地址来填写该数组。</li>
</ul>
<p>.idata段中的条目以如下方式被创建：</p>
<ol>
<li>
<p>最常见的一种情况，这些条目来自目标文件中的导入库（import library）。可以对你希望导出符号的DLL或者我们之前讨论过的.def文件使用dlltool工具来创建导入库。和导出库一样，用户必须在链接这些导入库时指定名称。</p>
</li>
<li>
<p>或者，有一些链接器（像GNU ld）也可以让你在链接时直接指定DLL文件。对于你需要从这些DLL文件中导入的符号，链接器会自动产生相应的.idata段条目。</p>
</li>
</ol>
<p>注意，跟导出符号不一样，<code>__declspec(dllimport)</code>修饰符并不会导致产生相应的.idata段。</p>
<p>比起第一次出现，导入库有点更复杂了。Windows动态加载器将导入符号（例如，函数Func的地址）的地址填入到导入符号地址表中。然而，当其它目标文件中的汇编代码执行<code>call Func</code>时，它们期待的是用Func来命名那段code的地址。但我们直到运行时的时候才知道这个地址：我们能够静态地得知的事情只有动态链接器会将这个地址存放在哪个地方。我们称这个地方为_imp_Func。<br>
为了处理这一层额外的中间层，导入库导出的函数Func仅仅间接引用了_imp_Func（来获得实际的函数指针），然后执行<code>jmp</code>跳转到它。同一个工程中的所有其它的目标文件现在可以调用<code>call Func</code>，仿佛Func已经在其它目标文件而不是其它DLL中定义过了一样。基于这个原因，动态链接的函数的声明上的<code>__declspec(dllimport)</code>只是可有可无的（尽管实际上如果加上这个修饰符的话，代码的效率会有轻微的提升，我们之后会谈到这一点）。<br>
不幸的是，如果你想要从另一个DLL中导入变量，则并没有类似的技巧。如果我们有一个导入的变量myData，并没有一种方法来定义一个导入库，使得链接到这个导入库的目标文件可以通过执行<code>mov $eax, myData</code>来写入到myData所在的内存位置。取而代之的是，导入库定义了一个符号<code>__imp__myData</code>，这个符号解析到一个可以找到myData链接地址的地方。然后编译器就会保证当你在读写用<code>__declspec(dllimport)</code>定义的变量时，这些读写其实是通过<code>__imp_myData</code>来间接进行的。因为需要在使用的时候再产生不同的代码，因此在导入变量时的<code>__declspec</code>声明是不可省去的。</p>
<h2 id="应用实例"><a class="header-anchor" href="#应用实例"></a>应用实例</h2>
<p>理论都很好，但在实践中看看所有这些的这些部分会对我们很有帮助。</p>
<h3 id="构建DLL"><a class="header-anchor" href="#构建DLL"></a>构建DLL</h3>
<p>首先，让我们来构建一个简单的DLL，同时导出了函数和变量。为了最大化地进行说明，我们将使用显式地导出库，而不是用<code>declspec(dllexport)</code>来修饰我们的函数，也不是提供一个.def文件给链接器。<br>
先创建一个.def文件，library.def：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">LIBRARY library</span><br><span class="line">EXPORTS</span><br><span class="line">   function_export</span><br><span class="line">   data_export      DATA</span><br></pre></td></tr></table></figure>
<p>（<code>DATA</code>关键词和<code>LIBRARY</code>这一行仅仅影响到导入库如何被产生，之后本文会解释这一点。现在请暂时忽略这个。）<br>
然后构建一个导出文件：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ dlltool --output-exp library_exports.o -d library.def</span><br></pre></td></tr></table></figure>
<p>产生的目标文件基本上只包含了一个.edata段，导出了符号<code>_data_export</code>和<code>_function_export</code>，名称分别是<code>data_export</code>和<code>function_export</code>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ objdump -xs library_exports.o</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">There is an export table in .edata at 0x0</span><br><span class="line"></span><br><span class="line">The Export Tables (interpreted .edata section contents)</span><br><span class="line"></span><br><span class="line">Export Flags                    0</span><br><span class="line">Time/Date stamp                 4e10e5c1</span><br><span class="line">Major/Minor                     0/0</span><br><span class="line">Name                            00000028 library_exports.o.dll</span><br><span class="line">Ordinal Base                    1</span><br><span class="line">Number in:</span><br><span class="line">        Export Address Table            00000002</span><br><span class="line">        [Name Pointer/Ordinal] Table    00000002</span><br><span class="line">Table Addresses</span><br><span class="line">        Export Address Table            00000040</span><br><span class="line">        Name Pointer Table              00000048</span><br><span class="line">        Ordinal Table                   00000050</span><br><span class="line"></span><br><span class="line">Export Address Table -- Ordinal Base 1</span><br><span class="line"></span><br><span class="line">[Ordinal/Name Pointer] Table</span><br><span class="line">        [   0] data_export</span><br><span class="line">        [   1] function_export</span><br><span class="line"></span><br><span class="line">Sections:</span><br><span class="line">Idx Name          Size      VMA       LMA       File off  Algn</span><br><span class="line">  0 .text         00000000  00000000  00000000  00000000  2**2</span><br><span class="line">                  ALLOC, LOAD, READONLY, CODE</span><br><span class="line">  1 .data         00000000  00000000  00000000  00000000  2**2</span><br><span class="line">                  ALLOC, LOAD, DATA</span><br><span class="line">  2 .bss          00000000  00000000  00000000  00000000  2**2</span><br><span class="line">                  ALLOC</span><br><span class="line">  3 .edata        00000070  00000000  00000000  000000b4  2**2</span><br><span class="line">                  CONTENTS, ALLOC, LOAD, RELOC, READONLY, DATA</span><br><span class="line">SYMBOL TABLE:</span><br><span class="line">[  0](sec -2)(fl 0x00)(ty   0)(scl 103) (nx 1) 0x00000000 fake</span><br><span class="line">File</span><br><span class="line">[  2](sec  4)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000028 name</span><br><span class="line">[  3](sec  4)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000040 afuncs</span><br><span class="line">[  4](sec  4)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000048 anames</span><br><span class="line">[  5](sec  4)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000050 anords</span><br><span class="line">[  6](sec  4)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000054 n1</span><br><span class="line">[  7](sec  4)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000060 n2</span><br><span class="line">[  8](sec  1)(fl 0x00)(ty   0)(scl   3) (nx 1) 0x00000000 .text</span><br><span class="line">AUX scnlen 0x0 nreloc 0 nlnno 0</span><br><span class="line">[ 10](sec  2)(fl 0x00)(ty   0)(scl   3) (nx 1) 0x00000000 .data</span><br><span class="line">AUX scnlen 0x0 nreloc 0 nlnno 0</span><br><span class="line">[ 12](sec  3)(fl 0x00)(ty   0)(scl   3) (nx 1) 0x00000000 .bss</span><br><span class="line">AUX scnlen 0x0 nreloc 0 nlnno 0</span><br><span class="line">[ 14](sec  4)(fl 0x00)(ty   0)(scl   3) (nx 1) 0x00000000 .edata</span><br><span class="line">AUX scnlen 0x70 nreloc 8 nlnno 0</span><br><span class="line">[ 16](sec  0)(fl 0x00)(ty   0)(scl   2) (nx 0) 0x00000000 _data_export</span><br><span class="line">[ 17](sec  0)(fl 0x00)(ty   0)(scl   2) (nx 0) 0x00000000 _function_export</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">RELOCATION RECORDS FOR [.edata]:</span><br><span class="line">OFFSET   TYPE              VALUE</span><br><span class="line">0000000c rva32             .edata</span><br><span class="line">0000001c rva32             .edata</span><br><span class="line">00000020 rva32             .edata</span><br><span class="line">00000024 rva32             .edata</span><br><span class="line">00000040 rva32             _data_export</span><br><span class="line">00000044 rva32             _function_export</span><br><span class="line">00000048 rva32             .edata</span><br><span class="line">0000004c rva32             .edata</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Contents of section .edata:</span><br><span class="line"> 0000 00000000 c1e5104e 00000000 28000000  .......N....(...</span><br><span class="line"> 0010 01000000 02000000 02000000 40000000  ............@...</span><br><span class="line"> 0020 48000000 50000000 6c696272 6172795f  H...P...library_</span><br><span class="line"> 0030 6578706f 7274732e 6f2e646c 6c000000  exports.o.dll...</span><br><span class="line"> 0040 00000000 00000000 54000000 60000000  ........T...`...</span><br><span class="line"> 0050 00000100 64617461 5f657870 6f727400  ....data_export.</span><br><span class="line"> 0060 66756e63 74696f6e 5f657870 6f727400  function_export.</span><br></pre></td></tr></table></figure>
<p>我们将会用一个简单的DLL实现来提供这些符号，library.c：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int data_export = 42;</span><br><span class="line"></span><br><span class="line">int function_export() &#123;</span><br><span class="line">    return 1337 + data_export;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>打包到一个DLL中：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ gcc -shared -o library.dll library.c library_exports.o</span><br></pre></td></tr></table></figure>
<p>这个DLL的导出符号表如下，可见我们已经导出了我们所需的符号信息：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">The Export Tables (interpreted .edata section contents)</span><br><span class="line"></span><br><span class="line">Export Flags                    0</span><br><span class="line">Time/Date stamp                 4e10e5c1</span><br><span class="line">Major/Minor                     0/0</span><br><span class="line">Name                            00005028 library_exports.o.dll</span><br><span class="line">Ordinal Base                    1</span><br><span class="line">Number in:</span><br><span class="line">        Export Address Table            00000002</span><br><span class="line">        [Name Pointer/Ordinal] Table    00000002</span><br><span class="line">Table Addresses</span><br><span class="line">        Export Address Table            00005040</span><br><span class="line">        Name Pointer Table              00005048</span><br><span class="line">        Ordinal Table                   00005050</span><br><span class="line"></span><br><span class="line">Export Address Table -- Ordinal Base 1</span><br><span class="line">        [   0] +base[   1] 200c Export RVA</span><br><span class="line">        [   1] +base[   2] 10f0 Export RVA</span><br><span class="line"></span><br><span class="line">[Ordinal/Name Pointer] Table</span><br><span class="line">        [   0] data_export</span><br><span class="line">        [   1] function_export</span><br></pre></td></tr></table></figure>
<h3 id="使用DLL"><a class="header-anchor" href="#使用DLL"></a>使用DLL</h3>
<p>当我们回过头来看看如何使用DLL时，事情变得更有有趣了。首先，我们需要一个导出库：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ dlltool --output-lib library.dll.a -d library.def</span><br></pre></td></tr></table></figure>
<p>（我们使用导入库<code>library.dll.a</code>而不是直接使用导出符号的对象文件<code>library_exports.o</code>，是因为使用库来导入允许链接器忽略<code>.idata</code>段中并没有被使用到的符号。而相反的是链接器无法忽略<code>.edata</code>段中的任何符号，因为任何一个符号都可能被这个DLL的使用者用到）。<br>
导入库是相当复杂的。对于每一个导入符号，导入库中都包含一个对应的目标文件（<code>disds00000.o</code>和<code>disds00001.o</code>），同时也包含了其它两个目标文件（<code>distdt.o</code>和<code>disdh.o</code>），用于设立导入列表的头部和尾部。（导入列表的头部除了其它的一些东西，还包含了在运行时需要链接的DLL的名字，这是从.def文件的LIBRARY一行派生而来的。）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ objdump -xs library.dll.a</span><br><span class="line">In archive library.dll.a:</span><br><span class="line"></span><br><span class="line">disdt.o:     file format pe-i386</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">Sections:</span><br><span class="line">Idx Name          Size      VMA       LMA       File off  Algn</span><br><span class="line">  0 .text         00000000  00000000  00000000  00000000  2**2</span><br><span class="line">                  ALLOC, LOAD, READONLY, CODE</span><br><span class="line">  1 .data         00000000  00000000  00000000  00000000  2**2</span><br><span class="line">                  ALLOC, LOAD, DATA</span><br><span class="line">  2 .bss          00000000  00000000  00000000  00000000  2**2</span><br><span class="line">                  ALLOC</span><br><span class="line">  3 .idata$4      00000004  00000000  00000000  00000104  2**2</span><br><span class="line">                  CONTENTS, ALLOC, LOAD, DATA</span><br><span class="line">  4 .idata$5      00000004  00000000  00000000  00000108  2**2</span><br><span class="line">                  CONTENTS, ALLOC, LOAD, DATA</span><br><span class="line">  5 .idata$7      0000000c  00000000  00000000  0000010c  2**2</span><br><span class="line">                  CONTENTS, ALLOC, LOAD, DATA</span><br><span class="line">SYMBOL TABLE:</span><br><span class="line">[  0](sec -2)(fl 0x00)(ty   0)(scl 103) (nx 1) 0x00000000 fake</span><br><span class="line">File</span><br><span class="line">[  2](sec  1)(fl 0x00)(ty   0)(scl   3) (nx 1) 0x00000000 .text</span><br><span class="line">AUX scnlen 0x0 nreloc 0 nlnno 0</span><br><span class="line">[  4](sec  2)(fl 0x00)(ty   0)(scl   3) (nx 1) 0x00000000 .data</span><br><span class="line">AUX scnlen 0x0 nreloc 0 nlnno 0</span><br><span class="line">[  6](sec  3)(fl 0x00)(ty   0)(scl   3) (nx 1) 0x00000000 .bss</span><br><span class="line">AUX scnlen 0x0 nreloc 0 nlnno 0</span><br><span class="line">[  8](sec  4)(fl 0x00)(ty   0)(scl   3) (nx 1) 0x00000000 .idata$4</span><br><span class="line">AUX scnlen 0x4 nreloc 0 nlnno 0</span><br><span class="line">[ 10](sec  5)(fl 0x00)(ty   0)(scl   3) (nx 1) 0x00000000 .idata$5</span><br><span class="line">AUX scnlen 0x4 nreloc 0 nlnno 0</span><br><span class="line">[ 12](sec  6)(fl 0x00)(ty   0)(scl   3) (nx 1) 0x00000000 .idata$7</span><br><span class="line">AUX scnlen 0x7 nreloc 0 nlnno 0</span><br><span class="line">[ 14](sec  6)(fl 0x00)(ty   0)(scl   2) (nx 0) 0x00000000 __library_dll_a_iname</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Contents of section .idata$4:</span><br><span class="line"> 0000 00000000                             ....</span><br><span class="line">Contents of section .idata$5:</span><br><span class="line"> 0000 00000000                             ....</span><br><span class="line">Contents of section .idata$7:</span><br><span class="line"> 0000 6c696272 6172792e 646c6c00           library.dll.</span><br><span class="line"></span><br><span class="line">disdh.o:     file format pe-i386</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">Sections:</span><br><span class="line">Idx Name          Size      VMA       LMA       File off  Algn</span><br><span class="line">  0 .text         00000000  00000000  00000000  00000000  2**2</span><br><span class="line">                  ALLOC, LOAD, READONLY, CODE</span><br><span class="line">  1 .data         00000000  00000000  00000000  00000000  2**2</span><br><span class="line">                  ALLOC, LOAD, DATA</span><br><span class="line">  2 .bss          00000000  00000000  00000000  00000000  2**2</span><br><span class="line">                  ALLOC</span><br><span class="line">  3 .idata$2      00000014  00000000  00000000  00000104  2**2</span><br><span class="line">                  CONTENTS, ALLOC, LOAD, RELOC, DATA</span><br><span class="line">  4 .idata$5      00000000  00000000  00000000  00000000  2**2</span><br><span class="line">                  ALLOC, LOAD, DATA</span><br><span class="line">  5 .idata$4      00000000  00000000  00000000  00000000  2**2</span><br><span class="line">                  ALLOC, LOAD, DATA</span><br><span class="line">SYMBOL TABLE:</span><br><span class="line">[  0](sec -2)(fl 0x00)(ty   0)(scl 103) (nx 1) 0x00000000 fake</span><br><span class="line">File</span><br><span class="line">[  2](sec  6)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000000 hname</span><br><span class="line">[  3](sec  5)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000000 fthunk</span><br><span class="line">[  4](sec  1)(fl 0x00)(ty   0)(scl   3) (nx 1) 0x00000000 .text</span><br><span class="line">AUX scnlen 0x0 nreloc 0 nlnno 0</span><br><span class="line">[  6](sec  2)(fl 0x00)(ty   0)(scl   3) (nx 1) 0x00000000 .data</span><br><span class="line">AUX scnlen 0x0 nreloc 0 nlnno 0</span><br><span class="line">[  8](sec  3)(fl 0x00)(ty   0)(scl   3) (nx 1) 0x00000000 .bss</span><br><span class="line">AUX scnlen 0x0 nreloc 0 nlnno 0</span><br><span class="line">[ 10](sec  4)(fl 0x00)(ty   0)(scl   3) (nx 1) 0x00000000 .idata$2</span><br><span class="line">AUX scnlen 0x14 nreloc 3 nlnno 0</span><br><span class="line">[ 12](sec  6)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000000 .idata$4</span><br><span class="line">[ 13](sec  5)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000000 .idata$5</span><br><span class="line">[ 14](sec  4)(fl 0x00)(ty   0)(scl   2) (nx 0) 0x00000000 __head_library_dll_a</span><br><span class="line">[ 15](sec  0)(fl 0x00)(ty   0)(scl   2) (nx 0) 0x00000000 __library_dll_a_iname</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">RELOCATION RECORDS FOR [.idata$2]:</span><br><span class="line">OFFSET   TYPE              VALUE</span><br><span class="line">00000000 rva32             .idata$4</span><br><span class="line">0000000c rva32             __library_dll_a_iname</span><br><span class="line">00000010 rva32             .idata$5</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Contents of section .idata$2:</span><br><span class="line"> 0000 00000000 00000000 00000000 00000000  ................</span><br><span class="line"> 0010 00000000                             ....</span><br><span class="line"></span><br><span class="line">disds00001.o:     file format pe-i386</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">Sections:</span><br><span class="line">Idx Name          Size      VMA       LMA       File off  Algn</span><br><span class="line">  0 .text         00000008  00000000  00000000  0000012c  2**2</span><br><span class="line">                  CONTENTS, ALLOC, LOAD, RELOC, READONLY, CODE</span><br><span class="line">  1 .data         00000000  00000000  00000000  00000000  2**2</span><br><span class="line">                  ALLOC, LOAD, DATA</span><br><span class="line">  2 .bss          00000000  00000000  00000000  00000000  2**2</span><br><span class="line">                  ALLOC</span><br><span class="line">  3 .idata$7      00000004  00000000  00000000  00000134  2**2</span><br><span class="line">                  CONTENTS, RELOC</span><br><span class="line">  4 .idata$5      00000004  00000000  00000000  00000138  2**2</span><br><span class="line">                  CONTENTS, RELOC</span><br><span class="line">  5 .idata$4      00000004  00000000  00000000  0000013c  2**2</span><br><span class="line">                  CONTENTS, RELOC</span><br><span class="line">  6 .idata$6      00000012  00000000  00000000  00000140  2**1</span><br><span class="line">                  CONTENTS</span><br><span class="line">SYMBOL TABLE:</span><br><span class="line">[  0](sec  1)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000000 .text</span><br><span class="line">[  1](sec  2)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000000 .data</span><br><span class="line">[  2](sec  3)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000000 .bss</span><br><span class="line">[  3](sec  4)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000000 .idata$7</span><br><span class="line">[  4](sec  5)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000000 .idata$5</span><br><span class="line">[  5](sec  6)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000000 .idata$4</span><br><span class="line">[  6](sec  7)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000000 .idata$6</span><br><span class="line">[  7](sec  1)(fl 0x00)(ty   0)(scl   2) (nx 0) 0x00000000 _function_export</span><br><span class="line">[  8](sec  5)(fl 0x00)(ty   0)(scl   2) (nx 0) 0x00000000 __imp__function_export</span><br><span class="line">[  9](sec  0)(fl 0x00)(ty   0)(scl   2) (nx 0) 0x00000000 __head_library_dll_a</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">RELOCATION RECORDS FOR [.text]:</span><br><span class="line">OFFSET   TYPE              VALUE</span><br><span class="line">00000002 dir32             .idata$5</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">RELOCATION RECORDS FOR [.idata$7]:</span><br><span class="line">OFFSET   TYPE              VALUE</span><br><span class="line">00000000 rva32             __head_library_dll_a</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">RELOCATION RECORDS FOR [.idata$5]:</span><br><span class="line">OFFSET   TYPE              VALUE</span><br><span class="line">00000000 rva32             .idata$6</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">RELOCATION RECORDS FOR [.idata$4]:</span><br><span class="line">OFFSET   TYPE              VALUE</span><br><span class="line">00000000 rva32             .idata$6</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Contents of section .text:</span><br><span class="line"> 0000 ff250000 00009090                    .%......</span><br><span class="line">Contents of section .idata$7:</span><br><span class="line"> 0000 00000000                             ....</span><br><span class="line">Contents of section .idata$5:</span><br><span class="line"> 0000 00000000                             ....</span><br><span class="line">Contents of section .idata$4:</span><br><span class="line"> 0000 00000000                             ....</span><br><span class="line">Contents of section .idata$6:</span><br><span class="line"> 0000 01006675 6e637469 6f6e5f65 78706f72  ..function_expor</span><br><span class="line"> 0010 7400                                 t.</span><br><span class="line"></span><br><span class="line">disds00000.o:     file format pe-i386</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">Sections:</span><br><span class="line">Idx Name          Size      VMA       LMA       File off  Algn</span><br><span class="line">  0 .text         00000000  00000000  00000000  00000000  2**2</span><br><span class="line">                  ALLOC, LOAD, READONLY, CODE</span><br><span class="line">  1 .data         00000000  00000000  00000000  00000000  2**2</span><br><span class="line">                  ALLOC, LOAD, DATA</span><br><span class="line">  2 .bss          00000000  00000000  00000000  00000000  2**2</span><br><span class="line">                  ALLOC</span><br><span class="line">  3 .idata$7      00000004  00000000  00000000  0000012c  2**2</span><br><span class="line">                  CONTENTS, RELOC</span><br><span class="line">  4 .idata$5      00000004  00000000  00000000  00000130  2**2</span><br><span class="line">                  CONTENTS, RELOC</span><br><span class="line">  5 .idata$4      00000004  00000000  00000000  00000134  2**2</span><br><span class="line">                  CONTENTS, RELOC</span><br><span class="line">  6 .idata$6      0000000e  00000000  00000000  00000138  2**1</span><br><span class="line">                  CONTENTS</span><br><span class="line">SYMBOL TABLE:</span><br><span class="line">[  0](sec  1)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000000 .text</span><br><span class="line">[  1](sec  2)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000000 .data</span><br><span class="line">[  2](sec  3)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000000 .bss</span><br><span class="line">[  3](sec  4)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000000 .idata$7</span><br><span class="line">[  4](sec  5)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000000 .idata$5</span><br><span class="line">[  5](sec  6)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000000 .idata$4</span><br><span class="line">[  6](sec  7)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000000 .idata$6</span><br><span class="line">[  7](sec  5)(fl 0x00)(ty   0)(scl   2) (nx 0) 0x00000000 __imp__data_export</span><br><span class="line">[  8](sec  0)(fl 0x00)(ty   0)(scl   2) (nx 0) 0x00000000 __head_library_dll_a</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">RELOCATION RECORDS FOR [.idata$7]:</span><br><span class="line">OFFSET   TYPE              VALUE</span><br><span class="line">00000000 rva32             __head_library_dll_a</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">RELOCATION RECORDS FOR [.idata$5]:</span><br><span class="line">OFFSET   TYPE              VALUE</span><br><span class="line">00000000 rva32             .idata$6</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">RELOCATION RECORDS FOR [.idata$4]:</span><br><span class="line">OFFSET   TYPE              VALUE</span><br><span class="line">00000000 rva32             .idata$6</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Contents of section .idata$7:</span><br><span class="line"> 0000 00000000                             ....</span><br><span class="line">Contents of section .idata$5:</span><br><span class="line"> 0000 00000000                             ....</span><br><span class="line">Contents of section .idata$4:</span><br><span class="line"> 0000 00000000                             ....</span><br><span class="line">Contents of section .idata$6:</span><br><span class="line"> 0000 00006461 74615f65 78706f72 7400      ..data_export.</span><br></pre></td></tr></table></figure>
<p>注意<code>data_export</code>对应的目标包含一个空的.text段，然而<code>function_export</code>却有定义一些代码。如果我们反汇编就会看到：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">00000000 &lt;_function_export&gt;:</span><br><span class="line">   0:   ff 25 00 00 00 00       jmp    *0x0</span><br><span class="line">                        2: dir32        .idata$5</span><br><span class="line">   6:   90                      nop</span><br><span class="line">   7:   90                      nop</span><br></pre></td></tr></table></figure>
<p>类型<code>dir32</code>的重定位告诉链接器如何填写被<code>jmp</code>间接引用的地址。我们可以看到当进入<code>_function_export</code>时，会直接跳到从名为<code>.idata$5</code>的内存处读取的地址。通过彻底地检查<code>.idata</code>段，可以发现<code>.idata$5</code>对应的是导入地址表中<code>function_export</code>这个导入名称所对应的地址，于是就能找到加载的导入项<code>function_export</code>的绝对地址。</p>
<p>虽然只有function_export拥有一个对应的<code>_function_export</code>函数，但是以上的两个导入项在导入库中分别对应了一个符号，这个符号的名称带有__imp__前缀（<code>__imp__data_export</code>和<code>__imp__function_export</code>)。就像我们之前探讨过的那样，这个符号代表了一个内存地址，这个地址中存放的是的指向函数或变量的指针，这个指针值由动态链接器负责填写。</p>
<p>通过一个导入库，我们就可以写一个使用这些导出函数的代码，例如这个main1.c：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line"></span><br><span class="line">__declspec(dllimport) extern int function_export(void);</span><br><span class="line">__declspec(dllimport) extern int data_export;</span><br><span class="line"></span><br><span class="line">int main(int argc, char **argv) &#123;</span><br><span class="line">    printf(&quot;%d\n&quot;, function_export());</span><br><span class="line">    printf(&quot;%d\n&quot;, data_export);</span><br><span class="line"></span><br><span class="line">    data_export++;</span><br><span class="line"></span><br><span class="line">    printf(&quot;%d\n&quot;, function_export());</span><br><span class="line">    printf(&quot;%d\n&quot;, data_export);</span><br><span class="line"></span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>编译这段代码并连接导入库，我们就会得到我们期待的结果：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ gcc main1.c library.dll.a -o main1 &amp;&amp; ./main1</span><br><span class="line">1379</span><br><span class="line">42</span><br><span class="line">1380</span><br><span class="line">43</span><br></pre></td></tr></table></figure>
<p>之所以library.dll.a内没有定义data_export符号而这段代码仍能编译，是因为main.c文件中的data_export声明上的__declspec(dllimport)修饰符导致编译器生成了直接使用__imp_data_export符号的代码，反汇编的话我们就会看到：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ gcc -c main1.c -o main1.o &amp;&amp; objdump --disassemble -r main1.o</span><br><span class="line"></span><br><span class="line">main1.o:     file format pe-i386</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Disassembly of section .text:</span><br><span class="line"></span><br><span class="line">00000000 &lt;_main&gt;:</span><br><span class="line">   0:   8d 4c 24 04             lea    0x4(%esp),%ecx</span><br><span class="line">   4:   83 e4 f0                and    $0xfffffff0,%esp</span><br><span class="line">   7:   ff 71 fc                pushl  -0x4(%ecx)</span><br><span class="line">   a:   55                      push   %ebp</span><br><span class="line">   b:   89 e5                   mov    %esp,%ebp</span><br><span class="line">   d:   51                      push   %ecx</span><br><span class="line">   e:   83 ec 14                sub    $0x14,%esp</span><br><span class="line">  11:   e8 00 00 00 00          call   16 &lt;_main+0x16&gt;</span><br><span class="line">                        12: DISP32      ___main</span><br><span class="line">  16:   a1 00 00 00 00          mov    0x0,%eax</span><br><span class="line">                        17: dir32       __imp__function_export</span><br><span class="line">  1b:   ff d0                   call   *%eax</span><br><span class="line">  1d:   89 44 24 04             mov    %eax,0x4(%esp)</span><br><span class="line">  21:   c7 04 24 00 00 00 00    movl   $0x0,(%esp)</span><br><span class="line">                        24: dir32       .rdata</span><br><span class="line">  28:   e8 00 00 00 00          call   2d &lt;_main+0x2d&gt;</span><br><span class="line">                        29: DISP32      _printf</span><br><span class="line">  2d:   a1 00 00 00 00          mov    0x0,%eax</span><br><span class="line">                        2e: dir32       __imp__data_export</span><br><span class="line">  32:   8b 00                   mov    (%eax),%eax</span><br><span class="line">  34:   89 44 24 04             mov    %eax,0x4(%esp)</span><br><span class="line">  38:   c7 04 24 00 00 00 00    movl   $0x0,(%esp)</span><br><span class="line">                        3b: dir32       .rdata</span><br><span class="line">  3f:   e8 00 00 00 00          call   44 &lt;_main+0x44&gt;</span><br><span class="line">                        40: DISP32      _printf</span><br><span class="line">  44:   a1 00 00 00 00          mov    0x0,%eax</span><br><span class="line">                        45: dir32       __imp__data_export</span><br><span class="line">  49:   8b 00                   mov    (%eax),%eax</span><br><span class="line">  4b:   8d 50 01                lea    0x1(%eax),%edx</span><br><span class="line">  4e:   a1 00 00 00 00          mov    0x0,%eax</span><br><span class="line">                        4f: dir32       __imp__data_export</span><br><span class="line">  53:   89 10                   mov    %edx,(%eax)</span><br><span class="line">  55:   a1 00 00 00 00          mov    0x0,%eax</span><br><span class="line">                        56: dir32       __imp__function_export</span><br><span class="line">  5a:   ff d0                   call   *%eax</span><br><span class="line">  5c:   89 44 24 04             mov    %eax,0x4(%esp)</span><br><span class="line">  60:   c7 04 24 00 00 00 00    movl   $0x0,(%esp)</span><br><span class="line">                        63: dir32       .rdata</span><br><span class="line">  67:   e8 00 00 00 00          call   6c &lt;_main+0x6c&gt;</span><br><span class="line">                        68: DISP32      _printf</span><br><span class="line">  6c:   a1 00 00 00 00          mov    0x0,%eax</span><br><span class="line">                        6d: dir32       __imp__data_export</span><br><span class="line">  71:   8b 00                   mov    (%eax),%eax</span><br><span class="line">  73:   89 44 24 04             mov    %eax,0x4(%esp)</span><br><span class="line">  77:   c7 04 24 00 00 00 00    movl   $0x0,(%esp)</span><br><span class="line">                        7a: dir32       .rdata</span><br><span class="line">  7e:   e8 00 00 00 00          call   83 &lt;_main+0x83&gt;</span><br><span class="line">                        7f: DISP32      _printf</span><br><span class="line">  83:   b8 00 00 00 00          mov    $0x0,%eax</span><br><span class="line">  88:   83 c4 14                add    $0x14,%esp</span><br><span class="line">  8b:   59                      pop    %ecx</span><br><span class="line">  8c:   5d                      pop    %ebp</span><br><span class="line">  8d:   8d 61 fc                lea    -0x4(%ecx),%esp</span><br><span class="line">  90:   c3                      ret</span><br><span class="line">  91:   90                      nop</span><br><span class="line">  92:   90                      nop</span><br><span class="line">  93:   90                      nop</span><br></pre></td></tr></table></figure>
<p>实际上，我们可以看到生成的代码甚至都没有使用<code>_function_export</code>符号，取而代之的是使用了<code>imp__function_export</code>。本质上，导入库中的<code>_function_export</code>符号在每处使用的地方都已经被内联过了。这也就是为什么使用<code>__declspec(dllimport)</code>可以提高跨DLL调用的性能，不过这个修饰符在声明函数时不是必须写的。<br>
我们也许会好奇，如果在声明时去掉<code>__declspec(dllimport)</code>修饰符会发生什么事情。鉴于我们之前讨论的关于导入变量和导入函数之间的差别，你也许以为会链接失败。我们的测试文件main2.c是：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line"></span><br><span class="line">extern int function_export(void);</span><br><span class="line">extern int data_export;</span><br><span class="line"></span><br><span class="line">int main(int argc, char **argv) &#123;</span><br><span class="line">    printf(&quot;%d\n&quot;, function_export());</span><br><span class="line">    printf(&quot;%d\n&quot;, data_export);</span><br><span class="line"></span><br><span class="line">    data_export++;</span><br><span class="line"></span><br><span class="line">    printf(&quot;%d\n&quot;, function_export());</span><br><span class="line">    printf(&quot;%d\n&quot;, data_export);</span><br><span class="line"></span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>让我们来试一试：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ gcc main2.c library.dll.a -o main2 &amp;&amp; ./main2</span><br><span class="line">1379</span><br><span class="line">42</span><br><span class="line">1380</span><br><span class="line">43</span><br></pre></td></tr></table></figure>
<p>见鬼了！编译居然通过了？这有点令人惊讶。之所以导入库library.dll.a没有定义<code>_data_export</code>符号但这仍能编译通过，是由于GNU ld的一个叫做自动导入的有趣的特性。如果没有自动导入特性，链接器就会如我们所愿地报错：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ gcc main2.c library.dll.a -o main2 -Wl,--disable-auto-import &amp;&amp; ./main2</span><br><span class="line">/tmp/ccGd8Urx.o:main2.c:(.text+0x2c): undefined reference to `_data_export&#x27;</span><br><span class="line">/tmp/ccGd8Urx.o:main2.c:(.text+0x41): undefined reference to `_data_export&#x27;</span><br><span class="line">/tmp/ccGd8Urx.o:main2.c:(.text+0x49): undefined reference to `_data_export&#x27;</span><br><span class="line">/tmp/ccGd8Urx.o:main2.c:(.text+0x63): undefined reference to `_data_export&#x27;</span><br><span class="line">collect2: ld returned 1 exit status</span><br></pre></td></tr></table></figure>
<p>微软的链接器没有实现自动导入的特性，因此如果你用的是微软的工具链的话，你就会看到类似的错误信息。</p>
<p>然而，有一个方法可以使得在写代码时既不用依赖于自动导入的特定，也不用使用<code>__declspec(dllimport)</code>关键字。我们新的代码main3.c就是这么写的：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line"></span><br><span class="line">extern int (*_imp__function_export)(void);</span><br><span class="line">extern int *_imp__data_export;</span><br><span class="line"></span><br><span class="line">#define function_export (*_imp__function_export)</span><br><span class="line">#define data_export (*_imp__data_export)</span><br><span class="line"></span><br><span class="line">int main(int argc, char **argv) &#123;</span><br><span class="line">    printf(&quot;%d\n&quot;, function_export());</span><br><span class="line">    printf(&quot;%d\n&quot;, data_export);</span><br><span class="line"></span><br><span class="line">    data_export++;</span><br><span class="line"></span><br><span class="line">    printf(&quot;%d\n&quot;, function_export());</span><br><span class="line">    printf(&quot;%d\n&quot;, data_export);</span><br><span class="line"></span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在这段代码中，我们直接使用了源自导入库中的带<code>__imp__</code>前缀的符号。这些符号对应的是导入函数和导入变量的真实内存地址，就像代码中的预处理宏定义<code>data_export</code>和<code>function_export</code>所表示的那样。</p>
<p>即使没有自动编译特性，这段代码也能完美地编译通过：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ gcc main3.c library.dll.a -o main3 -Wl,--disable-auto-import &amp;&amp; ./main3</span><br><span class="line">1379</span><br><span class="line">42</span><br><span class="line">1380</span><br><span class="line">43</span><br></pre></td></tr></table></figure>
<p>如果你一直阅读到了这里，你应该已经对Windows上上DLL的导入和导出有了透彻的理解。</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/everything-you-never-wanted-to-know-about-dlls-cn/">http://xnerv.wang/everything-you-never-wanted-to-know-about-dlls-cn/</a></strong></p>
]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>Windows</tag>
        <tag>DLL</tag>
        <tag>译文</tag>
      </tags>
  </entry>
  <entry>
    <title>Everything You Never Wanted To Know About DLLs（转载）</title>
    <url>/everything-you-never-wanted-to-know-about-dlls/</url>
    <content><![CDATA[<p>For the chinese translated version, please click <em><strong><a href="/everything-you-never-wanted-to-know-about-dlls-cn/">关于DLL的一些你不会想要知道的知识</a></strong></em>.</p>
<hr>
<p>I’ve recently had cause to investigate how dynamic linking is implemented on Windows. This post is basically a brain dump of everything I’ve learnt on the issue. This is mostly for my future reference, but I hope it will be useful to others too as I’m going to bring together lots of information you would otherwise have to hunt around for.</p>
<p>Without further ado, here we go:</p>
<span id="more"></span>
<h2 id="Export-and-import-directories"><a class="header-anchor" href="#Export-and-import-directories"></a>Export and import directories</h2>
<p>The Windows executable loader is responsible for doing all dynamic loading and symbol resolution before running the code. The linker works out what functions are exported or imported by each image (an <em>image</em> is a DLL or EXE file) by inspecting the <code>.edata</code> and <code>.idata</code> sections of those images, respectively.</p>
<p>The contents of these sections is covered in detail by the <a href="https://msdn.microsoft.com/en-us/library/windows/desktop/ms680547.aspx">PE/COFF specification</a>.</p>
<h3 id="The-edata-section"><a class="header-anchor" href="#The-edata-section"></a>The <code>.edata</code> section</h3>
<p>This section records the exports of the image (yes, EXEs can export things). This takes the form of:</p>
<ul>
<li>
<p>The export address table: an array of length N holding the addresses of the exported functions/data (the addresses are stored relative to the image base). Indexes into this table are called ordinals.</p>
</li>
<li>
<p>The export name pointer table: an array of length M holding pointers to strings that represent the name of an export. This array is lexically ordered by name, to allow binary searches for a given export.</p>
</li>
<li>
<p>The export ordinal table: a parallel array of length M holding the ordinal of the corresponding name in the export name pointer table.</p>
</li>
</ul>
<p>(As an alternative to importing an image’s export by its name, it is possible to import by specifying an ordinal. Importing by ordinal is slightly faster at runtime because the dynamic linker doesn’t have to do a lookup. Furthermore, if the import is not given a name by the exporting DLL, importing by ordinal is the <strong>only</strong> way to do the import.)</p>
<p>How does the <code>.edata</code> section get created in the first place? There are two main methods:</p>
<ol>
<li>
<p>Most commonly, they start life in the object files created by compiling some source code that defines a function/some data that was declared with the <code>__declspec(dllimport)</code> modifier. The compiler just emits an appropriate <code>.edata</code> section naming these exports.</p>
</li>
<li>
<p>Less commonly, the programmer might <a href="https://msdn.microsoft.com/en-us/library/d91k01sh.aspx">write a .def file</a> specifying which functions they would like to export. By supplying this to <code>dlltool --output-exp</code>, an export file can be generated. An export file is just an object file which only contains a <code>.edata</code> section, exporting (via some unresolved references that will be filled in by the linker in the usual way) the symbols named in the .def file. This export library must be named by the programmer when he comes to link together his object files into a DLL.</p>
</li>
</ol>
<p>In both these cases, the linker collects the <code>.edata</code> sections from all objects named on the link line to build the <code>.edata</code> for the overall image file. One last possible way that the <code>.edata</code> can be created is by the linker itself, without having to put <code>.edata</code> into any object files:</p>
<ol start="3">
<li>The linker could choose to export all symbols defined by object files named on the link line. For example, this is the <a href="http://sourceware.org/binutils/docs/ld/WIN32.html">default behaviour of GNU ld</a> (the behaviour can also be explicitly asked for using <code>–-export-all-symbols</code>). In this case, the linker generates the <code>.edata</code> section itself. (GNU ld also supports specifying a .def file on the command line, in which case the generated section will export just those things named by the .def).</li>
</ol>
<h3 id="The-idata-section"><a class="header-anchor" href="#The-idata-section"></a>The <code>.idata</code> section</h3>
<p>The <code>.idata</code> section records those things that the image imports. It consists of:</p>
<ul>
<li>
<p>For every image from which symbols are imported:</p>
<ul>
<li>
<p>The filename of the image. Used by the dynamic linker to locate it on disk.</p>
</li>
<li>
<p>The import lookup table: an array of length N, which each entry is either an ordinal or a pointer to a string representing the name to import.</p>
</li>
<li>
<p>The import address table: an array of N pointers. The dynamic linker is responsible for filling out this array with the address of the function/data named by the corresponding symbol in the import lookup table.</p>
</li>
</ul>
</li>
</ul>
<p>The ways in which <code>.idata</code> entries are created are as follows:</p>
<ol>
<li>
<p>Most commonly, they originate in a library of object files called an <code>import library</code>. This <code>import library</code> can be created by usingdlltool on the DLL you wish to export or a .def file of the type we discussed earlier. Just like the export library, the import library must be named by the user on the link line.</p>
</li>
<li>
<p>Alternatively, some linkers (like GNU ld) let you specify a DLL directly on the link line. The linker will automatically generate <code>.idata</code> entries for any symbols that you must import from the DLL.</p>
</li>
</ol>
<p>Notice that unlike the case when we were exporting symbols, <code>__declspec(dllimport)</code> does not cause <code>.idata</code> sections to be generated.</p>
<p>Import libraries are a bit more complicated than they first appear. The Windows dynamic loader fills the import <strong>address</strong> table with the addresses of the imported symbols (say, the address of a function <code>Func</code>). However, when the assembly code in other object files says <code>call Func</code> they expect that <code>Func</code> to name the address of that code. But we don’t know that address until runtime: the only thing we know statically is the address <strong>where that address will be placed by the dynamic linker</strong>. We will call this address <code>__imp__Func</code>.</p>
<p>To deal with this extra level of indirection, the import library exports a function <code>Func</code> that just dereferences <code>__imp__Func</code> (to get the actual function pointer) and then <code>jmp</code>s to it. All of the other object files in the project can now say <code>call Func</code> just as they would if <code>Func</code> had been defined in some other object file, rather than a DLL. For this reason, saying <code>__declspec(dllimport)</code> in the declaration of a dynamically linked function is optional (though in fact you will get slightly more efficient code if you add them, as we will see later).</p>
<p>Unfortunately, there is no equivalent trick if you want to import data from another DLL. If we have some imported data <code>myData</code>, there is no way the import library can be defined so that a <code>mov $eax, myData</code> in an object file linked against it writes to the storage for <code>myData</code> in that DLL. Instead, the import library defines a symbol <code>__imp__myData</code> that resolves to the address at which the linked-in address of the storage can be found. The compiler then ensures that when you read or write from a <em>variable</em> defined with <code>__declspec(dllimport)</code> those reads and writes go through the <code>__imp_myData</code> indirection. Because different code needs to be generated at the use site, <code>__declspec</code> declarations on data imports are not optional.</p>
<h2 id="Practical-example"><a class="header-anchor" href="#Practical-example"></a>Practical example</h2>
<p>Theory is all very well but it can be helpful to see all the pieces in play.</p>
<h3 id="Building-a-DLL"><a class="header-anchor" href="#Building-a-DLL"></a>Building a DLL</h3>
<p>First, lets build a simple DLL exporting both functions and data. For maximum clarity, we’ll use an explicit export library rather instead of decorating our functions with <code>declspec(dllexport)</code> or supply a .def file to the linker.</p>
<p>First lets write the .def file, <code>library.def</code>:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">LIBRARY library</span><br><span class="line">EXPORTS</span><br><span class="line">   function_export</span><br><span class="line">   data_export      DATA</span><br></pre></td></tr></table></figure>
<p>(The <code>DATA</code> keyword and <code>LIBRARY</code> line only affects how the import library is generated, as explained later on. Ignore them for now.)</p>
<p>Build an export file from that:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ dlltool --output-exp library_exports.o -d library.def</span><br></pre></td></tr></table></figure>
<p>The resulting object basically just contains an <code>.edata</code> section that exports the symbols <code>_data_export</code> and <code>_function_export</code> under the names <code>data_export</code> and <code>function_export</code> respectively:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ objdump -xs library_exports.o</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">There is an export table in .edata at 0x0</span><br><span class="line"></span><br><span class="line">The Export Tables (interpreted .edata section contents)</span><br><span class="line"></span><br><span class="line">Export Flags                    0</span><br><span class="line">Time/Date stamp                 4e10e5c1</span><br><span class="line">Major/Minor                     0/0</span><br><span class="line">Name                            00000028 library_exports.o.dll</span><br><span class="line">Ordinal Base                    1</span><br><span class="line">Number in:</span><br><span class="line">        Export Address Table            00000002</span><br><span class="line">        [Name Pointer/Ordinal] Table    00000002</span><br><span class="line">Table Addresses</span><br><span class="line">        Export Address Table            00000040</span><br><span class="line">        Name Pointer Table              00000048</span><br><span class="line">        Ordinal Table                   00000050</span><br><span class="line"></span><br><span class="line">Export Address Table -- Ordinal Base 1</span><br><span class="line"></span><br><span class="line">[Ordinal/Name Pointer] Table</span><br><span class="line">        [   0] data_export</span><br><span class="line">        [   1] function_export</span><br><span class="line"></span><br><span class="line">Sections:</span><br><span class="line">Idx Name          Size      VMA       LMA       File off  Algn</span><br><span class="line">  0 .text         00000000  00000000  00000000  00000000  2**2</span><br><span class="line">                  ALLOC, LOAD, READONLY, CODE</span><br><span class="line">  1 .data         00000000  00000000  00000000  00000000  2**2</span><br><span class="line">                  ALLOC, LOAD, DATA</span><br><span class="line">  2 .bss          00000000  00000000  00000000  00000000  2**2</span><br><span class="line">                  ALLOC</span><br><span class="line">  3 .edata        00000070  00000000  00000000  000000b4  2**2</span><br><span class="line">                  CONTENTS, ALLOC, LOAD, RELOC, READONLY, DATA</span><br><span class="line">SYMBOL TABLE:</span><br><span class="line">[  0](sec -2)(fl 0x00)(ty   0)(scl 103) (nx 1) 0x00000000 fake</span><br><span class="line">File</span><br><span class="line">[  2](sec  4)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000028 name</span><br><span class="line">[  3](sec  4)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000040 afuncs</span><br><span class="line">[  4](sec  4)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000048 anames</span><br><span class="line">[  5](sec  4)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000050 anords</span><br><span class="line">[  6](sec  4)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000054 n1</span><br><span class="line">[  7](sec  4)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000060 n2</span><br><span class="line">[  8](sec  1)(fl 0x00)(ty   0)(scl   3) (nx 1) 0x00000000 .text</span><br><span class="line">AUX scnlen 0x0 nreloc 0 nlnno 0</span><br><span class="line">[ 10](sec  2)(fl 0x00)(ty   0)(scl   3) (nx 1) 0x00000000 .data</span><br><span class="line">AUX scnlen 0x0 nreloc 0 nlnno 0</span><br><span class="line">[ 12](sec  3)(fl 0x00)(ty   0)(scl   3) (nx 1) 0x00000000 .bss</span><br><span class="line">AUX scnlen 0x0 nreloc 0 nlnno 0</span><br><span class="line">[ 14](sec  4)(fl 0x00)(ty   0)(scl   3) (nx 1) 0x00000000 .edata</span><br><span class="line">AUX scnlen 0x70 nreloc 8 nlnno 0</span><br><span class="line">[ 16](sec  0)(fl 0x00)(ty   0)(scl   2) (nx 0) 0x00000000 _data_export</span><br><span class="line">[ 17](sec  0)(fl 0x00)(ty   0)(scl   2) (nx 0) 0x00000000 _function_export</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">RELOCATION RECORDS FOR [.edata]:</span><br><span class="line">OFFSET   TYPE              VALUE</span><br><span class="line">0000000c rva32             .edata</span><br><span class="line">0000001c rva32             .edata</span><br><span class="line">00000020 rva32             .edata</span><br><span class="line">00000024 rva32             .edata</span><br><span class="line">00000040 rva32             _data_export</span><br><span class="line">00000044 rva32             _function_export</span><br><span class="line">00000048 rva32             .edata</span><br><span class="line">0000004c rva32             .edata</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Contents of section .edata:</span><br><span class="line"> 0000 00000000 c1e5104e 00000000 28000000  .......N....(...</span><br><span class="line"> 0010 01000000 02000000 02000000 40000000  ............@...</span><br><span class="line"> 0020 48000000 50000000 6c696272 6172795f  H...P...library_</span><br><span class="line"> 0030 6578706f 7274732e 6f2e646c 6c000000  exports.o.dll...</span><br><span class="line"> 0040 00000000 00000000 54000000 60000000  ........T...`...</span><br><span class="line"> 0050 00000100 64617461 5f657870 6f727400  ....data_export.</span><br><span class="line"> 0060 66756e63 74696f6e 5f657870 6f727400  function_export.</span><br></pre></td></tr></table></figure>
<p>We’ll fulfil these symbol with a trivial implementation of the DLL, <code>library.c</code>:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> data_export = <span class="number">42</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">function_export</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1337</span> + data_export;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>We can put it together into a DLL:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ gcc -shared -o library.dll library.c library_exports.o</span><br></pre></td></tr></table></figure>
<p>The export table for the DLL is as follows, showing that we have exported what we wanted:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">The Export Tables (interpreted .edata section contents)</span><br><span class="line"></span><br><span class="line">Export Flags                    0</span><br><span class="line">Time/Date stamp                 4e10e5c1</span><br><span class="line">Major/Minor                     0/0</span><br><span class="line">Name                            00005028 library_exports.o.dll</span><br><span class="line">Ordinal Base                    1</span><br><span class="line">Number in:</span><br><span class="line">        Export Address Table            00000002</span><br><span class="line">        [Name Pointer/Ordinal] Table    00000002</span><br><span class="line">Table Addresses</span><br><span class="line">        Export Address Table            00005040</span><br><span class="line">        Name Pointer Table              00005048</span><br><span class="line">        Ordinal Table                   00005050</span><br><span class="line"></span><br><span class="line">Export Address Table -- Ordinal Base 1</span><br><span class="line">        [   0] +base[   1] 200c Export RVA</span><br><span class="line">        [   1] +base[   2] 10f0 Export RVA</span><br><span class="line"></span><br><span class="line">[Ordinal/Name Pointer] Table</span><br><span class="line">        [   0] data_export</span><br><span class="line">        [   1] function_export</span><br></pre></td></tr></table></figure>
<h3 id="Using-the-DLL"><a class="header-anchor" href="#Using-the-DLL"></a>Using the DLL</h3>
<p>When we come to look at using the DLL, things become a lot more interesting. First, we need an import library:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ dlltool --output-lib library.dll.a -d library.def</span><br></pre></td></tr></table></figure>
<p>(The reason that we have an import <strong>library</strong> but an export <strong>object</strong> is because using a library for the imports allows the linker to discard <code>.idata</code> for any imports that are not used. Contrariwise ,he linker can never discard any <code>.edata</code> entry because any export may potentially be used by a user of the DLL).</p>
<p>This import library is rather complex. It contains one object for each export (<code>disds00000.o</code> and <code>disds00001.o</code>) but also two other object files (<code>distdt.o</code> and <code>disdh.o</code>) that set up the header and footer of the import list. (The header of the import list contains, among other things, the name of the DLL to link in at runtime, as derived from the <code>LIBRARY</code> line of the .def file.)</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ objdump -xs library.dll.a</span><br><span class="line">In archive library.dll.a:</span><br><span class="line"></span><br><span class="line">disdt.o:     file format pe-i386</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">Sections:</span><br><span class="line">Idx Name          Size      VMA       LMA       File off  Algn</span><br><span class="line">  0 .text         00000000  00000000  00000000  00000000  2**2</span><br><span class="line">                  ALLOC, LOAD, READONLY, CODE</span><br><span class="line">  1 .data         00000000  00000000  00000000  00000000  2**2</span><br><span class="line">                  ALLOC, LOAD, DATA</span><br><span class="line">  2 .bss          00000000  00000000  00000000  00000000  2**2</span><br><span class="line">                  ALLOC</span><br><span class="line">  3 .idata$4      00000004  00000000  00000000  00000104  2**2</span><br><span class="line">                  CONTENTS, ALLOC, LOAD, DATA</span><br><span class="line">  4 .idata$5      00000004  00000000  00000000  00000108  2**2</span><br><span class="line">                  CONTENTS, ALLOC, LOAD, DATA</span><br><span class="line">  5 .idata$7      0000000c  00000000  00000000  0000010c  2**2</span><br><span class="line">                  CONTENTS, ALLOC, LOAD, DATA</span><br><span class="line">SYMBOL TABLE:</span><br><span class="line">[  0](sec -2)(fl 0x00)(ty   0)(scl 103) (nx 1) 0x00000000 fake</span><br><span class="line">File</span><br><span class="line">[  2](sec  1)(fl 0x00)(ty   0)(scl   3) (nx 1) 0x00000000 .text</span><br><span class="line">AUX scnlen 0x0 nreloc 0 nlnno 0</span><br><span class="line">[  4](sec  2)(fl 0x00)(ty   0)(scl   3) (nx 1) 0x00000000 .data</span><br><span class="line">AUX scnlen 0x0 nreloc 0 nlnno 0</span><br><span class="line">[  6](sec  3)(fl 0x00)(ty   0)(scl   3) (nx 1) 0x00000000 .bss</span><br><span class="line">AUX scnlen 0x0 nreloc 0 nlnno 0</span><br><span class="line">[  8](sec  4)(fl 0x00)(ty   0)(scl   3) (nx 1) 0x00000000 .idata$4</span><br><span class="line">AUX scnlen 0x4 nreloc 0 nlnno 0</span><br><span class="line">[ 10](sec  5)(fl 0x00)(ty   0)(scl   3) (nx 1) 0x00000000 .idata$5</span><br><span class="line">AUX scnlen 0x4 nreloc 0 nlnno 0</span><br><span class="line">[ 12](sec  6)(fl 0x00)(ty   0)(scl   3) (nx 1) 0x00000000 .idata$7</span><br><span class="line">AUX scnlen 0x7 nreloc 0 nlnno 0</span><br><span class="line">[ 14](sec  6)(fl 0x00)(ty   0)(scl   2) (nx 0) 0x00000000 __library_dll_a_iname</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Contents of section .idata$4:</span><br><span class="line"> 0000 00000000                             ....</span><br><span class="line">Contents of section .idata$5:</span><br><span class="line"> 0000 00000000                             ....</span><br><span class="line">Contents of section .idata$7:</span><br><span class="line"> 0000 6c696272 6172792e 646c6c00           library.dll.</span><br><span class="line"></span><br><span class="line">disdh.o:     file format pe-i386</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">Sections:</span><br><span class="line">Idx Name          Size      VMA       LMA       File off  Algn</span><br><span class="line">  0 .text         00000000  00000000  00000000  00000000  2**2</span><br><span class="line">                  ALLOC, LOAD, READONLY, CODE</span><br><span class="line">  1 .data         00000000  00000000  00000000  00000000  2**2</span><br><span class="line">                  ALLOC, LOAD, DATA</span><br><span class="line">  2 .bss          00000000  00000000  00000000  00000000  2**2</span><br><span class="line">                  ALLOC</span><br><span class="line">  3 .idata$2      00000014  00000000  00000000  00000104  2**2</span><br><span class="line">                  CONTENTS, ALLOC, LOAD, RELOC, DATA</span><br><span class="line">  4 .idata$5      00000000  00000000  00000000  00000000  2**2</span><br><span class="line">                  ALLOC, LOAD, DATA</span><br><span class="line">  5 .idata$4      00000000  00000000  00000000  00000000  2**2</span><br><span class="line">                  ALLOC, LOAD, DATA</span><br><span class="line">SYMBOL TABLE:</span><br><span class="line">[  0](sec -2)(fl 0x00)(ty   0)(scl 103) (nx 1) 0x00000000 fake</span><br><span class="line">File</span><br><span class="line">[  2](sec  6)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000000 hname</span><br><span class="line">[  3](sec  5)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000000 fthunk</span><br><span class="line">[  4](sec  1)(fl 0x00)(ty   0)(scl   3) (nx 1) 0x00000000 .text</span><br><span class="line">AUX scnlen 0x0 nreloc 0 nlnno 0</span><br><span class="line">[  6](sec  2)(fl 0x00)(ty   0)(scl   3) (nx 1) 0x00000000 .data</span><br><span class="line">AUX scnlen 0x0 nreloc 0 nlnno 0</span><br><span class="line">[  8](sec  3)(fl 0x00)(ty   0)(scl   3) (nx 1) 0x00000000 .bss</span><br><span class="line">AUX scnlen 0x0 nreloc 0 nlnno 0</span><br><span class="line">[ 10](sec  4)(fl 0x00)(ty   0)(scl   3) (nx 1) 0x00000000 .idata$2</span><br><span class="line">AUX scnlen 0x14 nreloc 3 nlnno 0</span><br><span class="line">[ 12](sec  6)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000000 .idata$4</span><br><span class="line">[ 13](sec  5)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000000 .idata$5</span><br><span class="line">[ 14](sec  4)(fl 0x00)(ty   0)(scl   2) (nx 0) 0x00000000 __head_library_dll_a</span><br><span class="line">[ 15](sec  0)(fl 0x00)(ty   0)(scl   2) (nx 0) 0x00000000 __library_dll_a_iname</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">RELOCATION RECORDS FOR [.idata$2]:</span><br><span class="line">OFFSET   TYPE              VALUE</span><br><span class="line">00000000 rva32             .idata$4</span><br><span class="line">0000000c rva32             __library_dll_a_iname</span><br><span class="line">00000010 rva32             .idata$5</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Contents of section .idata$2:</span><br><span class="line"> 0000 00000000 00000000 00000000 00000000  ................</span><br><span class="line"> 0010 00000000                             ....</span><br><span class="line"></span><br><span class="line">disds00001.o:     file format pe-i386</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">Sections:</span><br><span class="line">Idx Name          Size      VMA       LMA       File off  Algn</span><br><span class="line">  0 .text         00000008  00000000  00000000  0000012c  2**2</span><br><span class="line">                  CONTENTS, ALLOC, LOAD, RELOC, READONLY, CODE</span><br><span class="line">  1 .data         00000000  00000000  00000000  00000000  2**2</span><br><span class="line">                  ALLOC, LOAD, DATA</span><br><span class="line">  2 .bss          00000000  00000000  00000000  00000000  2**2</span><br><span class="line">                  ALLOC</span><br><span class="line">  3 .idata$7      00000004  00000000  00000000  00000134  2**2</span><br><span class="line">                  CONTENTS, RELOC</span><br><span class="line">  4 .idata$5      00000004  00000000  00000000  00000138  2**2</span><br><span class="line">                  CONTENTS, RELOC</span><br><span class="line">  5 .idata$4      00000004  00000000  00000000  0000013c  2**2</span><br><span class="line">                  CONTENTS, RELOC</span><br><span class="line">  6 .idata$6      00000012  00000000  00000000  00000140  2**1</span><br><span class="line">                  CONTENTS</span><br><span class="line">SYMBOL TABLE:</span><br><span class="line">[  0](sec  1)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000000 .text</span><br><span class="line">[  1](sec  2)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000000 .data</span><br><span class="line">[  2](sec  3)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000000 .bss</span><br><span class="line">[  3](sec  4)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000000 .idata$7</span><br><span class="line">[  4](sec  5)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000000 .idata$5</span><br><span class="line">[  5](sec  6)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000000 .idata$4</span><br><span class="line">[  6](sec  7)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000000 .idata$6</span><br><span class="line">[  7](sec  1)(fl 0x00)(ty   0)(scl   2) (nx 0) 0x00000000 _function_export</span><br><span class="line">[  8](sec  5)(fl 0x00)(ty   0)(scl   2) (nx 0) 0x00000000 __imp__function_export</span><br><span class="line">[  9](sec  0)(fl 0x00)(ty   0)(scl   2) (nx 0) 0x00000000 __head_library_dll_a</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">RELOCATION RECORDS FOR [.text]:</span><br><span class="line">OFFSET   TYPE              VALUE</span><br><span class="line">00000002 dir32             .idata$5</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">RELOCATION RECORDS FOR [.idata$7]:</span><br><span class="line">OFFSET   TYPE              VALUE</span><br><span class="line">00000000 rva32             __head_library_dll_a</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">RELOCATION RECORDS FOR [.idata$5]:</span><br><span class="line">OFFSET   TYPE              VALUE</span><br><span class="line">00000000 rva32             .idata$6</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">RELOCATION RECORDS FOR [.idata$4]:</span><br><span class="line">OFFSET   TYPE              VALUE</span><br><span class="line">00000000 rva32             .idata$6</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Contents of section .text:</span><br><span class="line"> 0000 ff250000 00009090                    .%......</span><br><span class="line">Contents of section .idata$7:</span><br><span class="line"> 0000 00000000                             ....</span><br><span class="line">Contents of section .idata$5:</span><br><span class="line"> 0000 00000000                             ....</span><br><span class="line">Contents of section .idata$4:</span><br><span class="line"> 0000 00000000                             ....</span><br><span class="line">Contents of section .idata$6:</span><br><span class="line"> 0000 01006675 6e637469 6f6e5f65 78706f72  ..function_expor</span><br><span class="line"> 0010 7400                                 t.</span><br><span class="line"></span><br><span class="line">disds00000.o:     file format pe-i386</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">Sections:</span><br><span class="line">Idx Name          Size      VMA       LMA       File off  Algn</span><br><span class="line">  0 .text         00000000  00000000  00000000  00000000  2**2</span><br><span class="line">                  ALLOC, LOAD, READONLY, CODE</span><br><span class="line">  1 .data         00000000  00000000  00000000  00000000  2**2</span><br><span class="line">                  ALLOC, LOAD, DATA</span><br><span class="line">  2 .bss          00000000  00000000  00000000  00000000  2**2</span><br><span class="line">                  ALLOC</span><br><span class="line">  3 .idata$7      00000004  00000000  00000000  0000012c  2**2</span><br><span class="line">                  CONTENTS, RELOC</span><br><span class="line">  4 .idata$5      00000004  00000000  00000000  00000130  2**2</span><br><span class="line">                  CONTENTS, RELOC</span><br><span class="line">  5 .idata$4      00000004  00000000  00000000  00000134  2**2</span><br><span class="line">                  CONTENTS, RELOC</span><br><span class="line">  6 .idata$6      0000000e  00000000  00000000  00000138  2**1</span><br><span class="line">                  CONTENTS</span><br><span class="line">SYMBOL TABLE:</span><br><span class="line">[  0](sec  1)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000000 .text</span><br><span class="line">[  1](sec  2)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000000 .data</span><br><span class="line">[  2](sec  3)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000000 .bss</span><br><span class="line">[  3](sec  4)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000000 .idata$7</span><br><span class="line">[  4](sec  5)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000000 .idata$5</span><br><span class="line">[  5](sec  6)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000000 .idata$4</span><br><span class="line">[  6](sec  7)(fl 0x00)(ty   0)(scl   3) (nx 0) 0x00000000 .idata$6</span><br><span class="line">[  7](sec  5)(fl 0x00)(ty   0)(scl   2) (nx 0) 0x00000000 __imp__data_export</span><br><span class="line">[  8](sec  0)(fl 0x00)(ty   0)(scl   2) (nx 0) 0x00000000 __head_library_dll_a</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">RELOCATION RECORDS FOR [.idata$7]:</span><br><span class="line">OFFSET   TYPE              VALUE</span><br><span class="line">00000000 rva32             __head_library_dll_a</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">RELOCATION RECORDS FOR [.idata$5]:</span><br><span class="line">OFFSET   TYPE              VALUE</span><br><span class="line">00000000 rva32             .idata$6</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">RELOCATION RECORDS FOR [.idata$4]:</span><br><span class="line">OFFSET   TYPE              VALUE</span><br><span class="line">00000000 rva32             .idata$6</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Contents of section .idata$7:</span><br><span class="line"> 0000 00000000                             ....</span><br><span class="line">Contents of section .idata$5:</span><br><span class="line"> 0000 00000000                             ....</span><br><span class="line">Contents of section .idata$4:</span><br><span class="line"> 0000 00000000                             ....</span><br><span class="line">Contents of section .idata$6:</span><br><span class="line"> 0000 00006461 74615f65 78706f72 7400      ..data_export.</span><br></pre></td></tr></table></figure>
<p>Note that the object corresponding to <code>data_export</code> has an empty <code>.text</code> section, whereas <code>function_export</code> does define some code. If we disassemble it we get this:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">00000000 &lt;_function_export&gt;:</span><br><span class="line">   0:   ff 25 00 00 00 00       jmp    *0x0</span><br><span class="line">                        2: dir32        .idata$5</span><br><span class="line">   6:   90                      nop</span><br><span class="line">   7:   90                      nop</span><br></pre></td></tr></table></figure>
<p>The relocation of type <code>dir32</code> tells the linker how to fill in the address being dereferenced by the <code>jmp</code>. We can see that <code>_function_export</code>, when entered, will jump directly to the function at the address loaded from the memory named <code>.idata$5</code>. Inspection of the complete <code>.idata</code> section satisfies us that <code>.idata$5</code> corresponds to the address of the fragment of the import address table corresponding to the <code>function_export</code> import name, and hence the address where the absolute address of the loaded <code>function_export</code> import can be found.</p>
<p>Although only <code>function_export</code> gets a corresponding <code>_function_export</code> function, both of the exports have lead to a symbol with the <code>__imp__</code> prefix (<code>__imp__data_export</code> and <code>__imp__function_export</code>) being defined in the import library. As discussed before, this symbol stands for the address at which the pointer to the data/function will be inserted by the dynamic linker. As such, the <code>__imp__</code> symbols always point directly into the import address table.</p>
<p>With an import library in hand, we are capable of writing some client code that uses our exports, <code>main1.c</code>:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line"></span><br><span class="line">__declspec(dllimport) extern int function_export(void);</span><br><span class="line">__declspec(dllimport) extern int data_export;</span><br><span class="line"></span><br><span class="line">int main(int argc, char **argv) &#123;</span><br><span class="line">    printf(&quot;%d\n&quot;, function_export());</span><br><span class="line">    printf(&quot;%d\n&quot;, data_export);</span><br><span class="line"></span><br><span class="line">    data_export++;</span><br><span class="line"></span><br><span class="line">    printf(&quot;%d\n&quot;, function_export());</span><br><span class="line">    printf(&quot;%d\n&quot;, data_export);</span><br><span class="line"></span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Build and link it against the import library and we will get the results we expect:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ gcc main1.c library.dll.a -o main1 &amp;&amp; ./main1</span><br><span class="line">1379</span><br><span class="line">42</span><br><span class="line">1380</span><br><span class="line">43</span><br></pre></td></tr></table></figure>
<p>The reason that this works even though there is no <code>data_export</code> symbol defined by <code>library.dll.a</code> is because the <code>__declspec(dllimport)</code> qualifier on our <code>data_export</code> declaration in <code>main.c</code> has caused the compiled to generate code that uses the <code>__imp_data_export</code> symbol directly, as we can see if we disassemble the generated code:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ gcc -c main1.c -o main1.o &amp;&amp; objdump --disassemble -r main1.o</span><br><span class="line"></span><br><span class="line">main1.o:     file format pe-i386</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Disassembly of section .text:</span><br><span class="line"></span><br><span class="line">00000000 &lt;_main&gt;:</span><br><span class="line">   0:   8d 4c 24 04             lea    0x4(%esp),%ecx</span><br><span class="line">   4:   83 e4 f0                and    $0xfffffff0,%esp</span><br><span class="line">   7:   ff 71 fc                pushl  -0x4(%ecx)</span><br><span class="line">   a:   55                      push   %ebp</span><br><span class="line">   b:   89 e5                   mov    %esp,%ebp</span><br><span class="line">   d:   51                      push   %ecx</span><br><span class="line">   e:   83 ec 14                sub    $0x14,%esp</span><br><span class="line">  11:   e8 00 00 00 00          call   16 &lt;_main+0x16&gt;</span><br><span class="line">                        12: DISP32      ___main</span><br><span class="line">  16:   a1 00 00 00 00          mov    0x0,%eax</span><br><span class="line">                        17: dir32       __imp__function_export</span><br><span class="line">  1b:   ff d0                   call   *%eax</span><br><span class="line">  1d:   89 44 24 04             mov    %eax,0x4(%esp)</span><br><span class="line">  21:   c7 04 24 00 00 00 00    movl   $0x0,(%esp)</span><br><span class="line">                        24: dir32       .rdata</span><br><span class="line">  28:   e8 00 00 00 00          call   2d &lt;_main+0x2d&gt;</span><br><span class="line">                        29: DISP32      _printf</span><br><span class="line">  2d:   a1 00 00 00 00          mov    0x0,%eax</span><br><span class="line">                        2e: dir32       __imp__data_export</span><br><span class="line">  32:   8b 00                   mov    (%eax),%eax</span><br><span class="line">  34:   89 44 24 04             mov    %eax,0x4(%esp)</span><br><span class="line">  38:   c7 04 24 00 00 00 00    movl   $0x0,(%esp)</span><br><span class="line">                        3b: dir32       .rdata</span><br><span class="line">  3f:   e8 00 00 00 00          call   44 &lt;_main+0x44&gt;</span><br><span class="line">                        40: DISP32      _printf</span><br><span class="line">  44:   a1 00 00 00 00          mov    0x0,%eax</span><br><span class="line">                        45: dir32       __imp__data_export</span><br><span class="line">  49:   8b 00                   mov    (%eax),%eax</span><br><span class="line">  4b:   8d 50 01                lea    0x1(%eax),%edx</span><br><span class="line">  4e:   a1 00 00 00 00          mov    0x0,%eax</span><br><span class="line">                        4f: dir32       __imp__data_export</span><br><span class="line">  53:   89 10                   mov    %edx,(%eax)</span><br><span class="line">  55:   a1 00 00 00 00          mov    0x0,%eax</span><br><span class="line">                        56: dir32       __imp__function_export</span><br><span class="line">  5a:   ff d0                   call   *%eax</span><br><span class="line">  5c:   89 44 24 04             mov    %eax,0x4(%esp)</span><br><span class="line">  60:   c7 04 24 00 00 00 00    movl   $0x0,(%esp)</span><br><span class="line">                        63: dir32       .rdata</span><br><span class="line">  67:   e8 00 00 00 00          call   6c &lt;_main+0x6c&gt;</span><br><span class="line">                        68: DISP32      _printf</span><br><span class="line">  6c:   a1 00 00 00 00          mov    0x0,%eax</span><br><span class="line">                        6d: dir32       __imp__data_export</span><br><span class="line">  71:   8b 00                   mov    (%eax),%eax</span><br><span class="line">  73:   89 44 24 04             mov    %eax,0x4(%esp)</span><br><span class="line">  77:   c7 04 24 00 00 00 00    movl   $0x0,(%esp)</span><br><span class="line">                        7a: dir32       .rdata</span><br><span class="line">  7e:   e8 00 00 00 00          call   83 &lt;_main+0x83&gt;</span><br><span class="line">                        7f: DISP32      _printf</span><br><span class="line">  83:   b8 00 00 00 00          mov    $0x0,%eax</span><br><span class="line">  88:   83 c4 14                add    $0x14,%esp</span><br><span class="line">  8b:   59                      pop    %ecx</span><br><span class="line">  8c:   5d                      pop    %ebp</span><br><span class="line">  8d:   8d 61 fc                lea    -0x4(%ecx),%esp</span><br><span class="line">  90:   c3                      ret</span><br><span class="line">  91:   90                      nop</span><br><span class="line">  92:   90                      nop</span><br><span class="line">  93:   90                      nop</span><br></pre></td></tr></table></figure>
<p>In fact, we can see that the generated code doesn’t even use the <code>_function_export</code> symbol, preferring <code>__imp__function_export</code>. Essentially, the code of the <code>_function_export</code> symbol in the import library has been inlined at every use site. This is why using <code>__declspec(dllimport)</code> can improve performance of cross-DLL calls, even though it is entirely optional on function declarations.</p>
<p>We might wonder what happens if we drop the <code>__declspec(dllimport)</code> qualifier on our declarations. Because of our discussion about the difference between data and function imports earlier, you might expect linking to fail. Our test file, <code>main2.c</code> is:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">extern</span> <span class="type">int</span> <span class="title function_">function_export</span><span class="params">(<span class="type">void</span>)</span>;</span><br><span class="line"><span class="keyword">extern</span> <span class="type">int</span> data_export;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> **argv)</span> &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>, function_export());</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>, data_export);</span><br><span class="line"></span><br><span class="line">    data_export++;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>, function_export());</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>, data_export);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Let’s try it out:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ gcc main2.c library.dll.a -o main2 &amp;&amp; ./main2</span><br><span class="line">1379</span><br><span class="line">42</span><br><span class="line">1380</span><br><span class="line">43</span><br></pre></td></tr></table></figure>
<p>What the hell – it worked? This is a bit uprising. The reason that it works despite the fact that the import library <code>library.dll.a</code> not defining the <code>_data_export</code> symbol is because of a nifty feature of GNU ld called auto-import. Without auto-import the link fails as we would expect:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ gcc main2.c library.dll.a -o main2 -Wl,--disable-auto-import &amp;&amp; ./main2</span><br><span class="line">/tmp/ccGd8Urx.o:main2.c:(.text+0x2c): undefined reference to `_data_export&#x27;</span><br><span class="line">/tmp/ccGd8Urx.o:main2.c:(.text+0x41): undefined reference to `_data_export&#x27;</span><br><span class="line">/tmp/ccGd8Urx.o:main2.c:(.text+0x49): undefined reference to `_data_export&#x27;</span><br><span class="line">/tmp/ccGd8Urx.o:main2.c:(.text+0x63): undefined reference to `_data_export&#x27;</span><br><span class="line">collect2: ld returned 1 exit status</span><br></pre></td></tr></table></figure>
<p>The Microsoft linker does not implement auto-import, so this is the error you would get if you were using the Microsoft toolchain.</p>
<p>However, there is a way to write client code that does not depend on auto-import or use the <code>__declspec(dllimport)</code> keyword. Our new client, <code>main3.c</code> is as follows:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line"></span><br><span class="line">extern int (*_imp__function_export)(void);</span><br><span class="line">extern int *_imp__data_export;</span><br><span class="line"></span><br><span class="line">#define function_export (*_imp__function_export)</span><br><span class="line">#define data_export (*_imp__data_export)</span><br><span class="line"></span><br><span class="line">int main(int argc, char **argv) &#123;</span><br><span class="line">    printf(&quot;%d\n&quot;, function_export());</span><br><span class="line">    printf(&quot;%d\n&quot;, data_export);</span><br><span class="line"></span><br><span class="line">    data_export++;</span><br><span class="line"></span><br><span class="line">    printf(&quot;%d\n&quot;, function_export());</span><br><span class="line">    printf(&quot;%d\n&quot;, data_export);</span><br><span class="line"></span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>In this code, we directly use the <code>__imp__</code>-prefixed symbols from the import library. These name an address at which the real address of the import can be found, which is reflected by our C-preprocessor definitions of <code>data_export</code> and <code>function_export</code>.</p>
<p>This code compiles perfectly even without auto-import:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ gcc main3.c library.dll.a -o main3 -Wl,--disable-auto-import &amp;&amp; ./main3</span><br><span class="line">1379</span><br><span class="line">42</span><br><span class="line">1380</span><br><span class="line">43</span><br></pre></td></tr></table></figure>
<p>If you have followed along until this point you should have a solid understanding of how DLL import and export are implemented on Windows.</p>
<h2 id="How-auto-import-works"><a class="header-anchor" href="#How-auto-import-works"></a>How auto-import works</h2>
<p>As a bonus, I’m going to explain how auto-import is implemented by the GNU linker. It is a rather cute hack you may get a kick out of.</p>
<p>As a reminder, auto-import is a feature of the linker that allows the programmer to declare an item of DLL-imported data with a simple <code>extern</code> keyword, without having to explicitly use <code>__declspec(dllimport)</code>. This is extremely convenient because this is exactly how most <em>_nix</em> source code declares symbols it expects to import from a shared library, so by supporting this use case that_nix code becomes more portable to Windows.</p>
<p>Auto-import kicks in whenever the linker finds an object file making use of a symbol <code>foo</code> which is not defined by any other object in the link, but where a symbol <code>__imp_foo</code> <strong>is</strong> defined by some object. In this case, it assumes that the use of <code>foo</code> is an attempt to access some DLL-imported data item called <code>foo</code>.</p>
<p>Now, the problem is that the linker needs to replace the use of <code>foo</code> with the address of <code>foo</code> itself. However, all we seem to know statically is an address where that address will be placed at runtime (<code>__imp_foo</code>). To square the circle, the linker plays a clever trick.</p>
<p>The trick is to extend the <code>.idata</code> of the image being created with an entry for a “new” DLL. The new entry is set up as follows:</p>
<ul>
<li>
<p>The filename of the image being imported is set to the same filename as the <code>.idata</code> entry covering <code>__imp_foo</code>. So if <code>__imp_foo</code> was being filled out by an address in <code>Bar.dll</code>, our new <code>.idata</code> entry will use <code>Bar.dll</code> here.</p>
</li>
<li>
<p>The import lookup table is of length 1, whose sole entry is a pointer to the name of the imported symbol corresponding to <code>__imp_foo</code>. So if <code>__imp_foo</code> is filled out by the address of the <code>foo</code> export from <code>Bar.dll</code>, the name of the symbol we put in here will be <code>foo</code>.</p>
</li>
<li>
<p>The import address table is of length 1 – and here is the clever bit – <strong>is located precisely at the location in the object file that was referring to the (undefined) symbol</strong> <code>foo</code>.</p>
</li>
</ul>
<p>This solution neatly defers the task of filling out the address that the object file wants to the dynamic linker. The reason that the linker can play this trick is that it can see all of the object code that goes into the final image, and can thus fix all of the sites that need to refer to the imported data.</p>
<p>Note that in general the final image’s <code>.idata</code> will contain several entries for the same DLL: one from the import library, and one for every place in any object file in the link which referred to some data exported by the DLL. Although this is somewhat unusual behaviour, the Windows linker has no problem with there being several imports of the same DLL.</p>
<h3 id="A-wrinkle"><a class="header-anchor" href="#A-wrinkle"></a>A wrinkle</h3>
<p>Unfortunately, the scheme described above only works if the object code has an undefined reference to <code>foo</code> itself. What if instead it has a reference to <code>foo+N</code>, an address N bytes after the address of <code>foo</code> itself? There is no way to set up the <code>.idata</code> so that the dynamic linker adds a constant to the address it fills in, so we seem to be stuck.</p>
<p>Alas, such relocations are reasonably common, and originate from code that accesses a field of a DLL-imported structure type. Cygwin actually contains another hack to make auto-import work in such cases, known as “pseudo-relocations”. If you want to know the details of how these works, there is more information in the <a href="http://www.cygwin.com/ml/cygwin-apps/2002-06/msg00276.html">original thread on the topic</a>.</p>
<h2 id="Conclusion"><a class="header-anchor" href="#Conclusion"></a>Conclusion</h2>
<p>Dynamic linking on Windows is hairier than it at first appears. I hope this article has gone some way to clearing up the meaning of the mysterious <code>dllimport</code> and <code>dllexport</code> keywords, and at clarifying the role of the import and export libraries.</p>
<p>Linux and friends implement dynamic linking in a totally different manner to Windows. The scheme they use is more flexible and allows more in-memory sharing of code, but incurs a significant runtime penalty (especially on i386). For more details see <a href="http://www.greyhat.ch/lab/downloads/pic.html">here</a> and <a href="http://www.skyfree.org/linux/references/ELF_Format.pdf">the Dynamic Linking section of the the ELF spec</a>.</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/everything-you-never-wanted-to-know-about-dlls/">http://xnerv.wang/everything-you-never-wanted-to-know-about-dlls/</a></strong><br>
转载自：<a href="http://blog.omega-prime.co.uk/2011/07/04/everything-you-never-wanted-to-know-about-dlls/">Everything You Never Wanted To Know About DLLs</a></p>
]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Windows</tag>
        <tag>DLL</tag>
      </tags>
  </entry>
  <entry>
    <title>(Stack Overflow) Execute vs Read bit. How do directory permissions in Linux work?</title>
    <url>/execute-vs-read-bit-how-do-directory-permissions-in-linux-work/</url>
    <content><![CDATA[<h2 id="Question"><a class="header-anchor" href="#Question"></a>Question</h2>
<p>In my CMS, I noticed that directories need the executable bit (+x) set for the user to open them. Why is the execute permission required to read a directory, and how do directory permissions in Linux work?</p>
<h2 id="Answer-by-Chris-Down"><a class="header-anchor" href="#Answer-by-Chris-Down"></a>Answer by Chris Down</h2>
<p>When applying permissions to directories on Linux, the permission bits have different meanings than on regular files.</p>
<ul>
<li>The write bit allows the affected user to create, rename, or delete files within the directory, and modify the directory’s attributes</li>
<li>The read bit allows the affected user to list the files within the directory</li>
<li>The execute bit allows the affected user to enter the directory, and access files and directories inside</li>
<li>The sticky bit states that files and directories within that directory may only be deleted or renamed by their owner (or root)</li>
</ul>
<hr>
<p><strong>Article link: <a href="http://xnerv.wang/execute-vs-read-bit-how-do-directory-permissions-in-linux-work/">http://xnerv.wang/execute-vs-read-bit-how-do-directory-permissions-in-linux-work/</a></strong><br>
Reprinted from: <a href="https://unix.stackexchange.com/q/21251">(StackOverflow) Execute vs Read bit. How do directory permissions in Linux work?</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Linux</tag>
        <tag>Bash</tag>
        <tag>File System</tag>
        <tag>Stack Overflow</tag>
      </tags>
  </entry>
  <entry>
    <title>(MSDN) 格式规范语法：printf 和 wprintf 函数</title>
    <url>/format-specification-fields-printf-and-wprintf-functions/</url>
    <content><![CDATA[<p>各种 <code>printf</code> 函数采用格式字符串和可选参数，并生成用于输出的格式化的字符序列。 格式字符串包含零个或多个指令，这些指令是用于输出的文本字符或描述如何在输出中设置参数格式的已编码的转换规范。 本主题介绍用于对格式字符串中的转换规范进行编码的语法。 有关这些函数的列表，请参阅<a href="stream-i-o">流 I/O</a>。</p>
<p>一个转换规范由以下形式的可选和必需字段组成：</p>
<p><strong>%</strong>[<a href="#flags"><em>标志</em></a>][<a href="#width"><em>宽度</em></a>][.<a href="#precision"><em>精度</em></a>][<a href="#size"><em>大小</em></a>]<a href="#type"><em>类型</em></a></p>
<p>转换规范的每个字段都是一个用于指示特定的格式选项或转换说明符的字符或数字。 必填的类型字段指定要应用于参数的转换类型。 可选的标志、宽度和精度字段控制格式的其他方面（如前导空格或前导零、对齐方式和显示的精度）。 大小字段指定使用和转换的参数的大小。</p>
<p>一个基本的转换规范仅包含百分号和一个类型字符。 例如，<code>%s</code> 指定一个字符串转换。 若要打印百分号字符，请使用 <code>%%</code>。 如果百分号后跟一个没有任何意义的字符作为格式字段，则将调用无效的参数处理程序。 有关详细信息，请参阅<a href="parameter-validation">参数验证</a>。</p>
<span id="more"></span>
<blockquote>
<p><strong>重要</strong></p>
<p>为了实现安全性和稳定性，请确保转换规范字符串不是用户定义的。 例如，考虑这样一个程序，它提示用户输入名称并将输入存储在一个名为 <code>user_name</code> 的字符串变量中。 若要打印 <code>user_name</code>，请勿执行下列操作：</p>
<p>printf( user_name ); /* Danger! If user_name contains “%s”, program will crash */`</p>
<p>而应执行以下操作：</p>
<p><code>printf( &quot;%s&quot;, user_name );</code></p>
</blockquote>
<h2 id="类型转换说明符"><a class="header-anchor" href="#类型转换说明符"></a>类型转换说明符</h2>
<p>类型转换说明符字符指定是否要将相应的参数解释为字符、字符串、指针、整数或浮点数。 类型字符是唯一必填的转换规范字段，它出现在任何可选字段之后。</p>
<p>将根据相应的类型字符和可选的<a href="#size">大小</a>前缀对紧跟格式字符串的参数进行解释。 将通过使用 <strong>c</strong> 或 <strong>C</strong>指定字符类型 <code>char</code> 和 <code>wchar_t</code> 的转换，将通过使用 <strong>s</strong> 或 <strong>S</strong> 指定单字节和多字节或宽字符字符串，具体取决于正在使用的格式设置函数。 通过使用 <strong>c</strong> 和 <strong>s</strong> 指定的字符和字符串参数将被 <code>printf</code> 系列函数解释为 <code>char</code> 和 <code>char*</code>，或被 <code>wprintf</code> 系列函数解释为 <code>wchar_t</code> 和 <code>wchar_t*</code>。 通过使用 <strong>C</strong> 和 <strong>S</strong> 指定的字符和字符串参数将被 <code>printf</code> 系列函数解释为 <code>wchar_t</code> 和 <code>wchar_t*</code>，或被 <code>wprintf</code> 系列函数解释为 <code>char</code> 和 <code>char*</code>。 此行为是 Microsoft 专用的。</p>
<p>将通过使用 <strong>d</strong>、<strong>i</strong>、<strong>o</strong>、<strong>u</strong>、<strong>x</strong> 和 <strong>X</strong> 指定整数类型（如 <code>short</code>、<code>int</code>、<code>long</code>、<code>long long</code>）及其 <code>unsigned</code> 变体。将通过使用 <strong>a</strong>、<strong>A</strong>、<strong>e</strong>、<strong>E</strong>、<strong>f</strong>、<strong>F</strong>、<strong>g</strong> 和 <strong>G</strong> 指定浮点类型（如 <code>float</code>、<code>double</code> 和 <code>long double</code>）。默认情况下，除非由大小前缀进行修改，否则整数参数将被强制为 <code>int</code> 类型，浮点参数将被强制为 <code>double</code>。 在 64 位系统上，<code>int</code> 是 32 位的值；因此，确定 64 位整数的输出格式时，将把它截断，除非使用 <strong>ll</strong> 或 <strong>I64</strong> 的大小前缀。 由 <strong>p</strong> 指定的指针类型使用平台的默认指针大小。</p>
<blockquote>
<p><strong>备注</strong></p>
<p>与 <code>printf</code> 和 <code>wprintf</code> 函数一起使用时，<strong>Z</strong> 类型字符以及 <strong>c</strong>、<strong>C</strong>、<strong>s</strong> 和 <strong>S</strong> 类型字符的行为是 Microsoft 扩展。 在所有的格式设置函数中，ISO C 标准始终对窄字符和字符串使用 <strong>c</strong> 和 <strong>s</strong>，而对宽字符和字符串使用 <strong>C</strong> 和 <strong>S</strong>。</p>
</blockquote>
<h3 id="类型字段字符"><a class="header-anchor" href="#类型字段字符"></a>类型字段字符</h3>
<table>
<thead>
<tr>
<th>类型字符</th>
<th>参数</th>
<th>输出格式</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>c</strong></td>
<td>字符</td>
<td>与 <code>printf</code> 函数一起使用时，指定单字节字符；与 <code>wprintf</code> 函数一起使用时，指定宽字符。</td>
</tr>
<tr>
<td><strong>C</strong></td>
<td>字符</td>
<td>与 <code>printf</code> 函数一起使用时，指定宽字符；与 <code>wprintf</code> 函数一起使用时，指定单字节字符。</td>
</tr>
<tr>
<td><strong>d</strong></td>
<td>整数</td>
<td>带符号十进制整数。</td>
</tr>
<tr>
<td><strong>i</strong></td>
<td>整数</td>
<td>带符号十进制整数。</td>
</tr>
<tr>
<td><strong>o</strong></td>
<td>整数</td>
<td>无符号八进制整数。</td>
</tr>
<tr>
<td><strong>u</strong></td>
<td>整数</td>
<td>无符号十进制整数。</td>
</tr>
<tr>
<td><strong>x</strong></td>
<td>整数</td>
<td>无符号十六进制整数；使用“abcdef.”</td>
</tr>
<tr>
<td><strong>X</strong></td>
<td>整数</td>
<td>无符号十六进制整数；使用“ABCDEF.”</td>
</tr>
<tr>
<td><strong>e</strong></td>
<td>浮点</td>
<td>有符号的值，形式为 [-]<em>d.dddd</em><strong>e±</strong><em>dd</em>[<em>d</em>]，其中 <em>d</em> 是一个十进制数，<em>dddd</em> 是一个或多个十进制数（具体取决于指定的精度），或为默认的六个数，<em>dd</em>[<em>d</em>] 是两个或三个十进制数（具体取决于<a href="set-output-format">输出格式</a>和指数大小）。</td>
</tr>
<tr>
<td><strong>E</strong></td>
<td>浮点</td>
<td>与 <strong>e</strong> 格式相同，只不过指数由 <strong>E</strong> 引入，而不是由 <strong>e</strong> 引入。</td>
</tr>
<tr>
<td><strong>f</strong></td>
<td>浮点</td>
<td>有符号的值，形式为 [-]<em>dddd</em><strong>.</strong><em>dddd</em>，其中 <em>dddd</em> 是一个或多个十进制数。 小数点前的数字位数取决于数字的度量值，小数点后的数字位数取决于请求的精度，或为默认的六位数。</td>
</tr>
<tr>
<td><strong>F</strong></td>
<td>浮点</td>
<td>与 <strong>f</strong> 格式相同，只不过 infinity 和 nan 输出为大写形式。</td>
</tr>
<tr>
<td><strong>g</strong></td>
<td>浮点</td>
<td>有符号的值将显示为 <strong>f</strong> 或 <strong>e</strong> 格式，取其中对于给定的值和精度更为精简一个。 仅当值的指数小于 -4 或大于等于 <em>precision</em> 参数时，才使用 <strong>e</strong> 格式。 截去尾随零，仅当后跟一个或多个数字时，才会显示小数点。</td>
</tr>
<tr>
<td><strong>G</strong></td>
<td>浮点</td>
<td>与 <strong>g</strong> 格式相同，只不过指数由 <strong>E</strong> 引入，而不是由 <strong>e</strong> 引入（如果适用）。</td>
</tr>
<tr>
<td><strong>a</strong></td>
<td>浮点</td>
<td>有符号的十六进制双精度浮点值，形式为 [-]0x_h.hhhh_<strong>p±</strong><em>dd</em>，其中 <em>h.hhhh</em> 是尾数的十六进制数（使用小写字母），<em>dd</em> 是一位指数或多位指数。 精度指定此点后的数字位数。</td>
</tr>
<tr>
<td><strong>A</strong></td>
<td>浮点</td>
<td>有符号的十六进制双精度浮点值，形式为 [-]0X_h.hhhh_<strong>P±</strong><em>dd</em>，其中 <em>h.hhhh</em> 是尾数的十六进制数（使用大写字母），<em>dd</em> 是一位指数或多位指数。 精度指定此点后的数字位数。</td>
</tr>
<tr>
<td><strong>n</strong></td>
<td>指向整数的指针</td>
<td>目前成功写入流或缓冲区的字符数。 此值存储在地址作为自变量的整数中。 可通过参数大小规范前缀控制指向的整数的大小。 n 说明符默认为禁用；请参阅重要的安全说明了解相关信息。</td>
</tr>
<tr>
<td><strong>p</strong></td>
<td>指针类型</td>
<td>将自变量显示为十六进制数中的地址。</td>
</tr>
<tr>
<td><strong>s</strong></td>
<td>字符串</td>
<td>与 <code>printf</code> 函数一起使用时，指定单字节或多字节字符串；与 <code>wprintf</code> 函数一起使用时，指定宽字符字符串。 将于第一个空字符之前或达到精度值时显示字符。</td>
</tr>
<tr>
<td><strong>S</strong></td>
<td>字符串</td>
<td>与 <code>printf</code> 函数一起使用时，指定宽字符字符串；与 <code>wprintf</code> 函数一起使用时，指定单字节或多字节字符串。 将于第一个空字符之前或达到精度值时显示字符。</td>
</tr>
<tr>
<td><strong>Z</strong></td>
<td><code>ANSI_STRING</code> 或 <code>UNICODE_STRING</code> 结构</td>
<td>将 <a href="http://msdn.microsoft.com/library/windows/hardware/ff540605.aspx">ANSI_STRING</a> 或 <a href="http://msdn.microsoft.com/library/windows/hardware/ff564879.aspx">UNICODE_STRING</a> 结构的地址作为参数传递时，会显示包含在由结构的 <code>Buffer</code> 字段指向的缓冲区中的字符串。 使用 <strong>w</strong> 的大小修饰符前缀指定 <code>UNICODE_STRING</code> 参数，例如 <code>%wZ</code>。 结构的 <code>Length</code> 字段必须设置为字符串的长度（以字节为单位）。 结构的 <code>MaximumLength</code> 字段必须设置为缓冲区的长度（以字节为单位）。</td>
</tr>
</tbody>
</table>
<p>通常情况下，<strong>Z</strong> 类型字符仅在使用转换规范的驱动程序调试函数（如 <code>dbgPrint</code> 和 <code>kdPrint</code>）中使用。 |</p>
<p>从 Visual Studio 2015 开始，如果对应浮点转换说明符（<strong>a</strong>、<strong>A</strong>、<strong>e</strong>、<strong>E</strong>、<strong>f</strong>、<strong>F</strong>、<strong>g</strong>、<strong>G</strong>）的参数为无穷大、不定或 NaN，格式化的输出则符合 C99 标准。 下表列出了格式化的输出：</p>
<table>
<thead>
<tr>
<th>值</th>
<th>输出</th>
</tr>
</thead>
<tbody>
<tr>
<td>infinity</td>
<td><code>inf</code></td>
</tr>
<tr>
<td>静默 NaN</td>
<td><code>nan</code></td>
</tr>
<tr>
<td>信号 NaN</td>
<td><code>nan(snan)</code></td>
</tr>
<tr>
<td>不定 NaN</td>
<td><code>nan(ind)</code></td>
</tr>
</tbody>
</table>
<p>可能以符号作为其中任何一个值的前缀。 如果浮点类型转换说明符字符是一个大写字母，则输出也将使用大写字母格式。 例如，如果格式说明符是 <code>%F</code>而不是 <code>%f</code>，则 infinity 的格式将被设置为 <code>INF</code>，而不是 <code>inf</code>。 <code>scanf</code> 函数也可以分析这些字符串，使这些值可以通过 <code>printf</code> 和 <code>scanf</code> 函数进行往返。</p>
<p>在 Visual Studio 2015 之前，CRT 使用一种不同的非标准格式作为无穷大、不定和 NaN 值的输出：</p>
<table>
<thead>
<tr>
<th>值</th>
<th>输出</th>
</tr>
</thead>
<tbody>
<tr>
<td>+ 无穷</td>
<td><code>1.#INF</code> 随机数字</td>
</tr>
<tr>
<td>- 无穷</td>
<td><code>-1.#INF</code> 随机数字</td>
</tr>
<tr>
<td>不定（与静默 NaN 相同）</td>
<td><em>数字</em> <code>.#IND</code> 随机数字</td>
</tr>
<tr>
<td>NaN</td>
<td><em>数字</em> <code>.#NAN</code> 随机数字</td>
</tr>
</tbody>
</table>
<p>其中任何一种都可能已采用符号作为前缀并且格式设置也可能略有不同，具体取决于字段宽度和精度，有时会起到不寻常的作用。 例如，<code>printf(&quot;%.2f\n&quot;, INFINITY)</code> 可以打印 <code>1.#J</code>，因为 #INF 会“四舍五入”到 2 位数的精度。</p>
<blockquote>
<p><strong>备注</strong></p>
<p>如果与 <code>%s</code> 或 <code>%S</code> 对应的参数，或与 <code>%Z</code> 对应的参数的 <code>Buffer</code> 字段为空指针，则将显示“(null)”。</p>
</blockquote>
<blockquote>
<p><strong>备注</strong></p>
<p>在所有的指数格式中，要显示的指数的位数最少为两位，仅在必要时使用三位。 通过使用 <a href="set-output-format">_set_output_format</a> 函数，可以将显示的数字位数设置为三位，以确保与为 Visual Studio 2013 及更早版本编写的代码的后向兼容性。</p>
</blockquote>
<blockquote>
<p><strong>重要</strong></p>
<p><code>%n</code> 格式在本质上是不安全的，因此它默认处于禁用状态。 如果在格式字符串中遇到 <code>%n</code>，则将调用无效的参数处理程序，如<a href="parameter-validation">参数验证</a>中所述。 若要启用 <code>%n</code> 支持，请参阅 <a href="../c-runtime-library/reference/set-printf-count-output">_set_printf_count_output</a>。</p>
</blockquote>
<h2 id="标志指令"><a class="header-anchor" href="#标志指令"></a>标志指令</h2>
<p>转换规范中的第一个可选字段包含标志指令、零个或多个标志字符，用于指定输出对齐方式以及控制符号、空白、前导零、小数点以及八进制和十六进制前缀的输出。 转换规范中可能会出现多个标志指令，并且标志字符可能会按任意顺序出现。</p>
<h3 id="标志字符"><a class="header-anchor" href="#标志字符"></a>标志字符</h3>
<table>
<thead>
<tr>
<th>Flag</th>
<th>含义</th>
<th>默认</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>-</strong></td>
<td>在给定的字段宽度内左对齐结果。</td>
<td>右对齐。</td>
</tr>
<tr>
<td><strong>+</strong></td>
<td>如果输出值为有符号的类型，则在该值前使用符号（+ 或 -）作为前缀。</td>
<td>只对有符号的负值 (-) 显示符号。</td>
</tr>
<tr>
<td><strong>0</strong></td>
<td>如果将 <strong>0</strong> 作为宽度的前缀，则会在达到最小宽度前添加前导零。 如果 <strong>0</strong> 和 <strong>-</strong> 同时出现，<strong>0</strong> 则将被忽略。 如果为整数格式（<strong>i</strong>、<strong>u</strong>、<strong>x</strong>、<strong>X</strong>、<strong>o</strong>、<strong>d</strong>）指定了 <strong>0</strong>，并且还存在精度规范（例如 <code>%04.d</code>），<strong>0</strong> 则将被忽略。 如果为 <strong>a</strong> 或 <strong>A</strong> 浮点格式指定了 <strong>0</strong>，则会在 <code>0x</code> 或 <code>0X</code> 前缀后，在尾数前追加前导零。</td>
<td>不填充。</td>
</tr>
<tr>
<td><strong>空白</strong> (’ ')</td>
<td>如果输出值为有符号的正值，则使用空白作为其前缀。 如果空白和 + 标志同时出现，空白则将被忽略。</td>
<td>没有显示空白。</td>
</tr>
<tr>
<td><strong>#</strong></td>
<td>与 <strong>o</strong>、<strong>x</strong> 或 <strong>X</strong> 格式一起使用时，<strong>#</strong> 标志将分别使用 0、0x 或 0X 作为任何非零输出值的前缀。</td>
<td>没有显示空白。</td>
</tr>
<tr>
<td></td>
<td>与<strong>e</strong>、<strong>E</strong>、<strong>f</strong>、<strong>F</strong>、<strong>a</strong> 或 <strong>A</strong> 格式一起使用时，<strong>#</strong> 标志将强制输出值包含小数点。</td>
<td>仅当小数点后紧跟数字时，才会显示小数点。</td>
</tr>
<tr>
<td></td>
<td>与 <strong>g</strong> 或 <strong>G</strong> 格式一起使用时，<strong>#</strong> 标志将强制输出值包含小数点，并阻止截断尾随零。</td>
<td></td>
</tr>
</tbody>
</table>
<p>与 <strong>c</strong>、<strong>d</strong>、<strong>i</strong>、<strong>u</strong> 或 <strong>s</strong> 一起使用时，则将被忽略。 | 仅当小数点后紧跟数字时，才会显示小数点。 尾随零将被截断。 |</p>
<h2 id="宽度规范"><a class="header-anchor" href="#宽度规范"></a>宽度规范</h2>
<p>在转换规范中，可选宽度规范字段出现在任何标志字符之后。 宽度参数是控制输出的最小字符数量的非负十进制整数。 如果输出值中的字符数小于指定宽度，则将在值的左侧或右侧添加空白（具体取决于是否指定了左对齐标志 (<strong>-</strong>)），直到达到最小宽度为止。 如果 0 作为宽度的前缀，则将向整数或浮点转换添加前导零，直到达到最小宽度为止，但转换到 infinity 或 NaN 时除外。</p>
<p>宽度规范永远不会导致值被截断。 如果输出值中的字符数大于指定宽度，或如果未提供宽度，则将根据精度规范输出值中的所有字符。</p>
<p>如果宽度规范是一个星号 (<code>*</code>)，则参数列表中的 <code>int</code> 参数将提供此值。 宽度参数必须先于在参数列表中要设置其格式的值，如以下示例中所示：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;%0*f&quot;</span>, <span class="number">5</span>, <span class="number">3</span>); <span class="comment">/* 00003 is output */</span></span><br></pre></td></tr></table></figure>
<p>转换规范中缺少宽度值或此值较小将不会导致截断输出值。 如果转换结果的宽度大于宽度值，则字段将扩展以包含转换结果。</p>
<h2 id="精度规范"><a class="header-anchor" href="#精度规范"></a>精度规范</h2>
<p>在转换规范中，第三个可选字段是精度规范。 它包含一个句点 (.)，后跟一个非负十进制整数，指定字符串字符数、小数位数或要输出的有效数字位数，具体取决于转换类型.</p>
<p>与宽度规范不同的是，精度规范可能导致输出值截断或浮点值舍入。 如果将精度指定为 0 并且要转换的值为 0，则结果为无字符输出，如以下示例中所示：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">printf</span>( <span class="string">&quot;%.0d&quot;</span>, <span class="number">0</span> ); <span class="comment">/* No characters output */</span></span><br></pre></td></tr></table></figure>
<p>如果精度规范是一个星号 (*)，则参数列表中的某个 <code>int</code> 参数将提供此值。 在参数列表中，精度参数前必须先于要设置其格式的值，如以下示例中所示：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">printf</span>( <span class="string">&quot;%.*f&quot;</span>, <span class="number">3</span>, <span class="number">3.14159265</span> ); <span class="comment">/* 3.142 output */</span></span><br></pre></td></tr></table></figure>
<p>如果省略精度，则类型字符将决定精度的解释或默认精度，如下表中所示。</p>
<h3 id="精度值如何影响类型"><a class="header-anchor" href="#精度值如何影响类型"></a>精度值如何影响类型</h3>
<table>
<thead>
<tr>
<th>类型</th>
<th>含义</th>
<th>默认</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>a</strong>、<strong>A</strong></td>
<td>精度指定此点后的数字位数。</td>
<td>默认精度为 13。 如果精度为 0，除非使用了 <strong>#</strong> 标志，否则不会打印小数点。</td>
</tr>
<tr>
<td><strong>c</strong>、<strong>C</strong></td>
<td>精度不产生任何影响。</td>
<td>打印字符。</td>
</tr>
<tr>
<td><strong>d</strong>、<strong>i</strong>、<strong>o</strong>、<strong>u</strong>、<strong>x</strong>、<strong>X</strong></td>
<td>精度指定要打印的最小数字位数。 如果参数中的数字位数小于精度，则将在输出值的左侧使用零进行填充。 数字位数超过精度时，值将不会被截断。</td>
<td>默认精度为 1。</td>
</tr>
<tr>
<td><strong>e</strong>、<strong>E</strong></td>
<td>精度指定此小数点后要打印的数字位数。 打印的最后一位数舍入。</td>
<td>默认精度为 6。 如果精度为 0，或者如果句点 (.) 后面不跟数字，则不会打印小数点。</td>
</tr>
<tr>
<td><strong>f</strong>、<strong>F</strong></td>
<td>精度值指定此小数点后的数字位数。 如果出现小数点，则在它之前至少会显示一个数字。 该值舍入为适当数量的数字。</td>
<td>默认精度为 6。 如果精度为 0，或者如果句点 (.) 后面不跟数字，则不会打印小数点。</td>
</tr>
<tr>
<td><strong>g</strong>、<strong>G</strong></td>
<td>精度指定打印的最大有效位数。</td>
<td>打印六个有效位数，并且任何尾随零都会被截断。</td>
</tr>
<tr>
<td><strong>s</strong>、<strong>S</strong></td>
<td>精度指定要打印的最大字符数。 不会打印超过精度的字符。</td>
<td>在遇到 null 字符之前不会打印字符。</td>
</tr>
</tbody>
</table>
<h2 id="参数大小规范"><a class="header-anchor" href="#参数大小规范"></a>参数大小规范</h2>
<p>在转换规范中，大小字段是类型转换说明符的参数长度修饰符。 大小字段作为类型字段（<strong>hh</strong>、<strong>h</strong>、<strong>j</strong>、<strong>l</strong>（小写的 L）、<strong>L</strong>、<strong>ll</strong>、<strong>t</strong>、<strong>w</strong>、<strong>z</strong>、<strong>I</strong>（大写的 i）、<strong>I32</strong> 和 <strong>I64</strong>）的前缀，根据它们修饰的转换说明符，指定对应参数的“大小”（长型或短型、32 位或 64 位、单字节字符或宽字符）。 这些大小前缀在 <code>printf</code> 和 <code>wprintf</code> 系列函数中与 <em>类型</em> 字符一起使用，以指定参数大小的解释（如下表中所示）。 大小字段对于某些参数类型是可选的。 未指定任何大小前缀时，格式化程序使用整数参数（例如，有符号或无符号的 <code>char</code>、<code>short</code>、<code>int</code>、<code>long</code> 和枚举类型）作为 32 位 <code>int</code> 类型，而使用 <code>float</code>、<code>double</code> 和 <code>long double</code> 浮点参数作为 64 位 <code>double</code> 类型。 这与变量自变量列表的默认自变量提升规则相匹配。 有关自变量提升的详细信息，请参阅<a href="../cpp/postfix-expressions">后缀表达式</a>中的“省略号和默认自变量”。 在 32 位和 64 位系统上，64 位整数参数的转换规范必须包含 <strong>ll</strong> 或 <strong>I64</strong> 大小前缀。 否则，格式化程序的行为是不明确的。</p>
<p>某些类型在 32 位和 64 位代码中具有不同大小。 例如，<code>size_t</code> 在针对 x86 编译的代码中是 32 位长，而在针对 x64 编译的代码中是 64 位。 若要为宽度可变的类型创建与平台无关的格式设置代码，可以使用宽度可变的参数大小修饰符。 或者，使用 64 位参数大小修饰符，并将宽度可变的参数类型显式提升为 64 位。 特定于 Microsoft 的 <strong>I</strong>（大写的 i）参数大小修饰符可处理宽度可变的整数参数，但我们建议使用特定于类型的 <strong>j</strong>、<strong>t</strong> 和 <strong>z</strong> 修饰符以确保可移植性。</p>
<h3 id="printf-和-wprintf-格式类型说明符的大小前缀"><a class="header-anchor" href="#printf-和-wprintf-格式类型说明符的大小前缀"></a>printf 和 wprintf 格式类型说明符的大小前缀</h3>
<table>
<thead>
<tr>
<th>若要指定</th>
<th>使用前缀</th>
<th>及类型说明符</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>char</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>unsigned char</code></td>
<td><strong>hh</strong></td>
<td><strong>d</strong>、<strong>i</strong>、<strong>o</strong>、<strong>u</strong>、<strong>x</strong> 或 <strong>X</strong></td>
</tr>
<tr>
<td><code>short int</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>short unsigned int</code></td>
<td><strong>h</strong></td>
<td><strong>d</strong>、<strong>i</strong>、<strong>o</strong>、<strong>u</strong>、<strong>x</strong> 或 <strong>X</strong></td>
</tr>
<tr>
<td><code>__int32</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>unsigned __int32</code></td>
<td><strong>I32</strong></td>
<td><strong>d</strong>、<strong>i</strong>、<strong>o</strong>、<strong>u</strong>、<strong>x</strong> 或 <strong>X</strong></td>
</tr>
<tr>
<td><code>__int64</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>unsigned __int64</code></td>
<td><strong>I64</strong></td>
<td><strong>d</strong>、<strong>i</strong>、<strong>o</strong>、<strong>u</strong>、<strong>x</strong> 或 <strong>X</strong></td>
</tr>
<tr>
<td><code>intmax_t</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>uintmax_t</code></td>
<td><strong>j</strong> 或 <strong>I</strong>（大写的 i）</td>
<td><strong>d</strong>、<strong>i</strong>、<strong>o</strong>、<strong>u</strong>、<strong>x</strong> 或 <strong>X</strong></td>
</tr>
<tr>
<td><code>long double</code></td>
<td><strong>l</strong>（小写的 L）或 <strong>L</strong></td>
<td><strong>a</strong>、<strong>A</strong>、<strong>e</strong>、<strong>E</strong>、<strong>f</strong>、<strong>F</strong>、<strong>g</strong> 或 <strong>G</strong></td>
</tr>
<tr>
<td><code>long int</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>long unsigned int</code></td>
<td><strong>l</strong>（小写的 L）</td>
<td><strong>d</strong>、<strong>i</strong>、<strong>o</strong>、<strong>u</strong>、<strong>x</strong> 或 <strong>X</strong></td>
</tr>
<tr>
<td><code>long long int</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>unsigned long long int</code></td>
<td><strong>ll</strong>（小写的 LL）</td>
<td><strong>d</strong>、<strong>i</strong>、<strong>o</strong>、<strong>u</strong>、<strong>x</strong> 或 <strong>X</strong></td>
</tr>
<tr>
<td><code>ptrdiff_t</code></td>
<td><strong>t</strong> 或 <strong>I</strong>（大写的 i）</td>
<td><strong>d</strong>、<strong>i</strong>、<strong>o</strong>、<strong>u</strong>、<strong>x</strong> 或 <strong>X</strong></td>
</tr>
<tr>
<td><code>size_t</code></td>
<td><strong>z</strong> 或 <strong>I</strong>（大写的 i）</td>
<td><strong>d</strong>、<strong>i</strong>、<strong>o</strong>、<strong>u</strong>、<strong>x</strong> 或 <strong>X</strong></td>
</tr>
<tr>
<td>单字节字符</td>
<td><strong>h</strong></td>
<td><strong>c</strong> 或 <strong>C</strong></td>
</tr>
<tr>
<td>宽字符</td>
<td><strong>l</strong>（小写的 L）或 <strong>w</strong></td>
<td><strong>c</strong> 或 <strong>C</strong></td>
</tr>
<tr>
<td>单字节字符串</td>
<td><strong>h</strong></td>
<td><strong>s</strong>、<strong>S</strong> 或 <strong>Z</strong></td>
</tr>
<tr>
<td>宽字符字符串</td>
<td><strong>l</strong>（小写的 L）或 <strong>w</strong></td>
<td><strong>s</strong>、<strong>S</strong> 或 <strong>Z</strong></td>
</tr>
</tbody>
</table>
<p><code>intmax_t</code>、<code>uintmax_t</code>、<code>ptrdiff_t</code> 和 <code>size_t</code> 类型在 32 位平台上为 <code>__int32</code> 或 <code>unsigned __int32</code>，在 64 位平台上为 <code>__int64</code> 或 <code>unsigned __int64</code>。 <strong>I</strong>（大写的 i）、<strong>j</strong>、<strong>t</strong> 和 <strong>z</strong> 大小前缀采用平台的正确参数宽度。</p>
<p>在 Visual C++ 中，虽然 <code>long double</code> 是互异的类型，但是它具有与 <code>double</code> 相同的内部表示形式。</p>
<p><strong>hc</strong> 或 <strong>hC</strong> 类型说明符与 <code>printf</code> 函数中的 <strong>c</strong> 以及 <code>wprintf</code> 函数中的 <strong>C</strong> 是同义的。 <strong>lc</strong>、<strong>lC</strong>、<strong>wc</strong> 或 <strong>wC</strong> 类型说明符与 <code>printf</code> 函数中的 <strong>C</strong> 以及 <code>wprintf</code> 函数中的 <strong>c</strong> 是同义的。 <strong>hs</strong> 或 <strong>hS</strong> 类型说明符与 <code>printf</code> 函数中的 <strong>s</strong> 以及 <code>wprintf</code> 函数中的 <strong>S</strong> 是同义的。 <strong>ls</strong>、<strong>lS</strong>、<strong>ws</strong> 或 <strong>wS</strong> 类型说明符与 <code>printf</code> 函数中的 <strong>S</strong> 以及 <code>wprintf</code> 函数中的 <strong>s</strong> 是同义的。</p>
<blockquote>
<p><strong>备注</strong></p>
<p><strong>I</strong>（大写的 i）、<strong>I32</strong>、<strong>I64</strong> 和 <strong>w</strong> 参数大小修饰符前缀是 Microsoft 扩展，且不符合 ISO C。 <strong>h</strong> 前缀（在与 <code>char</code> 类型的数据一起使用时）和 <strong>l</strong> 前缀（在与 <code>double</code> 类型的数据一起使用时）是 Microsoft 扩展。</p>
</blockquote>
<h2 id="另请参阅"><a class="header-anchor" href="#另请参阅"></a>另请参阅</h2>
<ul>
<li><a href="../c-runtime-library/reference/printf-printf-l-wprintf-wprintf-l">printf、_printf_l、wprintf、_wprintf_l</a></li>
<li><a href="../c-runtime-library/reference/printf-s-printf-s-l-wprintf-s-wprintf-s-l">printf_s、_printf_s_l、wprintf_s、_wprintf_s_l</a></li>
<li><a href="printf-p-positional-parameters">printf_p 位置参数</a></li>
</ul>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/format-specification-fields-printf-and-wprintf-functions/">http://xnerv.wang/format-specification-fields-printf-and-wprintf-functions/</a></strong><br>
转载自：<a href="https://docs.microsoft.com/zh-cn/cpp/c-runtime-library/format-specification-syntax-printf-and-wprintf-functions">(MSDN) Format Specification Syntax: printf and wprintf Functions</a></p>
]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>C++</tag>
        <tag>MSDN</tag>
        <tag>Programing</tag>
      </tags>
  </entry>
  <entry>
    <title>(MSDN) 格式规范字段：scanf 和 wscanf 函数</title>
    <url>/format-specification-fields-scanf-and-wscanf-functions/</url>
    <content><![CDATA[<p>此处的信息适用于整个 <code>scanf</code> 函数系列（包括安全版本），并描述了用于告诉 <code>scanf</code> 函数如何将输入流（如 <code>stdin</code> 的输入流 <code>scanf</code>）分析为插入到程序变量中的值。</p>
<p>格式规范具有以下形式：</p>
<p><code>%</code>[<code>*</code>] [<a href="scanf-width-specification">width</a>] [{<a href="scanf-width-specification">h | l | ll | I64 | L</a>}]<a href="scanf-type-field-characters">type</a></p>
<span id="more"></span>
<p><code>format</code> 参数指定输入的解释，并且可以包含以下一项或多项：</p>
<ul>
<li>
<p>空白字符：空白 (’ ‘)；制表符 (’\t’)；或换行符 (‘\n’)。 空白字符将使得 <code>scanf</code> 读取（但不存储）输入中所有连续的空白字符，直至下一个非空白字符。 格式中的一个空白字符与输入中的任何数字（包括 0）和空白字符的组合相匹配。</p>
</li>
<li>
<p>百分号 (<code>%</code>) 除外的非空白字符。 非空白字符将使得 <code>scanf</code> 读取（但不存储）匹配的非空白字符。 如果输入流中的下一个字符不匹配，则 <code>scanf</code> 将会终止。</p>
</li>
<li>
<p>由百分号 (<code>%</code>) 引入的格式规范。 格式规范将使得 <code>scanf</code> 读取输入中的字符并将其转换为指定类型的值。 该值将分配给参数列表中的一个参数。</p>
<p>格式为从左向右读取。 不符合格式规范的字符应匹配输入流中的字符序列；将扫描但不存储输入流中的匹配字符。 如果输入流中的字符与格式规范冲突，则 <code>scanf</code> 将终止，并且将该字符留在输入流中，就像没有读取过它一样。</p>
<p>遇到第一个格式规范时，第一个输入字段的值将根据此规范进行转换并储存在第一个 <code>argument</code> 指定的位置中。 第二个格式规范将使得第二个输入字段进行转换并储存在第二个 <code>argument</code> 中，依此类推，直至格式字符串的末尾。</p>
<p>将输入字段定义为第一个空白字符（空格、制表符或换行符）之前的所有字符，或第一个无法根据格式规范转换的字符之前的所有字符，或在达到最大字段宽度（如果已指定）之前的所有字符。 如果给定的规范有太多参数，则将计算但忽略多余的参数。 如果格式规范没有足够参数，则结果不可预知。</p>
<p>格式规范的每个字段是一个用于指定特定格式选项的字符或数字。 位于最后一个可选格式字段之后的 <code>type</code> 字符决定将输入字段解释为字符、字符串还是数字。</p>
<p>最简单的格式规范仅包含百分号和一个 <code>type</code> 字符（例如，<code>%s</code>）。 如果百分号 (<code>%</code>) 后跟一个没有意义的字符作为格式控制字符，则该字符及其后面的字符（直至下一个百分号）将被视为普通字符序列，即必须与输入匹配的字符序列。 例如，若要指定要输入的百分号字符，请使用 <code>%%</code>。</p>
<p>百分号后面的星号 (<code>*</code>) 将取消下一个输入字段的分配（将被解释为指定类型的字段）。 将扫描但不储存该字段。</p>
<p><code>_s</code> 函数系列的安全版本（具有 <code>scanf</code> 后缀的版本）需要在每个 <code>c</code>、<code>C</code>、<code>s</code>、<code>S</code> 或 <code>[</code> 类型的参数之后立即传入一个缓冲区大小参数。 有关 <code>scanf</code> 系列函数的安全版本的更多信息，请参阅 <a href="../c-runtime-library/reference/scanf-s-scanf-s-l-wscanf-s-wscanf-s-l">scanf_s、_scanf_s_l、wscanf_s、_wscanf_s_l</a>。</p>
</li>
</ul>
<h2 id="另请参阅"><a class="header-anchor" href="#另请参阅"></a>另请参阅</h2>
<ul>
<li><a href="scanf-width-specification">scanf 宽度规范</a></li>
<li><a href="scanf-type-field-characters">scanf 类型字段字符</a></li>
<li><a href="../c-runtime-library/reference/scanf-scanf-l-wscanf-wscanf-l">scanf、_scanf_l、wscanf、_wscanf_l</a></li>
<li><a href="../c-runtime-library/reference/scanf-s-scanf-s-l-wscanf-s-wscanf-s-l">scanf_s、_scanf_s_l、wscanf_s、_wscanf_s_l</a></li>
</ul>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/format-specification-fields-scanf-and-wscanf-functions/">http://xnerv.wang/format-specification-fields-scanf-and-wscanf-functions/</a></strong><br>
转载自：<a href="https://docs.microsoft.com/zh-cn/cpp/c-runtime-library/format-specification-fields-scanf-and-wscanf-functions">(MSDN) Format Specification Fields: scanf and wscanf Functions</a></p>
]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>C++</tag>
        <tag>MSDN</tag>
        <tag>Programing</tag>
      </tags>
  </entry>
  <entry>
    <title>数据库弱一致性四个隔离级别（转载）</title>
    <url>/four-isolation-levels-of-database-weak-consistency/</url>
    <content><![CDATA[<p>SQL-92标准中定义了四个隔离级别，这四个隔离级别在以前版本的SQL Server中即受到支持：</p>
<h2 id="READ-UNCOMMITTED"><a class="header-anchor" href="#READ-UNCOMMITTED"></a>READ UNCOMMITTED</h2>
<p>READ UNCOMMITTED是限制性最弱的隔离级别，因为该级别忽略其他事务放置的锁。使用READ UNCOMMITTED级别执行的事务，可以读取尚未由其他事务提交的修改后的数据值，这些行为称为“脏”读。这是因为<span style="color: #ff0000;"><strong>在Read Uncommitted级别下，读取数据不需要加S锁，这样就不会跟被修改的数据上的X锁冲突</strong></span>。比如，事务1修改一行，事务2在事务1提交之前读取了这一行。如果事务1回滚，事务2就读取了一行没有提交的数据，这样的数据我们认为是不存在的。</p>
<span id="more"></span>
<h2 id="READ-COMMITTED"><a class="header-anchor" href="#READ-COMMITTED"></a>READ COMMITTED</h2>
<p>READ COMMITTED(Nonrepeatable reads)是SQL Server默认的隔离级别。该级别通过指定语句不能读取其他事务已修改但是尚未提交的数据值，禁止执行脏读。在当前事务中的各个语句执行之间，其他事务仍可以修改、插入或删除数据，从而产生无法重复的读操作，或“影子”数据。比如，事务1读取了一行，事务2修改或者删除这一行并且提交。如果事务1想再一次读取这一行，它将获得修改后的数据或者发现这一样已经被删除，因此事务的第二次读取结果与第一次读取结果不同，因此也叫不可重复读。</p>
<h3 id="实验1"><a class="header-anchor" href="#实验1"></a>实验1</h3>
<p>query1：事务1</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--step1:创建实验数据</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">into</span> Employee <span class="keyword">from</span> AdventureWorks.HumanResources.Employee</span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> Employee <span class="keyword">add</span> <span class="keyword">constraint</span> pk_Employee_EmployeeID <span class="keyword">primary</span> key(EmployeeID)</span><br><span class="line"></span><br><span class="line"><span class="comment">--step2:设置隔离级别,这是数据库的默认隔离界别</span></span><br><span class="line"><span class="keyword">SET</span> TRANSACTION ISOLATION LEVEL READ COMMITTED</span><br><span class="line"></span><br><span class="line"><span class="comment">--step3:开启第一个事务</span></span><br><span class="line"><span class="keyword">BEGIN</span> TRAN tran1</span><br><span class="line">    <span class="comment">--step4:执行select操作,查看VacationHours,对查找的记录加S锁，在语句执行完以后自动释放S锁</span></span><br><span class="line">    <span class="keyword">SELECT</span> EmployeeID, VacationHours</span><br><span class="line">        <span class="keyword">FROM</span> Employee</span><br><span class="line">        <span class="keyword">WHERE</span> EmployeeID <span class="operator">=</span> <span class="number">4</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">--step5:查看当前加锁情况,没有发现在Employee表上面有锁,这是因为当前的隔离界别是READ COMMITTED</span></span><br><span class="line">    <span class="comment">--在执行完step2以后马上释放了S锁.</span></span><br><span class="line">    <span class="keyword">SELECT</span> request_session_id, resource_type, resource_associated_entity_id,</span><br><span class="line">        request_status, request_mode, resource_description</span><br><span class="line">        <span class="keyword">FROM</span> sys.dm_tran_locks</span><br></pre></td></tr></table></figure>
<p>查看锁的情况如下图所示，我们发现在只有在数据库级别的S锁，而没有在表级别或者更低级别的锁，这是因为**<span style="color: #ff0000;">在Read Committed级别下，S锁在语句执行完以后就被释放</span>**。</p>
<p><img src="/assets/four-isolation-levels-of-database-weak-consistency/1.png" alt=""></p>
<p>query2：事务2</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--step6:开启第二个事务</span></span><br><span class="line"><span class="keyword">BEGIN</span> TRAN tran2;</span><br><span class="line">    <span class="comment">--step7:修改VacationHours,需要获得排它锁X,在VacationHours上没有有S锁</span></span><br><span class="line">    <span class="keyword">UPDATE</span> Employee</span><br><span class="line">        <span class="keyword">SET</span> VacationHours <span class="operator">=</span> VacationHours <span class="operator">-</span> <span class="number">8</span></span><br><span class="line">        <span class="keyword">WHERE</span> EmployeeID <span class="operator">=</span> <span class="number">4</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">--step8:查看当前加锁情况</span></span><br><span class="line">    <span class="keyword">SELECT</span> request_session_id, resource_type, resource_associated_entity_id,</span><br><span class="line">        request_status, request_mode, resource_description</span><br><span class="line">        <span class="keyword">FROM</span> sys.dm_tran_locks</span><br></pre></td></tr></table></figure>
<p>在开启另外一个update事务以后，我们再去查看当前的锁状况，如下图所示，我们发现在表(<strong>Object</strong>)级别上加了IX锁，在这张表所在的<strong>Page</strong>上也加了IX锁，因为表加了聚集索引，所以在叶子结点上加了X锁，这个锁的类型是<strong>KEY</strong>。</p>
<p><img src="/assets/four-isolation-levels-of-database-weak-consistency/2.png" alt=""></p>
<p>然后我们回到事务1当中再次执行查询语句，我们会发现查询被阻塞，我们新建一个查询query3来查看这个时候的锁状况，其查询结果如下，我们可以发现查询操作需要在KEY级别上申请S锁，在Page和表(Object)上面申请IS锁，但是因为Key上面原先有了X锁，与当前读操作申请的S锁冲突，所以这一步处于<span style="color: #ff0000;"><strong>WAIT</strong></span>状态。</p>
<p><img src="/assets/four-isolation-levels-of-database-weak-consistency/3.png" alt=""></p>
<p>如果此时提交事务2的update操作，那么事务1的select操作不再被阻塞，得到查询结果，但是我们发现此时得到的查询结果与第一次得到的查询结果不同，这也是为什么将read committed称为不可重复读，因为<span style="color: #ff0000;">同一个事物内的两次相同的查询操作的结果可能不同</span>。</p>
<h2 id="REPEATABLE-READ"><a class="header-anchor" href="#REPEATABLE-READ"></a>REPEATABLE READ</h2>
<p>REPEATABLE READ是比READ COMMITTED限制性更强的隔离级别。该级别包括READ COMMITTED，并且另外指定了在当前事务提交之前，其他任何事务均不可以修改或删除当前事务已读取的数据。并发性低于 READ COMMITTED，因为已读数据的共享锁在整个事务期间持有，而不是在每个语句结束时释放。比如，事务1读取了一行，事务2想修改或者删除这一行并且提交，但是因为事务1尚未提交，数据行中有事务1的锁，事务2无法进行更新操作，因此事务2阻塞。如果这时候事务1想再一次读取这一行，它读取结果与第一次读取结果相同，因此叫可重复读。</p>
<h3 id="实验2"><a class="header-anchor" href="#实验2"></a>实验2</h3>
<p>query1：事务1</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--step1:创建实验数据</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">into</span> Employee <span class="keyword">from</span> AdventureWorks.HumanResources.Employee</span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> Employee <span class="keyword">add</span> <span class="keyword">constraint</span> pk_Employee_EmployeeID <span class="keyword">primary</span> key(EmployeeID)</span><br><span class="line"></span><br><span class="line"><span class="comment">--step2:设置隔离级别</span></span><br><span class="line"><span class="keyword">SET</span> TRANSACTION ISOLATION LEVEL REPEATABLE READ</span><br><span class="line"></span><br><span class="line"><span class="comment">--step3:开启第一个事务</span></span><br><span class="line"><span class="keyword">BEGIN</span> TRAN tran1</span><br><span class="line">    <span class="comment">--step4:执行select操作,查看VacationHours</span></span><br><span class="line">    <span class="keyword">SELECT</span> EmployeeID, VacationHours</span><br><span class="line">        <span class="keyword">FROM</span> Employee</span><br><span class="line">        <span class="keyword">WHERE</span> EmployeeID <span class="operator">=</span> <span class="number">4</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">--step5:查看当前加锁情况,发现在Employee表上面有S锁,这是因为当前的隔离界别是REPEATABLE READ</span></span><br><span class="line">    <span class="comment">--S锁只有在事务执行完以后才会被释放.</span></span><br><span class="line">    <span class="keyword">SELECT</span> request_session_id, resource_type, resource_associated_entity_id,</span><br><span class="line">        request_status, request_mode, resource_description</span><br><span class="line">        <span class="keyword">FROM</span> sys.dm_tran_locks</span><br></pre></td></tr></table></figure>
<p>查询锁状态的结果如下图所示，我们发现在KEY上面加了S锁，在Page和Object上面加了IS锁，这是因为**<span style="color: #ff0000;">在Repeatable Read级别下S锁要在事务执行完以后才会被释放</span>**。</p>
<p><img src="/assets/four-isolation-levels-of-database-weak-consistency/4.png" alt=""></p>
<p>query2：事务2</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--step6:开启第二个事务</span></span><br><span class="line"><span class="keyword">BEGIN</span> TRAN tran2;</span><br><span class="line">    <span class="comment">--step7:修改VacationHours,需要获得排他锁X,在VacationHours上有S锁，出现冲突，所以update操作被阻塞</span></span><br><span class="line">    <span class="keyword">UPDATE</span> Employee</span><br><span class="line">        <span class="keyword">SET</span> VacationHours <span class="operator">=</span> VacationHours <span class="operator">-</span> <span class="number">8</span></span><br><span class="line">        <span class="keyword">WHERE</span> EmployeeID <span class="operator">=</span> <span class="number">4</span>;</span><br></pre></td></tr></table></figure>
<p>执行上述update操作的时候发现该操作被阻塞，这是因为update操作要加排它锁X，而因为原先的查询操作的S锁没有释放，所以两者冲突。我们新建一个查询3执行查询锁状态操作，发现结果如下图所示，我们可以发现是**<span style="color: #ff0000;">WAIT</span>**发生在对KEY加X锁的操作上面。</p>
<p><img src="/assets/four-isolation-levels-of-database-weak-consistency/5.png" alt=""></p>
<p>此时再次执行查询1中的select操作，我们发现查询结果跟第一次相同，所以这个叫做可重复读操作。但是可重复读操作并不是特定指两次读取的数据一模一样，Repeatable Read存在的一个问题是幻读，就是第二次读取的数据返回的条目数比第一次返回的条目数更多。</p>
<p>比如在Repeatable Read隔离级别下，事务1第一次执行查询<code>select id from users where id&gt;1 and id &lt;10</code>，返回的结果是2，4，6，8。这个时候事务1没有提交，那么对2，4，6，8上面依然保持有S锁。此时事务2执行一次插入操作insert into user(id) valuse(3)，插入成功。此时再次执行事务1中的查询，那么返回结果就是2，<span style="color: #ff0000;">3</span>，4，6，8。这里的3就是因为幻读而出现的。因此可以得出结论：<strong><span style="color: #ff0000;">REPEATABLE READ隔离级别保证了在相同的查询条件下，同一个事务中的两个查询，第二次读取的内容肯定包换第一次读到的内容。</span></strong></p>
<h2 id="SERIALIZABLE"><a class="header-anchor" href="#SERIALIZABLE"></a>SERIALIZABLE</h2>
<p>SERIALIZABLE 是限制性最强的隔离级别，因为该级别<span style="color: #ff0000;"><strong>锁定整个范围的键</strong></span>，并一直持有锁，直到事务完成。该级别包括REPEATABLE READ，并增加了在事务完成之前，其他事务不能向事务已读取的范围<strong>插入新行</strong>的限制。比如，事务1读取了一系列满足搜索条件的行。事务2在执行SQL statement产生一行或者多行满足事务1搜索条件的行时会冲突，则事务2</span>回滚。这时事务1</span>再次读取了一系列满足相同搜索条件的行，第二次读取的结果和第一次读取的结果相同。</p>
<h2 id="重复读与幻读"><a class="header-anchor" href="#重复读与幻读"></a>重复读与幻读</h2>
<p>重复读是为了保证在一个事务中，相同查询条件下读取的数据值不发生改变，但是不能保证下次同样条件查询，结果记录数不会增加。</p>
<p>幻读就是为了解决这个问题而存在的，他将这个查询范围都加锁了，所以就不能再往这个范围内插入数据，这就是SERIALIZABLE 隔离级别做的事情。</p>
<h2 id="隔离级别与锁的关系"><a class="header-anchor" href="#隔离级别与锁的关系"></a>隔离级别与锁的关系</h2>
<ol>
<li>在Read Uncommitted级别下，读操作不加S锁；</li>
<li>在Read Committed级别下，读操作需要加S锁，但是在语句执行完以后释放S锁；</li>
<li>在Repeatable Read级别下，读操作需要加S锁，但是在事务提交之前并不释放S锁，也就是必须等待事务执行完毕以后才释放S锁。</li>
<li>在Serialize级别下，会在Repeatable Read级别的基础上，添加一个范围锁。保证一个事务内的两次查询结果完全一样，而不会出现第一次查询结果是第二次查询结果的子集。</li>
</ol>
<p>（xnerv：SQL Server的四种隔离级别的加锁区别应该都只针对READ操作，如果是INSERT或UPDATE，应该都会加X锁并持有到事务结束。可以假设有一个RU级别的事务A修改了一行数据，另一个RC级别的事务B尝试读取这行数据。如果事务A不加X锁，或者修改完后在事务结束前释放X锁，都会导致事务B在事务A提交前读取到新数据而违反RC原则。）</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/four-isolation-levels-of-database-weak-consistency/">http://xnerv.wang/four-isolation-levels-of-database-weak-consistency/</a></strong><br>
转载自：<a href="http://www.cnblogs.com/xwdreamer/archive/2011/01/18/2297042.html">数据库弱一致性四个隔离级别</a></p>
]]></content>
      <categories>
        <category>DBMS</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>DBMS</tag>
        <tag>Transaction</tag>
        <tag>Isolation Level</tag>
      </tags>
  </entry>
  <entry>
    <title>深入探讨PageRank（一）：PageRank算法原理入门（转载）</title>
    <url>/further-disscusion-of-pagerank-1/</url>
    <content><![CDATA[<h2 id="一、PageRank简介"><a class="header-anchor" href="#一、PageRank简介"></a>一、PageRank简介</h2>
<p>大名鼎鼎的PageRank算法是Google排名运算法则（排名公式）的一个非常重要的组成部分，其用于衡量一个网站好坏的标准。在揉合了诸如Title、Keywords标识等所有其它因素之后，Google利用PageRank来调整网页的排名，使得“等级/重要性”的网页会相对排在前面。简单来说，Google通过下述几个步骤来实现网页在其搜索结果页面中排名：</p>
<ol>
<li>找到所有与搜索关键词匹配的网页</li>
<li>根据页面因素如标题、关键词密度等排列等级</li>
<li>计算导入链接的锚文本中关键词</li>
<li>通过PageRank得分调整网站排名结果</li>
</ol>
<p>事实上，真正的网站的排名过程并非这么简单，我们会在后面进行详细深入阐述。</p>
<span id="more"></span>
<p>PageRank于2001年9月被授予美国专利，专利人是Google创始人之一的拉里.佩奇（Larry Page）。所以，PageRank里面的Page并不是指网页，而是指佩奇<sub>PageRank对于网页重要性的级别分为1</sub>10级，10级为满级。PR值越高说明该网页越受欢迎，也即越重要。一个PR值为1的网站表明该网站不具备流行度，而PR值为<code>7~10</code>的网站则表明该网站是非常受欢迎的，或者说极其重要。一般PR值达到4，就算是一相当不错的网站了。Google把自己网站的PR值设置为<code>10~</code>类似里氏震级，PageRank级别并不是线性增长的，而是按照一种指数刻度，打个比方PageRank4比PageRank3虽然只是高了一级，但却在影响力上高上6~7倍，因此，一个PageRank5的网页和一个PageRank8的网页之间差距会比你可能认为的要大的多。</p>
<p>在讨论之前，先介绍两个概念：导入链接，又称逆向链接，是指链至你网站的站点，也就是我们一般所说的外部链接。而当你链至另外一个站点，那么这个站点就是你的导出链接，即你向其他网站提供本站的链接。</p>
<p>PageRank的思路很简单，打个比方：如何判断一篇论文的价值，即被其他论文引述的次数越多就越重要，如果被权威的论文引用，那么该论文也很重要。PageRank就是借鉴于这一思路，根据网站的外部链接和内部链接的数量和质量来衡量这个网站的价值，相当于每个到该页面的链接都是对该页面的一次投票，被链接的越多，就意味着被其他网站投票越多。这个就是所谓的链接流行度----衡量多少人愿意将他们的网站和你的网站挂钩。</p>
<p>搜索引擎网站排名算法中各排名因子的重要性取决于它们所提供信息的质量。但如果排名因子具有易操纵性，则往往会被一些网站管理员利用来实现不良竞争。例如初引入的排名因子之一----关键词元标识（Meta Keywords），是由于理论上它可以很好地概括反映一个页面的内容，但后来却由于一些网站管理员的恶意操纵而不得不黯然退出。</p>
<p>PageRank最初推出时针对的只是链接的数量，PageRank值较高的页面排名往往要比PageRank值较低的页面高，这导致了人们对于链接引用的着魔。在过去几年间，整个SEO社区人们忙于争夺、交换甚至销售链接，它是人们关注的焦点，所以被一些网站管理员钻了空子，利用链接工厂和访问簿大量低劣外部链接轻而易举地达到了自己的目的。Google意识到这个问题之后，便在系统中融合了对链接质量分析，开始放弃某些类型的链接，并对发现作弊的站点进行封杀，从而不但有效地打击了这种作法，而且保证了结果的和精准度。比如，被人们广泛接受的一条规定，来自缺乏内容的“link farm”（链接工厂）网站的链接将不会提供页面的PageRank，从PageRank较高的页面得到的链接但是内容不相差，比如说某个流行音乐网站链接到一个汽车网站就不会提供页面的PageRank。Google选择降低了对PageRank的更新频率，以便不鼓励人们不断地对其进行监测。</p>
<p>PageRank一般一年更新4次，所以刚上线不久的新网站是不可能获得PR值的。你的网站很有可能在相当长的时间内是看不到PR值的变化的，特别是一些新的网站。PR值暂时没有，这不是什么不好的事情，耐心等待就好~<br>
那么，我们如何知道一个网页的PageRank值呢？可以从<a href="http://toolbar.google.xn--comGoogle-sb6nla236hm36a15gg94b4m3in4xa">http://toolbar.google.com上下载安装Google工具栏</a>，这样就能显示所浏览网页的PageRank值了。若不能显示，可检查所安装版本号，需将老版本完全卸载，重启机器后安装最新版本即可<br>
为你的网站获得外部的链接是一件好事，但是无视其他SEO领域的工作而进行急迫的链接建设就是在浪费时间，要时刻保持一个整体思路并记住以下几点：</p>
<ol>
<li>Google的排名算法并不是完全基于外部链接的。</li>
<li>高PageRank并不能保证Google的高排名。</li>
<li>PageRank值更新的比较慢，今天看到的PageRank的值可能是三个月前的值。</li>
</ol>
<p>一般来说，网站排名因素包括网页的标题（META TITLE），网页正文中的关键词密度，锚文本（也叫链接文本，指链接或超链的文本内容）和PageRank所决定的。请记住：单靠PageRank是无法使你获得比较理想的网站排名的。PageRank只是网站排名算法中的一个乘积因子，若你网站的其它排名因子的得分是0，就算你的PageRank值是1个亿都木有用，最后得分还是0。但这并不是说PageRank就毫无价值，而是在什么情况下PageRank能够完全发挥其功力。</p>
<p>如果在Google上进行广泛搜索，看起来好象有几千个结果，但实际显示最多前1000项结果。例如对“car rental”，显示搜索结果为5,110,000，但实际显示结果只有826个。而且用时只有0.81秒。试想一下，0.84秒的时间就可以计算这五百万搜索结果的每个排名因子得分，然后给出最终我们所看到的网站排名结果吗？</p>
<p>答案就在于：搜索引擎选取与查询条件最相关的那些网页形成一个子集来加快搜索的速度。例如：假设子集中包含2000个元素，搜索引擎所做的就是使用排名因子中的两到三个因素对整个数据库进行查询，找到针对这两三个排名因子得分较高的前2000个网页。(请记住，虽然可能有五百多万搜索结果，但最终实际显示的1000项搜索结果却是从这个2000页的子集中提炼出来的。) 然后搜索引擎再把所有排名因子整合进这2000项搜索结果组成的子集中并进行相应的网站排名。由于按相性进行排序，子集中越靠后的搜索结果(不是指网页)相关性(质量)也就越低，所以搜索引擎只向用户显示与查询条件最相关的前1000项搜索结果。</p>
<p>请注意，在搜索引擎生成这2000项网页的子集中我们强调了“相关性”这个词。即搜索引擎找寻的是与查询条件有共同主题的网页。如果这时候我们把PageRank考虑进去，就很可能得到一些PageRank很高但主题只是略微相关的一些搜索结果。显然这有违搜索引擎为用户提供最为相关和精准的搜索结果的原则。</p>
<p>一旦理解了为什么会如此，就说明了为什么你应当首先努力在“页面”因子和锚文本上下足工夫，最后才是PageRank。所以关键在于：你必须首先在页面因素和/或锚文本上下足工夫，使这些排名因子能够获得足够的得分，从而使你的网站能够按目标关键词跻身于这2,000项搜索结果的子集中，否则PageRank再高也与事无补。</p>
<p>因此，我们不鼓励刻意地去追求PageRank，因为决定排名的因素可以有上百种。尽管如此，PageRank还是一个用来了解Google对你的网站页面如何评价的相当好的指标，建议网站设计者要充分认识PageRank在Google判断网站质量的重要作用，从设计前的考虑到后期网站更新都要给予PageRank足够的分析，很好的利用。我们要将PageRank看作一种业余爱好而不是一种信仰。</p>
<h2 id="二、PageRank原理"><a class="header-anchor" href="#二、PageRank原理"></a>二、PageRank原理</h2>
<p>通过对由超过50000万个变量和20亿个词汇组成的方程进行计算，PageRank能够对网页的重要性做出客观评价。PageRank并不计算直接链接的数量，而是将从网页A指向网页B的链接解释为由网页A对网页B所投的一票。这样，PageRank会根据网页B所收到的投票数量来评估该网页的重要性。此外，PageRank还会评估每个投票网页的重要性，因为某些重要网页的投票被认为具有较高的价值，这样，它所链接的网页就能获得较高的价值。这就是PageRank的核心思想，当然PageRank算法的实际实现上要复杂很多。</p>
<p>但是问题又来了，计算其他网页PageRank的值需要用到网页本身的PageRank值，而其他网页的PageRank值反过来又影响本网页的PageRank的值，这不就成了一个先有鸡还是先有蛋的问题了吗？Google的两个创始人拉里.佩奇（Larry Page）和谢耳盖.布林（Sergey Brin）把这个问题变成一个二维矩阵相乘的问题，并且用迭代的方法解决了这个问题。他们先假定所有网页的排名是相同的，并且根据这个初始值，算出各个网页的第一次迭代的排名，然后再根据第一次迭代排名算出第二次的排名。他们两人从理论上证明了不论初始值如何选取，这种算法都将能够保证了网页排名的估计值能够收敛到它们就有的真实值。值得一提的是，这种算法的执行是完全没有任何人工干预的。</p>
<p>理论问题解决了，但在实际的应用中，互联网上网页的数量是巨大的，上面提到的二维矩阵从理论上讲有网页数目平方之多个元素。如果我们假定有10亿个网页，那么这个矩阵就要有100亿亿个元素。这样大的矩阵相乘，计算量是非常之大。怎么办？怎么办？Larry和Sergey两利用稀疏矩阵计算的技巧，大大简化了计算量，并实现了这个网页排名算法。今天Google的工程师把这个算法移植移植到并行的计算机中，进一步缩短了计算的时间，使得网页的周期比以前短了许多。</p>
<p>网页排名的高明之处在于它把整个互联网当作了一个整体对等。它无意识中符合了系统论的观点。相比之下，之前的信息检索大多把每一个网页当作独立的个体对等，很多人当初只注意了网页的内容和查询语句的相差性，忽略了网页之间的关联。</p>
<p>今天，Google搜索引擎比最初复杂、完善了许多。但是网页的排名在Google所有算法中依然是到头重要的。在学术界，这个算法被公认为是文献检索中最大的贡献之一，并且被很多大学引入了信息检索课程的教程。</p>
<p>在计算网站排名时，PageRank会将网站的外部链接数考虑进去。并不能说一个网站的外部链接数越多其PR值就越高，如果这样的话，一个网站尽可能地获得最多的外部链接就OK了，这种想法是错误的。Google对一个网站上的外部链接数的重视程度并不意味着你因此可以不求策略与任何网站建立连接。这是因为Google并不是简单地由计算网站的外部链接数来决定其等级的。Google的PageRank系统不单考虑一个网站的外部链接数量，也会考虑其质量，这个问题看来很复杂。</p>
<p>首先来解释一下阻尼系数：当你投票或链接到另外一个站点时所获得的实际PR分值。阻尼系数一般是0.85。当然比起你网站的实际PR值，它就显得微不足道了。具体的PR值计算公式为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">PR(A) = (1 - d) + d (PR(t1) / C(t1) + … + PR(tn) / C(tn))</span><br></pre></td></tr></table></figure>
<p>其中，PR(A)表示从一个外部链接站点t1上，依据PageRank系统给你的网站所增加的PR值。PR(t1)表示该外部链接网站本身的PR值，C(t1)表示该外部链接站点所拥有的外部链接数量。大家要谨记：一个网站的投票权值只有该网站PR值的0.85倍。</p>
<p>必须要注意的一点是：PageRank不单考虑一个网站的外部链接质量，还需要考虑其数量。打个比方：对于网站X而言，网站Y是它唯一的一个外部链接，那么Google就相信网站X将网站Y视为它最好的一个外部链接，从而给网站Y更多的分值。可是，如果网站X上已经存在了49个外部链接，那么Google就相信网站X只是将网站Y视为它第50个好网站。因而一个网站上外部链接的数量越多，它所能够提供的PR值则会越低。如果一个PR值大于等于6的外部链接站点，可显著提升你的PR值。但如果这个外部链接站点已经有100个其它的外部链接时，那么你能够得到的PR值就几乎为0了。同样，如果一个外部链接站点PR值为2，但你却是它唯一一个外部链接，那么你所能够获得的PR值要远远大于那个PR值为6，外部链接数为100的网站。</p>
<p>影响Google PageRank的几个重要因素：</p>
<ol>
<li>与PR高的网站做链接</li>
<li>内容质量高的网站链接</li>
<li>加入搜索引擎分类目录</li>
<li>加入免费开源目录</li>
<li>你的链接出现在流量大、知名度高、频繁更新的重要网站上</li>
<li>Google对PDF格式的文件比较看重</li>
<li>域名和Title标题出现关键词与Meta标签等</li>
<li>反向链接数量和反向链接等级</li>
<li>Google抓取你网站的页面数量</li>
<li>导出链接数量</li>
</ol>
<p>PageRank和其他排名因子之间存在不同：网页Title标识仅能被列出一次；正文中出现的关键词连续的重复只会降低关键词的重要性，重要的是接近度；锚文本加权值极高，但存在上限，超过上限的锚文本信息将被忽略或降低权值；PageRank潜质无穷，没有上限的限制，但需要大量工作。除了PageRank外，其它排名因子都存在一个阙值，也叫临界值或差值。即当增长到一定值时，因子的重要性反而开始慢慢降低，则该值就是非PageRank因子的阙值。</p>
<p>设阙值为1000，如果网页A和B是我们对某一查询条件的其中两个查询结果，且A的总分数(包括页面因子得分和PageRank得分)是900，B是500，则显然A会排在B的前面。但由于A和B的分数均低于我们上面假设的非PageRank因子阙值，因而在不改变PageRank的情况下，我们可以通过对B页进行精心的页面优化使页面因子分数得到提高来使其排名超过A。但如果A的总得分升至1100分，则B若还只是一味优化页面因子是远远不够的。在这种情况下，提升PageRank就成为首要任务了。</p>
<p>一般说来，Google的查询结果页中既可能包含一些分数超过阙值的网页，也可能包含一些分数低于阙值的网页。所以为了提高竞争能力，必须在阙值范围内尽可能提高页面的搜索引擎排名得分，否则会降低页面的竞争力。“页面因子”是接近和达到阙值最迅捷的方式，它与PageRank的结合使用才是提升网站排名得分的最佳优化策略。阙值解释了搜索引擎商所遵循的原则和不同的实施途径，同时亦阐述了为什么会产生关于PageRank的一些误解。我们可以把这两种策略当成两个人A和B。</p>
<p>A认为“PageRank”并不重要。他们已有数年网页优化经验并知道如何完美地利用“页面因素”来达到优化的目的。他们亦理解基本的锚文本，但对PageRank得分毫不在意。结果如何呢？由于最大化地使用了“页面因子”，从而使A迅速达到“非PageRank因子的阙值”。所以通过精心选择关键词可使他们获得较好的网站排名。而且只要网站内容比较好，随着时间推移总会有排名高的站点链接，涓涓细流汇成河。A最后亦得到了PageRank得分，并籍此巩固了排名。</p>
<p>B认为“PageRank”十分重要。他掌握了很多关于提升PageRank得分的信息，并为提高该得分下足了工夫。结果又如何呢？B的做法和A相反，但A在非PageRank因子上下工夫，结果却得到了PageRank得分。而B在PageRank因子上下工夫，结果却得到非PageRank因子得分。究其原因，就是由于提高PageRank得分需要外部链接，链接又具有锚文本，从而通过精心挑选外部链接的锚文本，B自发提高了其非PageRank因子的得分，从而赢得了较高的PageRank得分。虽然这只是两个极端，但我们可以利用它们来推知这两种途径各自的优缺点：<br>
A：忽略PageRank  网站排名在短期内就可得到提升，自我生成链接节省了工作量，需投入大量工作维持网站排名，对新竞争者的应变速度较慢。<br>
B：忽略页面排名因子，可获得可靠网站排名，并可在需要时轻松修改页面因素使排名迅速提升，极可能从非搜索类引擎来源上获得更高访问量，网站排名提升较慢，操作难度较大，容易为SPAM过滤程序所制。</p>
<p>事实上，我们前面说过，最终排名得分=所有非PageRank因子实际得分x实际PageRank得分。亦即二者相辅相成，再加上随着网上营销方式的发展壮大，关键词的竞争也变的愈来愈激烈，这种情况下只靠非PageRank因子得到好排名显然是不可能的。而且非PageRank因子存在着阙值的局限性。同时，对于竞争性极高的关键词，还存在着PageRank下限的问题。也就是说，除非网站的PageRank得分超过这个下限标准，否则网站排名很难上去。PageRank的下限由关键词的竞争度所决定。竞争性一般的关键词PageRank下限也不高，而对竞争较为激烈的关键词来说，它所要求的PageRank下限相应就要高。而PageRank得分的提升又非常有难，这时候非PageRank因子就变的非常重要了。</p>
<p>综上所述：我们需要充分发挥各排名因子的优势来赢取理想的综合排名得分。同时关键词（竞争度适宜）的精心选择亦变的非常重要，它可以节省大量的支出。</p>
<h2 id="三、总结"><a class="header-anchor" href="#三、总结"></a>三、总结</h2>
<p>关于PageRank，最权威的发言人自然还是Google。虽然Google不会也不可能提供相关的技术信息，但我们亦可从中窥得一斑：</p>
<blockquote>
<p>Chris：PageRank的命名是基于“Page”，还是和某个创始人有关？<br>
Google：PageRank是以Google的联合创始人兼总裁Larry Page的名字命名的。<br>
Chris：Google是否把PageRank视做显著区别于其它搜索引擎的一个特性？<br>
Google：PageRank是一种能够使Google在搜索速度和搜索结果的相关性上区别于其它搜索引擎的技术。不唯如此，在排名公式中Google还使用了100种其它的算法。<br>
Chris：Google是否认为引入PageRank可以显著提高搜索结果的质量？以后是否仍将继续使用PageRank？<br>
Google：由于PageRank使用了量化方法来分析链接，所以它仍将是决定Google搜索结果页排名的一个重要因素。<br>
Chris：您认为Google工具栏上的PageRank的信息对普通用户/网站管理员/搜索引擎优化专家来说各有什么意义？<br>
Google：Google工具栏上所提供的PageRank信息仅作为一种网站评估信息使用。用户们会觉得它很有趣，网站管理员一般用它来衡量网站性能。不过，由于PageRank只是一个大体评估，所以对搜索引擎专家的价值并不大。<br>
Chris：常有网站试图通过“链接工厂”和访客簿的手段达到提升PageRank的目的。对这样的网站Google有什么举措？<br>
Google：Google的工程师会经常更新Google的排名算法以防止对Google排名的恶意操纵。</p>
</blockquote>
<p>选择导入链接时应首先考虑对方网站的内容如何，然后再考察其导出链接的数量进行决策。而在建立本站的导出链接时则应尽量使自己网站的PageRank维持在最大回馈和最小流失上。应确保合理的网站设计结构和内部联接方式。网站的结构和内部联接方式也会对PageRank产生影响，可利用其特性有效进行PagaRank在网站内部页面的再分布及尽可能保持网站整体的PageRank。网站的PageRank的提升应与该网站的访问者体验息息相关。即使获得再高的PageRank，如果没有客户访问，一样毫无价值。所以网站的内容始终是提升PageRank最关键的因素之一。</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/further-disscusion-of-pagerank-1/">http://xnerv.wang/further-disscusion-of-pagerank-1/</a></strong><br>
转载自：<a href="http://blog.csdn.net/monkey_d_meng/article/details/6554518">深入探讨PageRank（一）：PageRank算法原理入门</a></p>
]]></content>
      <categories>
        <category>搜索引擎</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>搜索引擎</tag>
        <tag>PageRank</tag>
      </tags>
  </entry>
  <entry>
    <title>深入探讨PageRank（二）：PageRank原理剖析（转载）</title>
    <url>/further-disscusion-of-pagerank-2/</url>
    <content><![CDATA[<p>关于PageRank的基础知识简介请参见博文：<a href="/further-disscusion-of-pagerank-2/">《深入探讨PageRank（一）：PageRank算法原理入门》</a>。</p>
<h2 id="一、PageRank算法的简单举例"><a class="header-anchor" href="#一、PageRank算法的简单举例"></a>一、PageRank算法的简单举例</h2>
<p>Google PageRank算法的思想精华在于：将一个网页级别/重要性的排序问题转化成了一个公共参与、以群体民主投票的方式求解的问题，网页之间的链接即被认为是投票行为。同时，各个站点投票的权重不同，重要的网站投票具有较大的分量，而该网站是否重要的标准还需要依照其PageRank值。这看似是一个矛盾的过程：即我们需要用PageRank值来计算PageRank值。</p>
<p>听起来有点不可思议，既像是递归，又像是迭代，似乎陷入了一个漩涡，Google的创始人佩奇和布林证明了这个过程最终收敛值与初始值无关。遗憾的是我一直都没有找到这个证明，甚至我把佩奇他们当年那篇论文找出来看也没有发现。</p>
<p>对于PageRank的收敛性，我们是可以找到反例的，这说明PageRank至少在某些情况下是不可能收敛的，或者说是收敛不完备的。在本文的第三部分，我们将PageRank的问题转化为了马尔可夫链的概率转移问题，其收敛性的证明也即转化为了马氏链的平稳分布是否存在的证明。我们先来看一个简单的例子：</p>
<span id="more"></span>
<p>Google PageRank取值范围是0<sub>10，为了叙述方便，我们使用0</sub>1的区间作为度量，这并不会影响我们对PageRank原理的剖析，并且在初始化的时候，我们假设所有网站的PageRank的值是均匀分布的。这意味着，如果有N个网站，那么每个网站的PageRank初始值都是1/N。现在假设有4个网站A、B、C、D，则它们的初始PageRank都是0.25，它们的链接关系如下：</p>
<center>
<img src="/assets/further-disscusion-of-pagerank-2/1.gif" />
</center>
<p>则初始值PR(A) = PR(B) = PR© = PR(D) = 0.25，又因为B、C、D都有指向A的链接，因此，它们每人都为A贡献了0.25的PageRank值，重新计算A的PageRank值为：PR(A) = PR(B) + PR© + PR(D) = 0.75，由于B、C和D并没有外部链接指向它们，因此PR(B)、PR©、PR(D)在这次计算中将被赋值为0。反复套用PageRank的计算公式，来看一下，这种情况下PageRank的收敛性，在第二次迭代之后，所有的PageRank值就都是0了：</p>
<table>
<thead>
<tr>
<th>PageRank</th>
<th>PR(A)</th>
<th>PR(B)</th>
<th>PR©</th>
<th>PR(D)</th>
</tr>
</thead>
<tbody>
<tr>
<td>初始值</td>
<td>0.25</td>
<td>0.25</td>
<td>0.25</td>
<td>0.25</td>
</tr>
<tr>
<td>第一次迭代后</td>
<td>0.75</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>第二次迭代后</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>我们来分析一下这个例子PageRank收敛的情况，由于没有网站链接到D，那么第一次迭代之后PR(D)=0，这将导致PR(B)=0，继而导致PR©=0和PR(A)=0。</p>
<p>现在来看第个例子，假设网站B还有C链接，网站D上有其他三个网站的链接。对于B而言的话，它把自己的总价值分散投给了A和C，各占一半的PageRank，即0.125，C和D的情况同理。即一个网站投票给其它网站PageRank的值，需要除以它所链接到的网站总数。此时PageRank的计算公式为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">PR(A) = PR(B) / 2 + PR(C) / 1 + PR(D) / 3</span><br><span class="line">PR(B) = PR(D) / 3</span><br><span class="line">PR(C) = PR(B) / 2 + PR(D) / 3</span><br><span class="line">PR(D) = 0</span><br></pre></td></tr></table></figure>
<center>
<img src="/assets/further-disscusion-of-pagerank-2/2.gif" />
</center>
<table>
<thead>
<tr>
<th>PageRank</th>
<th>PR(A)</th>
<th>PR(B)</th>
<th>PR©</th>
<th>PR(D)</th>
</tr>
</thead>
<tbody>
<tr>
<td>初始值</td>
<td>0.25</td>
<td>0.25</td>
<td>0.25</td>
<td>0.25</td>
</tr>
<tr>
<td>第一次迭代后</td>
<td>0.4583</td>
<td>0.0833</td>
<td>0.2083</td>
<td>0</td>
</tr>
<tr>
<td>第二次迭代后</td>
<td>0.25</td>
<td>0</td>
<td>0.0417</td>
<td>0</td>
</tr>
<tr>
<td>第三次迭代后</td>
<td>0.417</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>第四次迭代后</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>PageRank值计算过程的一般步骤可以概括如下：</p>
<ol>
<li>为每个网站设置一个初始的PageRank值。</li>
<li>第一次迭代：每个网站得到一个新的PageRank。</li>
<li>第二次迭代：用这组新的PageRank再按上述公式形成另一组新的PageRank。<br>
……</li>
</ol>
<p>当然，我们最关心的问题是，如此迭代下去，这些PageRank的值最终会收敛吗？我们上述的两个例子都是收敛的，但是不是所有情况都是如此呢？而且，上述例子中，我们发现，一旦某个页面的外部链接数目为0的话，那必然将导致全部网页最终收敛值为0。</p>
<h2 id="二、PageRank算法的“黑洞效应”"><a class="header-anchor" href="#二、PageRank算法的“黑洞效应”"></a>二、PageRank算法的“黑洞效应”</h2>
<p>为了讨论收敛性的问题，我们暂时抛开具体的网站，把问题做一个抽象化的描述，我们可以把网页之间的关联关系理解为是若干张有向图，图与图之间是互不连通的，那我们只考虑每一部分的收敛性，并不会影响其他部分的收敛性。我们考虑把边权值当作网站所传递的PageRank值，则对于任意一个顶点而言，其出边的权值之和必为1。</p>
<center>
<img src="/assets/further-disscusion-of-pagerank-2/3.gif" />
</center>
<p>一个很显然的结论是，如果连通图中有一个顶点的入度为0，则经过有限次迭代之后，该连通图内的所有顶点的PageRank均为0，形象的说，这个顶点就像一个黑洞一样，把整体的PageRank值慢慢地“吸收”了。由于它不对外贡献任何PR值，所以整体的PR总和是在不断地减少，直到最终收敛到0。我把它称之为：PageRank的“黑洞效应”。至于说Google是如何防止这种情况的发生，毕竟一个网站没有外链是完全有可能的，我也尚未找到确切的答案。不过网上道是有人给出了一种解决办法：即如果一个网站没有外链，那么就假定该连通图内其余所有的网点都是它的外链，这样我们就避免了整体PageRank值被吸收的现象。</p>
<p>当一个连通图内部每一个顶点入度均大于0时，不难看出，PR值在内部流通过程中，整体的PR值是守恒的。如果是存在一个顶点的入度为0呢？通过一次迭代，它的PR值就会变成0，而把它的那部分PR值贡献给了图中剩余的部分。所以，最终入度为0的顶点的PR值都将是0，而整体的PR仍然守恒。那么整体的PR值守恒就一定能够保证每个顶点的PR值最终会收敛吗？下面看一个简单的例子：</p>
<center>
<img src="/assets/further-disscusion-of-pagerank-2/4.gif" />
</center>
<p>按照之前的迭代步骤，会得到一个迭代的结果表。这将是一个无限循环，且不会收敛的过程。</p>
<table>
<thead>
<tr>
<th>PageRank</th>
<th>PR(A)</th>
<th>PR(B)</th>
<th>PR©</th>
<th>PR(D)</th>
</tr>
</thead>
<tbody>
<tr>
<td>初始值</td>
<td>0.25</td>
<td>0.25</td>
<td>0.25</td>
<td>0.25</td>
</tr>
<tr>
<td>第一次迭代后</td>
<td>0</td>
<td>0.375</td>
<td>0.25</td>
<td>0.375</td>
</tr>
<tr>
<td>第二次迭代后</td>
<td>0</td>
<td>0.375</td>
<td>0.375</td>
<td>0.25</td>
</tr>
<tr>
<td>第三次迭代后</td>
<td>0</td>
<td>0.25</td>
<td>0.375</td>
<td>0.375</td>
</tr>
<tr>
<td>第四次迭代后</td>
<td>0</td>
<td>0.375</td>
<td>0.25</td>
<td>0.375</td>
</tr>
<tr>
<td>第五次迭代后</td>
<td>0</td>
<td>…</td>
<td>…</td>
<td>…</td>
</tr>
</tbody>
</table>
<p>其实，同样的问题我们还可以换一个角度来考虑，因为本质上有向图和矩阵是可以相互转化的，令A[i][j]表示从顶点i到达顶点j的概率，那么目力的矩阵表示就是：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">0     0.5  0     0.5</span><br><span class="line">0     0     1     0</span><br><span class="line">0     0     0     1</span><br><span class="line">0     1     0     0</span><br></pre></td></tr></table></figure>
<p>而我们所给定的初始向量是：(0.25   0.25       0.25       0.25)，做第一次迭代，就相当于用初始向量乘以上面的矩阵。第二次迭代就相当于第一次迭代的结果再乘以上面的矩阵……实际上，在随机过程理论中，上述矩阵被称为“转移概率矩阵”。这种离散状态按照离散时间的随机转移过程称为马氏链（马尔可夫链，Markov Chain）。设转移概率矩阵为P，若存在正整数N，使得P^N&gt;0（每个元素大于0），这种链被称作正则链，它存在唯一的极限状态概率，并且与初始状态无关。</p>
<p>在这里，我们仅仅是非常简单地讨论了一下PageRank的原理，这与Google PageRank的实际算法实现相当甚远。域名数据、内容质量、用户数据、建站时间等都有可能被考虑进去，从而形成一个完善的算法。</p>
<p>当然，最让人惊叹的是，Google的PageRank能够应对互联网所产生的如此海量的网页信息和实时的变化，并能够在有限的时间内计算出所有网站的PageRank！这里面到底蕴涵着什么样的奥秘，我也会继续地追寻下去！</p>
<h2 id="三、PageRank算法的马尔科夫过程分析"><a class="header-anchor" href="#三、PageRank算法的马尔科夫过程分析"></a>三、PageRank算法的马尔科夫过程分析</h2>
<p>从第二节的陈述中我们知道，事实上，PageRank值在转移过程中变化规律是完全可以用马尔科夫的状态转移来进行表征的，两者本质属于同一个问题。则当PageRank值收敛时，即为马尔可科夫链达到平衡分布。推荐大家去读《随机过程》的教材，这里不在详细地讨论马氏链的内容，只给出相应的结论。<br>
为了形象说明马氏链，这里举一个例子。假设一{A, B, C}为马氏链，其转移概率矩阵如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">0.7         0.1         0.2</span><br><span class="line">0.1         0.8         0.1</span><br><span class="line">0.05       0.05       0.9</span><br></pre></td></tr></table></figure>
<p>因为该马氏链是不可约的非周期的有限状态，平稳分布存在，则我们要求其平衡分布为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">X = 0.7X + 0.1Y + 0.05Z</span><br><span class="line">Y = 0.1X + 0.8Y + 0.05Z</span><br><span class="line">Z = 0.2X + 0.1Y + 0.9Z</span><br><span class="line">X + Y + Z = 1</span><br></pre></td></tr></table></figure>
<p>解得上述方程组的平稳分布为：X = 0.1765，Y = 0.2353，Z = 0.5882。</p>
<p>既然，说我们把PageRank收敛性问题转化为了求马尔可夫链的平稳分布的问题，那么我们就可以从马氏链的角度来分析问题。因此，对于PageRank的收敛性问题的证明也就迎刃而解了，只需要证明马氏链在什么情况下才会出现平稳分布即可。我们可以知道马氏链有三个推论：<br>
推论1. 有限状态的不可约非周期马尔可夫链必存在平稳分布。<br>
推论2. 若不可约马尔可夫链的所有状态是非常返或零常返的，则不存在平稳分布。<br>
推论3. 若{Xi}是不可约的非周期马氏链的平稳分布，则lim(n→∞)Pj(n) = Xi。</p>
<p>上面的三个推论看不懂不要紧，找本《随机过程》的书就明白了，这里不再详细讨论了。既然问题得以转化，那么我们还计算一个实例，看看PageRank是如何工作的。假设这里有相互链接关系的7个HTML网页，并且HTML网页之间的链接关系闭合于这1~7个网页中，也即是说，除了这些网页之外，没有任何链接的出入。</p>
<center>
<img src="/assets/further-disscusion-of-pagerank-2/5.gif" />
</center>
<p>那么我们可以很容易地将这个链接关系使用数学的方式表示出来。首先，分析链接的关系，列举出各个链接源的ID及其所链接的目标ID。<br>
链接源I D 链接目标 ID</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1                   2,3 ,4,5, 7</span><br><span class="line">2                   1</span><br><span class="line">3                   1,2</span><br><span class="line">4                   2,3,5</span><br><span class="line">5                  1,3,4,6</span><br><span class="line">6                   1,5</span><br><span class="line">7                   5</span><br></pre></td></tr></table></figure>
<p>使用邻接矩阵的形式表述网页之间的链接关系，A[i][j]=1表示从i到j有链接，否则表示无链接，A为7*7的矩阵。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">A = [</span><br><span class="line">        0, 1, 1, 1, 1, 0, 1;</span><br><span class="line">        1, 0, 0, 0, 0, 0, 0;</span><br><span class="line">        1, 1, 0, 0, 0, 0, 0;</span><br><span class="line">        0, 1, 1, 0, 1, 0, 0;</span><br><span class="line">        1, 0, 1, 1, 0, 1, 0;</span><br><span class="line">        1, 0, 0, 0, 1, 0, 0;</span><br><span class="line">        0, 0, 0, 0, 1, 0, 0;</span><br><span class="line"> ]</span><br></pre></td></tr></table></figure>
<p>我们现假设，每个网页初始的PageRank均为1，则会形成一个初始的PageRank转移矩阵。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">A = [</span><br><span class="line">0,    1/5,        1/5,        1/5,        1/5,        0,    1/5;</span><br><span class="line">1,    0,           0,           0,           0,           0,    0;</span><br><span class="line">1/2, 1/2,        0,           0,           0,           0,    0;</span><br><span class="line">0,    1/3,        1/3,        0,           1/3,        0,    0;</span><br><span class="line">1/4, 0,           1/4,        1/4,        0,           1/4, 0;</span><br><span class="line">1/2, 0,           0,           0,           1/2,        0,    0;</span><br><span class="line">0,    0,           0,           0,           1,           0,    0;</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>这样的话，我们就可以按照求马氏链平稳分布的方式，求得PageRank收敛结果，方程组为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">X1 = X2 + X3 / 2 + X5 / 4 + X6 / 2</span><br><span class="line">X2 = X1 / 5 + X3 / 2 + X4 / 3</span><br><span class="line">X3 = X1 / 5 + X4 / 3 + X5 / 4</span><br><span class="line">X4 = X1 / 5 + X5 / 4</span><br><span class="line">X5 = X1 / 5 + X4 / 3 + X6 / 2 + X7</span><br><span class="line">X6 = X5 / 4</span><br><span class="line">X7 = X1 / 5</span><br><span class="line">X1 + X2 + X3 + X4 + X5 + X6 + x7 = 1</span><br></pre></td></tr></table></figure>
<p>解这个方程，最终我们得到每个网页的PageRank收敛值分别为：<br>
X1 = 0.303514，X2 = 0.38286，X3 = 0.32396，X4 = 0.24297，X5 = 0.41231，X6 = 0.10308，X7 = 0.13989。<br>
将PageRank的评价按顺序排列，小数点3位四舍五入，可以得到下表：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">名次 PageRank   文件ID   发出链接ID  被链接ID</span><br><span class="line">  1     0.304     1       2,3,4,5,7   2,3,5,6</span><br><span class="line">  2     0.179     5       1,3,4,6     1,4,6,7</span><br><span class="line">  3     0.166     2       1           1,3,4</span><br><span class="line">  4     0.141     3       1,2         1,4,5</span><br><span class="line">  5     0.105     4       2,3,5       1,5</span><br><span class="line">  6     0.061     7       5           1</span><br><span class="line">  7     0.045     6       1,5          5</span><br></pre></td></tr></table></figure>
<p>让我们详细地看一下。ID=1 的文件的 PageRank 是0.304，占据全体的三分之一，成为了第1位。特别需要说明的是，起到相当大效果的是从排在第3位的 ID=2 页面中得到了所有的 PageRank（0.166）数。ID=2页面有从3个地方过来的反向链接，而只有面向 ID=1页面的一个链接，因此（面向ID=1页面的）链接就得到了所有的 PageRank 数。不过，就因为 ID=1页面是正向链接和反向链接最多的页面，也可以理解它是最受欢迎的页面吧。</p>
<center>
<img src="/assets/further-disscusion-of-pagerank-2/6.gif" />
</center>
<p>依据上图的PageRank值，我们实际地试着计算一下PageRank的收支，只要将自各页的流入量单纯相加即可。譬如 ID=1 的流入量为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ID=1的流入量＝(ID=2发出的Rank)+(ID=3发出的Rank) + (ID=5发出的Rank) + (ID=6发出的Rank) = 0.166 + 0.141 / 2 + 0.179 / 4 + 0.045 / 2 = 0.30375</span><br></pre></td></tr></table></figure>
<p>在误差范围内PageRank的收支相符合。其他页面ID的情况也一样。以上的 PageRank 推移图正表示了这个收支。沿着各自的链接发出的PageRank等于此页面原有的PageRank除以发出链接数的值，而且和各自的页面的PageRank收支相平衡。</p>
<p>不过，这样绝妙均衡的本身，对理解线形代数的人来说当然不会是让人惊讶的事情。因为这正是“特性值和固有矢量的性质”，总之这样被选的数值的组就是固有矢量。以上就是 PageRank 的基本原理。 Google 做的就是大规模地处理这样的非常特性值问题。</p>
<p>PS：LZ系保研，由于没有参加考研，像《线性代数》、《随机过程》好多年没摸过了，很多知识都有所遗忘，所以写的不深入。本文的一些内容是参考了别人的博客，自己又加入了些新元素，算是做一次探讨。当然，接下来LZ会开始复习一下相关的数学知识，后续会重写本文，以便于让本文显得更为Strong~</p>
<p>参考的相关博客地址：<br>
<a href="http://www.charlesgao.com/?p=157">http://www.charlesgao.com/?p=157</a><br>
<a href="http://www.kreny.com/pagerank_cn.htm">http://www.kreny.com/pagerank_cn.htm</a></p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/further-disscusion-of-pagerank-2/">http://xnerv.wang/further-disscusion-of-pagerank-2/</a></strong><br>
转载自：<a href="http://blog.csdn.net/monkey_d_meng/article/details/6556295">深入探讨PageRank（二）：PageRank原理剖析</a></p>
]]></content>
      <categories>
        <category>搜索引擎</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>搜索引擎</tag>
        <tag>PageRank</tag>
      </tags>
  </entry>
  <entry>
    <title>深入探讨PageRank（四）：PageRank的危机及搜索引擎的未来（转载）</title>
    <url>/further-disscusion-of-pagerank-4/</url>
    <content><![CDATA[<p><strong>别到处找了，本系列文章没有（三）的。。。</strong></p>
<hr>
<p>作为10多年前搜索引擎代表性的技术成果之一，PageRank创造了Google辉煌的10年，同时也缔造了Google搜索的时代。然而，互联网越是往前发展，搜索服务越趋向于多元化、个性化、社区化和垂直化等，传统的通用搜索引擎越来越不能满足不同人群、不同习惯、不同场景的搜索需求，精而深的垂直搜索引擎的兴起对传统搜索市场引发了巨大的挑战。</p>
<p>正如同生物的生长一样，任何事物都是有其生命周期，PageRank也不例外。PageRank是否已经越过了它繁盛生命的顶锋？它是否能够担负起当今Web2.0，甚至是云计算时代的搜索排名之重任？我们慢慢来看~</p>
<span id="more"></span>
<h2 id="一、第二代搜索引擎的局限"><a class="header-anchor" href="#一、第二代搜索引擎的局限"></a>一、第二代搜索引擎的局限</h2>
<p>第二代搜索引擎是基于用户输入关键字做文本的相关性分析，通过排序算法（包含PageRank）将排序后的结果反馈给用户，其代表是Google和百度。大体而言，第二代搜索引擎的局限可概括为以下4个方面：</p>
<p><strong>（1）搜索结果不具备个性化因素，任何两个人得到的结果是一致的，没有考虑用户本身的搜索习惯。缺乏智能的感知体系，不能依据用户搜索偏好进行个性化的搜索推荐。</strong></p>
<p>在第二代搜索引擎中毋庸质疑的是任何两个人所享受到的搜索服务是完全一致的，不存在个性化的搜索。但是用户本身的搜索习惯是不同的，打个比方，一个从来不看江苏卫视《非诚勿扰》相亲节目的人，有一天突然在搜索栏中键入“非诚勿扰”，他更多地是想找《非诚勿扰》这部电影；然而对于一个经常在看这个相亲节目的人而言，搜索结果最好能够把江苏卫视的那个娱乐节目反馈给她。也就是说，不同的人在输入同样的关键词之后，所期待的输出结果是不同的，搜索引擎应该能够依据不同的人，反馈不同的搜索结果。</p>
<p>当然有人会说：我怎么知道是哪个用户在使用我的搜索引擎，嘿嘿<sub>问的好。Google可以发个公告说：Google搜索目前提供个性化搜索服务，使用的前提需要进行用户注册</sub>这并不是说面向大众的搜索服务不需要了，你还可以选择切换或自定义，想用个性就用，不想用还按常理出牌就可以了。我个人感觉这招还是挺吸引人的，当然，上面只是个原型的说辞，具体怎样推广就看Google的产品部那帮牛人怎么设计了。</p>
<p>既然，搜索引擎的发展必然是趋向于精细化、个性化的模式，不同用户应该享受和获得不同的搜索体验和搜索反馈。那么，如何才能make it to be true？本文第三部分会给出解释~</p>
<p><strong>（2）搜索内容是基本文本匹配的，搜索引擎本身并不理解你所输入的查询语句是什么意思，缺少语义分析。</strong></p>
<p>当前的搜索引擎的搜索过程全部是基于文本字符串匹配的，即先通过爬虫从互联网上下载数据，对数据进行清洗、格式化处理，对所有的文本内容分词，并创建倒排索引。用户输入检索词Query，搜索引擎会对Query分词，通过查找倒排索引表，返回与Query最相关的文本集合，利用PageRank算法排序后反馈给用户，但搜索引擎本身并不理解你所输入的Query是什么含义。</p>
<p>打个比方，比如你输入“愤怒的小狐狸是谁？”，搜索引擎就先分词为“愤怒”、“小”、“狐狸”、“是谁”，然后根据倒排索引表查找到底是哪些文档同时包含了这几个词条，排序后作为结果输出。然而，用户真正关心的是这只“愤怒的小狐狸”真人是谁，他并不需要知道哪些文档同时包含了这几个词，而只需要知道一个真实的人名即可。</p>
<p>这样的例子举不胜举，再比如说检索“华中科技大学计算机科学院董勐同学的个人信息”，则用户期待搜索引擎反馈给他一个整合的数据信息，包括了董勐同学的姓名、年龄、联系方式、生日、住址、兴趣爱好等等，而不是说只是简单地把找到包含这句话的网页给返回过来。</p>
<p>其实到这个时候，搜索引擎已经脱离了我们传统意义上理解的文本搜索引擎，而是能够智能地理解你要搜索的含义，并智能地生成你想要的结果。就像你跟一个真正的人在交流一样，你问他答，他在回答你话的同时，会根据他所储备的知识和信息推理演算你想要的结果，它是在思考问题，这属于问答式智能化的搜索引擎。</p>
<p><strong>（3）面向文本内容的搜索，对于多媒体类型内容，如图片、视频、音乐、影像的检索不给力或力不从心。</strong></p>
<p>在Web2.0时代，人们在互联网上所能接触、交流和分享的数据类型可谓琳琅满目，除了传统的文本信息外，多媒体的数据交互形式深受大众追捧。有例可考证像人人网、新浪微博这样的SNS网络，各种文本、视频、图片、音乐信息的共享铺天盖地。然而，搜索引擎在应对多媒体数据的时候总是显得非常的不给力或非常的力不从心。</p>
<p>这里面的原因，一方面是由于这些信息无法用自然语言量化或很难量化，另一方面是如果对多媒体文件进行细粒度的分析和建模，那对于存储、计算资源的消耗可以非常恐怖的，你想想一部高清电影有多少帧需要分析就明白了。</p>
<p>当然，不是没有办法做，现在是有一些基础性质的研究，其做法有点曲线救国的味道。以早期的Google图片搜索为例，你输入“海贼王”的话，搜索引擎实质上还是对文字的检索，返回的是打了“海贼王”标签的图片而已，本质上跟传统的文本搜索无异。如果是一张明明是“海贼王”里面乔巴的图片，你的标签描述写成了“茄菲猫”，那么即便它确实是“海贼王”也不可能被检索到。</p>
<p>如果你输入“即有蓝天、又有白云、即有溪水、又有远山、即有美女、又有竹筏、即有细雨、又有花伞的图片”，那么很抱歉，你将得到一大堆跟你想要的主题毫无关联的图片结果。因为现阶段基于标签的图片搜索与文本搜索是一样的，只能做到如此，它无法像人一样能够智能地识别某个图片是否是用户想要的。</p>
<p>目前，是有一些音频搜索的系统可以试用，可以对用户哼唱的曲目进行检索，但查准率还有待提升。Google刚刚推出了一项新的图片搜索服务，用户可以上传照片，Google能够检索与之类似的图片。我试了一下，在当前技术背景下，能够推出这样一款商用的图片搜索引擎，已经可以说是相当不错了，虽然说查准率还不是太高。</p>
<p>对于静态图片已经比较困难了，更不用说是动态的视频影像了。当然科技是在发展，相信未来10年之内的多媒体搜索技术肯定能够呈现一个爆炸性的发展趋势，这些个难题的求解并不是没有可能的，让我们拭目以待吧。</p>
<p><strong>（4）搜索结果排序依赖于人工智能，并没有考虑依靠真实用户的行为来引导和影响搜索结果的排序。</strong></p>
<p>PageRank虽然说是以网页之间民主投票的方式产生了网页的重要性/级别，但这毕竟是一种死板、单一的排序方式，并没有考虑到实际用户参与的情况，能不能有一种人直接参与、以人类集体智慧做引导的排序方法呢？</p>
<p>打个比方，当你检索“如何用U盘做引导盘”类似这种问问题的Query时，很多依据PageRank算出排名靠前的网页通常会让你无比失望，你点开一个一个又一个就是无法解决你的问题。然而，有可能你在刷了5、6页之后，偶然点开一个链接，却很轻易地解决了你的问题。这也就是说，按照PageRank排出来的结果未必真正是你所需要的。机器并不知道这个网页是否是真的好，它只是按照算法去一步步的执行而已，那么如何找到对网页质量更为智能的判定呢？</p>
<p>我这里提供一种思路：话说如果为每个页面质量设置一个打分器，问题是否会清楚化呢？对于一个页面而言，所有注册用户都可以打分。当用户输入Query时，搜索结果页面左侧还是会显示按照传统PageRank算法的排列项目，右侧则会显示出与此Query相似输入所产生的网页中用户打分较高的项目。</p>
<p>比如，我们可以这样说：对于“如何用U盘做引导盘”的检索，有100万的用户觉得网页A很赞，98万的用户觉得网页B很赞。如果你是一个用户的话，这样的搜索推荐对你有没有吸引力？那可是100万的人跟你输入同样问题的人都觉得很赞的网页啊！你说你会不会去点着试一下，你说你是去点PageRank排出来的页面，还是去点别人推荐的？这样我们就做到了依靠集体用户的智慧产生更为精确的结果推荐。当然，页面质量的评判还需要考虑到当前用户所输入的关键词，同一个页面对于不同的关键词而言，其质量也应该是有所不同的。</p>
<p>这个原型想法跟Facebook的那个“赞”按钮很相似，具体怎样去推广运营还没有过多的思考，毕竟咱也只是一个小小的程序员而已。</p>
<p>二、浮现出的第三代搜索引擎<br>
在看到pagerank的局限性以后，一些新兴的搜索公司开始尝试通过提供更精准、更个性化的搜索结果，目前关于第三代搜索引擎的商业化雏形或产品还是有一些的，我大概收集整理了一下：<br>
最近在美国颇受用户赞誉的另一个搜索引擎swicki，也在个性化和精准搜索方面可圈可点。虽然swicki的大部分内容来自Google，但同样针是对关键词，swicki可以根据用户注册时的使用偏好、搜索习惯，提供出不同的搜索结果。通过对搜索结果的二次评判，swicki还可以逐步校正搜索结果列表。<br>
在国内，除了类似bbmao这样的社会化搜索引擎开始提供自动分类、聚类、用户收藏等功能而崭露头角外，老牌搜索厂商雅虎中国，也在搜索算法和呈现方式上进行了诸多改进，不仅强化了对社区内容、blog等微内容的数据抓取，而且在个性化呈现、模糊搜索等方面也有较大举措。<br>
一个例子是，此前一个月，雅虎中国、雅虎全球、阿里巴巴三方联合推出了一个具有智能模糊匹配功能的搜索引擎——雅虎Imatch。据称，该系统可以根据用户的搜索习惯和意图，智能匹配相关的搜索结果。<br>
Clusty、bbmao等元搜索引擎的自动分类、聚类功能一出，即大受用户追捧，专家也认为其提供了比之Google更精准、细分的呈现方式，殊不知Clusty、bbmao等所提供的自动分类、聚类功能本身一点都不新鲜。早在10年前，英国的企业搜索巨擘Autonomy已经提供了同类乃至更智能的呈现方式。例如，Autonomy基于某种专有的模式匹配和概念搜索的算法，可以自动根据文本中的概念进行分类，自动标引，并基于用户兴趣自动匹配出个性化、多侧面的直接或隐含的相关档案。当用户在搜索框中键入某个关键词，出现的结果可能被系统自动分为10类（或更多类），若其中9类与用户的查询期望距离较大，用户就可以将接近的那个结果作为查询条件，进行第二次查询，直到找到最需要的搜索结果。而Google、百度等第二代搜索引擎则主要使用SVM和KNN算法进行分类，因为算法的先天缺陷，分类准确率仅能达到80%到85%。并且，如果分类树有变更，如增加、修改或删除某个分类节点，整颗分类树就必须重新学习。</p>
<h2 id="三、搜索引擎的未来：情景搜索？"><a class="header-anchor" href="#三、搜索引擎的未来：情景搜索？"></a>三、搜索引擎的未来：情景搜索？</h2>
<p>关于第三代搜索，众多的创新者已经为我们勾勒出一个大致的轮廓，作为对第二代搜索的一种超越，未来的搜索引擎发展套路将趋向于个性化、社会化、垂直化、知识问答化的方向。而搜索引擎的核心技术将从传统的索引结构转向包含数据挖掘、机器学习、人工智能、模式识别和语义分析等领域。</p>
<p>虽然迄今为止，计算机还无法做到完全理解语言，但通过采用基于统计学、概率论和信息论的概念识别技术，可以将信息和信息之间建立相应的关联规则。用户可以用自然语言描述自己的问题，搜索引擎会自动判断用户查询条件所描述的概念，借助于自身的知识库寻找与用户搜索概念相关的文档。显然，这种语义搜索比传统关键词搜索更能精准定位用户的搜索意图。</p>
<p>试想，为什么Google要做Chrome？抛开云计算、云操作系统不谈，其一个非常重要的原因在于，利用浏览器可以获取、分析用户对网站的访问行为，获取用户的操作历史记录，从而能够对PageRank算法规则形成补充。因为PageRank它只考虑了网页之间的链接关系来确定网页的级别/重要性，并未考虑用户具体检索的内容，用户检索的意图以及用户当前所处的环境。这说明PageRank并不是完美的，它确实存在些很多不完善的地方。</p>
<p>早在2009年，腾讯就提出了“情境搜索”的概念，目前基于这一概念诞生出了一系列的产品，比如QQ “表情搜索”、QQ的划词搜索、QQ聊天过程中会主动地帮你提取关键词并标明，点击后会触发信息检索。基于情境搜索更能贴近用户需求，搜索对用户来说将变得无处不在，如影随形。</p>
<p>打个比方，你在腾讯在线平台上关注或与好友讨论电影《让子弹飞》，情境搜索将自动挖掘你最关心的内容：效果最好的影院在哪？如何预订电影票？网友的评价如何？哪些好友支持这部电影？预告片和音乐在哪里下载？此时你甚至无需打开浏览器输入检索词，一次又一次的甄选结果。情境搜索通过深入挖掘用户的“情境”需求，深入地了解到你需要什么，他不仅会把需要的信息直接推送到你面前，还会整合在线预定、购买等后续服务，甚至可以帮你找到志同道合的“搜友”。</p>
<p>跟传统搜索引擎相比，情境搜索是基于用户历史、用户偏好、用户环境，计算用户情境搜索需求，进而提供信息融合及主动推送的搜索模式，传统的搜索则需要用户依靠用户键入关键词，并主动的触发检索过程。然而，很多时候，用户他并不清楚自己到底想要什么，他的信息量与知识面是有限的，与海量搜索引擎所掌握的信息是不对称的，甚至用户根本无法用语言或关键词来表述他的需求。</p>
<p>情境搜索则打破了这一弊端，综合考虑用户背景、兴趣爱好以及环境的智能化搜索，通过对用户意图的深入理解，在用户使用互联网服务的各种场景下提供给用户的最贴切的搜索服务。情境搜索包含7个要素（6W&amp;1H），它强调“以人（Who）为本”，也就是以用户为中心，根据其搜索行为的时间（When）、地点（Where）、输入（What）、需求（Want）、习惯（How）、背景（Why）等因素，由情境计算得到最适合的搜索结果，再将这一结果通过用户的搜索情境直接呈现。</p>
<p>Facebook的兴起，被视为Google的颠覆者。颠覆Google，不是在于Facebook流量已经超越了Facebook，也不在于Facebook的技术有很多强，而是Facebook对人的了解远远地超过Google，这对Google未来的搜索战略是极大的障碍。所以Google觊觎社交网站，更多是出于一种自卫的思想。</p>
<p>意识到危机的Google目前也提到了“情境”这个词，具体技术是“情境发现”（Contextual Discovery），据说2011年会有应用上线。这显然和PageRank体系的核心有很大区别。决定搜索结果及排序的规则，多出了很多维度，比如上下文关联、浏览习惯、搜索者所处的“情境”等。微软公司一直在研究一种叫“BrowserRank”的算法，其思路也是引入更多维的衡量模型，比如将用户在网站停留的时间作为考量标准之一。实际上，类似这种BrowserRank算法在腾讯等公司也早已经在应用了。</p>
<p>由此可见，随着情境搜索时代的来临，“人”的因素将在搜索技术中占据越来越重要的比重。换句话说，搜索服务商对“人”了解越深刻，对其所处环境了解越透彻，则其越能在情境搜索中占据主动。显然，拥有最海量用户群、最长停留时间、最深的互动关系、最强用户粘度的社交网络平台将在这一领域占得先机，代表的SNS如Facebook、人人网、新浪微博、QQ在线平台等。</p>
<p>以腾讯为例，其定位在提供“在线生活”平台，打造互联网一条龙的在线服务的战略发展方向，从即时通信的QQ、腾讯微博、QQ空间到Web QQ再到正在推行的腾讯开放平台，这几乎是100%的网民覆盖，这些都将为情境计算提供基础的信息源，从而衍生出智能化的搜索服务。现阶段，腾讯野心是占领移动平台，对于拥有庞大客户端和多年移动而已的腾讯来说，也是相当的如鱼得水。</p>
<p>Google曾经希望用户“找到信息，然后快速离开”，这句话在现在来看是非常荒谬的，而Google明显也已经意识到这一点了。所以Google也在通过iGoogle等手段将用户留下来，为未来的搜索演变做储备。</p>
<p>值得注意的是，“情境搜索”毕竟还处于初级阶段，更像是一种“搜索概念”，从传统搜索到它的演变过程将是缓慢、递进的过程。但是情境搜索发展的大趋势是无法阻挡的了的，传统的搜索服务将在这场历史变革中被逐步取代，而像PageRank这样的算法能否经受的住下一个时代搜索科技创新大风大浪的挑战？能否在搜索引擎发展的历史长河中沉淀下来？我们还需要拭目以待~</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/further-disscusion-of-pagerank-4/">http://xnerv.wang/further-disscusion-of-pagerank-4/</a></strong><br>
转载自：<a href="http://blog.csdn.net/monkey_d_meng/article/details/6558100">深入探讨PageRank（四）：PageRank的危机及搜索引擎的未来</a></p>
]]></content>
      <categories>
        <category>搜索引擎</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>搜索引擎</tag>
        <tag>PageRank</tag>
      </tags>
  </entry>
  <entry>
    <title>谷歌技术&quot;三宝&quot;之BigTable（转载）</title>
    <url>/google-3-gifts-bigtable/</url>
    <content><![CDATA[<p>2006年的OSDI有两篇google的论文，分别是BigTable和Chubby。Chubby是一个分布式锁服务，基于Paxos算法；BigTable是一个用于管理结构化数据的分布式存储系统，构建在GFS、Chubby、SSTable等google技术之上。相当多的google应用使用了BigTable，比如Google Earth和Google Analytics，因此它和<a href="/google-3-gifts-gfs/">GFS</a>、<a href="/google-3-gifts-mapreduce/">MapReduce</a>并称为谷歌技术&quot;三宝&quot;。</p>
<p>与GFS和MapReduce的论文相比，我觉得BigTable的论文难懂一些。一方面是因为自己对数据库不太了解，另一方面又是因为对数据库的理解局限于关系型数据库。尝试用关系型数据模型去理解BigTable就容易&quot;走火入魔&quot;。在这里推荐一篇文章（需要翻墙）：<a href="http://jimbojw.com/wiki/index.php?title=Understanding_Hbase_and_BigTable">Understanding HBase and BigTable</a>，相信这篇文章对理解BigTable/HBase的数据模型有很大帮助。</p>
<span id="more"></span>
<h2 id="1-什么是BigTable"><a class="header-anchor" href="#1-什么是BigTable"></a>1 什么是BigTable</h2>
<p>Bigtable是一个为管理大规模结构化数据而设计的分布式存储系统，可以扩展到PB级数据和上千台服务器。很多google的项目使用Bigtable存储数据，这些应用对Bigtable提出了不同的挑战，比如数据规模的要求、延迟的要求。Bigtable能满足这些多变的要求，为这些产品成功地提供了灵活、高性能的存储解决方案。</p>
<p>Bigtable看起来像一个数据库，采用了很多数据库的实现策略。但是Bigtable并不支持完整的关系型数据模型；而是为客户端提供了一种简单的数据模型，客户端可以动态地控制数据的布局和格式，并且利用底层数据存储的局部性特征。Bigtable将数据统统看成无意义的字节串，客户端需要将结构化和非结构化数据串行化再存入Bigtable。</p>
<p>下文对BigTable的数据模型和基本工作原理进行介绍，而各种优化技术（如压缩、Bloom Filter等）不在讨论范围。</p>
<h2 id="2-BigTable的数据模型"><a class="header-anchor" href="#2-BigTable的数据模型"></a>2 BigTable的数据模型</h2>
<p>Bigtable不是关系型数据库，但是却沿用了很多关系型数据库的术语，像table（表）、row（行）、column（列）等。这容易让读者误入歧途，将其与关系型数据库的概念对应起来，从而难以理解论文。<a href="http://jimbojw.com/wiki/index.php?title=Understanding_Hbase_and_BigTable">Understanding HBase and BigTable</a>是篇很优秀的文章，可以帮助读者从关系型数据模型的思维定势中走出来。</p>
<p>本质上说，Bigtable是一个键值（key-value）映射。按作者的说法，Bigtable是一个稀疏的，分布式的，持久化的，多维的排序映射。</p>
<p>先来看看多维、排序、映射。Bigtable的键有三维，分别是行键（row key）、列键（column key）和时间戳（timestamp），行键和列键都是字节串，时间戳是64位整型；而值是一个字节串。可以用 **(row:string, column:string, time:int64)→string **来表示一条键值对记录。</p>
<p>行键可以是任意字节串，通常有10-100字节。行的读写都是原子性的。Bigtable按照行键的字典序存储数据。Bigtable的表会根据行键自动划分为片（tablet），片是负载均衡的单元。最初表都只有一个片，但随着表不断增大，片会自动分裂，片的大小控制在100-200MB。行是表的第一级索引，我们可以把该行的列、时间和值看成一个整体，简化为一维键值映射，类似于：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">table&#123;</span><br><span class="line">  <span class="string">&quot;1&quot;</span> : &#123;sth.&#125;,<span class="comment">//一行</span></span><br><span class="line">  <span class="string">&quot;aaaaa&quot;</span> : &#123;sth.&#125;,</span><br><span class="line">  <span class="string">&quot;aaaab&quot;</span> : &#123;sth.&#125;,</span><br><span class="line">  <span class="string">&quot;xyz&quot;</span> : &#123;sth.&#125;,</span><br><span class="line">  <span class="string">&quot;zzzzz&quot;</span> : &#123;sth.&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>列是第二级索引，每行拥有的列是不受限制的，可以随时增加减少。为了方便管理，列被分为多个列族（column family，是访问控制的单元），一个列族里的列一般存储相同类型的数据。一行的列族很少变化，但是列族里的列可以随意添加删除。列键按照family:qualifier格式命名的。这次我们将列拿出来，将时间和值看成一个整体，简化为二维键值映射，类似于：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">table&#123;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">  <span class="string">&quot;aaaaa&quot;</span> : &#123; <span class="comment">//一行</span></span><br><span class="line">    <span class="string">&quot;A:foo&quot;</span> : &#123;sth.&#125;,<span class="comment">//一列</span></span><br><span class="line">    <span class="string">&quot;A:bar&quot;</span> : &#123;sth.&#125;,<span class="comment">//一列</span></span><br><span class="line">    <span class="string">&quot;B:&quot;</span> : &#123;sth.&#125; <span class="comment">//一列，列族名为B，但是列名是空字串</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">&quot;aaaab&quot;</span> : &#123; <span class="comment">//一行</span></span><br><span class="line">    <span class="string">&quot;A:foo&quot;</span> : &#123;sth.&#125;,</span><br><span class="line">    <span class="string">&quot;B:&quot;</span> : &#123;sth.&#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">或者可以将列族当作一层新的索引，类似于：</span><br><span class="line"><span class="string">``</span><span class="string">`javascript</span></span><br><span class="line"><span class="string">table&#123;</span></span><br><span class="line"><span class="string">  // ...</span></span><br><span class="line"><span class="string">  &quot;aaaaa&quot; : &#123; //一行</span></span><br><span class="line"><span class="string">    &quot;A&quot; : &#123; //列族A</span></span><br><span class="line"><span class="string">      &quot;foo&quot; : &#123;sth.&#125;, //一列</span></span><br><span class="line"><span class="string">      &quot;bar&quot; : &#123;sth.&#125;</span></span><br><span class="line"><span class="string">    &#125;,</span></span><br><span class="line"><span class="string">    &quot;B&quot; : &#123; //列族B</span></span><br><span class="line"><span class="string">      &quot;&quot; : &#123;sth.&#125;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">  &#125;,</span></span><br><span class="line"><span class="string">  &quot;aaaab&quot; : &#123; //一行</span></span><br><span class="line"><span class="string">    &quot;A&quot; : &#123;</span></span><br><span class="line"><span class="string">      &quot;foo&quot; : &#123;sth.&#125;,</span></span><br><span class="line"><span class="string">    &#125;,</span></span><br><span class="line"><span class="string">    &quot;B&quot; : &#123;</span></span><br><span class="line"><span class="string">      &quot;&quot; : &quot;ocean&quot;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">  &#125;,</span></span><br><span class="line"><span class="string">  // ...</span></span><br><span class="line"><span class="string">&#125;</span></span><br></pre></td></tr></table></figure>
<p>时间戳是第三级索引。Bigtable允许保存数据的多个版本，版本区分的依据就是时间戳。时间戳可以由Bigtable赋值，代表数据进入Bigtable的准确时间，也可以由客户端赋值。数据的不同版本按照时间戳降序存储，因此先读到的是最新版本的数据。我们加入时间戳后，就得到了Bigtable的完整数据模型，类似于：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">table&#123;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">  <span class="string">&quot;aaaaa&quot;</span> : &#123; <span class="comment">//一行</span></span><br><span class="line">    <span class="string">&quot;A:foo&quot;</span> : &#123; <span class="comment">//一列</span></span><br><span class="line">        <span class="number">15</span> : <span class="string">&quot;y&quot;</span>, <span class="comment">//一个版本</span></span><br><span class="line">        <span class="number">4</span> : <span class="string">&quot;m&quot;</span></span><br><span class="line">      &#125;,</span><br><span class="line">    <span class="string">&quot;A:bar&quot;</span> : &#123; <span class="comment">//一列</span></span><br><span class="line">        <span class="number">15</span> : <span class="string">&quot;d&quot;</span>,</span><br><span class="line">      &#125;,</span><br><span class="line">    <span class="string">&quot;B:&quot;</span> : &#123; <span class="comment">//一列</span></span><br><span class="line">        <span class="number">6</span> : <span class="string">&quot;w&quot;</span></span><br><span class="line">        <span class="number">3</span> : <span class="string">&quot;o&quot;</span></span><br><span class="line">        <span class="number">1</span> : <span class="string">&quot;w&quot;</span></span><br><span class="line">      &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>查询时，如果只给出行列，那么返回的是最新版本的数据；如果给出了行列时间戳，那么返回的是时间小于或等于时间戳的数据。比如，我们查询&quot;aaaaa&quot;/“A:foo”，返回的值是&quot;y&quot;；查询&quot;aaaaa&quot;/“A:foo”/10，返回的结果就是&quot;m&quot;；查询<span style="text-align:left">“aaaaa”/“A:foo”/2，返回的结果是空。</p>
<p><img src="/assets/google-3-gifts-bigtable/1.jpg" alt=""></p>
<p>图1是Bigtable论文里给出的例子，Webtable表存储了大量的网页和相关信息。在Webtable，每一行存储一个网页，其反转的url作为行键，比如<code>maps.google.com/index.html</code>的数据存储在键为<code>com.google.maps/index.html</code>的行里，反转的原因是为了让同一个域名下的子域名网页能聚集在一起。图1中的列族&quot;anchor&quot;保存了该网页的</span></span><span style="font-family:'Microsoft YaHei'">引用站点（比如引用了CNN主页的站点），qualifier是引用站点的名称，而数据是链接文本；列族&quot;contents&quot;保存的是网页的内容，这个列族只有一个空列&quot;contents:&quot;</span><span style="font-family:'Microsoft YaHei'">。图1中&quot;contents:&quot;列下保存了网页的三个版本，我们可以用(“com.cnn.www”, “contents:”, t5)来找到CNN主页在t5时刻的内容。</p>
<p>再来看看作者说的其它特征：稀疏，分布式，持久化。持久化的意思很简单，Bigtable的数据最终会以文件的形式放到GFS去。Bigtable建立在GFS之上本身就意味着分布式，当然分布式的意义还不仅限于此。稀疏的意思是，一个表里不同的行，列可能完完全全不一样。</p>
<h2 id="3-支撑技术"><a class="header-anchor" href="#3-支撑技术"></a>3 支撑技术</h2>
<p>Bigtable依赖于google的几项技术。用GFS来存储日志和数据文件；按SSTable文件格式存储数据；用Chubby管理元数据。</p>
<p>GFS参见<a href="/google-3-gifts-gfs/">谷歌技术&quot;三宝&quot;之谷歌文件系统</a>。BigTable的数据和日志都是写入GFS的。</p>
<p>SSTable的全称是Sorted Strings Table，是一种不可修改的有序的键值映射，提供了查询、遍历等功能。每个SSTable由一系列的块（block）组成，Bigtable将块默认设为64KB。在SSTable的尾部存储着块索引，在访问SSTable时，整个索引会被读入内存。BigTable论文没有提到SSTable的具体结构，<a href="http://www.samecity.com/blog/Article.asp?ItemID=100">LevelDb日知录之四： SSTable文件</a>这篇文章对LevelDb的SSTable格式进行了介绍，因为LevelDB的作者JeffreyDean正是BigTable的设计师，所以极具参考价值。每一个片（tablet）在GFS里都是按照SSTable的格式存储的，每个片可能对应多个SSTable。</p>
<p>Chubby是一种高可用的分布式锁服务，Chubby有五个活跃副本，同时只有一个主副本提供服务，副本之间用Paxos算法维持一致性，Chubby提供了一个命名空间（包括一些目录和文件），每个目录和文件就是一个锁，Chubby的客户端必须和Chubby保持会话，客户端的会话若过期则会丢失所有的锁。关于Chubby的详细信息可以看google的另一篇论文：<code>The Chubby lock service for loosely-coupled distributed systems</code>。Chubby用于片定位，片服务器的状态监控，访问控制列表存储等任务。</p>
<h2 id="4-Bigtable集群"><a class="header-anchor" href="#4-Bigtable集群"></a>4 Bigtable集群</h2>
<p>Bigtable集群包括三个主要部分：一个供客户端使用的库，一个主服务器（master server），许多片服务器（tablet server）。</p>
<p>正如数据模型小节所说，Bigtable会将表（table）进行分片，片（tablet）的大小维持在<code>100-200MB</code>范围，一旦超出范围就将分裂成更小的片，或者合并成更大的片。每个片服务器负责一定量的片，处理对其片的读写请求，以及片的分裂或合并。片服务器可以根据负载随时添加和删除。这里片服务器并不真实存储数据，而相当于一个连接Bigtable和GFS的代理，客户端的一些数据操作都通过片服务器代理间接访问GFS。</p>
<p>主服务器负责将片分配给片服务器，监控片服务器的添加和删除，平衡片服务器的负载，处理表和列族的创建等。注意，主服务器不存储任何片，不提供任何数据服务，也不提供片的定位信息。</p>
<p>客户端需要读写数据时，直接与片服务器联系。因为客户端并不需要从主服务器获取片的位置信息，所以大多数客户端从来不需要访问主服务器，主服务器的负载一般很轻。</p>
<h2 id="5-片的定位"><a class="header-anchor" href="#5-片的定位"></a>5 片的定位</h2>
<p>前面提到主服务器不提供片的位置信息，那么客户端是如何访问片的呢？来看看论文给的示意图，Bigtable使用一个类似B+树的数据结构存储片的位置信息。</p>
<p><img src="/assets/google-3-gifts-bigtable/2.jpg" alt=""></p>
<p>首先是第一层，Chubby file。这一层是一个Chubby文件，它保存着root tablet的位置。这个Chubby文件属于Chubby服务的一部分，一旦Chubby不可用，就意味着丢失了root tablet的位置，整个Bigtable也就不可用了。</p>
<p>第二层是root tablet。root tablet其实是元数据表（METADATA table）的第一个分片，它保存着元数据表其它片的位置。root tablet很特别，为了保证树的深度不变，root tablet从不分裂。</p>
<p>第三层是其它的元数据片，它们和root tablet一起组成完整的元数据表。每个元数据片都包含了许多用户片的位置信息。</p>
<p>可以看出整个定位系统其实只是两部分，一个Chubby文件，一个元数据表。注意元数据表虽然特殊，但也仍然服从前文的数据模型，每个分片也都是由专门的片服务器负责，这就是不需要主服务器提供位置信息的原因。客户端会缓存片的位置信息，如果在缓存里找不到一个片的位置信息，就需要查找这个三层结构了，包括访问一次Chubby服务，访问两次片服务器。</p>
<h2 id="6-片的存储和访问"><a class="header-anchor" href="#6-片的存储和访问"></a>6 片的存储和访问</h2>
<p>片的数据最终还是写到GFS里的，片在GFS里的物理形态就是若干个SSTable文件。图5展示了读写操作基本情况。</p>
<p><img src="/assets/google-3-gifts-bigtable/3.jpg" alt=""></p>
<p>当片服务器收到一个写请求，片服务器首先检查请求是否合法。如果合法，先将写请求提交到日志去，然后将数据写入内存中的memtable。memtable相当于SSTable的缓存，当memtable成长到一定规模会被冻结，Bigtable随之创建一个新的memtable，并且将冻结的memtable转换为SSTable格式写入GFS，这个操作称为minor compaction。</p>
<p>当片服务器收到一个读请求，同样要检查请求是否合法。如果合法，这个读操作会查看所有SSTable文件和memtable的合并视图，因为SSTable和memtable本身都是已排序的，所以合并相当快。</p>
<p>每一次minor compaction都会产生一个新的SSTable文件，SSTable文件太多读操作的效率就降低了，所以Bigtable定期执行merging compaction操作，将几个SSTable和memtable合并为一个新的SSTable。BigTable还有个更厉害的叫major compaction，它将所有SSTable合并为一个新的SSTable。</p>
<p>遗憾的是，BigTable作者没有介绍memtable和SSTable的详细数据结构。</p>
<h2 id="7-BigTable和GFS的关系"><a class="header-anchor" href="#7-BigTable和GFS的关系"></a>7 BigTable和GFS的关系</h2>
<p>集群包括主服务器和片服务器，主服务器负责将片分配给片服务器，而具体的数据服务则全权由片服务器负责。但是不要误以为片服务器真的存储了数据（除了内存中memtable的数据），数据的真实位置只有GFS才知道，主服务器将片分配给片服务器的意思应该是，片服务器获取了片的所有SSTable文件名，片服务器通过一些索引机制可以知道所需要的数据在哪个SSTable文件，然后从GFS中读取SSTable文件的数据，这个SSTable文件可能分布在好几台chunkserver上。</p>
<h2 id="8-元数据表的结构"><a class="header-anchor" href="#8-元数据表的结构"></a>8 元数据表的结构</h2>
<p>元数据表（METADATA table）是一张特殊的表，它被用于数据的定位以及一些元数据服务，不可谓不重要。但是Bigtable论文里只给出了少量线索，而对表的具体结构没有说明。这里我试图根据论文的一些线索，猜测一下表的结构。首先列出论文中的线索：</p>
<ol>
<li>The METADATA table stores the location of a tablet under a row key that is an encoding of the <code>tablet's table identifier</code> and its end row.</li>
<li>Each METADATA row stores approximately 1KB of data in memory（因为访问量比较大，元数据表是放在内存里的，这个优化在论文的locality groups中提到）.This feature（将locality group放到内存中的特性） is useful for small pieces of data that are accessed frequently: we use it internally for the location column family in the METADATA table.</li>
<li>We also store secondary information in the METADATA table, including a log of all events pertaining to each tablet(such as when a server begins serving it).</li>
</ol>
<p>第一条线索，元数据表的行键是由片所属表名的id和片最后一行编码而成，所以每个片在元数据表中占据一条记录（一行），而且行键既包含了其所属表的信息也包含了其所拥有的行的范围。譬如采取最简单的编码方式，元数据表的行键等于strcat(表名，片最后一行的行键)。</p>
<p>第二点线索，除了知道元数据表的地址部分是常驻内存以外，还可以发现元数据表有一个列族称为location，我们已经知道元数据表每一行代表一个片，那么为什么需要一个列族来存储地址呢？因为每个片都可能由多个SSTable文件组成，列族可以用来存储任意多个SSTable文件的位置。一个合理的假设就是每个SSTable文件的位置信息占据一列，列名为location:filename。当然不一定非得用列键存储完整文件名，更大的可能性是把SSTable文件名存在值里。获取了文件名就可以向GFS索要数据了。</p>
<p>第三个线索告诉我们元数据表不止存储位置信息，也就是说列族不止location，这些数据暂时不是咱们关心的。</p>
<p>通过以上信息，我画了一个简化的Bigtable结构图：<br>
<img src="/assets/google-3-gifts-bigtable/4.jpg" alt=""></p>
<p>结构图以Webtable表为例，表中存储了网易、百度和豆瓣的几个网页。当我们想查找百度贴吧昨天的网页内容，可以向Bigtable发出查询Webtable表的(com.baidu.tieba, contents:, yesterday)。</p>
<p>假设客户端没有该缓存，那么Bigtable访问root tablet的片服务器，希望得到该网页所属的片的位置信息在哪个元数据片中。使用METADATA.Webtable.com.baidu.tieba为行键在root tablet中查找，定位到最后一个比它大的是METADATA.Webtable.com.baidu.www，于是确定需要的就是元数据表的片A。访问片A的片服务器，继续查找Webtable.com.baidu.tieba，定位到Webtable.com.baidu.www是比它大的，确定需要的是Webtable表的片B。访问片B的片服务器，获得数据。</p>
<p>这里需要注意的是，每个片实际都由若干SSTable文件和memtable组成，而且这些SSTable和memtable都是已排序的。这就导致查找片B时，可能需要将所有SSTable和memtable都查找一遍；另外客户端应该不会直接从元数据表获得SSTable的文件名，而只是获得片属于片服务器的信息，通过片服务器为代理访问SSTable。</p>
<h2 id="参考文献"><a class="header-anchor" href="#参考文献"></a>参考文献</h2>
<p>[1] <code>Bigtable: A Distributed Storage System for Structured Data. In proceedings of OSDI'06</code>.<br>
[2] <a href="http://jimbojw.com/wiki/index.php?title=Understanding_Hbase_and_BigTable"></a><a href="http://jimbojw.com/wiki/index.php?title=Understanding_Hbase_and_BigTable">Understanding HBase and BigTable</a>.</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/google-3-gifts-bigtable/">http://xnerv.wang/google-3-gifts-bigtable/</a></strong><br>
转载自：<a href="http://blog.csdn.net/opennaive/article/details/7532589">谷歌技术&quot;三宝&quot;之BigTable</a></p>
]]></content>
      <categories>
        <category>分布式及存储</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>分布式及存储</tag>
        <tag>Google</tag>
        <tag>BigTable</tag>
      </tags>
  </entry>
  <entry>
    <title>谷歌技术&quot;三宝&quot;之谷歌文件系统（转载）</title>
    <url>/google-3-gifts-gfs/</url>
    <content><![CDATA[<p>题记：初学分布式文件系统，写篇博客加深点印象。GFS的特点是使用一堆廉价的商用计算机支撑大规模数据处理。<br>
虽然&quot;The Google File System &quot; 是03年发表的老文章了，但现在仍被广泛讨论，其对后来的分布式文件系统设计具有指导意义。然而，作者在设计GFS时，是基于过去很多实验观察的，并提出了很多假设作为前提，这等于给出了一个GFS的应用场景。所以我们自己在设计分布式系统时，一定要注意自己的应用场景是否和GFS相似，不能盲从GFS。</p>
<p>GFS的主要假设如下：</p>
<ol>
<li>GFS的服务器都是普通的商用计算机，并不那么可靠，集群出现结点故障是常态。因此必须时刻监控系统的结点状态，当结点失效时，必须能检测到，并恢复之。</li>
<li>系统存储适当数量的大文件。理想的负载是几百万个文件，文件一般都超过100MB，GB级别以上的文件是很常见的，必须进行有效管理。支持小文件，但不对其进行优化。</li>
<li>负载通常包含两种读：大型的流式读（顺序读），和小型的随机读。前者通常一次读数百KB以上，后者通常在随机位置读几个KB。</li>
<li>负载还包括很多连续的写操作，往文件追加数据（append）。文件很少会被修改，支持随机写操作，但不必进行优化。</li>
<li>系统必须实现良好定义的语义，用于多客户端并发写同一个文件。同步的开销必须保证最小。</li>
<li>高带宽比低延迟更重要，GFS的应用大多需要快速处理大量的数据，很少会严格要求单一操作的响应时间。</li>
</ol>
<p>从这些假设基本可以看出GFS期望的应用场景应该是大文件，连续读，不修改，高并发。国内的淘宝文件系统（TFS）就不一样，专门为处理小文件进行了优化。</p>
<span id="more"></span>
<h2 id="1-体系结构"><a class="header-anchor" href="#1-体系结构"></a>1 体系结构</h2>
<p>GFS包括一个master结点（元数据服务器），多个chunkserver（数据服务器）和多个client（运行各种应用的客户端）。在可靠性要求不高的场景，client和chunkserver可以位于一个结点。图1是GFS的体系结构示意图，每一结点都是普通的Linux服务器，GFS的工作就是协调成百上千的服务器为各种应用提供服务。</p>
<p><img src="/assets/google-3-gifts-gfs/1.jpg" alt=""></p>
<ul>
<li>chunkserver提供存储。GFS会将文件划分为定长数据块，每个数据块都有一个全局唯一不可变的id（chunk_handle），数据块以普通Linux文件的形式存储在chunkserver上，出于可靠性考虑，每个数据块会存储多个副本，分布在不同chunkserver。</li>
<li>GFS master就是GFS的元数据服务器，负责维护文件系统的元数据，包括命名空间、访问控制、文件-块映射、块地址等，以及控制系统级活动，如垃圾回收、负载均衡等。</li>
<li>应用需要链接client的代码，然后client作为代理与master和chunkserver交互。master会定期与chunkserver交流（心跳），以获取chunkserver的状态并发送指令。</li>
</ul>
<p>图1还描述了应用读取数据的流程。1.应用指定读取某个文件的某段数据，因为数据块是定长的，client可以计算出这段数据跨越了几个数据块，client将文件名和需要的数据块索引发送给master；2.master根据文件名查找命名空间和文件-块映射表，得到需要的数据块副本所在的地址，将数据块的id和其所有副本的地址反馈给client；3.client选择一个副本，联系chunkserver索取需要的数据；4.chunkserver返回数据给client。</p>
<h2 id="2-数据的布局"><a class="header-anchor" href="#2-数据的布局"></a>2 数据的布局</h2>
<p>GFS将文件条带化，按照类似RAID0的形式进行存储，可以提高聚合带宽。事实上，大多数分布式存储系统都会采取这种策略。GFS将文件按固定长度切分为数据块，master在创建一个新数据块时，会给每个数据块分配一个全局唯一且不可变的64位id。每个数据块以Linux文件的形式存储在chunkserver的本地文件系统里。</p>
<p>GFS为数据块设置了一个很大的长度，64MB，这比传统文件系统的块长要大多了。大块长会带来很多好处：1.减少client和master的交互次数，因为读写同一个块只需要一次交互，在GFS假设的顺序读写负载的场景下特别有用；2.同样也减少了client和chunkserver的交互次数，降低TCP/IP连接等网络开销；3.减少了元数据的规模，因此master可以将元数据完全放在内存，这对于集中式元数据模型的GFS尤为重要。</p>
<p>大数据块也有缺点。最大的缺点可能就是内部碎片了，不过考虑到文件一般都相当大，所以碎片也只存在于文件的最后一个数据块。还有一个缺点不是那么容易看出来，由于小文件可能只有少量数据块，极端情况只有一个，那么当这个小文件是热点文件时，存储该文件数据块的chunkserver可能会负载过重。不过正如前面所说，小文件不在GFS的优化范围。</p>
<p>为了提高数据的可靠性和并发性，每一个数据块都有多个副本。当客户端请求一个数据块时，master会将所有副本的地址都通知客户端，客户端再择优（距离最短等）选择一个副本。一个典型的GFS集群可能有数百台服务器，跨越多个子网，因此在考虑副本的放置时，不仅要考虑机器级别的错误，还要考虑整个子网瘫痪了该怎么办。将副本分布到多个子网去，还可以提高系统的聚合带宽。因此创建一个数据块时，主要考虑几个因素：1.优先考虑存储利用率低于平均水平的结点；2.限制单个结点同时创建副本的数量；3.副本尽量跨子网。</p>
<h2 id="3-元数据服务"><a class="header-anchor" href="#3-元数据服务"></a>3 元数据服务</h2>
<p>GFS是典型的集中式元数据服务，所有的元数据都存放在一个master结点内。元数据主要包括三种：文件和数据块的命名空间，文件-数据块映射表，数据块的副本位置。所有的元数据都是放在内存里的。</p>
<p>前两种元数据会被持久化到本地磁盘中，以操作日志的形式。操作日志会记录下这两种元数据的每一次关键变化，因此当master宕机，就可以根据日志恢复到某个时间点。日志的意义还在于，它提供了一个时间线，用于定义操作的先后顺序，文件、数据块的版本都依赖于这个时间顺序。</p>
<p>数据块的副本位置则没有持久化，因为动辄数以百计的chunkserver是很容易出错的，因此只有chunkserver对自己存储的数据块有绝对的话语权，而master上的位置信息很容易因为结点失效等原因而过时。取而代之的方法是，master启动时询问每个chunkserver的数据块情况，而且chunkserver在定期的心跳检查中也会汇报自己存储的部分数据块情况。</p>
<p>GFS物理上没有目录结构，也不支持链接操作，使用一张表来映射文件路径名和元数据。</p>
<h2 id="4-缓存和预取"><a class="header-anchor" href="#4-缓存和预取"></a>4 缓存和预取</h2>
<p>GFS的客户端和chunkserver都不会缓存任何数据，这是因为GFS的典型应用是顺序访问大文件，不存在时间局部性。空间局部性虽然存在，但是数据集一般很大，以致没有足够的空间缓存。</p>
<p>我们知道集中式元数据模型的元数据服务器容易成为瓶颈，应该尽量减少客户端与元数据服务器的交互。因此GFS设计了元数据缓存。client需要访问数据时，先询问master数据在哪儿，然后将这个数据地址信息缓存起来，之后client对该数据块的操作都只需直接与chunkserver联系了，当然缓存的时间是有限的，过期作废。</p>
<p>master还会元数据预取。因为空间局部性是存在，master可以将逻辑上连续的几个数据块的地址信息一并发给客户端，客户端缓存这些元数据，以后需要时就可以不用找master的麻烦了。</p>
<h2 id="5-出错了肿么办"><a class="header-anchor" href="#5-出错了肿么办"></a>5 出错了肿么办</h2>
<p>引用：“We treat component failures as the norm rather than the exception.&quot;<br>
分布式系统整体的可靠性是至关重要的。GFS集群使用的都是普通的商用计算机，而且机器的数量众多，设备故障经常出现，如何处理结点失效的问题是GFS最大的挑战。</p>
<h3 id="5-1-完整性"><a class="header-anchor" href="#5-1-完整性"></a>5.1 完整性</h3>
<p>GFS使用数以千计的磁盘，磁盘出错导致数据被破坏时有发生，我们可以用其它副本来恢复数据，但首先必须能检测出错误。chunksever会使用校验和来检测错误数据。每一个块（chunk）都被划分为64KB的单元（block），每个block对应一个32位的校验和。校验和与数据分开存储，内存有一份，然后以日志的形式在磁盘备一份。<br>
chunkserver在发送数据之前会核对数据的校验和，防止错误的数据传播出去。如果校验和与数据不匹配，就返回错误，并且向master反映情况。master会开始克隆副本的操作，完成后就命令该chunkserver删除非法副本。</p>
<h3 id="5-2-一致性"><a class="header-anchor" href="#5-2-一致性"></a>5.2 一致性</h3>
<p>一致性指的是master的元数据和chunkserver的数据是否一致，多个数据块副本之间是否一致，多个客户端看到的数据是否一致。</p>
<p>先来看看元数据一致性。GFS的命名空间操作是原子性的，并且用日志记录下操作顺序。虽然GFS没有目录结构，但是仍然有一颗逻辑的目录树，树的每个结点都有自己的读写锁，每个元数据操作都需要获得一系列的锁，应该是写锁会阻塞其它的锁，而读锁只阻塞写锁而不阻塞读锁。比如/home/user “目录” 正在创建快照，需要获得/home的读锁和/home/user的写锁，这时如果想创建文件/home/user/foo会被阻塞，因为需要获得/home、/home/user的读锁以及/home/user/foo的写锁，快照会阻塞创建操作获取/home/user的读锁。如果是在一个有传统目录树结构的文件系统里，创建一个文件需要修改父目录的数据，因此需要获得父目录的写锁。这种锁机制允许在一个目录里并发修改数据（如并发创建文件等），这在传统文件系统里是不允许的。</p>
<p><img src="/assets/google-3-gifts-gfs/2.jpg" alt=""></p>
<p>再来看看GFS是如何并发写（write）的，GFS必须将对数据块的修改同步到每一个副本。考虑一下多个应用同时修改同一数据块的情况，我们必须为修改操作定义统一的时序，不然多个副本会出现不一致的情况，那么定义时序由谁做呢？还记得前面提到的元数据缓存么，为了减少master的负担，client在获得副本位置后就不再和master交互，所以必然需要选出一个master代理来完成这个任务。事实上GFS采用了租约（lease）的机制，master会将租约授权给某个副本，称为primary，由这个primary来确定数据修改的顺序，其它副本照做就是。</p>
<p>图2是写操作的控制流和数据流：</p>
<ol>
<li>client需要更新一个数据块，询问master谁拥有该数据块的租约（谁是primary）；</li>
<li>master将持有租约的primary和其它副本的位置告知client，client缓存之；</li>
<li>client向所有副本传输数据，这里副本没有先后顺序，根据网络拓扑情况找出最短路径，数据从client出发沿着路径流向各个chunkserver，这个过程采用流水线（网络和存储并行）。chunkserver将数据放到LRU缓存；</li>
<li>一旦所有的副本都确定接受数据，client向primary发送写请求，primary为这个前面接受到的数据分配序列号（primary为所有的写操作分配连续的序列号表示先后顺序），并且按照顺序执行数据更新；</li>
<li>primary将写请求发送给其它副本，每个副本都按照primary确定的顺序执行更新；</li>
<li>其它副本向primary汇报操作情况；</li>
<li>primary回复client操作情况，任何副本错误都导致此次请求失败，并且此时副本处于不一致状态（写操作完成情况不一样）。client会尝试几次3到7的步骤，实在不行就只能重头来过了。</li>
</ol>
<p>如果一个写请求太大了或者跨越了chunk，GFS的client会将其拆分为多个写请求，每个写请求都遵循上述过程，但是可能和其它应用的写操作交叉在一起。所以这些写操作共享的数据区域就可能包含几个写请求的碎片（就是下文提到的undefined状态）。</p>
<p>GFS还提供另一种写操作append record，append只在文件的尾部以record为单位（为了避免内部碎片，record一般不会很大）写入数据。append是原子性的，GFS保证将数据顺序地写到文件尾部至少一次。append record的流程和图2类似，只是在primary有点区别，GFS必须保证一个record存储在一个chunk内，所以当primary判断当前chunk无足够空间时，就通知所有副本将chunk填充，然后汇报失败，client会申请创建新chunk并重新执行一次append record操作。如果该chunk大小合适，primary会将数据写到数据块的尾部，然后通知其它副本将数据写到一样的偏移。任何副本append失败，各个副本会处于不一致状态（完成或未完成），这时primary必然是成功写入的（不然就没有4以后的操作了）。客户端重试append record操作时，因为primary的chunk长度已经变化了，primary就必须在新的偏移写入数据，而其它副本也是照做。这就导致上一个失败的偏移位置，各个副本处于不一致状态，应用必须自己区分record正确与否，我称这为无效数据区。</p>
<p><img src="/assets/google-3-gifts-gfs/3.jpg" alt=""></p>
<p>表1说明了GFS的一致性保证，明白write和append操作后就容易理解了。consistent指的是多个副本之间是完全一致的；defined指的是副本数据修改后不仅一致而且client能看到其修改的数据全貌。</p>
<ul>
<li>成功的连续write是已定义的，各个副本数据一致；</li>
<li>成功的并发write能保证一致性性，即各个副本是一样的，但数据并不一定如用户所期望，如前所述，多个用户的修改可能交错在一起；</li>
<li>失败的write操作，使得副本之间不一致，而且数据undefined，不同client可能看到不同的数据（注意区别defined、undefined数据的方法）；</li>
<li>成功的append操作，不管是顺序还是并发都是defined，因为GFS保证了append是原子性的（atomically at least once）。有效数据区确实是defined的，但是失败append操作留下的无效数据区可能会有不一致的情况，所以中间可能零散分布着不一致的数据。</li>
</ul>
<p>如上所述，在primary的协调下，能保证并发write的一致性。但还有一些可能会导致数据不一致，比如chunkserver宕机错过了数据更新，这时就会出现新旧版本的数据，GFS为每个数据块分配版本来解决这个问题。master每次授权数据块租约给primary之前，都会增加数据块的版本号，并且通知所有副本更新版本号。客户端需要读数据时当然会根据这个版本号来判断副本的数据是否最新。</p>
<h2 id="5-3-可用性"><a class="header-anchor" href="#5-3-可用性"></a>5.3 可用性</h2>
<p>为了保证数据的可用性，GFS为每个数据块存储了多个副本，在数据的布局里有介绍，这里主要关注下元数据的可用性。</p>
<p>GFS是典型的集中式元数据模型，一个元数据服务器承担了巨大的压力，不仅有性能的问题，还有单点故障问题。master为了能快速从故障中恢复过来，采用了log和checkpoint技术，log记录了元数据的每一次变化。用咱们备份的话来说，checkpoint就相当于一次全量备份，log相当于连续数据保护，master宕机后，就先恢复到checkpoint，然后根据log恢复到最新状态。每次创建一个新的checkpoint，log就可以清空，这有效控制了log的大小。</p>
<p>这还不够，如果master完全坏了肿么办？GFS设置了“影子”服务器，master将日志备份到影子上，影子按照日志把元数据与master同步。如果master悲剧了，我们还有影子。平时正常工作时，影子可以分担一部分元数据访问工作，当然不提供直接的写操作。</p>
<h2 id="6-测试"><a class="header-anchor" href="#6-测试"></a>6 测试</h2>
<h3 id="6-1-模拟"><a class="header-anchor" href="#6-1-模拟"></a>6.1 模拟</h3>
<p><img src="/assets/google-3-gifts-gfs/4.jpg" alt=""></p>
<p>实验的网络拓扑图大概就是这样。集群包括一个master和它的两个影子，16个chunkserver，16个client，和两个HP交换机。两个交换机之间是1Gbps的链路，结点与交换机的链路是100Mbps。聚合带宽的理论上限是125MB/s，而单个client的理论带宽上限是12.5MB/s。</p>
<p><img src="/assets/google-3-gifts-gfs/5.jpg" alt=""></p>
<p>实验一：N个client同时随机各自读取1GB数据。<br>
图3(a)，x轴是N，y轴是聚合带宽，上面一条线是理论值，下面一条线是实际值。当N=1时，吞吐率是10MB/s，达到了理论值的80%。当N=16时，吞吐率是94MB/s，达到理论值的75%。此时瓶颈可能是在chunkserver，因为client数量很多，同时读一个chunkserver的概率很大。</p>
<p>实验二：N个client同时写N个不同文件，各自连续写1GB。<br>
图3(b)。理论值上限是67MB/s（The limit plateaus at 67 MB/s because we need to write each byte to 3 of the 16 chunkservers,<br>
each with a 12.5 MB/s input connection），这个理论值我没有看明白是怎么算的。当N=1，吞吐率是6.3MB/s，达到极限的一半，主要的瓶颈是数据在副本之间传递。N=16时，聚合带宽为35MB/s（每个client有2.2MB/s），达到极限的一半，这里chunkserver同时接受多个请求的情况比读更严重，因为得写3个副本。写比期望的要慢。</p>
<p>实验三：N个client同时向一个文件append record。<br>
图3©。理论上限值是一台chunkserver的带宽，即12.5MB/s。当N=1时，吞吐率有6.0MB/s。当N=16时，下降到4.8MB/s。这可能是因为拥塞。</p>
<h2 id="6-2-现实"><a class="header-anchor" href="#6-2-现实"></a>6.2 现实</h2>
<p>文章里还介绍了两个真实集群的使用情况，cluster A and B。</p>
<p><img src="/assets/google-3-gifts-gfs/6.jpg" alt=""></p>
<p>表2是两个集群的情况。A和B都有数百个chunkserver，存储利用率很高，冗余度是3，所以实际存储的数据是18TB和52TB。文件数相当，dead file是需要删除的文件，但还没被垃圾回收（GFS会为删除的文件保留三天才回收空间）。B的块数更多，意味着文件更大，不过A和B的文件平均都只有1到2个块。chunkserver的元数据主要是block（64KB）的校验和（4 Bytes），以及数据块的版本信息。master的元数据（文件和数据块的名字，文件-数据块映射，块位置等）相当小，平均每个文件只有100B元数据，大部分是用于存储文件名。平均下来，每个服务器有50~100MB的元数据。</p>
<h2 id="7-胡说八道"><a class="header-anchor" href="#7-胡说八道"></a>7 胡说八道</h2>
<p>画了个全分布式元数据模型。</p>
<p><img src="/assets/google-3-gifts-gfs/7.jpg" alt=""></p>
<p>这估计是最简单的，命名空间被划分为几个区域，master各管各的。为了可靠性，每个master做几个副本。映射方法可以是文件名计算哈希取模，好的哈希函数可以使文件随机分布，负载比较均衡。当然扩展性不是很好，加入新的结点，所有文件得重新映射。而且冗余度只能靠机器堆了，不能软件控制。</p>
<p><img src="/assets/google-3-gifts-gfs/8.jpg" alt=""></p>
<p>又构思了个复杂点的。将文件映射到r(&lt;=N)个master，利用参数r控制冗余度，当r=N时就变成全对等元数据集群。这个模型需要r个不同的哈希函数，为了减少开销，可以用两个函数模拟多个函数。比如有随机性很好的f(x)和g(x)函数，我们用式子f(x)+i*g(x)来模拟，其中i为非负整数。当我们处理文件x时，就用前面式子求出r个不同的位置（有冲突的概率，实际可能不止计算r次）。<br>
胡说八道，切勿当真；如有雷同，纯属巧合。</p>
<h2 id="参考文献："><a class="header-anchor" href="#参考文献："></a>参考文献：</h2>
<p>[1] The Google File System.</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/google-3-gifts-gfs/">http://xnerv.wang/google-3-gifts-gfs/</a></strong><br>
转载自：<a href="http://blog.csdn.net/opennaive/article/details/7483523">谷歌技术&quot;三宝&quot;之谷歌文件系统</a></p>
]]></content>
      <categories>
        <category>分布式及存储</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>分布式及存储</tag>
        <tag>Google</tag>
        <tag>GFS</tag>
      </tags>
  </entry>
  <entry>
    <title>谷歌技术&quot;三宝&quot;之MapReduce（转载）</title>
    <url>/google-3-gifts-mapreduce/</url>
    <content><![CDATA[<p><em>江湖传说永流传：谷歌技术有&quot;三宝&quot;，GFS、MapReduce和大表（BigTable）！</em></p>
<p>谷歌在03到06年间连续发表了三篇很有影响力的文章，分别是03年SOSP的GFS，04年OSDI的MapReduce，和06年OSDI的BigTable。SOSP和OSDI都是操作系统领域的顶级会议，在计算机学会推荐会议里属于A类。SOSP在单数年举办，而OSDI在双数年举办。</p>
<p>那么这篇博客就来介绍一下MapReduce。</p>
<span id="more"></span>
<h2 id="1-MapReduce是干啥的"><a class="header-anchor" href="#1-MapReduce是干啥的"></a>1. MapReduce是干啥的</h2>
<p>因为没找到谷歌的示意图，所以我想借用一张Hadoop项目的结构图来说明下MapReduce所处的位置，如下图。</p>
<p><img src="/assets/google-3-gifts-mapreduce/1.jpg" alt=""></p>
<p>Hadoop实际上就是谷歌三宝的开源实现，Hadoop MapReduce对应Google MapReduce，HBase对应BigTable，HDFS对应GFS。HDFS（或GFS）为上层提供高效的非结构化存储服务，HBase（或BigTable）是提供结构化数据服务的分布式数据库，Hadoop MapReduce（或Google MapReduce）是一种并行计算的编程模型，用于作业调度。</p>
<p>GFS和BigTable已经为我们提供了高性能、高并发的服务，但是并行编程可不是所有程序员都玩得转的活儿，如果我们的应用本身不能并发，那GFS、BigTable也都是没有意义的。MapReduce的伟大之处就在于让不熟悉并行编程的程序员也能充分发挥分布式系统的威力。</p>
<p>简单概括的说，MapReduce是将一个大作业拆分为多个小作业的框架（大作业和小作业应该本质是一样的，只是规模不同），用户需要做的就是决定拆成多少份，以及定义作业本身。</p>
<p>下面用一个贯穿全文的例子来解释MapReduce是如何工作的。</p>
<h2 id="2-例子：统计词频"><a class="header-anchor" href="#2-例子：统计词频"></a>2. 例子：统计词频</h2>
<p>如果我想统计下过去10年计算机论文出现最多的几个单词，看看大家都在研究些什么，那我收集好论文后，该怎么办呢？</p>
<p>方法一：我可以写一个小程序，把所有论文按顺序遍历一遍，统计每一个遇到的单词的出现次数，最后就可以知道哪几个单词最热门了。<br>
这种方法在数据集比较小时，是非常有效的，而且实现最简单，用来解决这个问题很合适。</p>
<p>方法二：写一个多线程程序，并发遍历论文。<br>
这个问题理论上是可以高度并发的，因为统计一个文件时不会影响统计另一个文件。当我们的机器是多核或者多处理器，方法二肯定比方法一高效。但是写一个多线程程序要比方法一困难多了，我们必须自己同步共享数据，比如要防止两个线程重复统计文件。</p>
<p>方法三：把作业交给多个计算机去完成。<br>
我们可以使用方法一的程序，部署到N台机器上去，然后把论文集分成N份，一台机器跑一个作业。这个方法跑得足够快，但是部署起来很麻烦，我们要人工把程序copy到别的机器，要人工把论文集分开，最痛苦的是还要把N个运行结果进行整合（当然我们也可以再写一个程序）。</p>
<p>方法四：让MapReduce来帮帮我们吧！<br>
MapReduce本质上就是方法三，但是如何拆分文件集，如何copy程序，如何整合结果这些都是框架定义好的。我们只要定义好这个任务（用户程序），其它都交给MapReduce。</p>
<p>在介绍MapReduce如何工作之前，先讲讲两个核心函数map和reduce以及MapReduce的伪代码。</p>
<h2 id="3-map函数和reduce函数"><a class="header-anchor" href="#3-map函数和reduce函数"></a>3. map函数和reduce函数</h2>
<p>map函数和reduce函数是交给用户实现的，这两个函数定义了任务本身。</p>
<ul>
<li>map函数：接受一个键值对（key-value pair），产生一组中间键值对。MapReduce框架会将map函数产生的中间键值对里键相同的值传递给一个reduce函数。</li>
<li>reduce函数：接受一个键，以及相关的一组值，将这组值进行合并产生一组规模更小的值（通常只有一个或零个值）。<br>
统计词频的MapReduce函数的核心代码非常简短，主要就是实现这两个函数。</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">map(String key, String value):</span><br><span class="line">    <span class="comment">// key: document name</span></span><br><span class="line">    <span class="comment">// value: document contents</span></span><br><span class="line">    <span class="keyword">for</span> each word w in value:</span><br><span class="line">        EmitIntermediate(w, <span class="string">&quot;1&quot;</span>);</span><br><span class="line"></span><br><span class="line">reduce(String key, Iterator values):</span><br><span class="line">    <span class="comment">// key: a word</span></span><br><span class="line">    <span class="comment">// values: a list of counts</span></span><br><span class="line">    <span class="type">int</span> <span class="variable">result</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> each v in values:</span><br><span class="line">        result += ParseInt(v);</span><br><span class="line">        Emit(AsString(result));</span><br></pre></td></tr></table></figure>
<p>在统计词频的例子里，map函数接受的键是文件名，值是文件的内容，map逐个遍历单词，每遇到一个单词w，就产生一个中间键值对<code>&lt;w, &quot;1&quot;&gt;</code>，这表示单词w咱又找到了一个；MapReduce将键相同（都是单词w）的键值对传给reduce函数，这样reduce函数接受的键就是单词w，值是一串&quot;1&quot;（最基本的实现是这样，但可以优化），个数等于键为w的键值对的个数，然后将这些“1”累加就得到单词w的出现次数。最后这些单词的出现次数会被写到用户定义的位置，存储在底层的分布式存储系统（GFS或HDFS）。</p>
<h2 id="4-MapReduce是如何工作的"><a class="header-anchor" href="#4-MapReduce是如何工作的"></a>4. MapReduce是如何工作的</h2>
<p><img src="/assets/google-3-gifts-mapreduce/2.jpg" alt=""></p>
<p>上图是论文里给出的流程图。一切都是从最上方的user program开始的，user program链接了MapReduce库，实现了最基本的Map函数和Reduce函数。图中执行的顺序都用数字标记了。</p>
<ol>
<li>MapReduce库先把user program的输入文件划分为M份（M为用户定义），每一份通常有16MB到64MB，如图左方所示分成了split0~4；然后使用fork将用户进程拷贝到集群内其它机器上。</li>
<li>user program的副本中有一个称为master，其余称为worker，master是负责调度的，为空闲worker分配作业（Map作业或者Reduce作业），worker的数量也是可以由用户指定的。</li>
<li>被分配了Map作业的worker，开始读取对应分片的输入数据，Map作业数量是由M决定的，和split一一对应；Map作业从输入数据中抽取出键值对，每一个键值对都作为参数传递给map函数，map函数产生的中间键值对被缓存在内存中。</li>
<li>缓存的中间键值对会被定期写入本地磁盘，而且被分为R个区，R的大小是由用户定义的，将来每个区会对应一个Reduce作业；这些中间键值对的位置会被通报给master，master负责将信息转发给Reduce worker。</li>
<li>master通知分配了Reduce作业的worker它负责的分区在什么位置（肯定不止一个地方，每个Map作业产生的中间键值对都可能映射到所有R个不同分区），当Reduce worker把所有它负责的中间键值对都读过来后，先对它们进行排序，使得相同键的键值对聚集在一起。因为不同的键可能会映射到同一个分区也就是同一个Reduce作业（谁让分区少呢），所以排序是必须的。</li>
<li>reduce worker遍历排序后的中间键值对，对于每个唯一的键，都将键与关联的值传递给reduce函数，reduce函数产生的输出会添加到这个分区的输出文件中。</li>
<li>当所有的Map和Reduce作业都完成了，master唤醒正版的user program，MapReduce函数调用返回user program的代码。</li>
</ol>
<p>所有执行完毕后，MapReduce输出放在了R个分区的输出文件中（分别对应一个Reduce作业）。用户通常并不需要合并这R个文件，而是将其作为输入交给另一个MapReduce程序处理。整个过程中，输入数据是来自底层分布式文件系统（GFS）的，中间数据是放在本地文件系统的，最终输出数据是写入底层分布式文件系统（GFS）的。而且我们要注意Map/Reduce作业和map/reduce函数的区别：Map作业处理一个输入数据的分片，可能需要调用多次map函数来处理每个输入键值对；Reduce作业处理一个分区的中间键值对，期间要对每个不同的键调用一次reduce函数，Reduce作业最终也对应一个输出文件。</p>
<p>我更喜欢把流程分为三个阶段。第一阶段是准备阶段，包括1、2，主角是MapReduce库，完成拆分作业和拷贝用户程序等任务；第二阶段是运行阶段，包括3、4、5、6，主角是用户定义的map和reduce函数，每个小作业都独立运行着；第三阶段是扫尾阶段，这时作业已经完成，作业结果被放在输出文件里，就看用户想怎么处理这些输出了。</p>
<h2 id="5-词频是怎么统计出来的"><a class="header-anchor" href="#5-词频是怎么统计出来的"></a>5. 词频是怎么统计出来的</h2>
<p><img src="/assets/google-3-gifts-mapreduce/3.jpg" alt=""></p>
<p>结合第四节，我们就可以知道第三节的代码是如何工作的了。假设咱们定义M=5，R=3，并且有6台机器，一台master。</p>
<p>这幅图描述了MapReduce如何处理词频统计。由于map worker数量不够，首先处理了分片1、3、4，并产生中间键值对；当所有中间值都准备好了，Reduce作业就开始读取对应分区，并输出统计结果。</p>
<h2 id="6-用户的权利"><a class="header-anchor" href="#6-用户的权利"></a>6. 用户的权利</h2>
<p>用户最主要的任务是实现map和reduce接口，但还有一些有用的接口是向用户开放的。</p>
<ul>
<li>an input reader。这个函数会将输入分为M个部分，并且定义了如何从数据中抽取最初的键值对，比如词频的例子中定义文件名和文件内容是键值对。</li>
<li>a partition function。这个函数用于将map函数产生的中间键值对映射到一个分区里去，最简单的实现就是将键求哈希再对R取模。</li>
<li>a compare function。这个函数用于Reduce作业排序，这个函数定义了键的大小关系。</li>
<li>an output writer。负责将结果写入底层分布式文件系统。</li>
<li>a combiner function。实际就是reduce函数，这是用于前面提到的优化的，比如统计词频时，如果每个&lt;w, “1”&gt;要读一次，因为reduce和map通常不在一台机器，非常浪费时间，所以可以在map执行的地方先运行一次combiner，这样reduce只需要读一次&lt;w, “n”&gt;了。</li>
<li>map和reduce函数就不多说了。</li>
</ul>
<h2 id="7-MapReduce的实现"><a class="header-anchor" href="#7-MapReduce的实现"></a>7. MapReduce的实现</h2>
<p>目前MapReduce已经有多种实现，除了谷歌自己的实现外，还有著名的hadoop，区别是谷歌是c++，而hadoop是用java。另外斯坦福大学实现了一个在多核/多处理器、共享内存环境内运行的MapReduce，称为Phoenix（介绍），相关的论文发表在07年的HPCA，是当年的最佳论文哦！</p>
<h2 id="参考文献"><a class="header-anchor" href="#参考文献"></a>参考文献</h2>
<p>[1] MapReduce : Simplified Data Processing on Large Clusters. In proceedings of OSDI’04.<br>
[2] Wikipedia. <a href="http://en.wikipedia.org/wiki/Mapreduce">http://en.wikipedia.org/wiki/Mapreduce</a><br>
[3] Phoenix. <a href="http://mapreduce.stanford.edu/">http://mapreduce.stanford.edu/</a><br>
[4] Evaluating MapReduce for Multi-core and Multiprocessor Systems. In proceedings of HPCA’07.</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/google-3-gifts-mapreduce/">http://xnerv.wang/google-3-gifts-mapreduce/</a></strong><br>
转载自：<a href="http://blog.csdn.net/opennaive/article/details/7514146">谷歌技术&quot;三宝&quot;之MapReduce</a></p>
]]></content>
      <categories>
        <category>分布式及存储</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>分布式及存储</tag>
        <tag>Google</tag>
        <tag>MapReduce</tag>
      </tags>
  </entry>
  <entry>
    <title>如果阿里月饼黑客事件发生在谷歌会怎样？前Google人亲述他抢了50件T-shirt的故事（转载）</title>
    <url>/google-50-tshirt/</url>
    <content><![CDATA[<p><em>本文作者吴卓浩，前Google中国用户体验团队负责人。微信公众号、知乎号：uxbang</em></p>
<p>2016年中秋节，被阿里的月饼门刷屏了。知乎上有人发起了讨论，“如果这样的事发生在Google会怎样”——如果也和阿里一样，我看着柜子里的差不多50件Google T-shirt，一头汗。</p>
<p>月饼事件的热闹，在于各种人都能从各种角度做各种分析评论。但是无论真相如何，上半场已经结束，希望那几位兄弟们吸取教训、但不要被吓怕，接下来的发展一定会有自己的精彩；而下半场才刚刚开始，对这几位兄弟来说是，对阿里，对整个行业，甚至对更大的体系，都是。</p>
<p>不论对于一个普通员工，还是对于一个公司的老大，公司 VS 个人，文化 VS 制度，永远是无法回避的问题，而且是没有标准解答的问题。比如，为了提高工作效率：</p>
<p>在一个初创公司中经常是没有标准流程的效率更高，而在一个大公司中是有标准流程效率更高；</p>
<p>在一个内容创作型的公司中，追随热点、快速响应的效率更高，而在一个产品研发型的公司中，做好计划、理清流程的效率更高；</p>
<p>在一个业务稳定成熟的公司中，以KPI推动工作效率更高，而在一个业务快速创新的公司中，以OKR推动工作效率更高；</p>
<span id="more"></span>
<p>创始人能力强，开始时亲力亲为效率高，可是如果不能接下来把中层建立培养起来，公司发展效率就不会高；</p>
<p>个别员工能力强，单兵作战效率高，可是如果不能把个体能力变为团队能力，团队战斗效率就不会高；</p>
<p>事事靠老大拿主意，眼前完成任务效率高，可是如果不能让员工形成独立思考能力，老大累死也不会得到真正的效率；</p>
<p>用制度管人，能马上见效的效率高，可是如果不能让员工形成文化上的认同和判断力，压力有多大反弹就会有多强；</p>
<p><img src="/assets/google-50-tshirt/1.jpg" alt="谁动了我的月饼"></p>
<p>公司本身也是一个产品，一个由创始人、员工、利益相关方、用户共同设计、不断迭代的产品，一直在路上、不断更成熟、永远不完美的产品。对我来说，如果在公司 中的人做的事情出了问题，无论是出于善意、恶意或者无意，首先需要反思的是公司的组织、制度、流程本身，最重要的是以此为契机改进公司本身。</p>
<p>过去的十多年，在我所服务或者创立的公司中，我也有不少请员工离开的经历，但每次都会深深自责反思，因为没有不合适的员工，只有不合适的工作，而把TA带进 来、放在不合适的位置上的人，是我。甚至当员工在工作上出现失误，造成公司不小的损失，我只会严肃的让员工明白事情的严重性、如何改进公司的系统来避免问 题再次发生，而损失由自己去承担，因为我能承担，而员工的经济状况无法承担。</p>
<p>在Google的面试中，除了对于工作能力的各项判断，最后还 有特别的一项：这个人是否Googley？Googley是Google自创的一个词，这个问题的含义是，这个人像不像Google人？对Googley 这个词，Google没有官方的定义，它具体的含义没人知道、却又人人明白；就像判例法，没有人去自上而下规定Google人应该怎么做，但是大家都互相 耳濡目染的学会要怎么做。</p>
<p>所以，当新来的刚毕业的大学生沉醉于零食间，没有人会去鄙视；当有人带朋友来蹭饭，公司提醒如果人多要提前和厨房 说、否则会影响到其他同事吃不上饭（接待旅游团，以此挣钱，显然是另一回事，这已经是靠出售公司资源谋私利，在任何文化下都不会被允许）。因为 Google人相信留在Google的同伴总归会变得Googley。</p>
<p>当员工为了抢每周补充的免费T-shirt，写程序、装监控摄像头， 是开放出一个邮件列表，让以此为乐的同事都能参与；当员工班车出现问题的时候，员工会自发组织起来，跨部门协作，以工程研发的方式做数据采集、写算法程 序，达成真正满足大多数人的解决方案。因为在Google，为全世界用户设计和开发产品，也正是这么做的呀！</p>
<p>开头所说的Google T-shirt，是我2006-2010年间收藏的，其实还不止这些，有的已经被亲朋好友强行索要走。Google有印制T-shirt庆祝产品上线或者 活动发布的文化，用户体验部门几乎是跨产品跨部门协作最多的，自然就获得了更多沾光的机会。每次整理这些T-shirt，都忍不住回想起背后的一个个人和 故事，心里暖暖的。这也是Google文化的强大之处，无论在不在Google，无论当时是因为什么原因离开Google，（曾经的）Google人都被 心中的Google文化仅仅团结在一起。</p>
<p>谢谢Google不会因为我抢了这么多T-shirt开除我！：）</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/google-50-tshirt/">http://xnerv.wang/google-50-tshirt/</a></strong><br>
转载自：<a href="https://www.techug.com/post/google-50-tshirt.html">如果阿里月饼黑客事件发生在谷歌会怎样？前Google人亲述他抢了50件T-shirt的故事</a></p>
]]></content>
      <categories>
        <category>程序员生活</category>
      </categories>
      <tags>
        <tag>程序员生活</tag>
        <tag>转载</tag>
        <tag>阿里月饼</tag>
      </tags>
  </entry>
  <entry>
    <title>(Google Developer) Protocol Buffers Encoding</title>
    <url>/google-protocol-buffers-encoding/</url>
    <content><![CDATA[<p>This document describes the binary wire format for protocol buffer messages. You don’t need to understand this to use protocol buffers in your applications, but it can be very useful to know how different protocol buffer formats affect the size of your encoded messages.</p>
<span id="more"></span>
<h2 id="A-Simple-Message"><a class="header-anchor" href="#A-Simple-Message"></a>A Simple Message</h2>
<p>Let’s say you have the following very simple message definition:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">message Test1 &#123;</span><br><span class="line">  required int32 a = 1;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>In an application, you create a <code>Test1</code> message and set <code>a</code> to 150. You then serialize the message to an output stream. If you were able to examine the encoded message, you’d see three bytes:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">08 96 01</span><br></pre></td></tr></table></figure>
<p>So far, so small and numeric – but what does it mean? Read on…</p>
<h2 id="Base-128-Varints"><a class="header-anchor" href="#Base-128-Varints"></a>Base 128 Varints</h2>
<p>To understand your simple protocol buffer encoding, you first need to understand <em>varints</em>. Varints are a method of serializing integers using one or more bytes. Smaller numbers take a smaller number of bytes.</p>
<p>Each byte in a varint, except the last byte, has the <em>most significant bit</em> (msb) set – this indicates that there are further bytes to come. The lower 7 bits of each byte are used to store the two’s complement representation of the number in groups of 7 bits, <strong>least significant group first</strong>.</p>
<p>So, for example, here is the number 1 – it’s a single byte, so the msb is not set:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">0000 0001</span><br></pre></td></tr></table></figure>
<p>And here is 300 – this is a bit more complicated:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1010 1100 0000 0010</span><br></pre></td></tr></table></figure>
<p>How do you figure out that this is 300? First you drop the msb from each byte, as this is just there to tell us whether we’ve reached the end of the number (as you can see, it’s set in the first byte as there is more than one byte in the varint):</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1010 1100 0000 0010</span><br><span class="line">→ 010 1100  000 0010</span><br></pre></td></tr></table></figure>
<p>You reverse the two groups of 7 bits because, as you remember, varints store numbers with the least significant group first. Then you concatenate them to get your final value:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">000 0010  010 1100</span><br><span class="line">→  000 0010 ++ 010 1100</span><br><span class="line">→  100101100</span><br><span class="line">→  256 + 32 + 8 + 4 = 300</span><br></pre></td></tr></table></figure>
<h2 id="Message-Structure"><a class="header-anchor" href="#Message-Structure"></a>Message Structure</h2>
<p>As you know, a protocol buffer message is a series of key-value pairs. The binary version of a message just uses the field’s number as the key – the name and declared type for each field can only be determined on the decoding end by referencing the message type’s definition (i.e. the <code>.proto</code> file).</p>
<p>When a message is encoded, the keys and values are concatenated into a byte stream. When the message is being decoded, the parser needs to be able to skip fields that it doesn’t recognize. This way, new fields can be added to a message without breaking old programs that do not know about them. To this end, the “key” for each pair in a wire-format message is actually two values – the field number from your <code>.proto</code> file, plus a <em>wire type</em> that provides just enough information to find the length of the following value.</p>
<p>The available wire types are as follows:</p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Meaning</th>
<th>Used For</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>Varint</td>
<td>int32, int64, uint32, uint64, sint32, sint64, bool, enum</td>
</tr>
<tr>
<td>1</td>
<td>64-bit</td>
<td>fixed64, sfixed64, double</td>
</tr>
<tr>
<td>2</td>
<td>Length-delimited</td>
<td>string, bytes, embedded messages, packed repeated fields</td>
</tr>
<tr>
<td>3</td>
<td>Start group</td>
<td>groups (deprecated)</td>
</tr>
<tr>
<td>4</td>
<td>End group</td>
<td>groups (deprecated)</td>
</tr>
<tr>
<td>5</td>
<td>32-bit</td>
<td>fixed32, sfixed32, float</td>
</tr>
</tbody>
</table>
<p>Each key in the streamed message is a varint with the value <code>(field_number &lt;&lt; 3) | wire_type</code> – in other words, the last three bits of the number store the wire type.</p>
<p>Now let’s look at our simple example again. You now know that the first number in the stream is always a varint key, and here it’s 08, or (dropping the msb):</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">000 1000</span><br></pre></td></tr></table></figure>
<p>You take the last three bits to get the wire type (0) and then right-shift by three to get the field number (1). So you now know that the tag is 1 and the following value is a varint. Using your varint-decoding knowledge from the previous section, you can see that the next two bytes store the value 150.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">96 01 = 1001 0110  0000 0001</span><br><span class="line">       → 000 0001  ++  001 0110 (drop the msb and reverse the groups of 7 bits)</span><br><span class="line">       → 10010110</span><br><span class="line">       → 2 + 4 + 16 + 128 = 150</span><br></pre></td></tr></table></figure>
<h2 id="More-Value-Types"><a class="header-anchor" href="#More-Value-Types"></a>More Value Types</h2>
<h3 id="Signed-Integers"><a class="header-anchor" href="#Signed-Integers"></a>Signed Integers</h3>
<p>As you saw in the previous section, all the protocol buffer types associated with wire type 0 are encoded as varints. However, there is an important difference between the signed int types (<code>sint32</code> and <code>sint64</code>) and the “standard” int types (<code>int32</code> and <code>int64</code>) when it comes to encoding negative numbers. If you use <code>int32</code> or <code>int64</code> as the type for a negative number, the resulting varint is <em>always ten bytes long</em> – it is, effectively, treated like a very large unsigned integer. If you use one of the signed types, the resulting varint uses ZigZag encoding, which is much more efficient.</p>
<p>ZigZag encoding maps signed integers to unsigned integers so that numbers with a small <em>absolute value</em> (for instance, -1) have a small varint encoded value too. It does this in a way that “zig-zags” back and forth through the positive and negative integers, so that -1 is encoded as 1, 1 is encoded as 2, -2 is encoded as 3, and so on, as you can see in the following table:</p>
<table>
<thead>
<tr>
<th>Signed Original</th>
<th>Encoded As</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>-1</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>2</td>
</tr>
<tr>
<td>-2</td>
<td>3</td>
</tr>
<tr>
<td>2147483647</td>
<td>4294967294</td>
</tr>
<tr>
<td>-2147483648</td>
<td>4294967295</td>
</tr>
</tbody>
</table>
<p>In other words, each value <code>n</code> is encoded using</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">(n &lt;&lt; <span class="number">1</span>) ^ (n &gt;&gt; <span class="number">31</span>)</span><br></pre></td></tr></table></figure>
<p>for <code>sint32</code>s, or</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">(n &lt;&lt; <span class="number">1</span>) ^ (n &gt;&gt; <span class="number">63</span>)</span><br></pre></td></tr></table></figure>
<p>for the 64-bit version.</p>
<p>Note that the second shift – the <code>(n &gt;&gt; 31)</code> part – is an arithmetic shift. So, in other words, the result of the shift is either a number that is all zero bits (if <code>n</code> is positive) or all one bits (if <code>n</code> is negative).</p>
<p>When the <code>sint32</code> or <code>sint64</code> is parsed, its value is decoded back to the original, signed version.</p>
<h3 id="Non-varint-Numbers"><a class="header-anchor" href="#Non-varint-Numbers"></a>Non-varint Numbers</h3>
<p>Non-varint numeric types are simple – <code>double</code> and <code>fixed64</code> have wire type 1, which tells the parser to expect a fixed 64-bit lump of data; similarly <code>float</code> and <code>fixed32</code> have wire type 5, which tells it to expect 32 bits. In both cases the values are stored in little-endian byte order.</p>
<h3 id="Strings"><a class="header-anchor" href="#Strings"></a>Strings</h3>
<p>A wire type of 2 (length-delimited) means that the value is a varint encoded length followed by the specified number of bytes of data.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">message Test2 &#123;</span><br><span class="line">  required string b = 2;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Setting the value of b to “testing” gives you:<br>
<code>12 07 <font color="red">74 65 73 74 69 6e 67</font></code></p>
<p>The red bytes are the UTF8 of “testing”. The key here is 0x12 → tag = 2, type = 2. The length varint in the value is 7 and lo and behold, we find seven bytes following it – our string.</p>
<h2 id="Embedded-Messages"><a class="header-anchor" href="#Embedded-Messages"></a>Embedded Messages</h2>
<p>Here’s a message definition with an embedded message of our example type, Test1:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">message Test3 &#123;</span><br><span class="line">  required Test1 c = 3;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>And here’s the encoded version, again with the Test1’s <code>a</code> field set to 150:<br>
<code>1a 03 <font color="red">08 96 01</font></code></p>
<p>As you can see, the last three bytes are exactly the same as our first example (<code>08 96 01</code>), and they’re preceded by the number 3 – embedded messages are treated in exactly the same way as strings (wire type = 2).</p>
<h2 id="Optional-And-Repeated-Elements"><a class="header-anchor" href="#Optional-And-Repeated-Elements"></a>Optional And Repeated Elements</h2>
<p>If a proto2 message definition has <code>repeated</code> elements (without the <code>[packed=true]</code> option), the encoded message has zero or more key-value pairs with the same tag number. These repeated values do not have to appear consecutively; they may be interleaved with other fields. The order of the elements with respect to each other is preserved when parsing, though the ordering with respect to other fields is lost. In proto3, repeated fields use <a href="#packed">packed encoding</a>, which you can read about below.</p>
<p>For any non-repeated fields in proto3, or <code>optional</code> fields in proto2, the encoded message may or may not have a key-value pair with that tag number.</p>
<p>Normally, an encoded message would never have more than one instance of a non-repeated field. However, parsers are expected to handle the case in which they do. For numeric types and strings, if the same field appears multiple times, the parser accepts the <em>last</em> value it sees. For embedded message fields, the parser merges multiple instances of the same field, as if with the <code>Message::MergeFrom</code> method – that is, all singular scalar fields in the latter instance replace those in the former, singular embedded messages are merged, and repeated fields are concatenated. The effect of these rules is that parsing the concatenation of two encoded messages produces exactly the same result as if you had parsed the two messages separately and merged the resulting objects. That is, this:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">MyMessage message;</span><br><span class="line">message.ParseFromString(str1 + str2);</span><br></pre></td></tr></table></figure>
<p>is equivalent to this:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">MyMessage message, message2;</span><br><span class="line">message.ParseFromString(str1);</span><br><span class="line">message2.ParseFromString(str2);</span><br><span class="line">message.MergeFrom(message2);</span><br></pre></td></tr></table></figure>
<p>This property is occasionally useful, as it allows you to merge two messages even if you do not know their types.</p>
<hr>
<p><strong>Article link: <a href="http://xnerv.wang/google-protocol-buffers-encoding/">http://xnerv.wang/google-protocol-buffers-encoding/</a></strong><br>
Reprinted from: <a href="https://developers.google.com/protocol-buffers/docs/encoding?hl=zh-CN">(Google Developer) Protocol Buffers: Encoding</a></p>
]]></content>
      <categories>
        <category>Protobuf</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Google</tag>
        <tag>Protobuf</tag>
        <tag>Google Developer</tag>
      </tags>
  </entry>
  <entry>
    <title>(Stack Overflow) HeapCreate, HeapAlloc in Linux, private allocator for Linux</title>
    <url>/heapcreate-heapalloc-in-linux-private-allocator-for-linux/</url>
    <content><![CDATA[<h2 id="Question"><a class="header-anchor" href="#Question"></a>Question</h2>
<p>In Windows, for very demanding applications, a programmer may use HeapCreate, HeapAlloc in order to better manage and control the allocation of memory- speed it up (aka private allocators). What is the equivalent in Linux c++ programming?</p>
<h2 id="Answer-by-psmears"><a class="header-anchor" href="#Answer-by-psmears"></a>Answer by psmears</h2>
<p>If you want to use your own private allocator, then use mmap() to map an amount of memory into your process, then you can use that memory as you like. Open a file descriptor to /dev/zero, and then use that as the ‘fildes’ parameter to mmap(). See man mmap for full details of the parameters to pass. In this respect mmap() plays the same role as HeapCreate().</p>
<hr>
<p><strong>Article link: <a href="http://xnerv.wang/heapcreate-heapalloc-in-linux-private-allocator-for-linux/">http://xnerv.wang/heapcreate-heapalloc-in-linux-private-allocator-for-linux/</a></strong><br>
Reprinted from: <a href="https://stackoverflow.com/q/2880639">(StackOverflow) HeapCreate, HeapAlloc in Linux, private allocator for Linux</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>OS</tag>
        <tag>Heap</tag>
        <tag>Linux</tag>
        <tag>Stack Overflow</tag>
        <tag>Memory Management</tag>
      </tags>
  </entry>
  <entry>
    <title>How does a mutex work? What does it cost?（转载）</title>
    <url>/how-does-a-mutex-work-what-does-it-cost/</url>
    <content><![CDATA[<p>Concurrent programming requires synchronization. We can’t have more than one thread accessing data at the same time; otherwise, we end up with a data race. The most common solution is to wrap the critical data access in a mutex. Mutexes are, of course, not free. A mutex can have a significant impact on the cost of the code we are writing. When used correctly we’ll barely notice the overhead. When misused it can cause a program to run worse in threaded mode than it would have single threaded!</p>
<span id="more"></span>
<blockquote>
<p>Also read <a href="https://wordpress.com/2010/11/18/cpu-memory-why-do-i-need-a-mutex/">CPU Memory – Why do I need a mutex?</a>.</p>
</blockquote>
<h3 id="What-is-a-mutex"><a class="header-anchor" href="#What-is-a-mutex"></a>What is a mutex?</h3>
<p>A mutex, in its most fundamental form, is just an integer in memory. This memory can have a few different values depending on the state of the mutex. Though usually when we speak of mutexes, we also talk of the locks which use the mutex. The integer in memory is not intriguing, but the operations around it are.</p>
<p>There are two fundamental operations which a mutex must provide to be useful:</p>
<ul>
<li>lock</li>
<li>unlock</li>
</ul>
<p><code>unlock</code> is a simple case since it’s usually just one function. Unlocking a mutex makes it available for another process to lock. <code>lock</code> on the other hand usually has several variants. In most cases, we’d like to wait until we can lock the mutex, so the most common lock operation does exactly this. Other users may wish to only wait for a given period, and yet some other users may not want to wait at all.</p>
<p>There can be only one lock on a mutex at any given time. If another thread wishes to gain control, it must wait for the first to unlock it. This <em>mutual exclusion</em> is the primary goal of the mutex, and indeed the origin of the name. Attempting to lock an already locked mutex is called contention. In a well-planned program, contention should be quite low; you should be designing your code so that most attempts to lock the mutex will not block.</p>
<p>There are two reasons why you want to avoid contention. The first is that any thread waiting on a mutex is obviously not doing anything else — possibly resulting in unused CPU cycles. The second reason is more interesting, in particular for high-performance code. Locking a currently unlocked mutex is cheap compared to the contention case. We have to look at how the mutex works to understand why.</p>
<h3 id="How-does-it-work"><a class="header-anchor" href="#How-does-it-work"></a>How does it work?</h3>
<p>As mentioned before, the data of a mutex is simply an integer in memory. Its value starts as 0, meaning that it is unlocked. If you wish to lock the mutex, you check if it is zero and then assign one. The mutex is now locked, and you are the owner of it.</p>
<p>The trick is that the test and set operation has to be atomic. If two threads happen to read 0 at the same time, then both would write 1 and think they own the mutex. Without CPU support there is no way to implement a mutex in user space: this operation must be atomic with respect to the other threads. Fortunately, CPUs has a function called “compare-and-set” or “test-and-set” which does exactly this. This function takes the address of the integer, and two integer values: a compare and set value. If the comparison value matches the current value of the integer then it is replaced with the new value. In C style code this might like look this:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">compare_set</span><span class="params">( <span class="type">int</span> * to_compare, <span class="type">int</span> compare, <span class="type">int</span> <span class="built_in">set</span> )</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> mutex_value;</span><br><span class="line"><span class="type">int</span> result = compare_set( &amp;mutex_value, <span class="number">0</span>, <span class="number">1</span> );</span><br><span class="line"><span class="keyword">if</span>( !result ) &#123; <span class="comment">/* we got the lock */</span> &#125;</span><br></pre></td></tr></table></figure>
<p>The caller determines what happens by inspecting the return value. It is the dereferenced <code>to_compare</code> pointer value before the swap. If this value is equal to the <code>compare</code> value the caller knows the set was successful. If the value is different, then the call was unsuccessful. When the section of code no longer requires the lock it can set the value back to 0. This makes up the basic part of our mutex.</p>
<blockquote>
<p>Atomic increment/decrement functions could also be used and are the recommended way if using the Linux <code>futex</code>.</p>
</blockquote>
<h3 id="What-about-waiting"><a class="header-anchor" href="#What-about-waiting"></a>What about waiting?</h3>
<p>Now comes the tricky part. Well, only in a way is it tricky, in another way it is simple. The above test-and-set mechanism provides no support for a thread to wait on the value (aside from a CPU intensive spin-lock). The CPU doesn’t really understand high-level threads and processes, so it isn’t in a position to implement waiting. The OS must provide the waiting functionality.</p>
<p>For the CPU to wait correctly, a caller is going to need to go through a system call. It is the only thing that can synchronize the various threads and provide the waiting functionality. So if we have to wait on a mutex, or release a waiting mutex, we have no choice but to call the OS. Most OSs have built in mutex primitives. In some cases, they provide full fledged mutexes. So if a system call does provide a full mutex why would we bother with any sort of test-and-set in user space? The answer is that system calls have quite a bit of overhead and should be avoided when possible.</p>
<p>Various operating systems diverge at this point, and will likely change as time goes on. Under Linux, there is a system call <code>futex</code> which provides mutex like semantics. Non-contention cases are resolved in user space. Contention cases are delegated to the operating system to handle in a safe, albeit far costlier manner. The waiting is handled as part of the OS process scheduler.</p>
<blockquote>
<p><code>futex</code> is quite flexible in allowing the creation of various locking mechanisms in addition to a mutex, such as a semaphore, a barrier, a read-write mutex, and event signaling.</p>
</blockquote>
<h3 id="The-Costs"><a class="header-anchor" href="#The-Costs"></a>The Costs</h3>
<p>There are a few points of interest when it comes to the cost of a mutex. The first most vital point is waiting time. Your threads should spend only a fraction of their time waiting on mutexes. If they are waiting too often, then you are losing concurrency. In a worst case scenario many threads always trying to lock the same mutex may result in performance worse than a single thread serving all requests. This isn’t a cost of the mutex itself, but a serious concern with concurrent programming.</p>
<p>The overhead costs of a mutex relate to the test-and-set operation and the system call that implements a mutex. The test-and-set is likely a minuscule cost; being essential to concurrent processing the CPUs have a strong incentive to make it efficient. We’ve ignored another important instruction, however: the fence. This is used in all high-level mutexes and may have a higher cost than the test-and-set operation. Most costly however is the system call. Not only do you suffer the context switch overhead of the system call, the kernel now spends some time in its scheduling code.</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/how-does-a-mutex-work-what-does-it-cost/">http://xnerv.wang/how-does-a-mutex-work-what-does-it-cost/</a></strong><br>
转载自：<a href="https://mortoray.com/2011/12/16/how-does-a-mutex-work-what-does-it-cost/">How does a mutex work? What does it cost?</a></p>
]]></content>
      <categories>
        <category>OS</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>OS</tag>
        <tag>Mutex</tag>
        <tag>Multi Threads</tag>
      </tags>
  </entry>
  <entry>
    <title>让 CPU 告诉你硬盘和网络到底有多慢（转载）</title>
    <url>/how-slow-is-disk-and-network/</url>
    <content><![CDATA[<h2 id="简介"><a class="header-anchor" href="#简介"></a>简介</h2>
<p>经常听到有人说磁盘很慢、网络很卡，这都是站在人类的感知维度去表述的，比如拷贝一个文件到硬盘需要几分钟到几十分钟，够我去吃个饭啦；而从网络下载一部电影，有时候需要几个小时，我都可以睡一觉了。</p>
<p>最为我们熟知的关于计算机不同组件速度差异的图表，是下面这种金字塔形式：越往上速度越快，容量越小，而价格越高。这张图只是给了我们一个直观地感觉，并没有对各个速度和性能做出量化的说明和解释。而实际上，不同层级之间的差异要比这张图大的多。这篇文章就让你站在 CPU 的角度看这个世界，说说到底它们有多慢。</p>
<p>希望你看到看完这篇文章能明白两件事情：磁盘和网络真的很慢，性能优化是个复杂的系统性的活。</p>
<p>注：所有的数据都是来自<a href="https://gist.github.com/hellerbarde/2843375">这个地址</a>。所有的数据会因为机器配置不同，或者硬件的更新而有出入，但是不影响我们直觉的感受。如果对这些数据比较感兴趣，<a href="https://people.eecs.berkeley.edu/~rcs/research/interactive_latency.html">这个网址</a>给出了不同年份一些指标的数值。</p>
<span id="more"></span>
<h2 id="数据"><a class="header-anchor" href="#数据"></a>数据</h2>
<ul>
<li>
<p>先来看看 CPU 的速度，就拿我的电脑来说，主频是 2.6G，也就是说每秒可以执行 2.6*10^9 个指令，每个指令只需要 0.38ns（现在很多个人计算机的主频要比这个高，配置比较高的能达到 3.0G+）。我们把这个时间当做基本单位 1s，因为 1s 大概是人类能感知的最小时间单位。<br>
<img src="/assets/how-slow-is-disk-and-network/1.jpg" alt=""></p>
</li>
<li>
<p>一级缓存读取时间为 0.5ns，换算成人类时间大约是 1.3s，大约一次或者两次心跳的时间。这里能看出缓存的重要性，因为它的速度可以赶上 CPU，程序本身的 locality 特性加上指令层级上的优化，cache 访问的命中率很高，这最终能极大提高效率。</p>
</li>
<li>
<p>分支预测错误需要耗时 5ns，换算成人类时间大约是 13s，这个就有点久了，所以你会看到很多文章分析如何优化代码来降低分支预测的几率，比如<a href="https://stackoverflow.com/questions/11227809/why-is-it-faster-to-process-a-sorted-array-than-an-unsorted-array">这个得分非常高的 stackoverflow 问题</a>。</p>
</li>
<li>
<p>二级缓存时间就比较久了，大约在 7ns，换算成人类时间大约是 18.2s，可以看到的是如果一级缓存没有命中，然后去二级缓存读取数据，时间差了一个数量级。</p>
</li>
</ul>
<p><strong>小知识</strong>：为什么需要多层的 CPU 缓存呢？<a href="https://fgiesen.wordpress.com/2016/08/07/why-do-cpus-have-multiple-cache-levels/">这篇文章通过一个通俗易懂的例子给出了讲解</a>。</p>
<ul>
<li>
<p>我们继续，互斥锁的加锁和解锁时间需要 25ns，换算成人类时间大约是 65s，首次达到了一分钟。并发编程中，我们经常听说锁是一个很耗时的东西，因为在微波炉里加热一个东西需要一分钟的话，你要在那傻傻地等蛮久了。</p>
</li>
<li>
<p>然后就到了内存，每次内存寻址需要 100ns，换算成人类时间是 260s，也就是4分多钟，如果读一些不需要太多思考的文章，这么久能读完2-3千字（这个快阅读的时代，很少人在手机上能静心多这么字了）。看起来还不算坏，不多要从内存中读取一段数据需要的时间会更多。到了内存之后，时间就变了一个量级，CPU 和内存之间的速度瓶颈被称为<a href="https://en.wikipedia.org/wiki/Von_Neumann_architecture#Von_Neumann_bottleneck">冯诺依曼瓶颈</a>。</p>
</li>
<li>
<p>一次 CPU 上下文切换（系统调用）需要大约 1500ns，也就是 1.5us（这个数字参考了<a href="http://blog.tsunanet.net/2010/11/how-long-does-it-take-to-make-context.html">这篇文章</a>，采用的是单核 CPU 线程平均时间），换算成人类时间大约是 65分钟，嗯，也就是一个小时。我们也知道上下文切换是很耗时的行为，毕竟每次浪费一个小时，也很让人有罪恶感的。上下文切换更恐怖的事情在于，<strong>这段时间里 CPU 没有做任何有用的计算</strong>，只是切换了两个不同进程的寄存器和内存状态；而且这个过程<strong>还破坏了缓存</strong>，让后续的计算更加耗时。</p>
</li>
<li>
<p>在 1Gbps 的网络上传输 2K 的数据需要 20us，换算成人类时间是 14.4小时，这么久都能把《星球大战》六部曲看完了（甚至还加上吃饭撒尿的时间）！可以看到网络上非常少数据传输对于 CPU 来说，已经很漫长。而且这里的时间还是理论最大值，实际过程还要更慢一些。</p>
</li>
<li>
<p>SSD 随机读取耗时为 150us，换算成人类时间大约是 4.5天。换句话说，SSD 读点数据，CPU 都能休假，报团参加周边游了。虽然我们知道 SSD 要比机械硬盘快很多，但是这个速度对于 CPU 来说也是像乌龟一样。I/O 设备 从硬盘开始速度开始变得漫长，这个时候我们就想起内存的好处了。尽量减少 IO 设备的读写，把最常用的数据放到内存中作为缓存是所有程序的通识。像 memcached 和 redis 这样的高速缓存系统近几年的异军突起，就是解决了这里的问题。</p>
</li>
<li>
<p>从内存中读取 1MB 的连续数据，耗时大约为 250us，换算成人类时间是 7.5天，这次假期升级到国庆七天国外游了。</p>
</li>
<li>
<p>同一个数据中心网络上跑一个来回需要 0.5ms，换算成人类时间大约是 15天，也就是半个月的时间。如果你的程序有段代码需要和数据中心的其他服务器交互，在这段时间里 CPU 都已经狂做了半个月的运算。减少不同服务组件的网络请求，是性能优化的一大课题。</p>
</li>
<li>
<p>从 SSD 读取 1MB 的顺序数据，大约需要 1ms，换算成人类时间是 1个月。也就是说 SSD 读一个普通的文件，如果要等你做完，CPU 一个月时间就荒废了。尽管如此，<strong>SSD</strong> 已经很快啦，不信你看下面机械磁盘的表现。</p>
</li>
<li>
<p>磁盘寻址时间为 10ms，换算成人类时间是 10个月，刚好够人类创造一个新的生命了。如果 CPU 需要让磁盘泡杯咖啡，在它眼里，磁盘去生了个孩子，回来告诉它你让我泡的咖啡好了。机械硬盘使用 RPM(Revolutions Per Minute/每分钟转速) 来评估磁盘的性能：RPM 越大，平均寻址时间更短，磁盘性能越好。寻址只是把磁头移动到正确的磁道上，然后才能读取指定扇区的内容。换句话说，寻址虽然很浪费时间，但其实它并没有办任何的正事（读取磁盘内容）。</p>
</li>
<li>
<p>从磁盘读取 1MB 连续数据需要 20ms，换算成人类时间是 20个月。<strong>IO 设备是计算机系统的瓶颈</strong>，希望读到这里你能更深切地理解这句话！如果还不理解，不妨想想你在网上买的东西，快递送了将近两年，你的心情是怎么样的。</p>
</li>
<li>
<p>而从世界上不同城市网络上走一个来回，平均需要 150ms（参考<a href="https://wondernetwork.com/pings/">世界各地 ping 报文的时间</a>），换算成人类时间是 12.5年。不难理解，所有的程序和架构都会尽量避免不同城市甚至是跨国家的网络访问，<a href="https://en.wikipedia.org/wiki/Content_delivery_network">CDN</a> 就是这个问题的一个解决方案：让用户和最接近自己的服务器交互，从而减少网络上报文的传输时间。</p>
</li>
<li>
<p>虚拟机重启一次大约要 4s 时间，换算成人类的时间是 3百多年。对于此，我想到了乔布斯要死命<a href="http://stevejobsdailyquote.com/2014/03/26/boot-time/">优化 Mac 系统开机启动时间</a>的故事。如果机器能少重启而且每次启动能快一点，不仅能救人命，也能救 CPU 的命。</p>
</li>
<li>
<p>物理服务器重启一次需要 5min，换算成人类时间是 2万5千年，快赶上人类的文明史了。5 分钟人类都要等一会了，更别提 CPU 了，所以没事不要乱重启服务器啊，分分钟终结一个文明的节奏。</p>
</li>
</ul>
<h2 id="参考资料"><a class="header-anchor" href="#参考资料"></a>参考资料</h2>
<ul>
<li><a href="https://www.akkadia.org/drepper/cpumemory.pdf">What Every Programmer Should Know About Memory</a></li>
<li><a href="http://duartes.org/gustavo/blog/post/getting-physical-with-memory/">Getting Physical With Memory</a></li>
</ul>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/how-slow-is-disk-and-network/">http://xnerv.wang/how-slow-is-disk-and-network/</a></strong><br>
转载自：<a href="https://cizixs.com/2017/01/03/how-slow-is-disk-and-network/">让 CPU 告诉你硬盘和网络到底有多慢</a></p>
]]></content>
      <categories>
        <category>计算机硬件</category>
      </categories>
      <tags>
        <tag>性能瓶颈</tag>
        <tag>CPU</tag>
        <tag>内存访问</tag>
        <tag>网络传输</tag>
        <tag>分支预测</tag>
        <tag>硬盘</tag>
        <tag>SSD</tag>
      </tags>
  </entry>
  <entry>
    <title>HOW TO: Find the Problem Exception Stack When You Receive an UnhandledExceptionFilter Call in the Stack Trace（转载）</title>
    <url>/how-to-find-the-problem-exception-stack-when-you-receive-an-unhandlede/</url>
    <content><![CDATA[<h2 id="Summary"><a class="header-anchor" href="#Summary"></a>Summary</h2>
<p>The <strong>UnhandledExceptionFilter</strong> function is called when no exception handler is defined to handle the exception that is raised. The function typically passes the exception up to the Ntdll.dll file, which catches and tries to handle it.</p>
<p>In some scenarios in which a memory snapshot of the process exists, you can see that the thread that holds the lock points to a thread that calls the <strong>UnhandledExceptionFilter</strong> function. In those cases, you can follow the steps in this article to identify the DLL that caused the exception.</p>
<span id="more"></span>
<h3 id="Open-a-Dump-File-by-Using-Windbg-exe"><a class="header-anchor" href="#Open-a-Dump-File-by-Using-Windbg-exe"></a>Open a Dump File by Using Windbg.exe</h3>
<ol>
<li>Download and install the debuggers. To download the debuggers, visit the following Microsoft Web site:
<blockquote>
<p>Microsoft Debugging Tools<br>
<a href="http://www.microsoft.com/whdc/devtools/ddk/default.mspx">http://www.microsoft.com/whdc/devtools/ddk/default.mspx</a></p>
</blockquote>
</li>
<li>Open the folder where you installed the debuggers, and then double-click <strong>Windbg.exe</strong> to start the debugger.</li>
<li>On the <strong>File</strong> menu, click <strong>Open Crash Dump</strong> (or press CTRL+D), and then select the dump file that you want to view.</li>
</ol>
<h3 id="Use-Windbg-exe-to-Identify-the-Exception-Stack"><a class="header-anchor" href="#Use-Windbg-exe-to-Identify-the-Exception-Stack"></a>Use Windbg.exe to Identify the Exception Stack.</h3>
<ol>
<li>
<p>In Windbg.exe, open the .dmp file of the process.</p>
</li>
<li>
<p>Make sure that you are pointing the symbol path to a correct location. For more information about how to do this, visit the following Microsoft Web site:</p>
<blockquote>
<p>How to Get Symbols<br>
<a href="http://www.microsoft.com/whdc/devtools/ddk/default.mspx">http://www.microsoft.com/whdc/devtools/ddk/default.mspx</a></p>
</blockquote>
</li>
<li>
<p>At a command prompt, type ~*kb to list all of the threads in the process.</p>
</li>
<li>
<p>Identify the thread that makes the call to the function <strong>Kernel32!UnhandledExceptionFilter</strong>. It looks similar to the following:</p>
</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">120  id: f0f0f0f0.a1c   Suspend: 1 Teb 7ff72000 Unfrozen</span><br><span class="line">ChildEBP RetAddr  Args to Child</span><br><span class="line">09a8f334 77eb9b46 0000244c 00000001 00000000 ntdll!ZwWaitForSingleObject+0xb [i386\usrstubs.asm @ 2004]</span><br><span class="line">09a8f644 77ea7e7a 09a8f66c 77e861ae 09a8f674 KERNEL32!UnhandledExceptionFilter+0x2b5</span><br><span class="line">[D:\nt\private\windows\base\client\thread.c @ 1753]</span><br><span class="line">09a8ffec 00000000 787bf0b8 0216fe94 00000000 KERNEL32!BaseThreadStart+0x65 [D:\nt\private\windows\base\client\support.c @ 453]</span><br></pre></td></tr></table></figure>
<ol start="5">
<li>
<p>Switch to that thread (in this example, the thread is “~120s”).</p>
</li>
<li>
<p>Display the memory contents at the location specified by the first parameter of <strong>Kernel32!UnhandledExceptionFilter</strong> by using <strong>dd <em>First Param</em></strong>. This points to the <strong>EXCEPTION_POINTERS</strong> structure.<br>
···<br>
0:120&gt; dd 09a8f66c<br>
09a8f66c  09a8f738 09a8f754 09a8f698 77f8f45c<br>
09a8f67c  09a8f738 09a8ffdc 09a8f754 09a8f710<br>
09a8f68c  09a8ffdc 77f8f5b5 09a8ffdc 09a8f720<br>
09a8f69c  77f8f3fa 09a8f738 09a8ffdc 09a8f754<br>
09a8f6ac  09a8f710 77e8615b 09a8fad4 00000000<br>
09a8f6bc  09a8f738 74a25336 09a8f6e0 09a8f910<br>
09a8f6cc  01dc8ad8 0d788918 00000001 018d1f28<br>
09a8f6dc  00000001 61746164 7073612e 09a8f71c<br>
···</p>
</li>
<li>
<p>The first DWORD represents the exception record. To obtain information about the type of exception, run the following at a command prompt:<br>
.exr <strong>first DWORD from step 6</strong><br>
···<br>
0:120&gt; .exr 09a8f738<br>
ExceptionAddress: 78011f32 (MSVCRT!strnicmp+0x00000092)<br>
ExceptionCode: c0000005<br>
ExceptionFlags: 00000000<br>
NumberParameters: 2<br>
Parameter[0]: 00000000<br>
Parameter[1]: 00000000<br>
Attempt to read from address 00000000<br>
···</p>
</li>
<li>
<p>The second DWORD is the context record. To obtain contextual information, run the following at a command prompt:<br>
.cxr <strong>second DWORD from step 6</strong><br>
···<br>
0:120&gt; .cxr 09a8f754<br>
eax=027470ff ebx=7803cb28 ecx=00000000 edx=00000000 esi=00000000 edi=09a8fad4<br>
eip=78011f32 esp=09a8fa20 ebp=09a8fa2c iopl=0         nv up ei ng nz na po nc<br>
cs=001b  ss=0023  ds=0023  es=0023  fs=003b  gs=0000             efl=00010286<br>
MSVCRT!strnicmp+92:<br>
78011f32 8a06             mov     al,[esi]<br>
···</p>
</li>
<li>
<p>Run a kv command to get the call stack of the actual exception. This helps you to identify the actual problem in the process that might not have been handled correctly.</p>
</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">0:120&gt; kv</span><br><span class="line">ChildEBP RetAddr  Args to Child</span><br><span class="line">WARNING: Stack unwind information not available. Following frames may be wrong.</span><br><span class="line">09a8fa2c 780119ab 09a8fad4 00000000 09a8faa8 MSVCRT!strnicmp+0x92</span><br><span class="line">09a8fa40 7801197c 09a8fad4 00000000 6d7044fd MSVCRT!stricmp+0x3c</span><br><span class="line">09a8fa80 6e5a6ef6 09a8fad4 2193d68d 00e5e298 MSVCRT!stricmp+0xd</span><br><span class="line">09a8fa94 6d7043bf 09a8fad4 09a8faa8 0000001c IisRTL!CLKRHashTable::FindKey+0x59 (FPO: [2,0,1])</span><br><span class="line">09a8faac 749fc22d 09a8fad4 01d553b0 0000001c ISATQ!CDirMonitor::FindEntry+0x1e</span><br><span class="line">(FPO: [Non-Fpo]) [D:\nt\private\inet\iis\svcs\infocomm\atq\dirmon.cpp @ 884]</span><br><span class="line">09a8fac4 749fd1cb 09a8fad4 09a8fb10 525c3a46 asp!RegisterASPDirMonitorEntry+0x6e</span><br><span class="line">(FPO: [EBP 0x09a8fb08] [2,0,4]) [D:\nt\private\inet\iis\svcs\cmp\asp\aspdmon.cpp @ 534]</span><br><span class="line">09a8fb08 749fcdd6 00000000 09a8fcbc 018d1f28 asp!CTemplateCacheManager::RegisterTemplateForChangeNotification+0x8a</span><br><span class="line">(FPO: [Non-Fpo]) [D:\nt\private\inet\iis\svcs\cmp\asp\cachemgr.cpp @ 621]</span><br><span class="line">09a8fb3c 74a08bfe 00000000 000000fa 74a30958 asp!CTemplateCacheManager::Load+0x382</span><br><span class="line">(FPO: [Non-Fpo]) [D:\nt\private\inet\iis\svcs\cmp\asp\cachemgr.cpp @ 364]</span><br><span class="line">09a8fc68 74a0d4c9 04c12518 018d1f28 09a8fcbc asp!LoadTemplate+0x42</span><br><span class="line">(FPO: [Non-Fpo]) [D:\nt\private\inet\iis\svcs\cmp\asp\exec.cpp @ 1037]</span><br><span class="line">09a8fcc0 74a2c3e5 00000000 0637ee38 09a8fd58 asp!CHitObj::ViperAsyncCallback+0x3e8</span><br><span class="line">(FPO: [Non-Fpo]) [D:\nt\private\inet\iis\svcs\cmp\asp\hitobj.cpp @ 2414]</span><br><span class="line">09a8fcd8 787c048a 00000000 77aa1b03 01e91ed8 asp!CViperAsyncRequest::OnCall+0x3f</span><br><span class="line">(FPO: [Non-Fpo]) [D:\nt\private\inet\iis\svcs\cmp\asp\viperint.cpp @ 194]</span><br><span class="line">09a8fce0 77aa1b03 01e91ed8 77a536d8 00000000 COMSVCS!STAActivityWorkHelper+0xa</span><br><span class="line">(FPO: [1,0,0])</span><br><span class="line">09a8fd24 77aa1927 000752f8 000864dc 787c0480 ole32!EnterForCallback+0x6a</span><br><span class="line">(FPO: [Non-Fpo]) [D:\nt\private\ole32\com\dcomrem\crossctx.cxx @ 1759]</span><br><span class="line">09a8fe50 77aa17ea 000864dc 787c0480 01e91ed8 ole32!SwitchForCallback+0x12b</span><br><span class="line">(FPO: [Non-Fpo]) [D:\nt\private\ole32\com\dcomrem\crossctx.cxx @ 1644]</span><br><span class="line">09a8fe78 77aa60c1 000864dc 787c0480 01e91ed8 ole32!PerformCallback+0x50</span><br><span class="line">(FPO: [Non-Fpo]) [D:\nt\private\ole32\com\dcomrem\crossctx.cxx @ 1559]</span><br><span class="line">09a8fed4 77aa5fa6 04f2b4c0 787c0480 01e91ed8 ole32!CObjectContext::InternalContextCallback+0xf5</span><br><span class="line">(FPO: [Non-Fpo]) [D:\nt\private\ole32\com\dcomrem\context.cxx @ 3866]</span><br><span class="line">09a8fef4 787bd3c3 04f2b4c0 787c0480 01e91ed8 ole32!CObjectContext::DoCallback+0x1a</span><br><span class="line">(FPO: [Non-Fpo]) [D:\nt\private\ole32\com\dcomrem\context.cxx @ 3746]</span><br><span class="line">09a8ff24 787bf373 0216fb3c 00000007 09a8ffec COMSVCS!STAActivityWork::DoWork+0x73</span><br><span class="line">(FPO: [0,4,2])</span><br><span class="line">09a8ffb4 77e8758a 0216fe94 0216fb3c 00000007 COMSVCS!STAThread::STAThreadWorker+0x2bb</span><br><span class="line">(FPO: [EBP 0x09a8ffec] [1,31,4])</span><br><span class="line">09a8ffec 00000000 787bf0b8 0216fe94 00000000 KERNEL32!BaseThreadStart+0x52</span><br><span class="line">(FPO: [Non-Fpo]) [D:\nt\private\windows\base\client\support.c @ 451]</span><br></pre></td></tr></table></figure>
<h2 id="References"><a class="header-anchor" href="#References"></a>References</h2>
<p>For more information, see the following books:</p>
<ul>
<li>Solomon, David A., and Mark Russinovich. <em>Inside Microsoft Windows 2000, Third Edition</em> (<a href="http://www.microsoft.com/mspress/books/4354.asp">http://www.microsoft.com/mspress/books/4354.asp</a>). Redmond: Microsoft Press, 2000.</li>
<li>Solomon, David A. <em>Inside Windows NT - Second Edition (Microsoft Programming Series)</em>. Redmond: Microsoft Press, 1998.</li>
<li>Richter, Jeffrey. <em>Programming Applications with Microsoft Windows (<a href="http://www.microsoft.com/mspress/books/2345.asp">http://www.microsoft.com/mspress/books/2345.asp</a>)</em>. Redmond: Microsoft Press, 1999.</li>
</ul>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/how-to-find-the-problem-exception-stack-when-you-receive-an-unhandlede/">http://xnerv.wang/how-to-find-the-problem-exception-stack-when-you-receive-an-unhandlede/</a></strong><br>
转载自：<a href="https://support.microsoft.com/en-us/help/313109/how-to-find-the-problem-exception-stack-when-you-receive-an-unhandlede">HOW TO: Find the Problem Exception Stack When You Receive an UnhandledExceptionFilter Call in the Stack Trace</a></p>
]]></content>
      <categories>
        <category>WinDbg</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Windows</tag>
        <tag>Heap</tag>
        <tag>MSDN</tag>
        <tag>WinDbg</tag>
      </tags>
  </entry>
  <entry>
    <title>如何实现一个malloc（转载）</title>
    <url>/how-to-implement-a-malloc/</url>
    <content><![CDATA[<p>任何一个用过或学过C的人对malloc都不会陌生。大家都知道malloc可以分配一段连续的内存空间，并且在不再使用时可以通过free释放掉。但是，许多程序员对malloc背后的事情并不熟悉，许多人甚至把malloc当做操作系统所提供的系统调用或C的关键字。实际上，malloc只是C的标准库中提供的一个普通函数，而且实现malloc的<strong>基本</strong>思想并不复杂，任何一个对C和操作系统有些许了解的程序员都可以很容易理解。</p>
<p>这篇文章通过实现一个简单的malloc来描述malloc背后的机制。当然与现有C的标准库实现（例如glibc）相比，我们实现的malloc并不是特别高效，但是这个实现比目前真实的malloc实现要简单很多，因此易于理解。重要的是，这个实现和真实实现在基本原理上是一致的。</p>
<p>这篇文章将首先介绍一些所需的基本知识，如操作系统对进程的内存管理以及相关的系统调用，然后逐步实现一个简单的malloc。为了简单起见，这篇文章将只考虑x86_64体系结构，操作系统为Linux。</p>
<span id="more"></span>
<h2 id="1-什么是malloc"><a class="header-anchor" href="#1-什么是malloc"></a>1 什么是malloc</h2>
<p>在实现malloc之前，先要相对正式地对malloc做一个定义。</p>
<p>根据标准C库函数的定义，malloc具有如下原型：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">void</span>* <span class="title function_">malloc</span><span class="params">(<span class="type">size_t</span> size)</span>;</span><br></pre></td></tr></table></figure>
<p>这个函数要实现的功能是在系统中分配一段连续的可用的内存，具体有如下要求：</p>
<ul>
<li>malloc分配的内存大小<strong>至少</strong>为size参数所指定的字节数</li>
<li>malloc的返回值是一个指针，指向一段可用内存的起始地址</li>
<li>多次调用malloc所分配的地址不能有重叠部分，除非某次malloc所分配的地址被释放掉</li>
<li>malloc应该尽快完成内存分配并返回（不能使用<a href="http://en.wikipedia.org/wiki/NP-hard">NP-hard</a>的内存分配算法）</li>
<li>实现malloc时应同时实现内存大小调整和内存释放函数（即realloc和free）</li>
</ul>
<p>对于malloc更多的说明可以在命令行中键入以下命令查看：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">man malloc</span><br></pre></td></tr></table></figure>
<h2 id="2-预备知识"><a class="header-anchor" href="#2-预备知识"></a>2 预备知识</h2>
<p>在实现malloc之前，需要先解释一些Linux系统内存相关的知识。</p>
<h3 id="2-1-Linux内存管理"><a class="header-anchor" href="#2-1-Linux内存管理"></a>2.1 Linux内存管理</h3>
<h4 id="2-1-1-虚拟内存地址与物理内存地址"><a class="header-anchor" href="#2-1-1-虚拟内存地址与物理内存地址"></a>2.1.1 虚拟内存地址与物理内存地址</h4>
<p>为了简单，现代操作系统在处理内存地址时，普遍采用虚拟内存地址技术。即在汇编程序（或机器语言）层面，当涉及内存地址时，都是使用虚拟内存地址。采用这种技术时，每个进程仿佛自己独享一片2<sup>N</sup>字节的内存，其中N是机器位数。例如在64位CPU和64位操作系统下，每个进程的虚拟地址空间为2<sup>64</sup>Byte。</p>
<p>这种虚拟地址空间的作用主要是简化程序的编写及方便操作系统对进程间内存的隔离管理，真实中的进程不太可能（也用不到）如此大的内存空间，实际能用到的内存取决于物理内存大小。</p>
<p>由于在机器语言层面都是采用虚拟地址，当实际的机器码程序涉及到内存操作时，需要根据当前进程运行的实际上下文将虚拟地址转换为物理内存地址，才能实现对真实内存数据的操作。这个转换一般由一个叫<a href="http://en.wikipedia.org/wiki/Memory_management_unit">MMU</a>（Memory Management Unit）的硬件完成。</p>
<h4 id="2-1-2-页与地址构成"><a class="header-anchor" href="#2-1-2-页与地址构成"></a>2.1.2 页与地址构成</h4>
<p>在现代操作系统中，不论是虚拟内存还是物理内存，都不是以字节为单位进行管理的，而是以页（Page）为单位。一个内存页是一段固定大小的连续内存地址的总称，具体到Linux中，典型的内存页大小为4096Byte（4K）。</p>
<p>所以内存地址可以分为页号和页内偏移量。下面以64位机器，4G物理内存，4K页大小为例，虚拟内存地址和物理内存地址的组成如下：</p>
<center>
<img src="/assets/how-to-implement-a-malloc/a-malloc-tutorial-01.png" alt="内存地址构成"/>
</center>
<p>上面是虚拟内存地址，下面是物理内存地址。由于页大小都是4K，所以页内便宜都是用低12位表示，而剩下的高地址表示页号。</p>
<p>MMU映射单位并不是字节，而是页，这个映射通过查一个常驻内存的数据结构<a href="http://en.wikipedia.org/wiki/Page_table">页表</a>来实现。现在计算机具体的内存地址映射比较复杂，为了加快速度会引入一系列缓存和优化，例如<a href="http://en.wikipedia.org/wiki/Translation_lookaside_buffer">TLB</a>等机制。下面给出一个经过简化的内存地址翻译示意图，虽然经过了简化，但是基本原理与现代计算机真实的情况的一致的。</p>
<center>
<img src="/assets/how-to-implement-a-malloc/a-malloc-tutorial-02.png" alt="内存地址翻译"/>
</center>
<h4 id="2-1-3-内存页与磁盘页"><a class="header-anchor" href="#2-1-3-内存页与磁盘页"></a>2.1.3 内存页与磁盘页</h4>
<p>我们知道一般将内存看做磁盘的的缓存，有时MMU在工作时，会发现页表表明某个内存页不在物理内存中，此时会触发一个缺页异常（Page Fault），此时系统会到磁盘中相应的地方将磁盘页载入到内存中，然后重新执行由于缺页而失败的机器指令。关于这部分，因为可以看做对malloc实现是透明的，所以不再详细讲述，有兴趣的可以参考《深入理解计算机系统》相关章节。</p>
<p>最后附上一张在维基百科找到的更加符合真实地址翻译的流程供大家参考，这张图加入了TLB和缺页异常的流程（<a href="http://en.wikipedia.org/wiki/Page_table">图片来源页</a>）。</p>
<center>
<img src="/assets/how-to-implement-a-malloc/a-malloc-tutorial-03.png" alt="较为完整的地址翻译流程"/>
</center>
<h3 id="2-2-Linux进程级内存管理"><a class="header-anchor" href="#2-2-Linux进程级内存管理"></a>2.2 Linux进程级内存管理</h3>
<h4 id="2-2-1-内存排布"><a class="header-anchor" href="#2-2-1-内存排布"></a>2.2.1 内存排布</h4>
<p>明白了虚拟内存和物理内存的关系及相关的映射机制，下面看一下具体在一个进程内是如何排布内存的。</p>
<p>以Linux 64位系统为例。理论上，64bit内存地址可用空间为0x0000000000000000 ~ 0xFFFFFFFFFFFFFFFF，这是个相当庞大的空间，Linux实际上只用了其中一小部分（256T）。</p>
<p>根据<a href="https://www.kernel.org/doc/Documentation/x86/x86_64/mm.txt">Linux内核相关文档</a>描述，Linux64位操作系统仅使用低47位，高17位做扩展（只能是全0或全1）。所以，实际用到的地址为空间为0x0000000000000000 ~ 0x00007FFFFFFFFFFF和0xFFFF800000000000 ~ 0xFFFFFFFFFFFFFFFF，其中前面为用户空间（User Space），后者为内核空间（Kernel Space）。图示如下：</p>
<center>
<img src="/assets/how-to-implement-a-malloc/a-malloc-tutorial-04.png" alt="Linux进程地址排布"/>
</center>
<p>对用户来说，主要关注的空间是User Space。将User Space放大后，可以看到里面主要分为如下几段：</p>
<ul>
<li>Code：这是整个用户空间的最低地址部分，存放的是指令（也就是程序所编译成的可执行机器码）</li>
<li>Data：这里存放的是初始化过的全局变量</li>
<li>BSS：这里存放的是未初始化的全局变量</li>
<li>Heap：堆，这是我们本文重点关注的地方，堆自低地址向高地址增长，后面要讲到的brk相关的系统调用就是从这里分配内存</li>
<li>Mapping Area：这里是与mmap系统调用相关的区域。大多数实际的malloc实现会考虑通过mmap分配较大块的内存区域，本文不讨论这种情况。这个区域自高地址向低地址增长</li>
<li>Stack：这是栈区域，自高地址向低地址增长</li>
</ul>
<p>下面我们主要关注Heap区域的操作。对整个Linux内存排布有兴趣的同学可以参考其它资料。</p>
<h4 id="2-2-2-Heap内存模型"><a class="header-anchor" href="#2-2-2-Heap内存模型"></a>2.2.2 Heap内存模型</h4>
<p>一般来说，malloc所申请的内存主要从Heap区域分配（本文不考虑通过mmap申请大块内存的情况）。</p>
<p>由上文知道，进程所面对的虚拟内存地址空间，只有按页映射到物理内存地址，才能真正使用。受物理存储容量限制，整个堆虚拟内存空间不可能全部映射到实际的物理内存。Linux对堆的管理示意如下：</p>
<center>
<img src="/assets/how-to-implement-a-malloc/a-malloc-tutorial-05.png" alt="Linux进程堆管理"/>
</center>
<p>Linux维护一个break指针，这个指针指向堆空间的某个地址。从堆起始地址到break之间的地址空间为映射好的，可以供进程访问；而从break往上，是未映射的地址空间，如果访问这段空间则程序会报错。</p>
<h4 id="2-2-3-brk与sbrk"><a class="header-anchor" href="#2-2-3-brk与sbrk"></a>2.2.3 brk与sbrk</h4>
<p>由上文知道，要增加一个进程实际的可用堆大小，就需要将break指针向高地址移动。Linux通过brk和sbrk系统调用操作break指针。两个系统调用的原型如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">brk</span><span class="params">(<span class="type">void</span> *addr)</span>;</span><br><span class="line"><span class="type">void</span> *<span class="title function_">sbrk</span><span class="params">(<span class="type">intptr_t</span> increment)</span>;</span><br></pre></td></tr></table></figure>
<p>brk将break指针直接设置为某个地址，而sbrk将break从当前位置移动increment所指定的增量。brk在执行成功时返回0，否则返回-1并设置errno为ENOMEM；sbrk成功时返回break移动之前所指向的地址，否则返回(void *)-1。</p>
<p>一个小技巧是，如果将increment设置为0，则可以获得当前break的地址。</p>
<p>另外需要注意的是，由于Linux是按页进行内存映射的，所以如果break被设置为没有按页大小对齐，则系统实际上会在最后映射一个完整的页，从而实际已映射的内存空间比break指向的地方要大一些。但是使用break之后的地址是很危险的（尽管也许break之后确实有一小块可用内存地址）。</p>
<h4 id="2-2-4-资源限制与rlimit"><a class="header-anchor" href="#2-2-4-资源限制与rlimit"></a>2.2.4 资源限制与rlimit</h4>
<p>系统对每一个进程所分配的资源不是无限的，包括可映射的内存空间，因此每个进程有一个rlimit表示当前进程可用的资源上限。这个限制可以通过getrlimit系统调用得到，下面代码获取当前进程虚拟内存空间的rlimit：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">rlimit</span> *<span class="title">limit</span> =</span> (<span class="keyword">struct</span> rlimit *)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="keyword">struct</span> rlimit));</span><br><span class="line">    getrlimit(RLIMIT_AS, limit);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;soft limit: %ld, hard limit: %ld\n&quot;</span>, limit-&gt;rlim_cur, limit-&gt;rlim_max);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中rlimit是一个结构体：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">rlimit</span> &#123;</span></span><br><span class="line">    <span class="type">rlim_t</span> rlim_cur;  <span class="comment">/* Soft limit */</span></span><br><span class="line">    <span class="type">rlim_t</span> rlim_max;  <span class="comment">/* Hard limit (ceiling for rlim_cur) */</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>每种资源有软限制和硬限制，并且可以通过setrlimit对rlimit进行有条件设置。其中硬限制作为软限制的上限，非特权进程只能设置软限制，且不能超过硬限制。</p>
<h2 id="3-实现malloc"><a class="header-anchor" href="#3-实现malloc"></a>3 实现malloc</h2>
<h3 id="3-1-玩具实现"><a class="header-anchor" href="#3-1-玩具实现"></a>3.1 玩具实现</h3>
<p>在正式开始讨论malloc的实现前，我们可以利用上述知识实现一个简单但几乎没法用于真实的玩具malloc，权当对上面知识的复习：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* 一个玩具malloc */</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/types.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="type">void</span> *<span class="title function_">malloc</span><span class="params">(<span class="type">size_t</span> size)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">void</span> *p;</span><br><span class="line">    p = sbrk(<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">if</span> (sbrk(size) == (<span class="type">void</span> *)<span class="number">-1</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">    <span class="keyword">return</span> p;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这个malloc每次都在当前break的基础上增加size所指定的字节数，并将之前break的地址返回。这个malloc由于对所分配的内存缺乏记录，不便于内存释放，所以无法用于真实场景。</p>
<h3 id="3-2-正式实现"><a class="header-anchor" href="#3-2-正式实现"></a>3.2 正式实现</h3>
<p>下面严肃点讨论malloc的实现方案。</p>
<h4 id="3-2-1-数据结构"><a class="header-anchor" href="#3-2-1-数据结构"></a>3.2.1 数据结构</h4>
<p>首先我们要确定所采用的数据结构。一个简单可行方案是将堆内存空间以块（Block）的形式组织起来，每个块由meta区和数据区组成，meta区记录数据块的元信息（数据区大小、空闲标志位、指针等等），数据区是真实分配的内存区域，并且数据区的第一个字节地址即为malloc返回的地址。</p>
<p>可以用如下结构体定义一个block：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">s_block</span> *<span class="title">t_block</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">s_block</span> &#123;</span></span><br><span class="line">    <span class="type">size_t</span> size;  <span class="comment">/* 数据区大小 */</span></span><br><span class="line">    t_block next; <span class="comment">/* 指向下个块的指针 */</span></span><br><span class="line">    <span class="type">int</span> <span class="built_in">free</span>;     <span class="comment">/* 是否是空闲块 */</span></span><br><span class="line">    <span class="type">int</span> padding;  <span class="comment">/* 填充4字节，保证meta块长度为8的倍数 */</span></span><br><span class="line">    <span class="type">char</span> data[<span class="number">1</span>]  <span class="comment">/* 这是一个虚拟字段，表示数据块的第一个字节，长度不应计入meta */</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>由于我们只考虑64位机器，为了方便，我们在结构体最后填充一个int，使得结构体本身的长度为8的倍数，以便内存对齐。示意图如下：</p>
<center>
<img src="/assets/how-to-implement-a-malloc/a-malloc-tutorial-06.png" alt="Block结构"/>
</center>
<h4 id="3-2-2-寻找合适的block"><a class="header-anchor" href="#3-2-2-寻找合适的block"></a>3.2.2 寻找合适的block</h4>
<p>现在考虑如何在block链中查找合适的block。一般来说有两种查找算法：</p>
<ul>
<li><strong>First fit</strong>：从头开始，使用第一个数据区大小大于要求size的块所谓此次分配的块</li>
<li><strong>Best fit</strong>：从头开始，遍历所有块，使用数据区大小大于size且差值最小的块作为此次分配的块</li>
</ul>
<p>两种方法各有千秋，best fit具有较高的内存使用率（payload较高），而first fit具有更好的运行效率。这里我们采用first fit算法。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* First fit */</span></span><br><span class="line">t_block <span class="title function_">find_block</span><span class="params">(t_block *last, <span class="type">size_t</span> size)</span> &#123;</span><br><span class="line">    t_block b = first_block;</span><br><span class="line">    <span class="keyword">while</span>(b &amp;&amp; !(b-&gt;<span class="built_in">free</span> &amp;&amp; b-&gt;size &gt;= size)) &#123;</span><br><span class="line">        *last = b;</span><br><span class="line">        b = b-&gt;next;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> b;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>find_block从frist_block开始，查找第一个符合要求的block并返回block起始地址，如果找不到这返回NULL。这里在遍历时会更新一个叫last的指针，这个指针始终指向当前遍历的block。这是为了如果找不到合适的block而开辟新block使用的，具体会在接下来的一节用到。</p>
<h4 id="3-2-3-开辟新的block"><a class="header-anchor" href="#3-2-3-开辟新的block"></a>3.2.3 开辟新的block</h4>
<p>如果现有block都不能满足size的要求，则需要在链表最后开辟一个新的block。这里关键是如何只使用sbrk创建一个struct：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> BLOCK_SIZE 24 <span class="comment">/* 由于存在虚拟的data字段，sizeof不能正确计算meta长度，这里手工设置 */</span></span></span><br><span class="line"></span><br><span class="line">t_block <span class="title function_">extend_heap</span><span class="params">(t_block last, <span class="type">size_t</span> s)</span> &#123;</span><br><span class="line">    t_block b;</span><br><span class="line">    b = sbrk(<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">if</span>(sbrk(BLOCK_SIZE + s) == (<span class="type">void</span> *)<span class="number">-1</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">    b-&gt;size = s;</span><br><span class="line">    b-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line">    <span class="keyword">if</span>(last)</span><br><span class="line">        last-&gt;next = b;</span><br><span class="line">    b-&gt;<span class="built_in">free</span> = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">return</span> b;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="3-2-4-分裂block"><a class="header-anchor" href="#3-2-4-分裂block"></a>3.2.4 分裂block</h4>
<p>First fit有一个比较致命的缺点，就是可能会让很小的size占据很大的一块block，此时，为了提高payload，应该在剩余数据区足够大的情况下，将其分裂为一个新的block，示意如下：</p>
<center>
<img src="/assets/how-to-implement-a-malloc/a-malloc-tutorial-07.png" alt="分裂block"/>
</center>
<p>实现代码：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">split_block</span><span class="params">(t_block b, <span class="type">size_t</span> s)</span> &#123;</span><br><span class="line">    t_block new;</span><br><span class="line">    new = b-&gt;data + s;</span><br><span class="line">    new-&gt;size = b-&gt;size - s - BLOCK_SIZE ;</span><br><span class="line">    new-&gt;next = b-&gt;next;</span><br><span class="line">    new-&gt;<span class="built_in">free</span> = <span class="number">1</span>;</span><br><span class="line">    b-&gt;size = s;</span><br><span class="line">    b-&gt;next = new;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="3-2-5-malloc的实现"><a class="header-anchor" href="#3-2-5-malloc的实现"></a>3.2.5 malloc的实现</h4>
<p>有了上面的代码，我们可以利用它们整合成一个简单但初步可用的malloc。注意首先我们要定义个block链表的头first_block，初始化为NULL；另外，我们需要剩余空间至少有BLOCK_SIZE + 8才执行分裂操作。</p>
<p>由于我们希望malloc分配的数据区是按8字节对齐，所以在size不为8的倍数时，我们需要将size调整为大于size的最小的8的倍数：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">size_t</span> <span class="title function_">align8</span><span class="params">(<span class="type">size_t</span> s)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span>(s &amp; <span class="number">0x7</span> == <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> s;</span><br><span class="line">    <span class="keyword">return</span> ((s &gt;&gt; <span class="number">3</span>) + <span class="number">1</span>) &lt;&lt; <span class="number">3</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> BLOCK_SIZE 24</span></span><br><span class="line"><span class="type">void</span> *first_block=<span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* other functions... */</span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> *<span class="title function_">malloc</span><span class="params">(<span class="type">size_t</span> size)</span> &#123;</span><br><span class="line">    t_block b, last;</span><br><span class="line">    <span class="type">size_t</span> s;</span><br><span class="line">    <span class="comment">/* 对齐地址 */</span></span><br><span class="line">    s = align8(size);</span><br><span class="line">    <span class="keyword">if</span>(first_block) &#123;</span><br><span class="line">        <span class="comment">/* 查找合适的block */</span></span><br><span class="line">        last = first_block;</span><br><span class="line">        b = find_block(&amp;last, s);</span><br><span class="line">        <span class="keyword">if</span>(b) &#123;</span><br><span class="line">            <span class="comment">/* 如果可以，则分裂 */</span></span><br><span class="line">            <span class="keyword">if</span> ((b-&gt;size - s) &gt;= ( BLOCK_SIZE + <span class="number">8</span>))</span><br><span class="line">                split_block(b, s);</span><br><span class="line">            b-&gt;<span class="built_in">free</span> = <span class="number">0</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">/* 没有合适的block，开辟一个新的 */</span></span><br><span class="line">            b = extend_heap(last, s);</span><br><span class="line">            <span class="keyword">if</span>(!b)</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        b = extend_heap(<span class="literal">NULL</span>, s);</span><br><span class="line">        <span class="keyword">if</span>(!b)</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">        first_block = b;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> b-&gt;data;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="3-2-6-calloc的实现"><a class="header-anchor" href="#3-2-6-calloc的实现"></a>3.2.6 calloc的实现</h4>
<p>有了malloc，实现calloc只要两步：</p>
<ol>
<li>malloc一段内存</li>
<li>将数据区内容置为0</li>
</ol>
<p>由于我们的数据区是按8字节对齐的，所以为了提高效率，我们可以每8字节一组置0，而不是一个一个字节设置。我们可以通过新建一个size_t指针，将内存区域强制看做size_t类型来实现。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">void</span> *<span class="title function_">calloc</span><span class="params">(<span class="type">size_t</span> number, <span class="type">size_t</span> size)</span> &#123;</span><br><span class="line">    <span class="type">size_t</span> *new;</span><br><span class="line">    <span class="type">size_t</span> s8, i;</span><br><span class="line">    new = <span class="built_in">malloc</span>(number * size);</span><br><span class="line">    <span class="keyword">if</span>(new) &#123;</span><br><span class="line">        s8 = align8(number * size) &gt;&gt; <span class="number">3</span>;</span><br><span class="line">        <span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; s8; i++)</span><br><span class="line">            new[i] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> new;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="3-2-7-free的实现"><a class="header-anchor" href="#3-2-7-free的实现"></a>3.2.7 free的实现</h4>
<p>free的实现并不像看上去那么简单，这里我们要解决两个关键问题：</p>
<ol>
<li>如何验证所传入的地址是有效地址，即确实是通过malloc方式分配的数据区首地址</li>
<li>如何解决碎片问题</li>
</ol>
<p>首先我们要保证传入free的地址是有效的，这个有效包括两方面：</p>
<ul>
<li>地址应该在之前malloc所分配的区域内，即在first_block和当前break指针范围内</li>
<li>这个地址确实是之前通过我们自己的malloc分配的</li>
</ul>
<p>第一个问题比较好解决，只要进行地址比较就可以了，关键是第二个问题。这里有两种解决方案：一是在结构体内埋一个magic number字段，free之前通过相对偏移检查特定位置的值是否为我们设置的magic number，另一种方法是在结构体内增加一个magic pointer，这个指针指向数据区的第一个字节（也就是在合法时free时传入的地址），我们在free前检查magic pointer是否指向参数所指地址。这里我们采用第二种方案：</p>
<p>首先我们在结构体中增加magic pointer（同时要修改BLOCK_SIZE）：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">s_block</span> *<span class="title">t_block</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">s_block</span> &#123;</span></span><br><span class="line">    <span class="type">size_t</span> size;  <span class="comment">/* 数据区大小 */</span></span><br><span class="line">    t_block next; <span class="comment">/* 指向下个块的指针 */</span></span><br><span class="line">    <span class="type">int</span> <span class="built_in">free</span>;     <span class="comment">/* 是否是空闲块 */</span></span><br><span class="line">    <span class="type">int</span> padding;  <span class="comment">/* 填充4字节，保证meta块长度为8的倍数 */</span></span><br><span class="line">    <span class="type">void</span> *ptr;    <span class="comment">/* Magic pointer，指向data */</span></span><br><span class="line">    <span class="type">char</span> data[<span class="number">1</span>]  <span class="comment">/* 这是一个虚拟字段，表示数据块的第一个字节，长度不应计入meta */</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>然后我们定义检查地址合法性的函数：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">t_block <span class="title function_">get_block</span><span class="params">(<span class="type">void</span> *p)</span> &#123;</span><br><span class="line">    <span class="type">char</span> *tmp;</span><br><span class="line">    tmp = p;</span><br><span class="line">    <span class="keyword">return</span> (p = tmp -= BLOCK_SIZE);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">valid_addr</span><span class="params">(<span class="type">void</span> *p)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span>(first_block) &#123;</span><br><span class="line">        <span class="keyword">if</span>(p &gt; first_block &amp;&amp; p &lt; sbrk(<span class="number">0</span>)) &#123;</span><br><span class="line">            <span class="keyword">return</span> p == (get_block(p))-&gt;ptr;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当多次malloc和free后，整个内存池可能会产生很多碎片block，这些block很小，经常无法使用，甚至出现许多碎片连在一起，虽然总体能满足某此malloc要求，但是由于分割成了多个小block而无法fit，这就是碎片问题。</p>
<p>一个简单的解决方式时当free某个block时，如果发现它相邻的block也是free的，则将block和相邻block合并。为了满足这个实现，需要将s_block改为双向链表。修改后的block结构如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">s_block</span> *<span class="title">t_block</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">s_block</span> &#123;</span></span><br><span class="line">    <span class="type">size_t</span> size;  <span class="comment">/* 数据区大小 */</span></span><br><span class="line">    t_block prev; <span class="comment">/* 指向上个块的指针 */</span></span><br><span class="line">    t_block next; <span class="comment">/* 指向下个块的指针 */</span></span><br><span class="line">    <span class="type">int</span> <span class="built_in">free</span>;     <span class="comment">/* 是否是空闲块 */</span></span><br><span class="line">    <span class="type">int</span> padding;  <span class="comment">/* 填充4字节，保证meta块长度为8的倍数 */</span></span><br><span class="line">    <span class="type">void</span> *ptr;    <span class="comment">/* Magic pointer，指向data */</span></span><br><span class="line">    <span class="type">char</span> data[<span class="number">1</span>]  <span class="comment">/* 这是一个虚拟字段，表示数据块的第一个字节，长度不应计入meta */</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>合并方法如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">t_block <span class="title function_">fusion</span><span class="params">(t_block b)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (b-&gt;next &amp;&amp; b-&gt;next-&gt;<span class="built_in">free</span>) &#123;</span><br><span class="line">        b-&gt;size += BLOCK_SIZE + b-&gt;next-&gt;size;</span><br><span class="line">        b-&gt;next = b-&gt;next-&gt;next;</span><br><span class="line">        <span class="keyword">if</span>(b-&gt;next)</span><br><span class="line">            b-&gt;next-&gt;prev = b;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> b;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>有了上述方法，free的实现思路就比较清晰了：首先检查参数地址的合法性，如果不合法则不做任何事；否则，将此block的free标为1，并且在可以的情况下与后面的block进行合并。如果当前是最后一个block，则回退break指针释放进程内存，如果当前block是最后一个block，则回退break指针并设置first_block为NULL。实现如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">free</span><span class="params">(<span class="type">void</span> *p)</span> &#123;</span><br><span class="line">    t_block b;</span><br><span class="line">    <span class="keyword">if</span>(valid_addr(p)) &#123;</span><br><span class="line">        b = get_block(p);</span><br><span class="line">        b-&gt;<span class="built_in">free</span> = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span>(b-&gt;prev &amp;&amp; b-&gt;prev-&gt;<span class="built_in">free</span>)</span><br><span class="line">            b = fusion(b-&gt;prev);</span><br><span class="line">        <span class="keyword">if</span>(b-&gt;next)</span><br><span class="line">            fusion(b);</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">if</span>(b-&gt;prev)</span><br><span class="line">                b-&gt;prev-&gt;prev = <span class="literal">NULL</span>;</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                first_block = <span class="literal">NULL</span>;</span><br><span class="line">            brk(b);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="3-2-8-realloc的实现"><a class="header-anchor" href="#3-2-8-realloc的实现"></a>3.2.8 realloc的实现</h4>
<p>为了实现realloc，我们首先要实现一个内存复制方法。如同calloc一样，为了效率，我们以8字节为单位进行复制：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">copy_block</span><span class="params">(t_block src, t_block dst)</span> &#123;</span><br><span class="line">    <span class="type">size_t</span> *sdata, *ddata;</span><br><span class="line">    <span class="type">size_t</span> i;</span><br><span class="line">    sdata = src-&gt;ptr;</span><br><span class="line">    ddata = dst-&gt;ptr;</span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>; (i * <span class="number">8</span>) &lt; src-&gt;size &amp;&amp; (i * <span class="number">8</span>) &lt; dst-&gt;size; i++)</span><br><span class="line">        ddata[i] = sdata[i];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>然后我们开始实现realloc。一个简单（但是低效）的方法是malloc一段内存，然后将数据复制过去。但是我们可以做的更高效，具体可以考虑以下几个方面：</p>
<ul>
<li>如果当前block的数据区大于等于realloc所要求的size，则不做任何操作</li>
<li>如果新的size变小了，考虑split</li>
<li>如果当前block的数据区不能满足size，但是其后继block是free的，并且合并后可以满足，则考虑做合并</li>
</ul>
<p>下面是realloc的实现：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">void</span> *<span class="title function_">realloc</span><span class="params">(<span class="type">void</span> *p, <span class="type">size_t</span> size)</span> &#123;</span><br><span class="line">    <span class="type">size_t</span> s;</span><br><span class="line">    t_block b, new;</span><br><span class="line">    <span class="type">void</span> *newp;</span><br><span class="line">    <span class="keyword">if</span> (!p)</span><br><span class="line">        <span class="comment">/* 根据标准库文档，当p传入NULL时，相当于调用malloc */</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">malloc</span>(size);</span><br><span class="line">    <span class="keyword">if</span>(valid_addr(p)) &#123;</span><br><span class="line">        s = align8(size);</span><br><span class="line">        b = get_block(p);</span><br><span class="line">        <span class="keyword">if</span>(b-&gt;size &gt;= s) &#123;</span><br><span class="line">            <span class="keyword">if</span>(b-&gt;size - s &gt;= (BLOCK_SIZE + <span class="number">8</span>))</span><br><span class="line">                split_block(b,s);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">/* 看是否可进行合并 */</span></span><br><span class="line">            <span class="keyword">if</span>(b-&gt;next &amp;&amp; b-&gt;next-&gt;<span class="built_in">free</span></span><br><span class="line">                    &amp;&amp; (b-&gt;size + BLOCK_SIZE + b-&gt;next-&gt;size) &gt;= s) &#123;</span><br><span class="line">                fusion(b);</span><br><span class="line">                <span class="keyword">if</span>(b-&gt;size - s &gt;= (BLOCK_SIZE + <span class="number">8</span>))</span><br><span class="line">                    split_block(b, s);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">/* 新malloc */</span></span><br><span class="line">                newp = <span class="built_in">malloc</span> (s);</span><br><span class="line">                <span class="keyword">if</span> (!newp)</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">                new = get_block(newp);</span><br><span class="line">                copy_block(b, new);</span><br><span class="line">                <span class="built_in">free</span>(p);</span><br><span class="line">                <span class="keyword">return</span>(newp);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> (p);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="3-3-遗留问题和优化"><a class="header-anchor" href="#3-3-遗留问题和优化"></a>3.3 遗留问题和优化</h3>
<p>以上是一个较为简陋，但是初步可用的malloc实现。还有很多遗留的可能优化点，例如：</p>
<ul>
<li>同时兼容32位和64位系统</li>
<li>在分配较大快内存时，考虑使用mmap而非sbrk，这通常更高效</li>
<li>可以考虑维护多个链表而非单个，每个链表中的block大小均为一个范围内，例如8字节链表、16字节链表、24-32字节链表等等。此时可以根据size到对应链表中做分配，可以有效减少碎片，并提高查询block的速度</li>
<li>可以考虑链表中只存放free的block，而不存放已分配的block，可以减少查找block的次数，提高效率</li>
</ul>
<p>还有很多可能的优化，这里不一一赘述。下面附上一些参考文献，有兴趣的同学可以更深入研究。</p>
<h2 id="4-其它参考"><a class="header-anchor" href="#4-其它参考"></a>4 其它参考</h2>
<ol>
<li>这篇文章大量参考了<a href="http://www.inf.udec.cl/~leo/Malloc_tutorial.pdf">A malloc Tutorial</a>，其中一些图片和代码直接引用了文中的内容，这里特别指出</li>
<li><a href="http://csapp.cs.cmu.edu/">Computer Systems: A Programmer’s Perspective, 2/E</a>一书有许多值得参考的地方</li>
<li>关于Linux的虚拟内存模型，<a href="http://duartes.org/gustavo/blog/post/anatomy-of-a-program-in-memory/">Anatomy of a Program in Memory</a>是很好的参考资料，另外作者还有一篇<a href="http://duartes.org/gustavo/blog/post/how-the-kernel-manages-your-memory/">How the Kernel Manages Your Memory</a>对于Linux内核中虚拟内存管理的部分有很好的讲解</li>
<li>对于真实世界的malloc实现，可以参考<a href="http://repo.or.cz/w/glibc.git/blob/HEAD:/malloc/malloc.c">glibc的实现</a></li>
<li>本文写作过程中大量参考了<a href="http://www.wikipedia.org/">维基百科</a>，再次感谢这个伟大的网站，并且呼吁大家在手头允许的情况下可以适当捐助维基百科，帮助这个造福人类的系统运行下去</li>
</ol>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/how-to-implement-a-malloc/">http://xnerv.wang/how-to-implement-a-malloc/</a></strong><br>
转载自：<a href="http://blog.codinglabs.org/articles/a-malloc-tutorial.html">如何实现一个malloc</a></p>
]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>编程语言</tag>
        <tag>C</tag>
        <tag>C内存管理</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL 5.6中Binlog Group Commit实现（转载）</title>
    <url>/implement-of-binlog-group-commit-in-mysql56/</url>
    <content><![CDATA[<h2 id="背景"><a class="header-anchor" href="#背景"></a>背景</h2>
<p>在MySQL 5.1中，如果配置项sync_binlog=1，并且innodb_flush_log_at_trx_commit=1，那么MySQL的TPS将会下降到几十每秒，完全不可接受。这是因为InnoDB提交事务时，不仅需要将REDO刷盘，还需要将Binlog刷盘，每个事务都需要2次sync操作。机械磁盘的IOPS也就为几百的水平，所以InnoDB的性能极差。</p>
<p>这个问题，在MySQL 5.6中得到了比较好的解决。在了解Binlog Group Commit之前，需要先了解MySQL Binlog和InnoDB的两阶段提交。MySQL为了保证主库和从库的数据一致性，就必须保证Binlog和InnoDB的一致性，即如果一个事务写入了Binlog，InnoDB中就必须提交该事务；相反，如果一个事务没有写入Binlog，InnoDB就不能提交该事务。做法是：</p>
<p><img src="http://utialun.bj.bcebos.com/resources/1436082376.83.2pc.png" alt=""></p>
<span id="more"></span>
<p>InnoDB先执行Prepare，将Redo日志写磁盘。然后再将Binlog写磁盘，最后InnoDB再执行Commit，将事务标记为提交。这样，可以保证Binlog和InnoDB的一致性。<strong>具体原因，可以分三种情况考虑：</strong></p>
<p><strong>情况1：</strong> 如果MySQL在InnoDB Prepare阶段Crash。MySQL在启动时做崩溃恢复，InnoDB会回滚这些事务，同时由于事务也没有写到binlog，InnoDB和Binlog一致。</p>
<p><strong>情况2：</strong> 如果MySQL在Binlog写磁盘阶段Crash。MySQL在启动时做崩溃恢复，在恢复时会扫描未成功提交的事务，和当时未成功关闭的binlog文件，如果事务已经Prepare了，并且也已经在Binlog中了，InnoDB会提交该事务；相反，如果事务已经在Prepare中了，但是不在Binlog中，InnoDB会回滚该事务。结果就是InnoDB和Binlog一致。</p>
<p><strong>情况3：</strong> 如果MySQL在InnoDB执行Commit阶段Crash，和情况2类似，由于事务已经成功Prepare，并且存在Binlog文件中，InnoDB在崩溃恢复时，仍然会提交该事务，确保Binlog和InnoDB一致。</p>
<p>MySQL在实现时，将mysql_bin_log作为2阶段提交的协调者，可以参考MySQL的代码：sql/handler.cc:ha_commit_trans。内部分别调用tc_log-&gt;prepare()和tc_log-&gt;commit()实现2阶段提交，这里的tc_log就是MySQL源码中的全局对象mysql_bin_log。</p>
<p>伪代码如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">ha_commit_trans</span>()</span><br><span class="line">  --&gt; tc_log-&gt;<span class="built_in">prepare</span>()</span><br><span class="line">        --&gt; <span class="built_in">ha_prepare_low</span>()</span><br><span class="line">              <span class="keyword">for</span> () &#123;</span><br><span class="line">                ht-&gt;<span class="built_in">prepare</span>() <span class="comment">//存储引擎 hton-&gt;prepare()</span></span><br><span class="line">              &#125;</span><br><span class="line">  --&gt; tc_log-&gt;<span class="built_in">commit</span>()</span><br><span class="line">        --&gt; MYSQL_BINLOG::<span class="built_in">ordered_commit</span>()<span class="comment">//做Group Commit</span></span><br><span class="line">              --&gt; MYSQL_BINLOG::<span class="built_in">process_commit_stage_queue</span>() <span class="comment">//Group Commit的Commit阶段，会调用InnoDB提交</span></span><br><span class="line">                    --&gt; <span class="built_in">ha_commit_low</span>()</span><br><span class="line">                          <span class="keyword">for</span> () &#123;</span><br><span class="line">                            ht-&gt;<span class="built_in">commit</span>(); <span class="comment">//存储引擎 hton-&gt;commit()</span></span><br><span class="line">                          &#125;</span><br></pre></td></tr></table></figure>
<p>两阶段提交的参与者分别为：binlog_hton和innobase_hton，它们实现了MySQL的存储引擎接口。如果你再深入调研一下，就会发现binlog_hton在2阶段提交时，啥也没干。所有binlog操作都是由协调者mysql_bin_log干的，包括Group Commit，也都是在mysql_bin_log中实现的。下面我们就来分析一下，mysql_bin_log是如何做到Group Commit的，也就是上面的函数ordered_commit()。</p>
<h2 id="实现"><a class="header-anchor" href="#实现"></a>实现</h2>
<p>和Level DB的Group Commit类似，MySQL的Group Commit也是维护了一个队列，第一个进入队列的线程就是Leader，负责写binlog。其他的线程是Flower，Flower不需要操作，只需要等待完成的通知即可。但是如果只用一个队列的话，在Group Commit进行中的时候，后来的线程就得等待，还可以进一步优化，MySQL把这个过程分裂成了3个阶段：FLUSH_STAGE，SYNC_STAGE和COMMIT_STAGE。它们像流水线一样工作，每个阶段都会涉及一批事务，它们组成一个Group。可以这样理解，事务刚提交时，处于FLUSH阶段，同时处于FLUSH阶段的事务为一个队列，形成一个Group，只有队列的头，Leader在干活，FLUSH完成以后，Leader进入SYNC阶段（所有的Flower也都进入SYNC阶段）。这时，新提交的事务可以进入FLUSH阶段，它们又会产生一个新的Leader，如此不断的推进。每个阶段都需要一个队列，所以MySQL在Group Commit时，需要3个队列。如下图所示，队列通过thd-&gt;next_to_commit连接：</p>
<p><img src="http://utialun.bj.bcebos.com/resources/1436082689.4.stage_queue.png" alt=""></p>
<p>MySQL把队列命名为Mutex_queue，这是一个C++的类，定义如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Mutex_queue</span> &#123;</span><br><span class="line">    THD *m_first; <span class="comment">//队列的头指针</span></span><br><span class="line">    THD **m_last; <span class="comment">//队列尾指针的地址。如果队列为空，相当于&amp;m_first，否则，相当于&amp;last-&gt;next_to_commit</span></span><br><span class="line">    <span class="type">mysql_mutex_t</span> m_lock;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>在Group Commit时，事务的状态首先转为FLUSH_STAGE，然后为SYNC_STAGE，最后为COMMIT_STAGE。在状态转变时，都会调用如下函数Stage_manager::enroll_for：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">Stage_manager::enroll_for</span><span class="params">(StageID stage, THD *thd, <span class="type">mysql_mutex_t</span> *stage_mutex)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 只有队列的第一个元素为Leader，其他情况均为false</span></span><br><span class="line">  <span class="type">bool</span> leader= m_queue[stage].<span class="built_in">append</span>(thd);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// The stage mutex can be NULL if we are enrolling for the first stage.</span></span><br><span class="line">  <span class="keyword">if</span> (stage_mutex)</span><br><span class="line">    <span class="built_in">mysql_mutex_unlock</span>(stage_mutex);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 如果不是Leader的话，只需等待Leader完成操作的通知</span></span><br><span class="line"><span class="comment">   * Leader完成以后，会设置thd-&gt;transaction.flags.pending = false</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">if</span> (!leader) &#123;</span><br><span class="line">    <span class="built_in">mysql_mutex_lock</span>(&amp;m_lock_done);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (thd-&gt;transaction.flags.pending)</span><br><span class="line">      <span class="built_in">mysql_cond_wait</span>(&amp;m_cond_done, &amp;m_lock_done);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">mysql_mutex_unlock</span>(&amp;m_lock_done);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> leader;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>从上面的代码可以看出，Flower线程什么也不干，所有的事情都要靠Leader去做。上述代码有一个细节需要注意，先把自己添加到队列中，然后再释放锁stage_mutex，这个在后面会有解释。下面逐个分析一下，在每个阶段Leader线程所做的事情。</p>
<h2 id="FLUSH阶段"><a class="header-anchor" href="#FLUSH阶段"></a>FLUSH阶段</h2>
<p>因为InnoDB在事务执行过程中，要保证事务的原子性。对于INSERT/UPDATE/DELETE操作，会先将Binlog写事务日志（binlog_cache_mngr），事务提交时，也就是在FLUSH阶段，再把事务日志复制到binlog文件中，然后通知Dump线程去发送binlog，由于要写Binlog文件，这个过程需要锁定LOCK_log锁。这也就是FLUSH阶段要做的事情，可参考函数：MYSQL_BIN_LOG::process_flush_stage_queue。</p>
<p>在这个阶段，Leader线程遍历遍历FLUSH_STAGE链表，依次取出thd对应的事务日志，并写到binlog的IOCACHE中，然后flush IOCACHE。代码如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">MYSQL_BIN_LOG::ordered_commit</span><span class="params">(THD *thd, <span class="type">bool</span> all, <span class="type">bool</span> skip_commit)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">   <span class="comment">//...</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">    Stage #1: flushing transactions to binary log</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    While flushing, we allow new threads to enter and will process</span></span><br><span class="line"><span class="comment">    them in due time. Once the queue was empty, we cannot reap</span></span><br><span class="line"><span class="comment">    anything more since it is possible that a thread entered and</span></span><br><span class="line"><span class="comment">    appointed itself leader for the flush phase.</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line">  <span class="keyword">if</span> (<span class="built_in">change_stage</span>(thd, Stage_manager::FLUSH_STAGE, thd, <span class="literal">NULL</span>, &amp;LOCK_log))</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="built_in">DBUG_PRINT</span>(<span class="string">&quot;return&quot;</span>, (<span class="string">&quot;Thread ID: %lu, commit_error: %d&quot;</span>,</span><br><span class="line">                          thd-&gt;thread_id, thd-&gt;commit_error));</span><br><span class="line">    <span class="built_in">DBUG_RETURN</span>(<span class="built_in">finish_commit</span>(thd));</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  THD *wait_queue= <span class="literal">NULL</span>;</span><br><span class="line">  flush_error= <span class="built_in">process_flush_stage_queue</span>(&amp;total_bytes, &amp;do_rotate, &amp;wait_queue);</span><br><span class="line"></span><br><span class="line">  <span class="type">my_off_t</span> flush_end_pos= <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">if</span> (flush_error == <span class="number">0</span> &amp;&amp; total_bytes &gt; <span class="number">0</span>)</span><br><span class="line">    flush_error= <span class="built_in">flush_cache_to_file</span>(&amp;flush_end_pos);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">    If the flush finished successfully, we can call the after_flush</span></span><br><span class="line"><span class="comment">    hook. Being invoked here, we have the guarantee that the hook is</span></span><br><span class="line"><span class="comment">    executed before the before/after_send_hooks on the dump thread</span></span><br><span class="line"><span class="comment">    preventing race conditions among these plug-ins.</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line">  <span class="keyword">if</span> (flush_error == <span class="number">0</span>)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">char</span> *file_name_ptr= log_file_name + <span class="built_in">dirname_length</span>(log_file_name);</span><br><span class="line">    <span class="built_in">DBUG_ASSERT</span>(flush_end_pos != <span class="number">0</span>);</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">RUN_HOOK</span>(binlog_storage, after_flush,</span><br><span class="line">                 (thd, file_name_ptr, flush_end_pos)))</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="built_in">sql_print_error</span>(<span class="string">&quot;Failed to run &#x27;after_flush&#x27; hooks&quot;</span>);</span><br><span class="line">      flush_error= ER_ERROR_ON_WRITE;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">signal_update</span>();</span><br><span class="line">    <span class="built_in">DBUG_EXECUTE_IF</span>(<span class="string">&quot;crash_commit_after_log&quot;</span>, <span class="built_in">DBUG_SUICIDE</span>(););</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在这个过程中有一个问题需要考虑，就是：一方面，Leader线程从链表中取出thd，将日志写binlog IOCACHE，另一方面，新提交的事务仍然会往FLUSH_STAGE链表中添加thd。如果MySQL的并发事务比较多，Leader线程写binlog的速度，小于新事务的提交速度，可能会造成事务停留在FLUSH阶段的时间过长。所以MySQL通过配置项binlog_max_flush_queue_time来控制这个时间，如果Leader线程在取THD时，发现超时了，Leader线程就将队列整个端走，再做处理。这样，当前已经处于FLUSH阶段的事务还用现在的Leader，而新提交的事务，会用新的Leader。因为LOCK_log锁的存在，所有新的Leader只能等当前的FLUSH执行完成才能开始执行。具体代码如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">MYSQL_BIN_LOG::process_flush_stage_queue</span><span class="params">(<span class="type">my_off_t</span> *total_bytes_var,</span></span></span><br><span class="line"><span class="params"><span class="function">                                         <span class="type">bool</span> *rotate_var,</span></span></span><br><span class="line"><span class="params"><span class="function">                                         THD **out_queue_var)</span></span></span><br><span class="line"><span class="function">  <span class="type">bool</span> has_more</span>= <span class="literal">true</span>;</span><br><span class="line">  THD *first_seen= <span class="literal">NULL</span>;</span><br><span class="line">  <span class="keyword">while</span> ((max_udelay == <span class="number">0</span> || <span class="built_in">my_micro_time</span>() &lt; start_utime + max_udelay) &amp;&amp; has_more)</span><br><span class="line">  &#123;</span><br><span class="line">    std::pair&lt;<span class="type">bool</span>,THD*&gt; current= stage_manager.<span class="built_in">pop_front</span>(Stage_manager::FLUSH_STAGE);</span><br><span class="line">    std::pair&lt;<span class="type">int</span>,<span class="type">my_off_t</span>&gt; result= <span class="built_in">flush_thread_caches</span>(current.second);</span><br><span class="line">    has_more= current.first;</span><br><span class="line">    total_bytes+= result.second;</span><br><span class="line">    <span class="keyword">if</span> (flush_error == <span class="number">1</span>)</span><br><span class="line">      flush_error= result.first;</span><br><span class="line">    <span class="keyword">if</span> (first_seen == <span class="literal">NULL</span>)</span><br><span class="line">      first_seen= current.second;</span><br><span class="line">  &#125;</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">    Either the queue is empty, or we ran out of time. If we ran out of</span></span><br><span class="line"><span class="comment">    time, we have to fetch the entire queue (and flush it) since</span></span><br><span class="line"><span class="comment">    otherwise the next batch will not have a leader.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">if</span> (has_more)</span><br><span class="line">  &#123;</span><br><span class="line">    THD *queue= stage_manager.<span class="built_in">fetch_queue_for</span>(Stage_manager::FLUSH_STAGE);</span><br><span class="line">    <span class="keyword">for</span> (THD *head= queue ; head ; head = head-&gt;next_to_commit)</span><br><span class="line">    &#123;</span><br><span class="line">      std::pair&lt;<span class="type">int</span>,<span class="type">my_off_t</span>&gt; result= <span class="built_in">flush_thread_caches</span>(head);</span><br><span class="line">      total_bytes+= result.second;</span><br><span class="line">      <span class="keyword">if</span> (flush_error == <span class="number">1</span>)</span><br><span class="line">        flush_error= result.first;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (first_seen == <span class="literal">NULL</span>)</span><br><span class="line">      first_seen= queue;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>写完binlog IOCACHE后，还要将IOCACHE写文件，最后通知Dump线程读取binlog，FLUSH阶段完成。</p>
<h2 id="SYNC阶段"><a class="header-anchor" href="#SYNC阶段"></a>SYNC阶段</h2>
<p>SYNC阶段的任务比较简单,但是却非常耗时，就是将binlog文件sync到磁盘。这个操作由配置项sync_binlog = N 来控制每隔N个binlog只sync一次。如果sync_binlog=1的话，MySQL在SYNC阶段不释放锁LOCK_log，而Dump线程为了读取binlog，必须先申请锁LOCK_log，所以可以保证主库先将binlog sync到磁盘，然后Dump线程才能读取Binlog，确保即使在主库操作系统Crash情况下，仍然保证主库和从库数据一致。其他情况会释放LOCK_log锁，这时Dump线程可以读取并发送binlog，同时新提交的事务也可以进入FLUSH阶段。所以SYNC阶段需要考虑有多个FLUSH阶段的Leader同时进入SYNC阶段的情况。MySQL将这些Leader合并为一个新的Leader，做法是：FLUSH阶段的Leader线程进入SYNC阶段前，需要将自己加入到SYNC_STAGE队列中，第一个进入SYNC_STAGE队列的线程为SYNC阶段的Leader，后进入的为Flower。由Leader完成后续操作，Flower线程只需等待通知即可。回忆前面的函数enroll_for()，在状态转变时，Leader先把自己添加到SYNC队列中，然后才释放锁stage_mutex，这里就是LOCK_log，其他事务才可以进入FLUSH阶段，这可以保证，第一个进入FLUSH阶段的Leader，在SYNC阶段仍然是Leader，同样，在COMMIT阶段还是Leader。这对于保证Binlog和InnoDB提交顺序一致非常重要。</p>
<p><img src="http://utialun.bj.bcebos.com/resources/1436088683.87.sync_stage.png" alt=""></p>
<p>SYNC阶段的代码如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">MYSQL_BIN_LOG::ordered_commit</span><span class="params">(THD *thd, <span class="type">bool</span> all, <span class="type">bool</span> skip_commit)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"></span><br><span class="line">   <span class="comment">// ...</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">    Stage #2: Syncing binary log file to disk</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line">  <span class="type">bool</span> need_LOCK_log= (<span class="built_in">get_sync_period</span>() == <span class="number">1</span>); <span class="comment">//只有sync_binlog=1，才不释放LOCK_log锁</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">    LOCK_log is not released when sync_binlog is 1. It guarantees that the</span></span><br><span class="line"><span class="comment">    events are not be replicated by dump threads before they are synced to disk.</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line">  <span class="comment">//不管怎样，都要申请锁LOCK_sync</span></span><br><span class="line">  <span class="keyword">if</span> (<span class="built_in">change_stage</span>(thd, Stage_manager::SYNC_STAGE, wait_queue,</span><br><span class="line">                   need_LOCK_log ? <span class="literal">NULL</span> : &amp;LOCK_log, &amp;LOCK_sync))</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="built_in">DBUG_PRINT</span>(<span class="string">&quot;return&quot;</span>, (<span class="string">&quot;Thread ID: %lu, commit_error: %d&quot;</span>,</span><br><span class="line">                          thd-&gt;thread_id, thd-&gt;commit_error));</span><br><span class="line">    <span class="built_in">DBUG_RETURN</span>(<span class="built_in">finish_commit</span>(thd));</span><br><span class="line">  &#125;</span><br><span class="line">  THD *final_queue= stage_manager.<span class="built_in">fetch_queue_for</span>(Stage_manager::SYNC_STAGE);</span><br><span class="line">  <span class="keyword">if</span> (flush_error == <span class="number">0</span> &amp;&amp; total_bytes &gt; <span class="number">0</span>)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="built_in">DEBUG_SYNC</span>(thd, <span class="string">&quot;before_sync_binlog_file&quot;</span>);</span><br><span class="line">    std::pair&lt;<span class="type">bool</span>, <span class="type">bool</span>&gt; result= <span class="built_in">sync_binlog_file</span>(<span class="literal">false</span>);</span><br><span class="line">    flush_error= result.first;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (need_LOCK_log)</span><br><span class="line">    <span class="built_in">mysql_mutex_unlock</span>(&amp;LOCK_log);</span><br><span class="line"></span><br><span class="line">  <span class="comment">//...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="COMMIT阶段"><a class="header-anchor" href="#COMMIT阶段"></a>COMMIT阶段</h2>
<p>经过前面2个阶段，Binlog已经顺利sync到磁盘了，COMMIT阶段的任务就是让InnoDB存储引擎完成Commit。COMMIT阶段的逻辑通过MySQL的配置项binlog_order_commits控制。如果配置项为1，MySQL要保证InnoDB的提交顺序和Binlog的写入顺序一致，这个特性在InnoDB热备中使用。下面只分析binlog_order_commits=1的情况。</p>
<p>MySQL释放锁LOCK_sync，申请锁LOCK_commit。由于释放锁LOCK_sync，所以需要考虑多个线程同时完成SYNC阶段的情况，处理逻辑和SYNC阶段类似，将当前SYNC阶段的Leader合并，关于Leader的产生和SYNC阶段类似。Leader产生以后，遍历THD，完成事务提交，等所有事务都提交完成以后，再遍历thd，设置thd-&gt;transaction.flags.pending=false，最后广播通知Flower线程提交完成，自此，Group Commit完成。</p>
<p>代码如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">MYSQL_BIN_LOG::ordered_commit</span><span class="params">(THD *thd, <span class="type">bool</span> all, <span class="type">bool</span> skip_commit)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">   <span class="comment">//...</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">    Stage #3: Commit all transactions in order.</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    This stage is skipped if we do not need to order the commits and</span></span><br><span class="line"><span class="comment">    each thread have to execute the handlerton commit instead.</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    Howver, since we are keeping the lock from the previous stage, we</span></span><br><span class="line"><span class="comment">    need to unlock it if we skip the stage.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">if</span> (opt_binlog_order_commits)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">change_stage</span>(thd, Stage_manager::COMMIT_STAGE,</span><br><span class="line">                     final_queue, &amp;LOCK_sync, &amp;LOCK_commit))</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="built_in">DBUG_PRINT</span>(<span class="string">&quot;return&quot;</span>, (<span class="string">&quot;Thread ID: %lu, commit_error: %d&quot;</span>,</span><br><span class="line">                            thd-&gt;thread_id, thd-&gt;commit_error));</span><br><span class="line">      <span class="built_in">DBUG_RETURN</span>(<span class="built_in">finish_commit</span>(thd));</span><br><span class="line">    &#125;</span><br><span class="line">    THD *commit_queue= stage_manager.<span class="built_in">fetch_queue_for</span>(Stage_manager::COMMIT_STAGE);</span><br><span class="line">    <span class="built_in">DBUG_EXECUTE_IF</span>(<span class="string">&quot;semi_sync_3-way_deadlock&quot;</span>,</span><br><span class="line">                    <span class="built_in">DEBUG_SYNC</span>(thd, <span class="string">&quot;before_process_commit_stage_queue&quot;</span>););</span><br><span class="line">    <span class="built_in">process_commit_stage_queue</span>(thd, commit_queue);</span><br><span class="line">    <span class="built_in">mysql_mutex_unlock</span>(&amp;LOCK_commit);</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">      Process after_commit after LOCK_commit is released for avoiding</span></span><br><span class="line"><span class="comment">      3-way deadlock among user thread, rotate thread and dump thread.</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="built_in">process_after_commit_stage_queue</span>(thd, commit_queue);</span><br><span class="line">    final_queue= commit_queue;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">    <span class="built_in">mysql_mutex_unlock</span>(&amp;LOCK_sync);</span><br><span class="line"></span><br><span class="line"> <span class="comment">/* Commit done so signal all waiting threads */</span></span><br><span class="line">  stage_manager.<span class="built_in">signal_done</span>(final_queue);</span><br><span class="line"></span><br><span class="line"> <span class="comment">//...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Leader产生以后，Leader线程通过next_to_commit遍历thd，对每个thd完成事务提交ha_commit_low(),代码如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span></span></span><br><span class="line"><span class="function"><span class="title">MYSQL_BIN_LOG::process_commit_stage_queue</span><span class="params">(THD *thd, THD *first)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (THD *head= first ; head ; head = head-&gt;next_to_commit)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">if</span> (head-&gt;commit_error == THD::CE_NONE)</span><br><span class="line">    &#123;</span><br><span class="line">      excursion.<span class="built_in">try_to_attach_to</span>(head);</span><br><span class="line">      <span class="type">bool</span> all= head-&gt;transaction.flags.real_commit;</span><br><span class="line">      <span class="keyword">if</span> (head-&gt;transaction.flags.commit_low)</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="comment">/* head is parked to have exited append() */</span></span><br><span class="line">        <span class="built_in">DBUG_ASSERT</span>(head-&gt;transaction.flags.ready_preempt);</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">          storage engine commit</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">ha_commit_low</span>(head, all, <span class="literal">false</span>))</span><br><span class="line">          head-&gt;commit_error= THD::CE_COMMIT_ERROR;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">      Decrement the prepared XID counter after storage engine commit.</span></span><br><span class="line"><span class="comment">      We also need decrement the prepared XID when encountering a</span></span><br><span class="line"><span class="comment">      flush error or session attach error for avoiding 3-way deadlock</span></span><br><span class="line"><span class="comment">      among user thread, rotate thread and dump thread.</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="keyword">if</span> (head-&gt;transaction.flags.xid_written)</span><br><span class="line">      <span class="built_in">dec_prep_xids</span>(head);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Stage_manager</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  <span class="comment">//遍历THD，标记提交完成，并广播通知</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">signal_done</span><span class="params">(THD *queue)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">mysql_mutex_lock</span>(&amp;m_lock_done);</span><br><span class="line">    <span class="keyword">for</span> (THD *thd= queue ; thd ; thd = thd-&gt;next_to_commit)</span><br><span class="line">      thd-&gt;transaction.flags.pending= <span class="literal">false</span>;</span><br><span class="line">    <span class="built_in">mysql_mutex_unlock</span>(&amp;m_lock_done);</span><br><span class="line">    <span class="built_in">mysql_cond_broadcast</span>(&amp;m_cond_done);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/implement-of-binlog-group-commit-in-mysql56/">http://xnerv.wang/implement-of-binlog-group-commit-in-mysql56/</a></strong><br>
转载自：<a href="http://hamilton.duapp.com/detail?articleId=42">MySQL 5.6中Binlog Group Commit实现</a></p>
]]></content>
      <categories>
        <category>DBMS</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>DBMS</tag>
        <tag>MySQL</tag>
        <tag>Binlog Group Commit</tag>
      </tags>
  </entry>
  <entry>
    <title>IMPLEMENTING REPEATABLE READ AND SERIALIZABLE TRANSACTION ISOLATION（转载）</title>
    <url>/implementing-repeatable-read-and-serializable-transaction-isolation/</url>
    <content><![CDATA[<p>This article is part of a series. You do not have to read them in order but I will be referring to topics and explanations in previous articles:</p>
<ol>
<li><a href="/implementing-your-own-transactions-with-mvcc">Implementing Your Own Transactions With MVCC</a></li>
<li><a href="/sql-transaction-isolation-levels-explained">SQL Transaction Isolation Levels Explained</a></li>
<li><strong>Implementing Repeatable Read and Serializable Transaction Isolation</strong></li>
</ol>
<span id="more"></span>
<hr>
<p><em>Repeatable read</em> and <em>serializable</em> are usually higher than most databases use by default (if they are available at all). You can read a full explanation of the differences in the levels in the previous article, <a href="http://elliot.land/post/sql-transaction-isolation-levels-explained">SQL Transaction Isolation Levels Explained</a>.</p>
<p>This article will focus on a real Python implementation of all four levels but mainly focused on repeatable read and serializable.</p>
<p>I’m going to use the code from the <a href="https://elliot.land/post/implementing-your-own-transactions-with-mvcc">original article on MVCC which implemented read-committed</a> and refactor it to allow us to set the transaction isolation. You should understand how MVCC works an how it is implemented for <em>read committed</em> in that article before proceeding.</p>
<p>You can view the <a href="https://gist.github.com/elliotchance/21e31b8ffb18cbbca23b8031639e1c3f">entire program here</a>.</p>
<h2 id="Implementing-the-Isolation-Levels-as-Classes"><a class="header-anchor" href="#Implementing-the-Isolation-Levels-as-Classes"></a>Implementing the Isolation Levels as Classes</h2>
<p>The majority of the logic of a transaction will remain in the Transaction class. There have been some new methods added:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Transaction</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, table, xid</span>):</span><br><span class="line">        self.table = table</span><br><span class="line">        self.xid = xid</span><br><span class="line">        self.rollback_actions = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add_record</span>(<span class="params">self, <span class="built_in">id</span>, name</span>):</span><br><span class="line">        record = &#123;</span><br><span class="line">            <span class="string">&#x27;id&#x27;</span>: <span class="built_in">id</span>,</span><br><span class="line">            <span class="string">&#x27;name&#x27;</span>: name,</span><br><span class="line">            <span class="string">&#x27;created_xid&#x27;</span>: self.xid,</span><br><span class="line">            <span class="string">&#x27;expired_xid&#x27;</span>: <span class="number">0</span></span><br><span class="line">        &#125;</span><br><span class="line">        self.rollback_actions.append([<span class="string">&quot;delete&quot;</span>, <span class="built_in">len</span>(self.table.records)])</span><br><span class="line">        self.table.records.append(record)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">delete_record</span>(<span class="params">self, <span class="built_in">id</span></span>):</span><br><span class="line">        <span class="keyword">for</span> i, record <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.table.records):</span><br><span class="line">            <span class="keyword">if</span> self.record_is_visible(record) <span class="keyword">and</span> record[<span class="string">&#x27;id&#x27;</span>] == <span class="built_in">id</span>:</span><br><span class="line">                <span class="keyword">if</span> self.record_is_locked(record):</span><br><span class="line">                    <span class="keyword">raise</span> RollbackException(<span class="string">&quot;Row locked by another transaction.&quot;</span>)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    record[<span class="string">&#x27;expired_xid&#x27;</span>] = self.xid</span><br><span class="line">                    self.rollback_actions.append([<span class="string">&quot;add&quot;</span>, i])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update_record</span>(<span class="params">self, <span class="built_in">id</span>, name</span>):</span><br><span class="line">        self.delete_record(<span class="built_in">id</span>)</span><br><span class="line">        self.add_record(<span class="built_in">id</span>, name)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fetch_record</span>(<span class="params">self, <span class="built_in">id</span></span>):</span><br><span class="line">        <span class="keyword">for</span> record <span class="keyword">in</span> self.table.records:</span><br><span class="line">            <span class="keyword">if</span> self.record_is_visible(record) <span class="keyword">and</span> record[<span class="string">&#x27;id&#x27;</span>] <span class="keyword">is</span> <span class="built_in">id</span>:</span><br><span class="line">                <span class="keyword">return</span> record</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">count_records</span>(<span class="params">self, min_id, max_id</span>):</span><br><span class="line">        count = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> record <span class="keyword">in</span> self.table.records:</span><br><span class="line">            <span class="keyword">if</span> self.record_is_visible(record) <span class="keyword">and</span> \</span><br><span class="line">                min_id &lt;= record[<span class="string">&#x27;id&#x27;</span>] &lt;= max_id:</span><br><span class="line">                count += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> count</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fetch_all_records</span>(<span class="params">self</span>):</span><br><span class="line">        visible_records = []</span><br><span class="line">        <span class="keyword">for</span> record <span class="keyword">in</span> self.table.records:</span><br><span class="line">            <span class="keyword">if</span> self.record_is_visible(record):</span><br><span class="line">                visible_records.append(record)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> visible_records</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fetch</span>(<span class="params">self, expr</span>):</span><br><span class="line">        visible_records = []</span><br><span class="line">        <span class="keyword">for</span> record <span class="keyword">in</span> self.table.records:</span><br><span class="line">            <span class="keyword">if</span> self.record_is_visible(record) <span class="keyword">and</span> expr(record):</span><br><span class="line">                visible_records.append(record)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> visible_records</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">commit</span>(<span class="params">self</span>):</span><br><span class="line">        self.table.active_xids.discard(self.xid)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">rollback</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">for</span> action <span class="keyword">in</span> <span class="built_in">reversed</span>(self.rollback_actions):</span><br><span class="line">            <span class="keyword">if</span> action[<span class="number">0</span>] == <span class="string">&#x27;add&#x27;</span>:</span><br><span class="line">                self.table.records[action[<span class="number">1</span>]][<span class="string">&#x27;expired_xid&#x27;</span>] = <span class="number">0</span></span><br><span class="line">            <span class="keyword">elif</span> action[<span class="number">0</span>] == <span class="string">&#x27;delete&#x27;</span>:</span><br><span class="line">                self.table.records[action[<span class="number">1</span>]][<span class="string">&#x27;expired_xid&#x27;</span>] = self.xid</span><br><span class="line"></span><br><span class="line">        self.table.active_xids.discard(self.xid)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<hr>
<p>We also introduce a new type of error, the RollbackException. We will use this to indicate that some race condition has occurred, that if allowed to continue would break the requirements of the chosen isolation level. This type of error becomes more common as the isolation level increases and is caught by the DBMS so that the transaction can be safely rolled back and the client notified.</p>
<p>It is really just an alias for Exception. However, we want to differentiate this type of error so that other errors are not mistakenly caught:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RollbackException</span>(<span class="title class_ inherited__">Exception</span>):</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<hr>
<p>It’s not easy to demonstrate interfaces or abstract classes in Python. Two methods that are missing from the Transaction class above are record_is_locked(record) and record_is_visible(record) and are implemented by the child class. As long as we implement these two methods we can control the isolation behaviour of the transaction.</p>
<p>For example the most simple isolation level is <em>read uncommitted</em>:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ReadUncommittedTransaction</span>(<span class="title class_ inherited__">Transaction</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">record_is_locked</span>(<span class="params">self, record</span>):</span><br><span class="line">        <span class="keyword">return</span> record[<span class="string">&#x27;expired_xid&#x27;</span>] != <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">record_is_visible</span>(<span class="params">self, record</span>):</span><br><span class="line">        <span class="keyword">return</span> record[<span class="string">&#x27;expired_xid&#x27;</span>] == <span class="number">0</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>It may seem like an anti-transaction pattern to read data that is not yet confirmed by another transaction. Read uncommitted is useful for large reporting queries where you really don’t want to impose any locking that would affect in-flight or new transactions. In exchange for this your totals may be a little off. Sometimes this is insignificant enough (such as processing millions of rows) that it makes sense to trade accuracy for concurrency.</p>
<hr>
<p>Here is the implementation for <em>read committed</em> (if you have read the previous article this should look very familiar):</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ReadCommittedTransaction</span>(<span class="title class_ inherited__">Transaction</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">record_is_locked</span>(<span class="params">self, record</span>):</span><br><span class="line">        <span class="keyword">return</span> record[<span class="string">&#x27;expired_xid&#x27;</span>] != <span class="number">0</span> <span class="keyword">and</span> \</span><br><span class="line">            row[<span class="string">&#x27;expired_xid&#x27;</span>] <span class="keyword">in</span> self.table.active_xids</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">record_is_visible</span>(<span class="params">self, record</span>):</span><br><span class="line">        <span class="comment"># The record was created in active transaction that is not our</span></span><br><span class="line">        <span class="comment"># own.</span></span><br><span class="line">        <span class="keyword">if</span> record[<span class="string">&#x27;created_xid&#x27;</span>] <span class="keyword">in</span> self.table.active_xids <span class="keyword">and</span> \</span><br><span class="line">            record[<span class="string">&#x27;created_xid&#x27;</span>] != self.xid:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># The record is expired or and no transaction holds it that is</span></span><br><span class="line">        <span class="comment"># our own.</span></span><br><span class="line">        <span class="keyword">if</span> record[<span class="string">&#x27;expired_xid&#x27;</span>] != <span class="number">0</span> <span class="keyword">and</span> \</span><br><span class="line">            (record[<span class="string">&#x27;expired_xid&#x27;</span>] <span class="keyword">not</span> <span class="keyword">in</span> self.table.active_xids <span class="keyword">or</span> \</span><br><span class="line">            record[<span class="string">&#x27;expired_xid&#x27;</span>] == self.xid):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>I won’t explain this now as there was already a whole article dedicated to it.</p>
<hr>
<p>Now we can move onto the higher isolation levels that most databases do not use by default because concurrency and performance start to suffer in exchange for greater accuracy and isolations of the transactions:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RepeatableReadTransaction</span>(<span class="title class_ inherited__">ReadCommittedTransaction</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">record_is_locked</span>(<span class="params">self, record</span>):</span><br><span class="line">        <span class="keyword">return</span> ReadCommittedTransaction.record_is_locked(self, record) <span class="keyword">or</span> \</span><br><span class="line">            self.table.locks.exists(self, record[<span class="string">&#x27;id&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">record_is_visible</span>(<span class="params">self, record</span>):</span><br><span class="line">        is_visible = ReadCommittedTransaction.record_is_visible(self, record)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> is_visible:</span><br><span class="line">            self.table.locks.add(self, record[<span class="string">&#x27;id&#x27;</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> is_visible</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>To achieve repeatable read we use the same visibility (and locking) checks as read committed (ReadCommittedTransaction), but we add a read lock on every record that is read (and hence, visible) by us. It’s important we don’t add read locks to records that would otherwise not be visible to us, so that another transaction cannot remove it if we need to rescan the data.</p>
<p>Here is a very crude lock manager, it simply keeps track of which transactions hold a read lock on any particular row. How this lock manager performs isn’t important, and there many ways to make this mechanism work better and faster. For the purpose of this demonstration just know that there is <em>something</em> that remembers when transactions have <em>seen</em> a row:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LockManager</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.locks = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">self, transaction, record_id</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.exists(transaction, record_id):</span><br><span class="line">            self.locks.append([transaction, record_id])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">exists</span>(<span class="params">self, transaction, record_id</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">any</span>(lock[<span class="number">0</span>] <span class="keyword">is</span> transaction <span class="keyword">and</span> lock[<span class="number">1</span>] == record_id \</span><br><span class="line">            <span class="keyword">for</span> lock <span class="keyword">in</span> self.locks)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<hr>
<p>Finally, we can implement <em>serializable</em>:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SerializableTransaction</span>(<span class="title class_ inherited__">RepeatableReadTransaction</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, table, xid</span>):</span><br><span class="line">        Transaction.__init__(self, table, xid)</span><br><span class="line">        self.existing_xids = self.table.active_xids.copy()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">record_is_visible</span>(<span class="params">self, record</span>):</span><br><span class="line">        is_visible = ReadCommittedTransaction.record_is_visible(self, record) \</span><br><span class="line">            <span class="keyword">and</span> record[<span class="string">&#x27;created_xid&#x27;</span>] &lt;= self.xid \</span><br><span class="line">            <span class="keyword">and</span> record[<span class="string">&#x27;created_xid&#x27;</span>] <span class="keyword">in</span> self.existing_xids</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> is_visible:</span><br><span class="line">            self.table.locks.add(self, record[<span class="string">&#x27;id&#x27;</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> is_visible</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>Once again it uses the logic of ReadCommittedTransaction (but not RepeatableReadTransaction as you might originally suspect). Serializable primarily enforces one main new restriction to prevent phantom reads. That is, we must ignore any record that is added or updated in a transaction that was created after the current transaction.</p>
<p><strong>Bring On the Tests</strong></p>
<p>To really demonstrate the isolation levels we need to create test cases. All of the tests start with the same fixture data:</p>
<table>
<thead>
<tr>
<th>id</th>
<th>name</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Joe</td>
</tr>
<tr>
<td>3</td>
<td>Jill</td>
</tr>
</tbody>
</table>
<p>A transaction test is implemented as a class. It will setup the fixture data (in the table above) and clients on which the test will be performed. It also runs the test and returns a pretty tick or cross for the outcome (we will use this later).</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TransactionTest</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, transaction_type</span>):</span><br><span class="line">        self.table = Table()</span><br><span class="line">        client = self.table.new_transaction(ReadCommittedTransaction)</span><br><span class="line">        client.add_record(<span class="built_in">id</span>=<span class="number">1</span>, name=<span class="string">&quot;Joe&quot;</span>)</span><br><span class="line">        client.add_record(<span class="built_in">id</span>=<span class="number">3</span>, name=<span class="string">&quot;Jill&quot;</span>)</span><br><span class="line">        client.commit()</span><br><span class="line"></span><br><span class="line">        self.client1 = self.table.new_transaction(transaction_type)</span><br><span class="line">        self.client2 = self.table.new_transaction(transaction_type)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">run_test</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">return</span> self.run()</span><br><span class="line">        <span class="keyword">except</span> RollbackException:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">result</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">if</span> self.run_test():</span><br><span class="line">            <span class="keyword">return</span> <span class="string">u&#x27;✔&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">u&#x27;✘&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>Individual error scenarios (dirty reads, non-repeatable reads and phantom reads) are implemented by extending the TransactionTest and providing the run() method:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">DirtyRead</span>(<span class="title class_ inherited__">TransactionTest</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">self</span>):</span><br><span class="line">        result1 = self.client1.fetch_record(<span class="built_in">id</span>=<span class="number">1</span>)</span><br><span class="line">        self.client2.update_record(<span class="built_in">id</span>=<span class="number">1</span>, name=<span class="string">&quot;Joe 2&quot;</span>)</span><br><span class="line">        result2 = self.client1.fetch_record(<span class="built_in">id</span>=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result1 != result2</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NonRepeatableRead</span>(<span class="title class_ inherited__">TransactionTest</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">self</span>):</span><br><span class="line">        result1 = self.client1.fetch_record(<span class="built_in">id</span>=<span class="number">1</span>)</span><br><span class="line">        self.client2.update_record(<span class="built_in">id</span>=<span class="number">1</span>, name=<span class="string">&quot;Joe 2&quot;</span>)</span><br><span class="line">        self.client2.commit()</span><br><span class="line">        result2 = self.client1.fetch_record(<span class="built_in">id</span>=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result1 != result2</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PhantomRead</span>(<span class="title class_ inherited__">TransactionTest</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">self</span>):</span><br><span class="line">        result1 = <span class="built_in">len</span>(self.client1.fetch(<span class="keyword">lambda</span> r: <span class="number">1</span> &lt;= r[<span class="string">&#x27;id&#x27;</span>] &lt;= <span class="number">3</span>))</span><br><span class="line">        self.client2.add_record(<span class="built_in">id</span>=<span class="number">2</span>, name=<span class="string">&quot;John&quot;</span>)</span><br><span class="line">        self.client2.commit()</span><br><span class="line">        result2 = self.client1.count_records(min_id=<span class="number">1</span>, max_id=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result1 != result2</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>Running the <a href="https://gist.github.com/elliotchance/21e31b8ffb18cbbca23b8031639e1c3f">complete program</a> prints a table of results. The <font style="font-family: 'Courier New';">✔ means that it could replicate that kind of error (a little counterintuitive, I know):</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">                  Dirty Repeat Phantom</span><br><span class="line">read uncommitted    ✔      ✔      ✔</span><br><span class="line">read committed      ✘      ✔      ✔</span><br><span class="line">repeatable read     ✘      ✘      ✔</span><br><span class="line">serializable        ✘      ✘      ✘</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/implementing-repeatable-read-and-serializable-transaction-isolation/">http://xnerv.wang/implementing-repeatable-read-and-serializable-transaction-isolation/</a></strong><br>
转载自：<a href="http://elliot.land/post/implementing-repeatable-read-and-serializable-transaction-isolation">IMPLEMENTING REPEATABLE READ AND SERIALIZABLE TRANSACTION ISOLATION</a></p>
]]></content>
      <categories>
        <category>DBMS</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>DBMS</tag>
        <tag>SQL Server</tag>
        <tag>Transaction</tag>
        <tag>Isolation Level</tag>
      </tags>
  </entry>
  <entry>
    <title>IMPLEMENTING YOUR OWN TRANSACTIONS WITH MVCC（转载）</title>
    <url>/implementing-your-own-transactions-with-mvcc/</url>
    <content><![CDATA[<p>This article is part of a series. You do not have to read them in order but I will be referring to topics and explanations in previous articles:</p>
<ol>
<li><strong>Implementing Your Own Transactions With MVCC</strong></li>
<li><a href="/sql-transaction-isolation-levels-explained">SQL Transaction Isolation Levels Explained</a></li>
<li><a href="/implementing-repeatable-read-and-serializable-transaction-isolation">Implementing Repeatable Read and Serializable Transaction Isolation</a></li>
</ol>
<span id="more"></span>
<hr>
<p><img src="http://postachio-images.s3.amazonaws.com/aa0e0e8e-5932-48c5-bbd5-bb782bc5caef/34bf5c8b-35b7-4768-944c-7baf3acce0d5/3c68b122-cc0d-4461-ade6-fae0d9594095.png" alt=""></p>
<p>MVCC (<a href="https://en.wikipedia.org/wiki/Multiversion_concurrency_control">MultiVersion Concurrency Control</a>) is a simple and effective way to implement transactional isolation with any application managing a group of things. We usually think of these things as database records by they could be anything really.</p>
<p>MVCC is one of the most widely implemented concurrency control algorithms because reads do not block other reads and writes do not block other reads or writes. This means that we can safely and concurrently have lots of clients reading and writing simultaneously without blocking each other. With some notable specific cases that I will explain later.</p>
<h2 id="What-is-Isolation"><a class="header-anchor" href="#What-is-Isolation"></a>What is Isolation?</h2>
<p>Isolation (the I from <a href="https://en.wikipedia.org/wiki/ACID">ACID</a>) makes sure that when a client begins a transaction that the data it sees will always be the same. Event if other clients are modifying the data.</p>
<p>If another client (or clients);</p>
<ul>
<li><strong>Add a record</strong>: It will not be visible to you.</li>
<li><strong>Delete a record</strong>: It will remain visible to you.</li>
<li><strong>Modify a record</strong>: You will forever see the version before it was changed.</li>
</ul>
<p>However, inside your transaction those three things do to take affect. So if you add a record then it will be visible to you.</p>
<p>Often overlooked, transactions applied to the correct applications can;</p>
<ul>
<li><strong>Alleviate blocking</strong> if you previously relied on simply locking the whole database until your modifications where finished.</li>
<li><strong>Prevent read issues from arising</strong> if your application is affected by reading the same data twice and getting two different answers unexpectedly.</li>
<li><strong>Provide durability</strong>. At any time you can throw away the changes if you change your mind without explicitly undoing all the changes yourself.</li>
</ul>
<h2 id="Terminology"><a class="header-anchor" href="#Terminology"></a>Terminology</h2>
<p>A <em>record</em> is a single entity. This would be best explained as a database record. It could also be a file, a JSON object, anything that encapsulates something. Most importantly here is that a record cannot be simultaneously modified by two separate clients. If you have a complex data structure you will want to make sure what you define as a record does not encapsulate too much.</p>
<p>A <em>collection</em> is the set of records. This would be like a table in a database. The important thing here is that a transaction is not isolated to a single collection as long as each of the records share the same transaction IDs.</p>
<p>A <em>transaction ID</em> (also called an <em>XID</em>) is the unique number for the transaction. All records that have been modified under the same transaction can be saved or rolled back as one atomic operation, which is ultimately what we want.</p>
<h2 id="Transaction-IDs"><a class="header-anchor" href="#Transaction-IDs"></a>Transaction IDs</h2>
<p>There are three categories of transaction ID numbering systems we can use;</p>
<ol>
<li><strong>An incrementing number.</strong> Before a transaction starts (before any changes occur is important, even if there are no changes). This is the transaction ID for all the record changes. It doesn’t matter if the changes are saved or thrown away the same transaction ID can never be used again so it must be atomic. Also important is the value must be kept when the script/server restarts to prevent transaction IDs from being reused.</li>
<li><strong>A timestamp.</strong> We do not need to maintain an atomic counter. This has the added benefit of allowing us to restore the collections to some point in time. There is one caveat; if the timestamp does not have a high enough resolution (lets say your using whole seconds) transactions that start very close to each other would potentially share the same transaction ID and horrible things will happen…</li>
<li><strong>Custom transaction ID implementations</strong>. Special cases where you are working with distributed databases or have other requirements that are not satisfied by the two types above. This may include UUID based algorithms and may not even be strictly a number.</li>
</ol>
<p>Items 2 and 3 each deserve their own blog post so we won’t walk about it here. Just the mechanism of the most simple implementation of using an incrementing counter.</p>
<h2 id="It’s-Time-to-Dive-In"><a class="header-anchor" href="#It’s-Time-to-Dive-In"></a>It’s Time to Dive In</h2>
<p>I’m going to provide the code examples in Python. The full example program is available <a href="https://gist.github.com/elliotchance/d169e39f5d4d056a9138">in this gist</a>. But I will explain each piece below.</p>
<p>In a nutshell what we need is the next transaction ID and an array (or set) of the transactions currently active to produce new transactions:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">next_xid = <span class="number">1</span></span><br><span class="line">active_xids = <span class="built_in">set</span>()</span><br><span class="line">records = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">new_transaction</span>():</span><br><span class="line">    <span class="keyword">global</span> next_xid</span><br><span class="line">    next_xid += <span class="number">1</span></span><br><span class="line">    active_xids.add(next_xid)</span><br><span class="line">    <span class="keyword">return</span> Transaction(next_xid)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Transaction</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, xid</span>):</span><br><span class="line">        self.xid = xid</span><br><span class="line">        self.rollback_actions = []</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>In your application you may decide that clients (if you have any) can control when transactions are opened or closed. It doesn’t affect how the transactions work and they are independent of this.</p>
<p>Next we need to add two discreet pieces of information attached to each record. Called the created XID and expired XID. It’s best to store these directly with the record itself. However, that is not always possible so you can maintain them somewhere external as long as you are the only one modifying the data to maintain consistency.</p>
<h2 id="Row-Visibility-and-Locking"><a class="header-anchor" href="#Row-Visibility-and-Locking"></a>Row Visibility and Locking</h2>
<p>Ultimately this is what MVCC comes down to: The visibility of a row depending on who is looking at it. Ever row has to be tested if it is visible to the client looking at it:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#class Transaction:</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">record_is_visible</span>(<span class="params">self, record</span>):</span><br><span class="line">        <span class="comment"># The record was created in active transaction that is not our</span></span><br><span class="line">        <span class="comment"># own.</span></span><br><span class="line">        <span class="keyword">if</span> record[<span class="string">&#x27;created_xid&#x27;</span>] <span class="keyword">in</span> active_xids <span class="keyword">and</span> \</span><br><span class="line">            record[<span class="string">&#x27;created_xid&#x27;</span>] != self.xid:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># The record is expired or and no transaction holds it that is</span></span><br><span class="line">        <span class="comment"># our own.</span></span><br><span class="line">        <span class="keyword">if</span> record[<span class="string">&#x27;expired_xid&#x27;</span>] != <span class="number">0</span> <span class="keyword">and</span> \</span><br><span class="line">            (record[<span class="string">&#x27;expired_xid&#x27;</span>] <span class="keyword">not</span> <span class="keyword">in</span> active_xids <span class="keyword">or</span> \</span><br><span class="line">            record[<span class="string">&#x27;expired_xid&#x27;</span>] == self.xid):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>(xnerv: created_id is the transaction ID which created this row. expired_id is the transaction ID which deleted this row.)</p>
<p>Furthermore, we discussed before that simultaneous transactions cannot make a modification to the same record. If this happens there are two ways to handle this:</p>
<ol>
<li><strong>Abort (rollback)</strong> the transaction that tried to make the most recent changes and propagate the error back to the original client.</li>
<li><strong>Wait (block)</strong> the second transaction until that record becomes available. This has some special challenges with performance and potential reread errors.</li>
</ol>
<p>The safest and easiest one is the first choice - so that’s what we’re going to use in this tutorial. When we do need to modify a record we need to check if it is locked by another transaction with this:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#class Transaction:</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">row_is_locked</span>(<span class="params">self, record</span>):</span><br><span class="line">        <span class="keyword">return</span> record[<span class="string">&#x27;expired_xid&#x27;</span>] != <span class="number">0</span> <span class="keyword">and</span> \</span><br><span class="line">            record[<span class="string">&#x27;expired_xid&#x27;</span>] <span class="keyword">in</span> active_xids</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="Adding-a-Record"><a class="header-anchor" href="#Adding-a-Record"></a>Adding a Record</h2>
<p>This is an easy one. We set the  created_xid  to the current transaction ID and  expired_xid  to  0 :</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#class Transaction:</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add_record</span>(<span class="params">self, record</span>):</span><br><span class="line">        record[<span class="string">&#x27;created_xid&#x27;</span>] = self.xid</span><br><span class="line">        record[<span class="string">&#x27;expired_xid&#x27;</span>] = <span class="number">0</span></span><br><span class="line">        self.rollback_actions.append([<span class="string">&quot;delete&quot;</span>, <span class="built_in">len</span>(records)])</span><br><span class="line">        records.append(record)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>The <code>rollback_actions</code> will be explained later.</p>
<h2 id="Deleting-a-Record"><a class="header-anchor" href="#Deleting-a-Record"></a>Deleting a Record</h2>
<p>There are two possibilities:</p>
<ol>
<li>The <code>expired_xid</code> is <code>0</code> meaning the record has never been deleted by anyone. So by setting <code>expired_xid</code> to the current transaction ID we are marking it as deleted.</li>
<li>The <code>expired_xid</code> it not <code>0</code> <em>and</em> <code>expired_xid</code> is an active transaction. The record has been deleted by another active transaction and so we cannot touch it.</li>
</ol>
<p>The third scenario where <code>expired_xid</code> is not an active transaction is not possible due to the normal visibility constraints.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#class Transaction:</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">delete_record</span>(<span class="params">self, <span class="built_in">id</span></span>):</span><br><span class="line">        <span class="keyword">for</span> i, record <span class="keyword">in</span> <span class="built_in">enumerate</span>(records):</span><br><span class="line">            <span class="keyword">if</span> self.record_is_visible(record) <span class="keyword">and</span> record[<span class="string">&#x27;id&#x27;</span>] == <span class="built_in">id</span>:</span><br><span class="line">                <span class="keyword">if</span> self.row_is_locked(record):</span><br><span class="line">                    <span class="keyword">raise</span> Error(<span class="string">&quot;Row locked by another transaction.&quot;</span>)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    record[<span class="string">&#x27;expired_xid&#x27;</span>] = self.xid</span><br><span class="line">                    self.rollback_actions.append([<span class="string">&quot;add&quot;</span>, i])</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>The <code>rollback_actions</code> will be explained later.</p>
<h2 id="Updating-a-Record"><a class="header-anchor" href="#Updating-a-Record"></a>Updating a Record</h2>
<p>Updating is a combination of deleting the old one and adding a new one. This allows the existing record to still be viewed by other transactions. If the <code>delete_record</code> fails then the exception raised would cause the subsequent <code>add_record</code> not to happen which is what we want.</p>
<p>(xnerv: Absolutely this implementation is different from popular DBMS like MySQL.)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#class Transaction:</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update_record</span>(<span class="params">self, <span class="built_in">id</span>, name</span>):</span><br><span class="line">        self.delete_record(<span class="built_in">id</span>)</span><br><span class="line">        self.add_record(&#123;<span class="string">&quot;id&quot;</span>: <span class="built_in">id</span>, <span class="string">&quot;name&quot;</span>: name&#125;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="Committing-Changes"><a class="header-anchor" href="#Committing-Changes"></a>Committing Changes</h2>
<p>Once all the modifications have been made we need to <em>commit</em> all the changes so that future clients can see these new changes. Very easy, we simply remove our transaction ID from the active list of transactions:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#class Transaction:</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">commit</span>(<span class="params">self</span>):</span><br><span class="line">        active_xids.discard(self.xid)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="Rollback-Changes"><a class="header-anchor" href="#Rollback-Changes"></a>Rollback Changes</h2>
<p>Rolling back can be done several ways, one way is to replay the changes in reverse:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#class Transaction:</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">rollback</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">for</span> action <span class="keyword">in</span> <span class="built_in">reversed</span>(self.rollback_actions):</span><br><span class="line">            <span class="keyword">if</span> action[<span class="number">0</span>] == <span class="string">&#x27;add&#x27;</span>:</span><br><span class="line">                records[action[<span class="number">1</span>]][<span class="string">&#x27;expired_xid&#x27;</span>] = <span class="number">0</span></span><br><span class="line">            <span class="keyword">elif</span> action[<span class="number">0</span>] == <span class="string">&#x27;delete&#x27;</span>:</span><br><span class="line">                records[action[<span class="number">1</span>]][<span class="string">&#x27;expired_xid&#x27;</span>] = self.xid</span><br><span class="line"></span><br><span class="line">        active_xids.discard(self.xid)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>Note: This is fine for an environment where the server can guarantee that the all rollback actions will be replayed and that when the server is shut down forcefully that all the active transactions will have <code>rollback()</code> invoked on them.</p>
<p>If you want higher durability that can recover from a server randomly crashing you will need to keep the transaction ID stored somewhere atomically and have extra code on the server start up that checks to see if it was shutdown safely, and manually repairs the records if need be. I will not go into this as this article is already long enough, but it may be explained in a future article.</p>
<h2 id="Vacuuming-or-Reclaiming-Space"><a class="header-anchor" href="#Vacuuming-or-Reclaiming-Space"></a>Vacuuming or Reclaiming Space</h2>
<p>You have probably noticed with this algorithm is that it does not ever actually delete data, only mark it as deleted. This makes it fantastic for keeping lots of records on disk by only appending to the file for modifications.</p>
<p>Overtime you will likely want to gain back all that dead space. If it’s in a memory database you could simply iterate through the records and permanently delete the records that are now fully dead.</p>
<p>If your using a medium like the disk this isn’t so easy. If your application isn’t too complicated you may be able to rewrite all of the non-dead rows out to a new file and switch it underneath your server. There are tons of solutions for this that aren’t specific to how MVCC works so I’ll leave that up to you.</p>
<p>In any case we need to be sensitive to row visibility here as well. Records that have an <code>expired_xid</code> that is not <code>0</code> <em>and</em> it does not appear in the active transactions are fully dead rows.</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/implementing-your-own-transactions-with-mvcc/">http://xnerv.wang/implementing-your-own-transactions-with-mvcc/</a></strong><br>
转载自：<a href="http://elliot.land/post/implementing-your-own-transactions-with-mvcc">IMPLEMENTING YOUR OWN TRANSACTIONS WITH MVCC</a></p>
]]></content>
      <categories>
        <category>DBMS</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>DBMS</tag>
        <tag>MVCC</tag>
        <tag>SQL Server</tag>
        <tag>Transaction</tag>
      </tags>
  </entry>
  <entry>
    <title>InnoDB Log Block Structure(InnoDB日志Block结构详解)（转载）</title>
    <url>/innodb-log-block-structure/</url>
    <content><![CDATA[<p><img src="/assets/innodb-log-block-structure/1.jpg" alt=""></p>
<span id="more"></span>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/innodb-log-block-structure/">http://xnerv.wang/innodb-log-block-structure/</a></strong><br>
转载自：<a href="http://hedengcheng.com/?p=124">InnoDB Log Block Structure(InnoDB日志Block结构详解)</a></p>
]]></content>
      <categories>
        <category>DBMS</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>DBMS</tag>
        <tag>MySQL</tag>
        <tag>InnoDB</tag>
        <tag>InnoDB Log</tag>
      </tags>
  </entry>
  <entry>
    <title>InnoDB 事务锁系统简介（转载）</title>
    <url>/introduction-of-innodb-transaction-lock/</url>
    <content><![CDATA[<h2 id="前言"><a class="header-anchor" href="#前言"></a>前言</h2>
<p>本文的目的是对 InnoDB 的事务锁模块做个简单的介绍，使读者对这块有初步的认识。本文先介绍行级锁和表级锁的相关概念，再介绍其内部的一些实现；最后以两个有趣的案例结束本文。</p>
<p>本文所有的代码和示例都是基于当前最新的 MySQL5.7.10 版本。</p>
<h2 id="行级锁"><a class="header-anchor" href="#行级锁"></a>行级锁</h2>
<p>InnoDB 支持到行级别粒度的并发控制，本小节我们分析下几种常见的行级锁类型，以及在哪些情况下会使用到这些类型的锁。</p>
<p><strong>LOCK_REC_NOT_GAP</strong></p>
<p>锁带上这个 FLAG 时，表示这个锁对象只是单纯的锁在记录上，不会锁记录之前的 GAP。在 RC 隔离级别下一般加的都是该类型的记录锁（但唯一二级索引上的 duplicate key 检查除外，总是加 <code>LOCK_ORDINARY</code> 类型的锁）。</p>
<span id="more"></span>
<p><strong>LOCK_GAP</strong></p>
<p>表示只锁住一段范围，不锁记录本身，通常表示两个索引记录之间，或者索引上的第一条记录之前，或者最后一条记录之后的锁。可以理解为一种区间锁，一般在RR隔离级别下会使用到GAP锁。</p>
<p>你可以通过切换到RC隔离级别，或者开启选项<code>innodb_locks_unsafe_for_binlog</code>来避免GAP锁。这时候只有在检查外键约束或者duplicate key检查时才会使用到GAP LOCK。</p>
<p><strong>LOCK_ORDINARY(Next-Key Lock)</strong></p>
<p>也就是所谓的 NEXT-KEY 锁，包含记录本身及记录之前的GAP。当前 MySQL 默认情况下使用RR的隔离级别，而NEXT-KEY LOCK正是为了解决RR隔离级别下的幻读问题。所谓幻读就是一个事务内执行相同的查询，会看到不同的行记录。在RR隔离级别下这是不允许的。</p>
<p>假设索引上有记录1, 4, 5, 8，12 我们执行类似语句：SELECT… WHERE col &gt; 10 FOR UPDATE。如果我们不在(8, 12)之间加上Gap锁，另外一个 Session 就可能向其中插入一条记录，例如9，再执行一次相同的SELECT FOR UPDATE，就会看到新插入的记录。</p>
<p>这也是为什么插入一条记录时，需要判断下一条记录上是否加锁了。</p>
<p><strong>LOCK_S（共享锁）</strong></p>
<p>共享锁的作用通常用于在事务中读取一条行记录后，不希望它被别的事务锁修改，但所有的读请求产生的LOCK_S锁是不冲突的。在InnoDB里有如下几种情况会请求S锁。</p>
<ol>
<li>
<p>普通查询在隔离级别为 SERIALIZABLE 会给记录加 LOCK_S 锁。但这也取决于场景：非事务读（auto-commit）在 SERIALIZABLE 隔离级别下，无需加锁(不过在当前最新的5.7.10版本中，SHOW ENGINE INNODB STATUS 的输出中不会打印只读事务的信息，只能从<code>informationschema.innodb_trx</code>表中获取到该只读事务持有的锁个数等信息)。</p>
</li>
<li>
<p>类似 SQL SELECT … IN SHARE MODE，会给记录加S锁，其他线程可以并发查询，但不能修改。基于不同的隔离级别，行为有所不同:</p>
<ul>
<li>RC隔离级别： <code>LOCK_REC_NOT_GAP | LOCK_S</code>；</li>
<li>RR隔离级别：如果查询条件为唯一索引且是唯一等值查询时，加的是 <code>LOCK_REC_NOT_GAP | LOCK_S</code>；对于非唯一条件查询，或者查询会扫描到多条记录时，加的是<code>LOCK_ORDINARY | LOCK_S</code>锁，也就是记录本身+记录之前的GAP；</li>
</ul>
</li>
<li>
<p>通常INSERT操作是不加锁的，但如果在插入或更新记录时，检查到 duplicate key（或者有一个被标记删除的duplicate key），对于普通的INSERT/UPDATE，会加LOCK_S锁，而对于类似REPLACE INTO或者INSERT … ON DUPLICATE这样的SQL加的是X锁。而针对不同的索引类型也有所不同：</p>
<ul>
<li>对于聚集索引（参阅函数<code>row_ins_duplicate_error_in_clust</code>），隔离级别小于等于RC时，加的是<code>LOCK_REC_NOT_GAP</code>类似的S或者X记录锁。否则加<code>LOCK_ORDINARY</code>类型的记录锁（NEXT-KEY LOCK）；</li>
<li>对于二级唯一索引，若检查到重复键，当前版本总是加 LOCK_ORDINARY 类型的记录锁(函数 <code>row_ins_scan_sec_index_for_duplicate</code>)。实际上按照RC的设计理念，不应该加GAP锁（<a href="http://bugs.mysql.com/bug.php?id=68021">bug#68021</a>），官方也事实上尝试修复过一次，即对于RC隔离级别加上<code>LOCK_REC_NOT_GAP</code>，但却引入了另外一个问题，导致二级索引的唯一约束失效(<a href="http://bugs.mysql.com/bug.php?id=73170">bug#73170</a>)，感兴趣的可以参阅我写的<a href="http://mysqllover.com/?p=1041">这篇博客</a>，由于这个严重bug，官方很快又把这个fix给revert掉了。</li>
</ul>
</li>
<li>
<p>外键检查</p>
<p>当我们删除一条父表上的记录时，需要去检查是否有引用约束(<code>row_pd_check_references_constraints</code>)，这时候会扫描子表(<code>dict_table_t::referenced_list</code>)上对应的记录，并加上共享锁。按照实际情况又有所不同。我们举例说明</p>
<p>使用RC隔离级别，两张测试表：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> t1 (a <span class="type">int</span>, b <span class="type">int</span>, <span class="keyword">primary</span> key(a));</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> t2 (a <span class="type">int</span>, b <span class="type">int</span>, <span class="keyword">primary</span> key (a), key(b), <span class="keyword">foreign</span> key(b) <span class="keyword">references</span> t1(a));</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t1 <span class="keyword">values</span> (<span class="number">1</span>,<span class="number">2</span>), (<span class="number">2</span>,<span class="number">3</span>), (<span class="number">3</span>,<span class="number">4</span>), (<span class="number">4</span>,<span class="number">5</span>), (<span class="number">5</span>,<span class="number">6</span>), (<span class="number">7</span>,<span class="number">8</span>), (<span class="number">10</span>,<span class="number">11</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t2 <span class="keyword">values</span> (<span class="number">1</span>,<span class="number">2</span>), (<span class="number">2</span>,<span class="number">2</span>), (<span class="number">4</span>,<span class="number">4</span>);</span><br></pre></td></tr></table></figure>
<p>执行SQL：delete from t1 where a = 10;</p>
<ul>
<li>在t1表记录10上加 <code>LOCKREC_NOT_GAP|LOCK_X</code></li>
<li>在t2表的supremum记录（表示最大记录）上加 <code>LOCK_ORDINARY|LOCK_S</code>，即锁住(4, ~)区间</li>
</ul>
<p>执行SQL：delete from t1 where a = 2;</p>
<ul>
<li>在t1表记录(2,3)上加 <code>LOCK_REC_NOT_GAP|LOCK_X</code></li>
<li>在t2表记录(1,2)上加 <code>LOCK_REC_NOT_GAP|LOCK_S</code>锁，这里检查到有引用约束，因此无需继续扫描(2,2)就可以退出检查，判定报错。</li>
</ul>
<p>执行SQL：delete from t1 where a = 3;</p>
<ul>
<li>在t1表记录(3,4)上加 <code>LOCK_REC_NOT_GAP|LOCK_X</code></li>
<li>在t2表记录(4,4)上加 <code>LOCK_GAP|LOCK_S</code>锁</li>
</ul>
<p>另外从代码里还可以看到，如果扫描到的记录被标记删除时，也会加<code>LOCK_ORDINARY|LOCK_S</code> 锁。具体参阅函数<code>row_ins_check_foreign_constraint</code></p>
</li>
<li>
<p>INSERT … SELECT插入数据时，会对SELECT的表上扫描到的数据加LOCK_S锁</p>
</li>
</ol>
<p><strong>LOCK_X（排他锁）</strong></p>
<p>排他锁的目的主要是避免对同一条记录的并发修改。通常对于UPDATE或者DELETE操作，或者类似SELECT … FOR UPDATE操作，都会对记录加排他锁。</p>
<p>我们以如下表为例：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> t1 (a <span class="type">int</span>, b <span class="type">int</span>, c <span class="type">int</span>, <span class="keyword">primary</span> key(a), key(b));</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t1 <span class="keyword">values</span> (<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>), (<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>),(<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>), (<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>),(<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>);</span><br></pre></td></tr></table></figure>
<p>执行SQL（通过二级索引查询）：update t1 set c = c +1 where b = 3;</p>
<ul>
<li>RC隔离级别：1. 锁住二级索引记录，为NOT GAP X锁；2.锁住对应的聚集索引记录，也是NOT GAP X锁。</li>
<li>RR隔离级别下：1.锁住二级索引记录，为<code>LOCK_ORDINARY|LOCK_X</code>锁；2.锁住聚集索引记录，为NOT GAP X锁</li>
</ul>
<p>执行SQL（通过聚集索引检索，更新二级索引数据）：update t1 set b = b +1 where a = 2;</p>
<ul>
<li>对聚集索引记录加 <code>LOCK_REC_NOT_GAP | LOCK_X</code>锁;</li>
<li>在标记删除二级索引时，检查二级索引记录上的锁（<code>lock_sec_rec_modify_check_and_lock</code>），如果存在和<code>LOCK_X | LOCK_REC_NOT_GAP</code>冲突的锁对象，则创建锁对象并返回等待错误码；否则无需创建锁对象；</li>
<li>当到达这里时，我们已经持有了聚集索引上的排他锁，因此能保证别的线程不会来修改这条记录。（修改记录总是先聚集索引，再二级索引的顺序），即使不对二级索引加锁也没有关系。但如果已经有别的线程已经持有了二级索引上的记录锁，则需要等待。</li>
<li>在标记删除后，需要插入更新后的二级索引记录时，依然要遵循插入意向锁的加锁原则。</li>
</ul>
<p>我们考虑上述两种 SQL 的混合场景，一个是先锁住二级索引记录，再锁聚集索引；另一个是先锁聚集索引，再检查二级索引冲突，因此在这类并发更新场景下，可能会发生死锁。</p>
<p>不同场景，不同隔离级别下的加锁行为都有所不同，例如在RC隔离级别下，不符合WHERE条件的扫描到的记录，会被立刻释放掉，但RR级别则会持续到事务结束。你可以通过GDB，断点函数<code>lock_rec_lock</code>来查看某条SQL如何执行加锁操作。</p>
<p><strong>LOCK_INSERT_INTENTION(插入意向锁)</strong></p>
<p>INSERT INTENTION锁是GAP锁的一种，如果有多个session插入同一个GAP时，他们无需互相等待，例如当前索引上有记录4和8，两个并发session同时插入记录6，7。他们会分别为(4,8)加上GAP锁，但相互之间并不冲突（因为插入的记录不冲突）。</p>
<p>当向某个数据页中插入一条记录时，总是会调用函数<code>lock_rec_insert_check_and_lock</code>进行锁检查（构建索引时的数据插入除外），会去检查当前插入位置的下一条记录上是否存在锁对象，这里的下一条记录不是指的物理连续，而是按照逻辑顺序的下一条记录。 如果下一条记录上不存在锁对象：若记录是二级索引上的，先更新二级索引页上的最大事务ID为当前事务的ID；直接返回成功。</p>
<p>如果下一条记录上存在锁对象，就需要判断该锁对象是否锁住了GAP。如果GAP被锁住了，并判定和插入意向GAP锁冲突，当前操作就需要等待，加的锁类型为<code>LOCK_X | LOCK_GAP | LOCK_INSERT_INTENTION</code>，并进入等待状态。但是插入意向锁之间并不互斥。这意味着在同一个GAP里可能有多个申请插入意向锁的会话。</p>
<p><strong>锁表更新</strong></p>
<p>我们知道GAP锁是在一个记录上描述的，表示记录及其之前的记录之间的GAP。但如果记录之前发生了插入或者删除操作，之前描述的GAP就会发生变化，InnoDB需要对锁表进行更新。</p>
<p>对于数据插入，假设我们当前在记录[3,9]之间有会话持有锁(不管是否和插入意向锁冲突)，现在插入一条新的记录5，需要调用函数<code>lock_update_insert</code>。这里会遍历所有在记录9上的记录锁，如果这些锁不是插入意向锁并且是LOCK_GAP或者NEXT-KEY LOCK（没有设置<code>LOCK_REC_NOT_GAP</code>标记)(<code>lock_rec_inherit_to_gap_if_gap_lock</code>)，就会为这些会话的事务增加一个新的锁对象，锁的类型为<code>LOCK_REC | LOCK_GAP</code>，锁住的GAP范围在本例中为(3,5)。所有符合条件的会话都继承了这个新的GAP，避免之前的GAP锁失效。</p>
<p>对于数据删除操作，调用函数<code>lock_update_delete</code>，这里会遍历在被删除记录上的记录锁，当符合如下条件时，需要为这些锁对应的事务增加一个新的GAP锁，锁的Heap No为被删除记录的下一条记录：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">lock_rec_inherit_to_gap</span></span><br><span class="line"><span class="function">        <span class="title">for</span> <span class="params">(lock = lock_rec_get_first(lock_sys-&gt;rec_hash, block, heap_no);</span></span></span><br><span class="line"><span class="params"><span class="function">             lock != <span class="literal">NULL</span>;</span></span></span><br><span class="line"><span class="params"><span class="function">             lock = lock_rec_get_next(heap_no, lock))</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (!<span class="built_in">lock_rec_get_insert_intention</span>(lock)</span><br><span class="line">                    &amp;&amp; !((srv_locks_unsafe_for_binlog</span><br><span class="line">                          || lock-&gt;trx-&gt;isolation_level</span><br><span class="line">                          &lt;= TRX_ISO_READ_COMMITTED)</span><br><span class="line">                         &amp;&amp; <span class="built_in">lock_get_mode</span>(lock) ==</span><br><span class="line">                         (lock-&gt;trx-&gt;duplicates ? LOCK_S : LOCK_X))) &#123;</span><br><span class="line">                        <span class="built_in">lock_rec_add_to_queue</span>(</span><br><span class="line">                                LOCK_REC | LOCK_GAP | <span class="built_in">lock_get_mode</span>(lock),</span><br><span class="line">                                heir_block, heir_heap_no, lock-&gt;index,</span><br><span class="line">                                lock-&gt;trx, FALSE);</span><br><span class="line">                &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>从上述判断可以看出，即使在RC隔离级别下，也有可能继承LOCK GAP锁，这也是当前版本InnoDB唯一的意外：判断Duplicate key时目前容忍GAP锁。上面这段代码实际上在最近的版本中才做过更新，更早之前的版本可能存在二级索引损坏，感兴趣的可以阅读我的<a href="http://mysqllover.com/?p=1477">这篇博客</a></p>
<p>完成GAP锁继承后，会将所有等待该记录的锁对象全部唤醒(<code>lock_rec_reset_and_release_wait</code>)。</p>
<p><strong>LOCK_PREDICATE</strong></p>
<p>从 MySQL5.7 开始MySQL整合了<code>boost.geometry</code>库以更好的支持空间数据类型，并支持在在Spatial数据类型的列上构建索引，在InnoDB内，这个索引和普通的索引有所不同，基于R-TREE的结构，目前支持对2D数据的描述，暂不支持3D.</p>
<p>R-TREE和BTREE不同，它能够描述多维空间，而多维数据并没有明确的数据顺序，因此无法在RR隔离级别下构建NEXT-KEY锁以避免幻读，因此InnoDB使用称为Predicate Lock的锁模式来加锁，会锁住一块查询用到的被称为MBR(minimum boundingrectangle/box)的数据区域。 因此这个锁不是锁到某个具体的记录之上的，可以理解为一种Page级别的锁。</p>
<p>Predicate Lock和普通的记录锁或者表锁（如上所述）存储在不同的lock hash中，其相互之间不会产生冲突。</p>
<p>Predicate Lock相关代码见<code>lock/lock0prdt.cc</code>文件</p>
<p>关于Predicate Lock的设计参阅官方<a href="http://dev.mysql.com/worklog/task/?id=6609">WL#6609</a>。</p>
<p><em>由于这块的代码量比较庞大，目前小编对InnoDB的spatial实现了解有限，本文暂不对此展开，将在后面单独专门介绍spatial index时，再细细阐述这块内容。</em></p>
<p><strong>隐式锁</strong></p>
<p>InnoDB 通常对插入操作无需加锁，而是通过一种“隐式锁”的方式来解决冲突。聚集索引记录中存储了事务id，如果另外有个session查询到了这条记录，会去判断该记录对应的事务id是否属于一个活跃的事务，并协助这个事务创建一个记录锁，然后将自己置于等待队列中。该设计的思路是基于大多数情况下新插入的记录不会立刻被别的线程并发修改，而创建锁的开销是比较昂贵的，涉及到全局资源的竞争。</p>
<p>关于隐式锁转换，上一期的月报<a href="http://mysql.taobao.org/monthly/2015/12/01/">InnoDB 事务子系统介绍</a>我们已经介绍过了，这里不再赘述。</p>
<p><strong>锁的冲突判定</strong></p>
<p>锁模式的兼容性矩阵通过如下数组进行快速判定：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">static</span> <span class="type">const</span> byte lock_compatibility_matrix[<span class="number">5</span>][<span class="number">5</span>] = &#123;</span><br><span class="line"><span class="comment">/** IS IX S X AI /</span></span><br><span class="line"><span class="comment">/ IS / &#123; TRUE, TRUE, TRUE, FALSE, TRUE&#125;,</span></span><br><span class="line"><span class="comment">/ IX / &#123; TRUE, TRUE, FALSE, FALSE, TRUE&#125;,</span></span><br><span class="line"><span class="comment">/ S / &#123; TRUE, FALSE, TRUE, FALSE, FALSE&#125;,</span></span><br><span class="line"><span class="comment">/ X / &#123; FALSE, FALSE, FALSE, FALSE, FALSE&#125;,</span></span><br><span class="line"><span class="comment">/ AI / &#123; TRUE, TRUE, FALSE, FALSE, FALSE&#125;</span></span><br><span class="line"><span class="comment">&#125;;</span></span><br><span class="line"><span class="comment"></span></span><br></pre></td></tr></table></figure>
<p>对于记录锁而言，锁模式只有LOCK_S 和LOCK_X，其他的 FLAG 用于锁的描述，如前述 LOCK_GAP、LOCK_REC_NOT_GAP 以及 LOCK_ORDINARY、LOCK_INSERT_INTENTION 四种描述。在比较两个锁是否冲突时，即使不满足兼容性矩阵，在如下几种情况下，依然认为是相容的，无需等待（参考函数<code>lock_rec_has_to_wait</code>）</p>
<ul>
<li>对于GAP类型（锁对象建立在supremum上或者申请的锁类型为LOCK_GAP）且申请的不是插入意向锁时，无需等待任何锁，这是因为不同Session对于相同GAP可能申请不同类型的锁，而GAP锁本身设计为不互相冲突；</li>
<li>LOCK_ORDINARY 或者LOCK_REC_NOT_GAP类型的锁对象，无需等待LOCK_GAP类型的锁；</li>
<li>LOCK_GAP类型的锁无需等待LOCK_REC_NOT_GAP类型的锁对象；</li>
<li>任何锁请求都无需等待插入意向锁。</li>
</ul>
<h2 id="表级锁"><a class="header-anchor" href="#表级锁"></a>表级锁</h2>
<p>InnoDB的表级别锁包含五种锁模式：LOCK_IS、LOCK_IX、LOCK_X、LOCK_S以及LOCK_AUTO_INC锁，锁之间的相容性遵循数组<code>lock_compatibility_matrix</code>中的定义。</p>
<p>InnoDB表级锁的目的是为了防止DDL和DML的并发问题。但从5.5版本开始引入MDL锁后，InnoDB层的表级锁的意义就没那么大了，MDL锁本身已经覆盖了其大部分功能。以下我们介绍下几种InnoDB表锁类型。</p>
<p><strong>LOCK_IS/LOCK_IX</strong></p>
<p>也就是所谓的意向锁，这实际上可以理解为一种“暗示”未来需要什么样行级锁，IS表示未来可能需要在这个表的某些记录上加共享锁，IX表示未来可能需要在这个表的某些记录上加排他锁。意向锁是表级别的，IS和IX锁之间相互并不冲突，但与表级S/X锁冲突。</p>
<p>在对记录加S锁或者X锁时，必须保证其在相同的表上有对应的意向锁或者锁强度更高的表级锁。</p>
<p><strong>LOCK_X</strong></p>
<p>当加了LOCK_X表级锁时，所有其他的表级锁请求都需要等待。通常有这么几种情况需要加X锁：</p>
<ul>
<li>DDL操作的最后一个阶段(<code>ha_innobase::commit_inlace_alter_table</code>)对表上加LOCK_X锁，以确保没有别的事务持有表级锁。通常情况下Server层MDL锁已经能保证这一点了，在DDL的commit 阶段是加了排他的MDL锁的。但诸如外键检查或者刚从崩溃恢复的事务正在进行某些操作，这些操作都是直接InnoDB自治的，不走server层，也就无法通过MDL所保护；</li>
<li>当设置会话的autocommit变量为OFF时，执行<code>LOCK TABLE tbname WRITE</code>这样的操作会加表级的LOCK_X锁(<code>ha_innobase::external_lock</code>)；</li>
<li>对某个表空间执行discard或者import操作时，需要加LOCK_X锁(<code>ha_innobase::discard_or_import_tablespace</code>)。</li>
</ul>
<p><strong>LOCK_S</strong></p>
<ul>
<li>
<p>在DDL的第一个阶段，如果当前DDL不能通过ONLINE的方式执行，则对表加LOCK_S锁(<code>prepare_inplace_alter_table_dict</code>)；</p>
</li>
<li>
<p>设置会话的autocommit为OFF，执行LOCK TABLE tbname READ时，会加LOCK_S锁(<code>ha_innobase::external_lock</code>)。</p>
</li>
</ul>
<p>从上面的描述我们可以看到LOCK_X及LOCK_S锁在实际的大部分负载中都很少会遇到。主要还是互相不冲突的LOCK_IS及LOCK_IX锁。一个有趣的问题是，每次加表锁时，却总是要扫描表上所有的表级锁对象，检查是否有冲突的锁。很显然，如果我们在同一张表上的更新并发度很高，这个链表就会非常长。</p>
<p>基于大多数表锁不冲突的事实，我们在RDS MYSQL中对各种表锁对象进行计数，在检查是否有冲突时，例如当前申请的是意向锁，如果此时LOCK_S和LOCK_X的锁计数都是0，就可以认为没有冲突，直接忽略检查。由于检查是在持有全局大锁<code>lock_sys-&gt;mutex</code>下进行的。在单表大并发下，这个优化的效果还是非常明显的，可以减少持有全局大锁的时间。</p>
<p><strong>LOCK_AUTO_INC</strong></p>
<p>AUTO_INC锁加在表级别，和AUTO_INC、表级S锁以及X锁不相容。锁的范围为SQL级别，SQL结束后即释放。AUTO_INC的加锁逻辑和InnoDB的锁模式相关，这里在简单介绍一下。</p>
<p>通常对于自增列，我们既可以显式指定该值，也可以直接用NULL，系统将自动递增并填充该列。我们还可以在批量插入时混合使用者两种方式。不同的分配方式，其具体行为受到参数<code>innodb_autoinc_lock_mode</code>的影响。但在基于STATEMENT模式复制时，可能会影响到复制的数据一致性，<a href="http://dev.mysql.com/doc/refman/5.7/en/innodb-auto-increment-handling.html">官方文档</a> 有详细描述，不再赘述，只说明下锁的影响。</p>
<p>自增锁模式通过参数<code>innodb_autoinc_lock_mode</code>来控制，加锁选择参阅函数<code>ha_innobase::innobase_lock_autoinc</code></p>
<p>具体的，有以下几个值：</p>
<p><code>AUTOINC_OLD_STYLE_LOCKING</code>（0）</p>
<p>也就是所谓的传统加锁模式（在5.1版本引入这个参数之前的策略），在该策略下，会在分配前加上AUTO_INC锁，并在SQL结束时释放掉。该模式保证了在STATEMENT复制模式下，备库执行类似INSERT … SELECT这样的语句时的一致性，因为这样的语句在执行时无法确定到底有多少条记录，只有在执行过程中不允许别的会话分配自增值，才能确保主备一致。</p>
<p>很显然这种锁模式非常影响并发插入的性能，但却保证了一条SQL内自增值分配的连续性。</p>
<p><code>AUTOINC_NEW_STYLE_LOCKING</code>（1）</p>
<p>这是InnoDB的默认值。在该锁模式下</p>
<ul>
<li>
<p>普通的 INSERT 或 REPLACE 操作会先加一个<code>dict_table_t::autoinc_mutex</code>，然后去判断表上是否有别的线程加了LOCK_AUTO_INC锁，如果有的话，释放autoinc_mutex，并使用OLD STYLE的锁模式。否则，在预留本次插入需要的自增值之后，就快速的将autoinc_mutex释放掉。很显然，对于普通的并发INSERT操作，都是无需加LOCK_AUTO_INC锁的。因此大大提升了吞吐量；</p>
</li>
<li>
<p>但是对于一些批量插入操作，例如LOAD DATA，INSERT …SELECT 等还是使用OLD STYLE的锁模式，SQL执行期间加LOCK_AUTO_INC锁。</p>
</li>
</ul>
<p>和传统模式相比，这种锁模式也能保证STATEMENT模式下的复制安全性，但却无法保证一条插入语句内的自增值的连续性，并且在执行一条混合了显式指定自增值和使用系统分配两种方式的插入语句时，可能存在一定的自增值浪费。</p>
<p>例如执行SQL：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> t1 (c1,c2) <span class="keyword">VALUES</span> (<span class="number">1</span>,<span class="string">&#x27;a&#x27;</span>), (<span class="keyword">NULL</span>,<span class="string">&#x27;b&#x27;</span>), (<span class="number">5</span>,<span class="string">&#x27;c&#x27;</span>), (<span class="keyword">NULL</span>,’d’）</span><br></pre></td></tr></table></figure>
<p>假设当前AUTO_INCREMENT值为101，在传统模式下执行完后，下一个自增值为103，而在新模式下，下一个可用的自增值为105，因为在开始执行SQL时，会先预取了[101, 104] 4个自增值，这和插入行的个数相匹配，然后将AUTO_INCREMENT设为105，导致自增值103和104被浪费掉。</p>
<p><code>AUTOINC_NO_LOCKING</code>（2）</p>
<p>这种模式下只在分配时加个mutex即可，很快就释放，不会像NEW STYLE那样在某些场景下会退化到传统模式。因此设为2不能保证批量插入的复制安全性。</p>
<p><strong>关于自增锁的小BUG</strong></p>
<p>这是Mariadb的Jira上报的一个小bug，在row模式下，由于不走parse的逻辑，我们不知道行记录是通过什么批量导入还是普通INSERT产生的，因此command类型为SQLCOM_END，而在判断是否加自增锁时的逻辑时，是通过COMMAND类型是否为SQLCOM_INSERT或者SQLCOM_REPLACE来判断是否忽略加AUTO_INC锁。这个额外的锁开销，会导致在使用ROW模式时，InnoDB总是加AUTO_INC锁，加AUTO_INC锁又涉及到全局事务资源的开销，从而导致性能下降。</p>
<p>修复的方式也比较简单，将SQLCOM_END这个command类型也纳入考虑。</p>
<p>具体参阅<a href="https://mariadb.atlassian.net/browse/MDEV-7578">Jira链接</a>。</p>
<h2 id="事务锁管理"><a class="header-anchor" href="#事务锁管理"></a>事务锁管理</h2>
<p>InnoDB 所有的事务锁对象都是挂在全局对象lock_sys上，同时每个事务对象上也维持了其拥有的事务锁，每个表对象(<code>dict_table_t</code>)上维持了构建在其上的表级锁对象。</p>
<p>如下图所示：</p>
<center>
<img src="http://mysql.taobao.org/monthly/pic/2016-01-01/innodb_lock.png" alt="innodb 锁"/>
<span>innodb 锁</span>
</center>
<p><strong>加表级锁</strong></p>
<ul>
<li>首先从当前事务的<code>trx_lock_t::table_locks</code>中查找是否已经加了等同或更高级别的表锁，如果已经加锁了，则直接返回成功（<code>lock_table_has</code>）；</li>
<li>检查当前是否有和正在申请的锁模式冲突的表级锁对象（<code>lock_table_other_has_incompatible</code>）；
<ul>
<li>直接遍历链表<code>dict_table_t::locks</code>链表</li>
</ul>
</li>
<li>如果存在冲突的锁对象，则需要进入等待队列（<code>lock_table_enqueue_waiting</code>）
<ul>
<li>创建等待锁对象 （<code>lock_table_create</code>）</li>
<li>检查是否存在死锁（<code>DeadlockChecker::check_and_resolve</code>），当存在死锁时：如果当前会话被选作牺牲者，就移除锁请求(<code>lock_table_remove_low</code>)，重置当前事务的wait_lock为空，并返回错误码DB_DEADLOCK；若被选成胜利者，则锁等待解除，可以认为当前会话已经获得了锁，返回成功；</li>
<li>若没有发生死锁，设置事务对象的相关变量后，返回错误码DB_LOCK_WAIT，随后进入锁等待状态</li>
</ul>
</li>
<li>如果不存在冲突的锁，则直接创建锁对象（<code>lock_table_create</code>），加入队列。</li>
</ul>
<p><code>lock_table_create</code>: 创建锁对象</p>
<ul>
<li>当前请求的是AUTO-INC锁时；
<ul>
<li>递增<code>dict_table_t::n_waiting_or_granted_auto_inc_locks</code>。前面我们已经提到过，当这个值非0时，对于自增列的插入操作就会退化到OLD-STYLE;</li>
<li>锁对象直接引用已经预先创建好的<code>dict_table_t::autoinc_lock</code>，并加入到<code>trx_t::autoinc_locks</code>集合中;</li>
</ul>
</li>
<li>对于非AUTO-INC锁，则从一个pool中分配锁对象
<ul>
<li>在事务对象<code>trx_t::lock</code>中，维持了两个pool，一个是<code>trx_lock_t::rec_pool</code>，预分配了一组锁对象用于记录锁分配，另外一个是<code>trx_lock_t::table_pool</code>，用于表级锁的锁对象分配。通过预分配内存的方式，可以避免在持有全局大锁时(<code>lock_sys-&gt;mutex</code>)进行昂贵的内存分配操作。rec_pool和table_pool预分配的大小都为8个锁对象。（<code>lock_trx_alloc_locks</code>）;</li>
<li>如果table_pool已经用满，则走内存分配，创建一个锁对象；</li>
</ul>
</li>
<li>构建好的锁对象分别加入到事务的<code>trx_t::lock.trx_locks</code>链表上以及表对象的<code>dict_table_t::locks</code>链表上；</li>
<li>构建好的锁对象加入到当前事务的<code>trx_t::lock.table_locks</code>集合中。</li>
</ul>
<p>可以看到锁对象会加入到不同的集合或者链表中，通过挂载到事务对象上，可以快速检查当前事务是否已经持有表锁；通过挂到表对象的锁链表上，可以用于检查该表上的全局冲突情况。</p>
<p><strong>加行级锁</strong></p>
<p>行级锁加锁的入口函数为<code>lock_rec_lock</code>，其中第一个参数impl如果为TRUE，则当当前记录上已有的锁和<code>LOCK_X | LOCK_REC_NOT_GAP</code>不冲突时，就无需创建锁对象。（见上文关于记录锁LOCK_X相关描述部分），为了描述清晰，下文的流程描述，默认impl为FALSE。</p>
<p><code>lock_rec_lock</code>：</p>
<ul>
<li>首先尝试fast lock的方式，对于冲突少的场景，这是比较普通的加锁方式(<code>lock_rec_lock_fast</code>), 符合如下情况时，可以走fast lock:
<ul>
<li>记录所在的page上没有任何记录锁时，直接创建锁对象，加入rec_hash，并返回成功;</li>
<li>记录所在的page上只存在一个记录锁，并且属于当前事务，且这个记录锁预分配的bitmap能够描述当前的heap no（预分配的bit数为创建锁对象时的page上记录数 + 64，参阅函数<code>RecLock::lock_size</code>），则直接设置对应的bit位并返回;</li>
</ul>
</li>
<li>无法走fast lock时，再调用slow lock的逻辑(<code>lock_rec_lock_slow</code>)
<ul>
<li>判断当前事务是否已经持有了一个优先级更高的锁，如果是的话，直接返回成功（<code>lock_rec_has_expl</code>）;</li>
<li>检查是否存在和当前申请锁模式冲突的锁（<code>lock_rec_other_has_conflicting</code>），如果存在的话，就创建一个锁对象（<code>RecLock::RecLock</code>），并加入到等待队列中（<code>RecLock::add_to_waitq</code>），这里会进行死锁检测;</li>
<li>如果没有冲突的锁，则入队列（<code>lock_rec_add_to_queue</code>）：已经有在同一个Page上的锁对象且没有别的会话等待相同的heap no时，可以直接设置对应的bitmap（<code>lock_rec_find_similar_on_page</code>）；否则需要创建一个新的锁对象;</li>
</ul>
</li>
<li>返回错误码，对于DB_LOCK_WAIT, DB_DEADLOCK等错误码，会在上层进行处理。</li>
</ul>
<p><strong>等待及死锁判断</strong></p>
<p>当发现有冲突的锁时，调用函数<code>RecLock::add_to_waitq</code>进行判断</p>
<ul>
<li>如果持有冲突锁的线程是内部的后台线程（例如后台dict_state线程），这个线程不会被一个高优先级的事务取消掉，因为总是优先保证内部线程正常执行；</li>
<li>比较当前会话和持有锁的会话的事务优先级，调用函数trx_arbitrate 返回被选作牺牲者的事务；
<ul>
<li>当前发起请求的会话是后台线程，但持有锁的会话设置了高优先级时，选择当前线程作为牺牲者；</li>
<li>持有锁的线程为后台线程时，在第一步已经判断了，不会选作牺牲者；</li>
<li>如果两个会话都设置了优先级，低优先级的被选做牺牲者，优先级相同时，请求者被选做牺牲者(<code>thd_tx_arbitrate</code>)；</li>
<li>PS: 目前最新版本的5.7还不支持用户端设置线程优先级（但增加一个配置session变量的接口非常容易)；</li>
</ul>
</li>
<li>如果当前会话的优先级较低，或者另外一个持有锁的会话为后台线程，这时候若当前会话设置了优先级，直接报错，并返回错误码DB_DEADLOCK；
<ul>
<li>默认不设置优先级时，请求锁的会话也会被选作victim_trx，但只创建锁等待对象，不会直接返回错误；</li>
</ul>
</li>
<li>当持有锁的会话被选作牺牲者时，说明当前会话肯定设置了高优先级，这时候会走<code>RecLock::enqueue_priority</code>的逻辑；
<ul>
<li>如果持有锁的会话在等待另外一个不同的锁时，或者持有锁的事务不是readonly的，当前会话会被回滚掉；</li>
<li>开始跳队列，直到当前会话满足加锁条件（<code>RecLock::jump_queue</code>）；
<ul>
<li>请求的锁对象跳过阻塞它的锁对象，直接操作hash链表，将锁对象往前挪；</li>
<li>从当前lock，向前遍历链表，逐个判断是否有别的会话持有了相同记录上的锁（<code>RecLock::is_on_row</code>），并将这些会话标记为回滚（<code>mark_trx_for_rollback</code>）,同时将这些事务对象搜集下来，以待后续处理（但直接阻塞当前会话的事务会被立刻回滚掉）；</li>
</ul>
</li>
<li>高优先级的会话非常具有杀伤力，其他低优先级会话即使拿到了锁，也会被它所干掉。</li>
</ul>
</li>
</ul>
<p>不过实际场景中，我们并没有多少机会去设置事务的优先级，这里先抛开这个话题，只考虑默认的场景，即所有的事务优先级都未设置。</p>
<p>在创建了一个处于WAIT状态的锁对象后，我们需要进行死锁检测（<code>RecLock::deadlock_check</code>），死锁检测采用深度优先遍历的方式，通过事务对象上的<code>trx_t::lock.wait_lock</code>构造事务的wait-for graph进行判断，当最终发现一个锁请求等待闭环时，可以判定发生了死锁。另外一种情况是，如果检测深度过长（即锁等待的会话形成的检测链路非常长），也会认为发生死锁，最大深度默认为<code>LOCK_MAX_DEPTH_IN_DEADLOCK_CHECK</code>，值为200。</p>
<p>当发生死锁时，需要选择一个牺牲者（<code>DeadlockChecker::select_victim()</code>）来解决死锁，通常事务权重低的回滚（<code>trx_weight_ge</code>）。</p>
<ul>
<li>修改了非事务表的会话具有更高的权重；</li>
<li>如果两个表都修改了、或者都没有修改事务表，那么就根据的事务的undo数量加上持有的事务锁个数来决定权值（TRX_WEIGHT）；</li>
<li>低权重的事务被回滚，高权重的获得锁对象。</li>
</ul>
<p>Tips：对于一个经过精心设计的应用，我们可以从业务上避免死锁，而死锁检测本身是通过持有全局大锁来进行的，代价非常高昂，在阿里内部的应用中，由于有专业的团队来保证业务SQL的质量，我们可以选择性的禁止掉死锁检测来提升性能，尤其是在热点更新场景，带来的性能提升非常明显，极端高并发下，甚至能带来数倍的提升。</p>
<p>当无法立刻获得锁时，会将错误码传到上层进行处理（<code>row_mysql_handle_errors</code>）</p>
<ul>
<li><code>DB_LOCK_WAIT</code>：
<ul>
<li>具有高优先级的事务已经搜集了会阻塞它的事务链表，这时候会统一将这些事务回滚掉（<code>trx_kill_blocking</code>）；</li>
<li>将当前的线程挂起（<code>lock_wait_suspend_thread</code>），等待超时时间取决于session级别配置（<code>innodb_lock_wait_timeout</code>），默认为50秒；</li>
<li>如果当前会话的状态设置为running，一种是被选做死锁检测的牺牲者，需要回滚当前事务，另外一种是在进入等待前已经获得了事务锁，也无需等待；</li>
<li>获得等待队列的一个空闲slot。（<code>lock_wait_table_reserve_slot</code>）
<ul>
<li>系统启动时，已经创建好了足够用的slot数组，类型为<code>srv_slot_t</code>，挂在<code>lock_sys-&gt;waiting_threads</code>上；</li>
<li>分配slot时，从slot数组的第一个元素开始遍历，直到找到一个空闲的slot。注意这里存在的一个性能问题是，如果挂起的线程非常多，每个新加入挂起等待的线程都需要遍历直到找到一个空闲的slot。 实际上如果每次遍历都从上次分配的位置往后找，到达数组末尾在循环到数组头，这样可以在高并发高锁冲突场景下获得一定的性能提升；</li>
</ul>
</li>
<li>如果会话在innodb层（通常为true），则强制从InnoDB层退出，确保其不占用<code>innodb_thread_concurrency</code>的槽位。然后进入等待状态。被唤醒后，会再次强制进入InnoDB层；</li>
<li>被唤醒后，释放slot（<code>lock_wait_table_release_slot</code>）；</li>
<li>若被选作死锁的牺牲者了，返回上层回滚事务；若等待超时了，则根据参数<code>innodb_rollback_on_timeout</code>的配置，默认为OFF只回滚当前SQL，设置为ON表示回滚整个事务。</li>
</ul>
</li>
<li><code>DB_DEADLOCK</code>: 直接回滚当前事务</li>
</ul>
<p><strong>释放锁及唤醒</strong></p>
<p>大多数情况下事务锁都是在事务提交时释放，但有两种意外：</p>
<ul>
<li>AUTO-INC锁在SQL结束时直接释放（<code>innobase_commit --&gt; lock_unlock_table_autoinc</code>）；</li>
<li>在RC隔离级别下执行DML语句时，从引擎层返回到Server层的记录，如果不满足where条件，则需要立刻unlock掉（<code>ha_innobase::unlock_row</code>）。</li>
</ul>
<p>除这两种情况外，其他的事务锁都是在事务提交时释放的(<code>lock_trx_release_locks --&gt; lock_release</code>)。事务持有的所有锁都维护在链表<code>trx_t::lock.trx_locks</code>上，依次遍历释放即可。</p>
<p>对于行锁，从全局hash中删除后，还需要判断别的正在等待的会话是否可以被唤醒（<code>lock_rec_dequeue_from_page</code>）。例如如果当前释放的是某个记录的X锁，那么所有的S锁请求的会话都可以被唤醒。</p>
<p>这里的移除锁和检查的逻辑开销比较大，尤其是大量线程在等待少量几个锁时。当某个锁从hash链上移除时，InnoDB实际上通过遍历相同page上的所有等待的锁，并判断这些锁等待是否可以被唤醒。而判断唤醒的逻辑又一次遍历，这是因为当前的链表维护是基于&lt;space, page no&gt;的，并不是基于Heap no构建的。关于这个问题的讨论，可以参阅<a href="http://bugs.mysql.com/bug.php?id=53825">bug#53825</a>。官方开发Sunny也提到虽然使用&lt;space, page no, heap no&gt;来构建链表，移除Bitmap会浪费更多的内存，但效率更高，而且现在的内存也没有以前那么昂贵。</p>
<p>对于表锁，如果表级锁的类型不为LOCK_IS，且当前事务修改了数据，就将表对象的<code>dict_table_t::query_cache_inv_id</code>设置为当前最大的事务id。在检查是否可以使用该表的Query Cache时会使用该值进行判断（<code>row_search_check_if_query_cache_permitted</code>），如果某个用户会话的事务对象的low_limit_id（即最大可见事务id）比这个值还小，说明它不应该使用当前table cache的内容，也不应该存储到query cache中。</p>
<p>表级锁对象的释放调用函数<code>lock_table_dequeue</code>。</p>
<p>注意在释放锁时，如果该事务持有的锁对象太多，每释放1000（<code>LOCK_RELEASE_INTERVAL</code>）个锁对象，会暂时释放下<code>lock_sys-&gt;mutex</code>再重新持有，防止InnoDB hang住。</p>
<h2 id="两个有趣的案例"><a class="header-anchor" href="#两个有趣的案例"></a>两个有趣的案例</h2>
<p>本小节我们来分析几个比较有趣的死锁案例。</p>
<p><strong>普通的并发插入导致的死锁</strong></p>
<p><code>create table t1 (a int primary key);</code> 开启三个会话执行： <code>insert into t1(a) values (2);</code></p>
<table>
<thead>
<tr>
<th>session 1</th>
<th>session 2</th>
<th>session 3</th>
</tr>
</thead>
<tbody>
<tr>
<td>BEGIN; INSERT…</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>INSERT (block),为session1创建X锁，并等待S锁</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>INSERT (block， 同上等待S锁)</td>
</tr>
<tr>
<td>ROLLBACK，释放锁</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>获得S锁</td>
<td>获得S锁</td>
</tr>
<tr>
<td></td>
<td>申请插入意向X锁，等待session3</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>申请插入意向X锁，等待session2</td>
</tr>
</tbody>
</table>
<p>上述描述了互相等待的场景，因为插入意向X锁和S锁是不相容的。这也是一种典型的锁升级导致的死锁。如果session1执行COMMIT的话，则另外两个线程都会因为duplicate key失败。</p>
<p>这里需要解释下为何要申请插入意向锁，因为ROLLBACK时原记录回滚时是被标记删除的。而我们尝试插入的记录和这个标记删除的记录是相邻的(键值相同)，根据插入意向锁的规则，插入位置的下一条记录上如果存在与插入意向X锁冲突的锁时，则需要获取插入意向X锁。</p>
<p>另外一种类似（但产生死锁的原因不同）的场景是在一张同时存在聚集索引和唯一索引的表上，通过replace into的方式插入冲突的唯一键，可能会产生死锁，在3月份的月报，我已经专门描述过这个问题，感兴趣的可以<a href="http://mysql.taobao.org/index.php?title=MySQL%E5%86%85%E6%A0%B8%E6%9C%88%E6%8A%A5_2015.03#MySQL_.C2.B7_.E7.AD.94.E7.96.91.E9.87.8A.E6.83.91.C2.B7_.E5.B9.B6.E5.8F.91Replace_into.E5.AF.BC.E8.87.B4.E7.9A.84.E6.AD.BB.E9.94.81.E5.88.86.E6.9E.90">延伸阅读下</a>。</p>
<p><strong>又一个并发插入的死锁现象</strong></p>
<p>两个会话参与。在RR隔离级别下</p>
<p>例表如下：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> t1 (a <span class="type">int</span> <span class="keyword">primary</span> key ,b <span class="type">int</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t1 <span class="keyword">values</span> (<span class="number">1</span>,<span class="number">2</span>),(<span class="number">2</span>,<span class="number">3</span>),(<span class="number">3</span>,<span class="number">4</span>),(<span class="number">11</span>,<span class="number">22</span>);</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>session 1</th>
<th>session 2</th>
</tr>
</thead>
<tbody>
<tr>
<td>begin;select * from t1 where a = 5 for update;(获取记录(11,22)上的GAP X锁)</td>
<td></td>
</tr>
<tr>
<td></td>
<td>begin;select * from t1 where a = 5 for update; (同上,GAP锁之间不冲突</td>
</tr>
<tr>
<td>insert into t1 values (4,5); (block，等待session1)</td>
<td></td>
</tr>
<tr>
<td></td>
<td>insert into t1 values (4,5);（需要等待session2，死锁）</td>
</tr>
</tbody>
</table>
<p>引起这个死锁的原因是非插入意向的GAP X锁和插入意向X锁之间是冲突的。</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/introduction-of-innodb-transaction-lock/">http://xnerv.wang/introduction-of-innodb-transaction-lock/</a></strong><br>
转载自：<a href="http://mysql.taobao.org/monthly/2016/01/01/">InnoDB 事务锁系统简介</a></p>
]]></content>
      <categories>
        <category>DBMS</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>DBMS</tag>
        <tag>MySQL</tag>
        <tag>Transaction</tag>
        <tag>InnoDB</tag>
        <tag>Lock</tag>
      </tags>
  </entry>
  <entry>
    <title>一些流行引擎存储格式简介（转载）</title>
    <url>/introduction-of-some-popular-engine-storage-formats/</url>
    <content><![CDATA[<h2 id="概述"><a class="header-anchor" href="#概述"></a>概述</h2>
<p>本文简要介绍了一些存储引擎存储结构，包括InnoDB, TokuDB, RocksDB, TiDB, CockroachDB, 供大家对比分析</p>
<h2 id="InnoDB"><a class="header-anchor" href="#InnoDB"></a>InnoDB</h2>
<p>InnoDB 底层存储结构为B+树，结构如下<br>
<img src="http://ata2-img.cn-hangzhou.img-pub.aliyun-inc.com/dd1413b4fed7c0a756ee70cba6610f98.png" alt="image.png"></p>
<span id="more"></span>
<p>B树的每个节点对应innodb的一个page，page大小是固定的，一般设为16k。 其中非叶子节点只有键值，叶子节点包含完整数据。<br>
InnoDB按segment, extent, page方式管理page<br>
<img src="http://ata2-img.cn-hangzhou.img-pub.aliyun-inc.com/c5a908f693bee18e747827957107975f.png" alt="image.png"></p>
<p>每个数据节点page结构如下<br>
<img src="http://ata2-img.cn-hangzhou.img-pub.aliyun-inc.com/2922a11a3ef1006a86fc12fd476d249f.png" alt="image.png"></p>
<p>数据记录record按行存储，record具体格式由row_format决定. 详情可以参考<a href="http://mysql.taobao.org/monthly/2016/02/">数据内核月报</a></p>
<h2 id="TokuDB"><a class="header-anchor" href="#TokuDB"></a>TokuDB</h2>
<p>TokuDB 底层存储结构为Fractal Tree <img src="http://ata2-img.cn-hangzhou.img-pub.aliyun-inc.com/3f95cac52f4dc3aa7a07a59f31eba1db.png" alt="屏幕快照 2017-10-16 下午2.38.11.png"></p>
<p>Fractal Tree的结构与B+树有些类似, 在Fractal Tree中，每一个child指针除了需要指向一个child节点外，还会带有一个Message Buffer ，这个Message Buffer 是一个FIFO的队列，用来缓存更新操作。</p>
<p>例如，一次插入操作只需要落在某节点的Message Buffer就可以马上返回了，并不需要搜索到叶子节点。这些缓存的更新会在查询时或后台异步合并应用到对应的节点中。</p>
<h2 id="RocksDB"><a class="header-anchor" href="#RocksDB"></a>RocksDB</h2>
<p>RockDB的存储结构如下<br>
<img src="http://ata2-img.cn-hangzhou.img-pub.aliyun-inc.com/1e448f44fca20e47bc5ed6b6a83c3be8.png" alt="xx.png"></p>
<p>RocksDB写入数据时，先写到memtable中,memtable一般为skiplist, memtable写满时转为immutable memtable并刷入Level 0.</p>
<p>Level0中的SST文件中的数据都是有序的，Level0中SST文件之间的数据范围可能存在重叠。 其他Level中的SST文件之间的数据范围不重叠。</p>
<p>RocksDB会以一定的<a href="https://github.com/facebook/rocksdb/wiki/Compaction">机制</a>从低level compact数据到高level中。</p>
<p>RocksDB中SST文件的结构如下<br>
<img src="http://ata2-img.cn-hangzhou.img-pub.aliyun-inc.com/caddf538cf0ea192640f0c53ca1da890.png" alt="image.png"></p>
<p>MyRocks使用的存储引擎就是RocksDB, MyRocks的中RocksDB的数据映射关系参考 <a href="http://mysql.taobao.org/monthly/2016/10/05/">之前的月报</a> <img src="http://ata2-img.cn-hangzhou.img-pub.aliyun-inc.com/9901603bcbd388271c4e0efd244037f2.png" alt="image.png"></p>
<h2 id="TiDB"><a class="header-anchor" href="#TiDB"></a>TiDB</h2>
<p><strong>TiDB的存储结构</strong></p>
<p><img src="http://ata2-img.cn-hangzhou.img-pub.aliyun-inc.com/b8315e48c3ff0f4a78255bb7bbe87416.png" alt="image.png"></p>
<p>TiDB是分布式存储，分为两个部分TiKV和Placement Driver server。<br>
TiKV用于存储真正的数据，TiKV由分布在不同机器上的RocksDB实例组成。 数据按范围划分为一个个Region. 并且会尽量保持每个 Region 中保存的数据不超过一定的大小(这个大小可以配置，目前默认是 64MB). 同一Region分布在不同的RocksDB实例中，一个RocksDB实例包含多个Region. 图中，Region4有三个副本分布在三个RocksDB实例中，这三个Region副本组成一个RaftGroup，副本间通过Raft协议保证一致性。<br>
Placement Driver server（PD）， 也是一个集群，也通过Raft协议保证一致性。PD主要有以下作用：</p>
<ul>
<li>存储region的位置等元数据信息</li>
<li>调度和rebalance regions, TiKV中的Raft leader等信息</li>
<li>分配全局事务ID</li>
</ul>
<p><strong>TiDB的数据映射关系</strong><br>
以下表为例</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> <span class="keyword">user</span>(user_id <span class="type">int</span> <span class="keyword">primary</span> key, name <span class="type">varchar</span>(<span class="number">100</span>), email <span class="type">varchar</span>(<span class="number">200</span>));</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">user</span> <span class="keyword">VALUES</span> (<span class="number">1</span>, “bob”, “huang<span class="variable">@pingcap</span>.com”);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">user</span> <span class="keyword">VALUES</span> (<span class="number">2</span>, “tom”, “tom<span class="variable">@pingcap</span>.com”);</span><br></pre></td></tr></table></figure>
<p>对应到RocksDB中的KV结构如下</p>
<table>
<thead>
<tr>
<th>Key</th>
<th>Values</th>
</tr>
</thead>
<tbody>
<tr>
<td>user/1</td>
<td>bob <a href="mailto:huang@pingcap.com">huang@pingcap.com</a></td>
</tr>
<tr>
<td>user/2</td>
<td>tom <a href="mailto:tom@pingcap.com">tom@pingcap.com</a></td>
</tr>
</tbody>
</table>
<h2 id="CockroachDB"><a class="header-anchor" href="#CockroachDB"></a>CockroachDB</h2>
<p><strong>CockroachDB的存储结构</strong></p>
<p><img src="http://ata2-img.cn-hangzhou.img-pub.aliyun-inc.com/0abea895e3849958da154361eaa8a816.png" alt="image.png"></p>
<p><img src="http://ata2-img.cn-hangzhou.img-pub.aliyun-inc.com/ff1c24a5412a5c3c1db08b3ca692b6ef.png" alt="image.png"></p>
<p>CockroachDB的也是分布式存储，其结构和TiDB类似。CockroachDB按范围划分为Range，Range默认为64M，Range的存储为RocksDB， CockroachDB的一个node包含多个RocksDB实例。 Range副本分布在不同的node中，通过Raft协议保证一致。</p>
<p>Range的元数据信息也保存在Range中(靠前的Range中).</p>
<p>System keys come in several subtypes:</p>
<ul>
<li>Global keys store cluster-wide data such as the “meta1” and “meta2” keys as well as various other system-wide keys such as the node and store ID allocators.</li>
<li>Store local keys are used for unreplicated store metadata (e.g. the StoreIdent structure). “Unreplicated” indicates that these values are not replicated across multiple stores because the data they hold is tied to the lifetime of the store they are present on.</li>
<li>Range local keys store range metadata that is associated with a global key. Range local keys have a special prefix followed by a global key and a special suffix. For example, transaction records are range local keys which look like: <code>\x01ktxn-</code>.</li>
<li>Replicated Range ID local keys store range metadata that is present on all of the replicas for a range. These keys are updated via Raft operations. Examples include the range lease state and abort cache entries.</li>
<li>Unreplicated Range ID local keys store range metadata that is local to a replica. The primary examples of such keys are the Raft state and Raft log.</li>
</ul>
<p><strong>CockroachDB的数据映射关系</strong></p>
<p>以下表为例</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> mydb.customers(name <span class="type">varchar</span>(<span class="number">100</span>) <span class="keyword">primary</span> key, address <span class="type">varchar</span>(<span class="number">100</span>) , URL <span class="type">varchar</span>(<span class="number">100</span>));</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> mydb.customers <span class="keyword">values</span>(<span class="string">&#x27;Apple&#x27;</span>,<span class="string">&#x27;1 Infinite Loop, Cupertino, CA&#x27;</span>,<span class="string">&#x27;http://apple.com/&#x27;</span>);</span><br></pre></td></tr></table></figure>
<p>表结构信息</p>
<table>
<thead>
<tr>
<th>Key</th>
<th>Values</th>
</tr>
</thead>
<tbody>
<tr>
<td>/system/databases/mydb/id</td>
<td>51</td>
</tr>
<tr>
<td>/system/tables/customer/id</td>
<td>42</td>
</tr>
<tr>
<td>/system/desc/51/42/address</td>
<td>69</td>
</tr>
<tr>
<td>/system/desc/51/42/url</td>
<td>66</td>
</tr>
</tbody>
</table>
<p>表中的数据</p>
<table>
<thead>
<tr>
<th>Key</th>
<th>Values</th>
</tr>
</thead>
<tbody>
<tr>
<td>/51/42/Apple/69</td>
<td>1 Infinite Loop, Cupertino, CA</td>
</tr>
<tr>
<td>/51/42/Apple/66</td>
<td><a href="http://apple.com/">http://apple.com/</a></td>
</tr>
</tbody>
</table>
<h2 id="最后"><a class="header-anchor" href="#最后"></a>最后</h2>
<p>本文简要介绍了各存储引擎的结构，供大家参考，有错误之处请指正.</p>
<h2 id="参考文档"><a class="header-anchor" href="#参考文档"></a>参考文档</h2>
<ul>
<li><a href="https://github.com/facebook/rocksdb">https://github.com/facebook/rocksdb</a></li>
<li><a href="https://www.percona.com/doc/percona-server/LATEST/tokudb/tokudb_intro.html">https://www.percona.com/doc/percona-server/LATEST/tokudb/tokudb_intro.html</a></li>
<li><a href="https://github.com/cockroachdb/cockroach/blob/master/docs/design.md">https://github.com/cockroachdb/cockroach/blob/master/docs/design.md</a></li>
<li><a href="https://github.com/pingcap/tidb">https://github.com/pingcap/tidb</a></li>
<li><a href="https://www.percona.com/live/plam16/sessions/how-we-build-tidb">https://www.percona.com/live/plam16/sessions/how-we-build-tidb</a></li>
<li><a href="https://dev.mysql.com/doc/internals/en/innodb.html">https://dev.mysql.com/doc/internals/en/innodb.html</a></li>
<li><a href="http://img3.tbcdn.cn/L1/461/1/d0069515c04809a449eda659386afbe966e0d1df">http://img3.tbcdn.cn/L1/461/1/d0069515c04809a449eda659386afbe966e0d1df</a></li>
</ul>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/introduction-of-some-popular-engine-storage-formats/">http://xnerv.wang/introduction-of-some-popular-engine-storage-formats/</a></strong><br>
转载自：<a href="http://mysql.taobao.org/monthly/2017/10/04/">一些流行引擎存储格式简介</a></p>
]]></content>
      <categories>
        <category>分布式及存储</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>分布式及存储</tag>
        <tag>InnoDB</tag>
        <tag>TokuDB</tag>
        <tag>RocksDB</tag>
        <tag>TiDB</tag>
        <tag>CockroachDB</tag>
      </tags>
  </entry>
  <entry>
    <title>IOCP的使用和技术内幕</title>
    <url>/iocp-usage-and-inside/</url>
    <content><![CDATA[<h2 id="IOCP-wiki"><a class="header-anchor" href="#IOCP-wiki"></a><a href="https://zh.wikipedia.org/wiki/IOCP">IOCP wiki</a></h2>
<blockquote>
<p>使用CreateIoCompletionPort函数创建IOCP，还可以把socket或文件句柄与IOCP关联起来。<br>
一个线程，第一次调用GetQueuedCompletionStatus函数时，该线程变为关联了该IOCP的线程，直道下述三种情形之一发生：</p>
<ul>
<li>该线程退出；</li>
<li>该线程调用GetQueuedCompletionStatus函数关联到其他的IOCP；</li>
<li>该IOCP被关闭。</li>
</ul>
<p>即，一个线程在任何时刻最多关联一个IOCP。</p>
<span id="more"></span>
<p>线程调用GetQueuedCompletionStatus函数等待放入IOCP的I/O完成包（completion packet）。IOCP拥有一个线程池。阻塞在IOCP上的线程按照后进先出（LIFO）顺序被释放（这是为了减少线程切换的代价）；而一个线程的完成包按照先进先出（FIFO）顺序从IOCP的队列中取走。IOCP有一个最大允许并发的线程数量上限，在CreateIoCompletionPort函数中制定，每次I/O完成包在从队列取走前检查关联与该IOCP且正在并发执行的线程数量是否达到该限。因其他原因（如调用SuspendThread函数）而挂起的线程不算作正在执行的线程。CompletionKey(完成键)一般作为“单句柄数据”的结构体（PER_HANDLE_DATA），用来标识是哪个设备的I/O完成操作己经完成。IO重叠结构（Overlapped）一般作为“单IO数据”的结构体（PER_IO_DATA），该结构体的第1个成员为OVERLAPPED结构体，用来标识是设备的具体哪个操作。</p>
<p>线程可以用PostQueuedCompletionStatus函数在IOCP上放置一个完成包。</p>
<p>IOCP不能跨进程使用。</p>
<p>关闭IOCP之前，必须先关闭关联在该IOCP之上的所有File Handle或socket。</p>
</blockquote>
<h3 id="内部结构"><a class="header-anchor" href="#内部结构"></a>内部结构</h3>
<blockquote>
<p>Windows中利用CreateIoCompletionPort命令创建完成端口对象时， 操作系统内部为该对象自动创建了5个数据结构，分别是：</p>
<ul>
<li>设备列表（Device List）： 每当调用CreateIoCompletionPort函数时，操作系统会将该设备句柄添加到设备列表中；每当调用CloseHandle关闭了某个设备句柄时，系统会将该设句柄从设备列表中删除</li>
<li>IO完成请求队列（I/O Completion Queue-FIFO）：当I/O请求操作完成时，或者调用了PostQueuedCompeltionStatus函数时，操作系统会将I/O请求完成包添加到I/O完成队列中。当操作系统从完成端口对象的等待线程队列中取出一个工作线程时，操作系统会同时从I/O完成队列中取出一个元素（I/O请求完成包。<br>
等待线程队列（WaitingThread List-LIFO）：当线程中调用GetQueuedCompletionStatus函数时，操作系统会将该线程压入到等待* 线程队列中。为了减少线程切换，该队列是LIFO。当I/O完成队列非空，且工作线程并未超出总的并发数时，系统从等待线程队列中取出线程，该线程从自身代码的GetQueuedCompletoinStatus函数调用处返回并继续运行。</li>
<li>释放线程队列（Released Thread List）：当操作系统从等待线程队列中激活了一个工作线程时，或者挂起的线程重新被激活时，该线程被压入释放线程队列中，也即这个队列的线程处于运行状态。这个队列中的线程有两个出队列的机会：一是当线程重新调用GetQueuedCompeltionStatus函数时，线程被添加到等待线程队列中；二是当线程调用其他函数使得线程挂起时，该线程被添加到挂起线程队列中。</li>
<li>暂停线程队列（Paused Thread List）：释放线程队列中的线程被挂起的时候，线程被压入到挂起线程队列中；当挂起的线程重新被唤醒时，从挂起线程队列中取出放入到释放线程队列。</li>
</ul>
</blockquote>
<h2 id="IOCP-浅析"><a class="header-anchor" href="#IOCP-浅析"></a><a href="https://www.ibm.com/developerworks/cn/java/j-lo-iocp/">IOCP 浅析</a></h2>
<h3 id="IOCP-实现的基本步骤"><a class="header-anchor" href="#IOCP-实现的基本步骤"></a>IOCP 实现的基本步骤</h3>
<blockquote>
<p>那么 IOCP 完成端口模型又是怎样实现的呢？首先我们创建一个完成端口 CreateIOCompletionPort，然后再创建一个或多个工作线程，并指定它们到这个完成端口上去读取数据。再将远程连接的套接字句柄关联到这个完成端口。工作线程调用 getQueuedCompletionStatus 方法在关联到这个完成端口上的所有套接字上等待 I/O 的完成，再判断完成了什么类型的 I/O，然后接着发出 WSASend 和 WSARecv，并继续下一次循环阻塞在 getQueuedCompletionStatus。<br>
具体的说，一个完成端口大概的处理流程包括：</p>
<ol>
<li>创建一个完成端口；</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">Port</span> <span class="variable">port</span> <span class="operator">=</span> createIoCompletionPort(INVALID_HANDLE_VALUE, <span class="number">0</span>, <span class="number">0</span>, fixedThreadCount());</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>创建一个线程 ThreadA；</li>
<li>ThreadA 线程循环调用 GetQueuedCompletionStatus 方法来得到 I/O 操作结果，这个方法是一个阻塞方法；</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">While(<span class="literal">true</span>)&#123;</span><br><span class="line"> getQueuedCompletionStatus(port, ioResult);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ol start="4">
<li>主线程循环调用 accept 等待客户端连接上来；</li>
<li>主线程 accept 返回新连接建立以后，把这个新的套接字句柄用 CreateIoCompletionPort 关联到完成端口，然后发出一个异步的 Read 或者 Write 调用，因为是异步函数，Read/Write 会马上返回，实际的发送或者接收数据的操作由操作系统去做。</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (handle != <span class="number">0L</span>) &#123;</span><br><span class="line">	 createIoCompletionPort(handle, port, key, <span class="number">0</span>);</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<ol start="6">
<li>主线程继续下一次循环，阻塞在 accept 这里等待客户端连接。</li>
<li>操作系统完成 Read 或者 Write 的操作，把结果发到完成端口。</li>
<li>ThreadA 线程里的 GetQueuedCompletionStatus() 马上返回，并从完成端口取得刚完成的 Read/Write 的结果。</li>
<li>在 ThreadA 线程里对这些数据进行处理 ( 如果处理过程很耗时，需要新开线程处理 )，然后接着发出 Read/Write，并继续下一次循环阻塞在 GetQueuedCompletionStatus() 这里。</li>
</ol>
</blockquote>
<h2 id="更多参考"><a class="header-anchor" href="#更多参考"></a>更多参考</h2>
<p>《Windows.Internals.Part.2.6th.Edition》 - CHAPTER 8: I/O System - I/O Completion Ports</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/iocp-usage-and-inside/">http://xnerv.wang/iocp-usage-and-inside/</a></strong></p>
]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>Windows</tag>
        <tag>Windows Internals</tag>
        <tag>IOCP</tag>
      </tags>
  </entry>
  <entry>
    <title>LevelDB 实现分析（转载）</title>
    <url>/leveldb-analysis/</url>
    <content><![CDATA[<h2 id="LevelDB-介绍"><a class="header-anchor" href="#LevelDB-介绍"></a><a href="#LevelDB-%E4%BB%8B%E7%BB%8D" title="LevelDB 介绍"></a>LevelDB 介绍</h2>
<p>LevelDB 是由 Google 开发的 key-value 非关系型数据库存储系统，是基于 LSM(Log-Structured-Merge Tree) 的典型实现，LSM 的原理是：当读写数据库时，首先纪录读写操作到 Op log 文件中，然后再操作内存数据库，当达到 checkpoint 时，则写入磁盘，同时删除相应的 Op log 文件，后续重新生成新的内存文件和 Op log 文件。</p>
<p>LevelDB 内部采用了内存缓存机制，也就是在写数据库时，首先会存储在内存中，内存的存储结构采用了 skip list 结构，待达到 checkpoint 时，才进行落盘操作，保证了数据库的高效运转。</p>
<h2 id="LevelDB-总体架构"><a class="header-anchor" href="#LevelDB-总体架构"></a><a href="#LevelDB-%E6%80%BB%E4%BD%93%E6%9E%B6%E6%9E%84" title="LevelDB 总体架构"></a>LevelDB 总体架构</h2>
<p><img src="/assets/leveldb-analysis/TB1AMqNSXXXXXczXFXXXXXXXXXX-851-479.png" alt="resources structure"></p>
<span id="more"></span>
<p>如上图所示，整个 LevelDB 由以下几部分组成：</p>
<ol>
<li>Write(k,v)，对外的接口</li>
<li>Op log，操作日志记录文件</li>
<li>memtable，数据库存储的内存结构</li>
<li>Immutable memtable，待落盘的数据库内存数据</li>
<li>sstable，落盘后的磁盘存储结构</li>
<li>manifest，LevelDB 元信息清单，包括数据库的配置信息和中间使用的文件列表</li>
<li>current，当前正在使用的文件清单</li>
</ol>
<p>整体结构清晰紧凑，非常容易理解。</p>
<h2 id="对外接口"><a class="header-anchor" href="#对外接口"></a><a href="#%E5%AF%B9%E5%A4%96%E6%8E%A5%E5%8F%A3" title="对外接口"></a>对外接口</h2>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">DB</span>() &#123; &#125;;</span><br><span class="line"><span class="keyword">virtual</span> ~<span class="built_in">DB</span>();</span><br><span class="line"><span class="function"><span class="type">static</span> Status <span class="title">Open</span><span class="params">(<span class="type">const</span> Options&amp; options,</span></span></span><br><span class="line"><span class="params"><span class="function">                   <span class="type">const</span> std::string&amp; name,</span></span></span><br><span class="line"><span class="params"><span class="function">                   DB** dbptr)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">virtual</span> Status <span class="title">Put</span><span class="params">(<span class="type">const</span> WriteOptions&amp; options,</span></span></span><br><span class="line"><span class="params"><span class="function">                   <span class="type">const</span> Slice&amp; key,</span></span></span><br><span class="line"><span class="params"><span class="function">                   <span class="type">const</span> Slice&amp; value)</span> </span>= <span class="number">0</span>;</span><br><span class="line"><span class="function"><span class="keyword">virtual</span> Status <span class="title">Delete</span><span class="params">(<span class="type">const</span> WriteOptions&amp; options, <span class="type">const</span> Slice&amp; key)</span> </span>= <span class="number">0</span>;</span><br><span class="line"><span class="function"><span class="keyword">virtual</span> Status <span class="title">Write</span><span class="params">(<span class="type">const</span> WriteOptions&amp; options, WriteBatch* updates)</span> </span>= <span class="number">0</span>;</span><br><span class="line"><span class="function"><span class="keyword">virtual</span> Status <span class="title">Get</span><span class="params">(<span class="type">const</span> ReadOptions&amp; options,</span></span></span><br><span class="line"><span class="params"><span class="function">                   <span class="type">const</span> Slice&amp; key, std::string* value)</span> </span>= <span class="number">0</span>;</span><br><span class="line"><span class="function"><span class="keyword">virtual</span> Iterator* <span class="title">NewIterator</span><span class="params">(<span class="type">const</span> ReadOptions&amp; options)</span> </span>= <span class="number">0</span>;</span><br><span class="line"><span class="function"><span class="keyword">virtual</span> <span class="type">const</span> Snapshot* <span class="title">GetSnapshot</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line"><span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">ReleaseSnapshot</span><span class="params">(<span class="type">const</span> Snapshot* snapshot)</span> </span>= <span class="number">0</span>;</span><br></pre></td></tr></table></figure>
<p>整体接口分为：</p>
<ul>
<li>数据库创建和删除</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">DB</span>() &#123; &#125;;</span><br><span class="line"><span class="keyword">virtual</span> ~<span class="built_in">DB</span>();</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>数据库打开</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">static</span> Status <span class="title">Open</span><span class="params">(<span class="type">const</span> Options&amp; options,</span></span></span><br><span class="line"><span class="params"><span class="function">                   <span class="type">const</span> std::string&amp; name,</span></span></span><br><span class="line"><span class="params"><span class="function">                   DB** dbptr)</span></span>;</span><br></pre></td></tr></table></figure>
<ul>
<li>数据库读写删除操作</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">virtual</span> Status <span class="title">Put</span><span class="params">(<span class="type">const</span> WriteOptions&amp; options,</span></span></span><br><span class="line"><span class="params"><span class="function">                   <span class="type">const</span> Slice&amp; key,</span></span></span><br><span class="line"><span class="params"><span class="function">                   <span class="type">const</span> Slice&amp; value)</span> </span>= <span class="number">0</span>;</span><br><span class="line"><span class="function"><span class="keyword">virtual</span> Status <span class="title">Delete</span><span class="params">(<span class="type">const</span> WriteOptions&amp; options, <span class="type">const</span> Slice&amp; key)</span> </span>= <span class="number">0</span>;</span><br><span class="line"><span class="function"><span class="keyword">virtual</span> Status <span class="title">Get</span><span class="params">(<span class="type">const</span> ReadOptions&amp; options,</span></span></span><br><span class="line"><span class="params"><span class="function">                   <span class="type">const</span> Slice&amp; key, std::string* value)</span> </span>= <span class="number">0</span>;</span><br></pre></td></tr></table></figure>
<ul>
<li>数据库批处理操作</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">virtual</span> Status <span class="title">Write</span><span class="params">(<span class="type">const</span> WriteOptions&amp; options, WriteBatch* updates)</span> </span>= <span class="number">0</span>;</span><br></pre></td></tr></table></figure>
<ul>
<li>数据库遍历操作</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">virtual</span> Iterator* <span class="title">NewIterator</span><span class="params">(<span class="type">const</span> ReadOptions&amp; options)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ol start="6">
<li>获取快照操作</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">virtual</span> <span class="type">const</span> Snapshot* <span class="title">GetSnapshot</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line"><span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">ReleaseSnapshot</span><span class="params">(<span class="type">const</span> Snapshot* snapshot)</span> </span>= <span class="number">0</span>;</span><br></pre></td></tr></table></figure>
<h3 id="Op-log结构分析"><a class="header-anchor" href="#Op-log结构分析"></a><a href="#Op-log%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90" title="Op log结构分析"></a>Op log结构分析</h3>
<p>LevelDB 使用的 Op log 日志采用了文件记录的方式，且文件使用了 mmap 方式操作，以提高效率。</p>
<p>Op log 存储切分为 32KB 大小的数据块，每个 32KB 数据块存储着 Op log，每 个Op log 格式如下：</p>
<p><img src="/assets/leveldb-analysis/TB1IRGFSXXXXXbsXVXXXXXXXXXX-405-79.png" alt="resources structure"></p>
<p>其中：</p>
<ul>
<li>CRC32 为 crc 校验码，保证数据的完整性</li>
<li>Length，为 Op log 的数据长度</li>
<li>Log Type，Op log 的类型，之所以会有类型，是由于 32KB 可能存不下一条 Op log，Op log 有可能跨数据块，类型分为：
<ul>
<li>FULL：代表 Data 包含了所有的数据</li>
<li>FIRST：代表该 Data 是 Op log 的开始数据</li>
<li>MIDDLE：代表该 Data 是 Op log 的中间数据</li>
<li>LAST: 代表该 Data 是 Op log 的结束数据</li>
</ul>
</li>
<li>Data，为 Op log 的实际数据</li>
</ul>
<h4 id="memtable-结构分析"><a class="header-anchor" href="#memtable-结构分析"></a><a href="#memtable-%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90" title="memtable 结构分析"></a>memtable 结构分析</h4>
<p>memtable 是 LevelDB 数据库的内存存储结构，采用了 skip list 结构存储，如下图所示：</p>
<blockquote>
<p>skip list 是一种可以代替平衡树的存储结构，它采用概率的方式来保证平衡，而平衡树则是采用严格的旋转树结构来保证平衡，复杂度会高一些。<br>
对于 skip list，会有 n 层链表，其中 0 层保存所有的值，越往上层，保存的值越少。每当插入一个值时，会通过概率计算该值需要插入的最高层级 k，然后从 0~k-1 层，分别插入该值。</p>
</blockquote>
<p><img src="/assets/leveldb-analysis/TB1aoiISXXXXXX4XVXXXXXXXXXX-941-359.png" alt="resources structure"></p>
<p>其中每个表项的存储结构如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">key_size | key_value | sequence_num&amp;type | value_size | value</span><br></pre></td></tr></table></figure>
<p>其中：</p>
<p>sequence_num：表示操作的序列号，每一个数据项都会带有一个序列号，用以表示数据的新旧程度。</p>
<p>type：表示数据的类型，分为：</p>
<ul>
<li>kTypeValue：表明数据有效</li>
<li>kTypeDeletion：表明数据已经失效，在数据进行 delete 操作时会打上该标识</li>
</ul>
<h3 id="sstable-结构分析"><a class="header-anchor" href="#sstable-结构分析"></a><a href="#sstable-%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90" title="sstable 结构分析"></a>sstable 结构分析</h3>
<p>sstable 作为落盘的存储结构，每个 sstable 最大 2MB，从宏观来看，它属于分层的结构，即：</p>
<ul>
<li>level 0：最多存储 4 个 sstable</li>
<li>level 1：存储不超过 10MB 大小的 sstable</li>
<li>level 2：存储不超过 100MB 大小的 sstable</li>
</ul>
<p>level 3 及之后：存储大小不超过上一级大小的 10 倍</p>
<p>之所以这样分层，是为了提高查找效率，也是 LevelDB 名称的由来。当每一层超过限制时，会进行 compaction 操作，合并到上一层，递归进行。</p>
<p>从微观的角度看，每个 sstable 文件结构入下图所示：</p>
<p><img src="/assets/leveldb-analysis/TB1n.yuSXXXXXacaXXXXXXXXXXX-345-228.png" alt="resources structure"></p>
<p>其中：</p>
<ul>
<li>Data Block 存储具体的 k-v 数据</li>
<li>Meta Block 存储索引过滤信息，用于快速定位 key 是否存在于 Data Block 中</li>
<li>Meta Index Block 存储 Meta Block 的偏移位置及大小</li>
<li>Index Block 存储 Data Block 的偏移位置及大小</li>
<li>Footer 则存储 Meta Index Block 和 Index Block 的偏移位置及大小，相当于二级索引，Footer 的结构如下：<br>
<img src="/assets/leveldb-analysis/TB1C9DXSXXXXXcyXXXXXXXXXXXX-197-140.png" alt="resources structure"></li>
</ul>
<p>另外 Data Block 及 Meta Block 的存储格式是统一的，都是如下格式：</p>
<p><img src="/assets/leveldb-analysis/TB1X9qPSXXXXXbwXFXXXXXXXXXX-435-67.png" alt="resources structure"></p>
<p>其中 type 表示是否是压缩存储，目前 LevelDB 支持 key 值的 snappy 压缩或者不压缩。</p>
<p>而上图中的 Block data 的格式则为：</p>
<p><img src="/assets/leveldb-analysis/TB11UGqSXXXXXaEaXXXXXXXXXXX-819-359.png" alt="resources structure"></p>
<p>上图有几点要说明：</p>
<ul>
<li>对于 Block data 中的第一项总是不压缩存储的，不压缩存储的项称为 restarts，会被记录在上图的最尾部，同时每隔 k 个值（k 值可定制），都会存储一个不压缩的项，这些都称为 restarts，都会被记录在最尾部。</li>
<li>每个 restarts 表项会作为索引项存储。</li>
<li>除了 restarts 表项以外，其它的表项则基于该 restarts 项，计算跟他相同部分和不同部分，上图中的 shared_bytes 和 unshared_bytes 记录了相同部分长度和不同部分的长度，key_delta 则记录了不同的部分的值，value_length 和 value 则记录了 value 部分的值。</li>
<li>压不压缩是可选的，默认会进行 snappy 压缩。</li>
</ul>
<p>对于 Meta Block 来说，它保存了用于快速定位 key 是否在 Data Block 中的信息，具体方法是：</p>
<ul>
<li>采用了 bloom filter 的过滤机制，bloom filter 是一种 hash 机制，它对每一个 key，会计算 k 个 hash 值，然后在 k 个 bit 位记录为 1。当查找时，相应计算出 k 个 hash 值，然后比对 k 个 bit 位是否为 1，只要有一个不为 1，则不存在。</li>
<li>对于每一个 Data Block，所有的 key 值会传入进行 bloom filter 的 hash 计算，每个 key 存储 k 个 bit 位值。</li>
</ul>
<h3 id="版本管理"><a class="header-anchor" href="#版本管理"></a><a href="#%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86" title="版本管理"></a>版本管理</h3>
<p>对于 LevelDB 来说，它采用了简单的 sequence num 机制来管理，具体为：</p>
<ol>
<li>对于 Op log 文件，每一个 Op log 文件名中会包含一个唯一的 sequence num，每创建一个新的 Op log 文件，sequence num 则加 1，sequence num 越大，则表示文件越新，同时最新的 sequence num 会记录下来。</li>
<li>对于每个 key-value 对，也会对应一个 sequence num，对于同一个 key，如果后续更新值时，sequence num 也会相应更新，这样就可以根据 sequence num 的大小，找到最新的 key-value 对</li>
</ol>
<h3 id="新增特性"><a class="header-anchor" href="#新增特性"></a><a href="#%E6%96%B0%E5%A2%9E%E7%89%B9%E6%80%A7" title="新增特性"></a>新增特性</h3>
<ul>
<li>
<p>支持模糊查询</p>
<p>该功能支持 key 以模糊规则匹配的方式进行数据库查询，支持＊和？两种模糊规则查询。</p>
</li>
<li>
<p>支持 JSON 格式数据存储</p>
<p>该功能支持 k-v 中，v以json格式传入，后续可以通过关键字，查询json里面的数据。</p>
</li>
</ul>
<h3 id="结束语"><a class="header-anchor" href="#结束语"></a><a href="#%E7%BB%93%E6%9D%9F%E8%AF%AD" title="结束语"></a>结束语</h3>
<p>LevelDB 短小精悍，代码运行效率高效，且通俗易懂，是一个非常不错的 k-v 存储系统。</p>
<p>注：图片来源于网络</p>
<blockquote>
<p>题图：<a href="https://unsplash.com/photos/9wwF-VmSOrY">https://unsplash.com/photos/9wwF-VmSOrY</a> By @eberhard grossgasteiger</p>
</blockquote>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/leveldb-analysis/">http://xnerv.wang/leveldb-analysis/</a></strong><br>
转载自：<a href="http://taobaofed.org/blog/2017/07/05/leveldb-analysis/">LevelDB 实现分析</a></p>
]]></content>
      <categories>
        <category>分布式及存储</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>分布式及存储</tag>
        <tag>LevelDB</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux进程、内核及文件系统总结</title>
    <url>/linux-process-kernel-and-file-system-summary/</url>
    <content><![CDATA[<h2 id="fork"><a class="header-anchor" href="#fork"></a>fork</h2>
<p><a href="http://www.ahlinux.com/start/kernel/10313.html">关于linux进程间的close-on-exec机制</a></p>
<blockquote>
<p>一般我们会调用exec执行另一个程序，此时会用全新的程序替换子进程的正文，数据，堆和栈等。此时保存文件描述符的变量当然也不存在 了，我们就无法关闭无用的文件描述符了。所以通常我们会fork子进程后在子进程中直接执行close关掉无用的文件描述符，然后再执行exec。<br>
但是在复杂系统中，有时我们fork子进程时已经不知道打开了多少个文件描述符（包括socket句柄等），这此时进行逐一清理确实有很大难 度。我们期望的是能在fork子进程前打开某个文件句柄时就指定好：“这个句柄我在fork子进程后执行exec时就关闭”。其实时有这样的方法的：即所 谓 的 close-on-exec。<br>
回到我们的应用场景中来，只要我们在创建socket的时候加上 SOCK_CLOEXEC标志，就能够达到我们要求的效果，在fork子进程中执行exec的时候，会清理掉父进程创建的socket。</p>
</blockquote>
<span id="more"></span>
<p><a href="http://stackoverflow.com/questions/395877/are-child-processes-created-with-fork-automatically-killed-when-the-parent-is">Are child processes created with fork() automatically killed when the parent is killed?</a></p>
<blockquote>
<p>No. If the parent is killed, children become children of the init process (that has the process id 1 and is launched as the first user process by the kernel).<br>
The init process checks periodically for new children, and kills them if they have exited (thus freeing resources that are allocated by their return value).</p>
</blockquote>
<p><a href="http://stackoverflow.com/questions/284325/how-to-make-child-process-die-after-parent-exits">How to make child process die after parent exits?</a></p>
<blockquote>
<p>Child can ask kernel to deliver SIGHUP (or other signal) when parent dies by specifying option PR_SET_PDEATHSIG in prctl() syscall like this:<br>
prctl(PR_SET_PDEATHSIG, SIGHUP);<br>
See man 2 prctl for details.</p>
</blockquote>
<p><a href="https://www.ibm.com/developerworks/cn/linux/l-cn-nohup/">Linux 技巧：让进程在后台可靠运行的几种方法</a></p>
<h2 id="线程实现"><a class="header-anchor" href="#线程实现"></a>线程实现</h2>
<h3 id="LinuxThreads的不足"><a class="header-anchor" href="#LinuxThreads的不足"></a>LinuxThreads的不足</h3>
<blockquote>
<p>按照POSIX定义，同一进程的所有线程应该共享一个进程id和父进程id，这在目前的&quot;一对一&quot;模型下是无法实现的。<br>
由于异步信号是内核以进程为单位分发的，而LinuxThreads的每个线程对内核来说都是一个进程，且没有实现&quot;线程组&quot;，因此，某些语义不符合POSIX标准，比如没有实现向进程中所有线程发送信号，README对此作了说明。<br>
LinuxThreads将每个进程的线程最大数目定义为1024，但实际上这个数值还受到整个系统的总进程数限制，这又是由于线程其实是核心进程。<br>
管理线程容易成为瓶颈，这是这种结构的通病；同时，管理线程又负责用户线程的清理工作，因此，尽管管理线程已经屏蔽了大部分的信号，但一旦管理线程死亡，用户线程就不得不手工清理了，而且用户线程并不知道管理线程的状态，之后的线程创建等请求将无人处理。<br>
LinuxThreads中的线程同步很大程度上是建立在信号基础上的，这种通过内核复杂的信号处理机制的同步方式，效率一直是个问题。</p>
</blockquote>
<h3 id="其他的线程实现机制"><a class="header-anchor" href="#其他的线程实现机制"></a>其他的线程实现机制</h3>
<blockquote>
<p>LinuxThreads的问题，特别是兼容性上的问题，严重阻碍了Linux上的跨平台应用（如Apache）采用多线程设计，从而使得Linux上的线程应用一直保持在比较低的水平。在Linux社区中，已经有很多人在为改进线程性能而努力，其中既包括用户级线程库，也包括核心级和用户级配合改进的线程库。目前最为人看好的有两个项目，一个是RedHat公司牵头研发的NPTL（Native Posix Thread Library），另一个则是IBM投资开发的NGPT（Next Generation Posix Threading），二者都是围绕完全兼容POSIX 1003.1c，同时在核内和核外做工作以而实现多对多线程模型。这两种模型都在一定程度上弥补了LinuxThreads的缺点，且都是重起炉灶全新设计的。</p>
</blockquote>
<p><a href="http://www.ibm.com/developerworks/cn/linux/l-threading.html">Linux 线程模型的比较：LinuxThreads 和 NPTL</a></p>
<blockquote>
<p>LinuxThreads 的限制已经在 NPTL 以及 LinuxThreads 后期的一些版本中得到了克服。例如，最新的 LinuxThreads 实现使用了线程注册来定位线程本地数据；例如在 Intel® 处理器上，它就使用了 %fs 和 %gs 段寄存器来定位访问线程本地数据所使用的虚拟地址。尽管这个结果展示了 LinuxThreads 所采纳的一些修改的改进结果，但是它在更高负载和压力测试中，依然存在很多问题，因为它过分地依赖于一个管理线程，使用它来进行信号处理等操作。<br>
您应该记住，在使用 LinuxThreads 构建库时，需要使用 -D_REENTRANT 编译时标志。这使得库线程是安全的。<br>
最后，也许是最重要的事情，请记住 LinuxThreads 项目的创建者已经不再积极更新它了，他们认为 NPTL 会取代 LinuxThreads。<br>
LinuxThreads 的缺点并不意味着 NPTL 就没有错误。作为一个面向 SMP 的设计，NPTL 也有一些缺点。我曾经看到过在最近的 Red Hat 内核上出现过这样的问题：一个简单线程在单处理器的机器上运行良好，但在 SMP 机器上却挂起了。我相信在 Linux 上还有更多工作要做才能使它具有更好的可伸缩性，从而满足高端应用程序的需求。</p>
</blockquote>
<h2 id="SIGNAL"><a class="header-anchor" href="#SIGNAL"></a>SIGNAL</h2>
<p><a href="http://programmergamer.blogspot.jp/2013/05/clarification-on-sigint-sigterm-sigkill.html">Clarification on SIGKILL, SIGTERM, SIGINT, SIGQUIT, SIGSTP and SIGHUP</a></p>
<blockquote>
<ul>
<li>SIGKILL: kill -9</li>
<li>SIGTERM: kill</li>
<li>SIGINT: Ctrl+C (The difference between SIGINT and SIGTERM is that the former can be sent from a terminal as input characters.)</li>
<li>SIGQUIT Ctrl+\ (generates a core dump of the process and also cleans up resources held up by a process.)</li>
<li>SIGSTP Ctrl+Z (Suspends a process. The process can be resumed by sending a SIGCONT signal.)</li>
<li>SIGHUP Ctrl+D (Hangs up a process when the controlling terminal is disconnected.)</li>
</ul>
</blockquote>
<p><a href="http://www.spongeliu.com/165.html">Linux内核信号处理机制介绍</a></p>
<blockquote>
<p>如果想要进程捕获某个信号，然后作出相应的处理，就需要注册信号处理函数。同中断类似，内核也为每个进程准备了一个信号向量表,信号向量表中记录着每个信号所对应的处理机制，默认情况下是调用默认处理机制。当进程为某个信号注册了信号处理程序后，发生该信号时，内核就会调用注册的函数。<br>
信号是异步的，一个进程不可能等待信号的到来，也不知道信号会到来，那么，进程是如何发现和接受信号呢？实际上，信号的接收不是由用户进程来完成的，而是由内核代理。当一个进程P2向另一个进程P1发送信号后，内核接受到信号，并将其放在P1的信号队列当中。当P1再次陷入内核态时，会检查信号队列，并根据相应的信号调取相应的信号处理函数。</p>
</blockquote>
<h2 id="内核态与用户态"><a class="header-anchor" href="#内核态与用户态"></a><a href="http://jakielong.iteye.com/blog/771663">内核态与用户态</a></h2>
<blockquote>
<p>Intel x86架构的CPU来说一共有0~3四个特权级，0级最高，3级最低，硬件上在执行每条指令时都会对指令所具有的特权级做相应的检查，相关的概念有CPL、DPL和RPL<br>
用户态切换到内核态的3种方式：系统调用、异常、外围设备的中断。其中系统调用可以认为是用户进程主动发起的，异常和外围设备中断则是被动的。<br>
从触发方式上看，可以认为存在前述3种不同的类型，但是从最终实际完成由用户态到内核态的切换操作上来说，涉及的关键步骤是完全一致的，没有任何区别，都相当于执行了一个中断响应的过程，因为系统调用实际上最终是中断机制实现的，而异常和中断的处理机制基本上也是一致的。</p>
<p>涉及到由用户态切换到内核态的步骤主要包括：</p>
<ol>
<li>从当前进程的描述符中提取其内核栈的ss0及esp0信息。</li>
<li>使用ss0和esp0指向的内核栈将当前进程的cs,eip,eflags,ss,esp信息保存起来，这个过程也完成了由用户栈到内核栈的切换过程，同时保存了被暂停执行的程序的下一条指令。</li>
<li>将先前由中断向量检索得到的中断处理程序的cs,eip信息装入相应的寄存器，开始执行中断处理程序，这时就转到了内核态的程序执行了。</li>
</ol>
<p>内核态程序执行完毕时如果要从内核态返回用户态，可以通过执行指令iret来完成，指令iret会将先前压栈的进入内核态前的cs,eip,eflags,ss,esp信息从栈里弹出，加载到各个对应的寄存器中，重新开始执行用户态的程序。</p>
<p>处理器总处于以下状态中的一种：</p>
<ol>
<li>内核态，运行于进程上下文，内核代表进程运行于内核空间；</li>
<li>内核态，运行于中断上下文，内核代表硬件运行于内核空间；</li>
<li>用户态，运行于用户空间。</li>
</ol>
</blockquote>
<h2 id="系统调用"><a class="header-anchor" href="#系统调用"></a>系统调用</h2>
<p>strace常用来跟踪进程执行时的系统调用和所接收的信号。 在Linux世界，进程不能直接访问硬件设备，当进程需要访问硬件设备(比如读取磁盘文件，接收网络数据等等)时，必须由用户态模式切换至内核态模式，通过系统调用访问硬件设备。strace可以跟踪到一个进程产生的系统调用,包括参数，返回值，执行消耗的时间。<br>
GDB则主要依赖一个系统函数ptrace。<br>
Windows上的替代物则是WinDbg的Logger.exe和wt调试命令，以及Process Monitor则工具。</p>
<h2 id="中断及IO调度"><a class="header-anchor" href="#中断及IO调度"></a>中断及IO调度</h2>
<p><a href="http://blog.csdn.net/zqixiao_09/article/details/50876866">Linux 设备驱动开发 —— Tasklets 机制浅析</a></p>
<blockquote>
<p>tasklet是I/O驱动程序中实现可延迟函数的首选方法。</p>
</blockquote>
<p><a href="http://blog.chinaunix.net/uid-27177626-id-3438994.html">中断处理程序&amp;中断服务例程</a><br>
<img src="http://blog.chinaunix.net/attachment/201212/13/27177626_1355390534Khaa.png" alt=""></p>
<p><a href="https://stackoverflow.com/questions/13341870/signals-and-interrupts-a-comparison">Signals and interrupts a comparison</a></p>
<blockquote>
<p>Interrupts can be viewed as a mean of communication between the CPU and the OS kernel. Signals can be viewed as a mean of communication between the OS kernel and OS processes.<br>
Interrupts may be initiated by the CPU (exceptions - e.g.: divide by zero, page fault), devices (hardware interrupts - e.g: input available), or by a CPU instruction (traps - e.g: syscalls, breakpoints). They are eventually managed by the CPU, which “interrupts” the current task, and invokes an OS-kernel provided ISR/interrupt handler.<br>
Signals may be initiated by the OS kernel (e.g: SIGFPE, SIGSEGV, SIGIO), or by a process(kill()). They are eventually managed by the OS kernel, which delivers them to the target thread/process, invoking either a generic action (ignore, terminate, terminate and dump core) or a process-provided signal handler.<br>
Hardware interrupts can also generate signals, like a keyboard interrupt generates SIGINT. Thus interrupts and signals are closely tied to each other.</p>
</blockquote>
<p><a href="https://www.ibm.com/developerworks/cn/linux/kernel/interrupt/">Linux 2.4.x内核软中断机制</a></p>
<p><a href="http://blog.csdn.net/zhangskd/article/details/21992933">硬中断、软中断</a></p>
<blockquote>
<p>中断：通常被定义成一个事件，该事件改变处理器执行的指令顺序。这样的事件与cpu芯片外部电路产生的电信号相对应。<br>
中断的产生：每个能够发出中断请求的硬件设备控制器都有一条称为IRQ的输出线（中断线）。所有的IRQ线都与一个中断控制器的输入引脚相连，中断控制器与cpu的intr引脚相连。<br>
中断向量：每个中断由0-255之间的一个8位数来标识。称为中断向量。<br>
中断描述符表：IDT是一个系统表，它与每一个中断或者异常向量相联系，每一个向量在表中有相应的中断处理程 序的入口地址。cpu的idtr寄存器执行IDT表的物理基地址。<br>
硬中断是由硬件产生的，比如，像磁盘，网卡，键盘，时钟等。每个设备或设备集都有它自己的IRQ（中断请求）。基于IRQ，CPU可以将相应的请求分发到对应的硬件驱动上（注：硬件驱动通常是内核中的一个子程序，而不是一个独立的进程）。<br>
中断的硬件处理：在内核被init进程初始化后，cpu运行在保护模式下。当执行一条指令后，sc和eip这对寄存器包含了下一条将要执行的指令的逻辑地址。在执行这条指令之前，cpu控制单元会检查在运行前一条指令时是否发生了一个中断。如果发生了，cpu控制单元处理中断。<br>
中断与信号的区别：软中断通常是硬中断服务程序对内核的中断。信号则是由内核或者其他进程对某个进程的中断。<br>
硬中断可以直接中断CPU。它会引起内核中相关的代码被触发。对于那些需要花费一些时间去处理的进程，中断代码本身也可以被其他的硬中断中断。<br>
对于时钟中断，内核调度代码会将当前正在运行的进程挂起，从而让其他的进程来运行。它的存在是为了让调度代码（或称为调度器）可以调度多任务。<br>
软中断的处理非常像硬中断。然而，它们仅仅是由当前正在运行的进程所产生的。<br>
软中断并不会直接中断CPU。也只有当前正在运行的代码（或进程）才会产生软中断。这种中断是一种需要内核为正在运行的进程去做一些事情（通常为I/O）的请求。有一个特殊的软中断是Yield调用，它的作用是请求内核调度器去查看是否有一些其他的进程可以运行。<br>
int n - 触发软中断n。相应的中断处理函数的地址为：中断向量表地址 + 4 * n。软件中断处理程序是由操作系统提供的为保证系统异步执行的机制。如在linux下由用户态向内核态转换需要调用0x80软件中断。软中断是实现系统API函数调用的手段。<br>
中断嵌套：Linux下硬中断是可以嵌套的，但是没有优先级的概念，也就是说任何一个新的中断都可以打断正在执行的中断，但同种中断除外。软中断不能嵌套，但相同类型的软中断可以在不同CPU上并行执行。</p>
</blockquote>
<h2 id="文件系统"><a class="header-anchor" href="#文件系统"></a>文件系统</h2>
<p><a href="https://www.ibm.com/developerworks/cn/linux/l-linux-filesystem/">Linux 文件系统剖析</a><br>
<img src="https://www.ibm.com/developerworks/cn/linux/l-linux-filesystem/figure1.gif" alt="Linux 文件系统组件的体系结构"></p>
<p><a href="https://www.ibm.com/developerworks/cn/linux/l-virtual-filesystem-switch/">Linux 虚拟系统文件交换器剖析</a></p>
<p><a href="http://blog.chinaunix.net/uid-7828352-id-3233062.html">linux文件系统中superblock,inode,dentry及file的关系</a></p>
<blockquote>
<p>需要注意的几点如下所示：</p>
<ol>
<li>进程每打开一个文件，就会有一个file结构与之对应。同一个进程可以多次打开同一个文件而得到多个不同的file结构，file结构描述被打开文件的属性，如文件的当前偏移量等信息。</li>
<li>两个不同的file结构可以对应同一个dentry结构。进程多次打开同一个文件时，对应的只有一个dentry结构。Dentry结构存储目录项和对应文件（inode）的信息。</li>
<li>在存储介质中，每个文件对应唯一的inode结点，但是每个文件又可以有多个文件名。即可以通过不同的文件名访问同一个文件。这里多个文件名对应一个文件的关系在数据结构中表示就是dentry和inode的关系。</li>
<li>Inode中不存储文件的名字，它只存储节点号；而dentry则保存有名字和与其对应的节点号，所以就可以通过不同的dentry访问同一个inode。</li>
<li>不同的dentry则是同个文件链接（ln命令）来实现的。</li>
</ol>
</blockquote>
<p><a href="https://superuser.com/questions/303040/how-do-file-permissions-apply-to-symlinks">How do file permissions apply to symlinks?</a><br>
macos不考虑，一般的linux在chmod符号链接时其实作用于指向的文件本身，但chmod在有些情况下是会跳过涉及符号链接的情况的。</p>
<p><a href="https://unix.stackexchange.com/questions/12769/symbolic-link-permissions">Symbolic link permissions</a><br>
权限是记录在inode上的，符号链接最终指向的也是同一个inode。</p>
<p><a href="http://www.cnblogs.com/ggjucheng/archive/2012/08/22/2651641.html">EXT2 文件系统</a></p>
<blockquote>
<p>我们将 inode 与 block 区块用图解来说明一下，如下图所示，文件系统先格式化出 inode 与 block 的区块，假设某一个文件的属性与权限数据是放置到 inode 4 号(下图较小方格内)，而这个 inode 记录了文件数据的实际放置点为 2, 7, 13, 15 这四个 block 号码，此时我们的操作系统就能够据此来排列磁盘的阅读顺序，可以一口气将四个 block 内容读出来！ 那么数据的读取就如同下图中的箭头所指定的模样了。<br>
<img src="http://pic002.cnblogs.com/images/2012/360373/2012082223131010.jpg" alt="inode/block 数据存取示意图"></p>
<p>这种数据存取的方法我们称为索引式文件系统(indexed allocation)。那有没有其他的惯用文件系统可以比较一下啊？ 有的，那就是我们惯用的闪盘(闪存)，闪盘使用的文件系统一般为 FAT 格式。FAT 这种格式的文件系统并没有 inode 存在，所以 FAT 没有办法将这个文件的所有 block 在一开始就读取出来。每个 block 号码都记录在前一个 block 当中， 他的读取方式有点像底下这样：<br>
<img src="http://pic002.cnblogs.com/images/2012/360373/2012082223132263.jpg" alt="FAT文件系统数据存取示意图"><br>
上图中我们假设文件的数据依序写入1-&gt;7-&gt;4-&gt;15号这四个 block 号码中， 但这个文件系统没有办法一口气就知道四个 block 的号码，他得要一个一个的将 block 读出后，才会知道下一个 block 在何处。 如果同一个文件数据写入的 block 分散的太过厉害时，则我们的磁盘读取头将无法在磁盘转一圈就读到所有的数据， 因此磁盘就会多转好几圈才能完整的读取到这个文件的内容！</p>
<p>常常会听到所谓的『碎片整理』吧？ 需要碎片整理的原因就是文件写入的 block 太过于离散了，此时文件读取的效能将会变的很差所致。 这个时候可以透过碎片整理将同一个文件所属的 blocks 汇整在一起，这样数据的读取会比较容易啊！ 想当然尔，FAT 的文件系统需要经常的碎片整理一下，那么 Ext2 是否需要磁盘重整呢？</p>
<p>由于 Ext2 是索引式文件系统，基本上不太需要常常进行碎片整理的。但是如果文件系统使用太久， 常常删除/编辑/新增文件时，那么还是可能会造成文件数据太过于离散的问题，此时或许会需要进行重整一下的。</p>
</blockquote>
<p><a href="http://blog.csdn.net/cywosp/article/details/38965239">每天进步一点点——Linux中的文件描述符与打开文件之间的关系</a><br>
<img src="http://img.blog.csdn.net/20140831224917875?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvY3l3b3Nw/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""></p>
<p>SUID(Set UID)是让执行一个可执行程序的process拥有owner的权限，如passwd程序修改/etc/passwd文件。<br>
SGID(Set GID)可以设置在目录上，也可以设置在文件上。设置在目录上是强制本目录下新建的（一级）文件和（一级）目录的group自动变为该目录的group。而设置在文件上，则是让执行一个可执行程序的process拥有该目录group的权限。<br>
SBIT（Sticky Bit）设置在目录上，该目录下的（一级）文件和目录只有owner和root可以删除。</p>
<p>Linux的chattr和lsattr可以达到和NTFS权限一样复杂的功能。</p>
<p>The difference between fsync() and fdatasync() is that the later does not necessarily update the meta-data associated with a file – such as the “last modified” date – but only the file data.</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/linux-process-kernel-and-file-system-summary/">http://xnerv.wang/linux-process-kernel-and-file-system-summary/</a></strong></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>Linux</tag>
        <tag>信号</tag>
        <tag>中断</tag>
        <tag>内核态与用户态</tag>
        <tag>文件系统</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux session和进程组概述（转载）</title>
    <url>/linux-session-and-processgroup-summary/</url>
    <content><![CDATA[<p>在<a href="/linux-tty-pts-summary/">上一篇</a>中介绍了tty的相关原理，这篇将介绍跟tty密切相关的session和进程组。</p>
<blockquote>
<p>本篇主要目的是澄清一些概念，不涉及细节</p>
</blockquote>
<span id="more"></span>
<h2 id="session"><a class="header-anchor" href="#session"></a>session</h2>
<p>session就是一组进程的集合，session id就是这个session中leader的进程ID。</p>
<h3 id="session的特点"><a class="header-anchor" href="#session的特点"></a>session的特点</h3>
<p>session的主要特点是当session的leader退出后，session中的所有其它进程将会收到SIGHUP信号，其默认行为是终止进程，即session的leader退出后，session中的其它进程也会退出。</p>
<p>如果session和tty关联的话，它们之间只能一一对应，一个tty只能属于一个session，一个session只能打开一个tty。当然session也可以不和任何tty关联。</p>
<h3 id="session的创建"><a class="header-anchor" href="#session的创建"></a>session的创建</h3>
<p>session可以在任何时候创建，调用setsid函数即可，session中的第一个进程即为这个session的leader，leader是不能变的。常见的创建session的场景是：</p>
<ul>
<li>用户登录后，启动shell时将会创建新的session，shell会作为session的leader，随后shell里面运行的进程都将属于这个session，当shell退出后，所有该用户运行的进程将退出。这类session一般都会和一个特定的tty关联，session的leader会成为tty的控制进程，当session的前端进程组发生变化时，控制进程负责更新tty上关联的前端进程组，当tty要关闭的时候，控制进程所在session的所有进程都会收到SIGHUP信号。</li>
<li>启动deamon进程，这类进程需要和父进程划清界限，所以需要启动一个新的session。这类session一般不会和任何tty关联。</li>
</ul>
<h2 id="进程组"><a class="header-anchor" href="#进程组"></a>进程组</h2>
<p>进程组（process group）也是一组进程的集合，进程组id就是这个进程组中leader的进程ID。</p>
<h3 id="进程组的特点"><a class="header-anchor" href="#进程组的特点"></a>进程组的特点</h3>
<p>进程组的主要特点是可以以进程组为单位通过函数<a href="http://man7.org/linux/man-pages/man3/killpg.3.html">killpg</a>发送信号</p>
<h3 id="进程组的创建"><a class="header-anchor" href="#进程组的创建"></a>进程组的创建</h3>
<p>进程组主要用在shell里面，shell负责进程组的管理，包括创建、销毁等。（这里shell就是session的leader）</p>
<ul>
<li>对大部分进程来说，它自己就是进程组的leader，并且进程组里面就只有它自己一个进程</li>
<li>shell里面执行类似<code>ls|more</code>这样的以管道连接起来的命令时，两个进程就属于同一个进程组，ls是进程组的leader。</li>
<li>shell里面启动一个进程后，一般都会将该进程放到一个单独的进程组，然后该进程fork的所有进程都会属于该进程组，比如多进程的程序，它的所有进程都会属于同一个进程组，当在shell里面按下CTRL+C时，该程序的所有进程都会收到SIGINT而退出。</li>
</ul>
<h3 id="后台进程组"><a class="header-anchor" href="#后台进程组"></a>后台进程组</h3>
<p>shell中启动一个进程时，默认情况下，该进程就是一个前端进程组的leader，可以收到用户的输入，并且可以将输出打印到终端，只有当该进程组退出后，shell才可以再响应用户的输入。</p>
<p>但我们也可以将该进程组运行在后台，这样shell就可以继续相应用户的输入，常见的方法如下：</p>
<ul>
<li>启动程序时，在后面加<code>&amp;</code>，如<code>sleep 1000 &amp;</code>，进程将会进入后台继续运行</li>
<li>程序启动后，可以按CTRL+Z让它进入后台，和后面加<code>&amp;</code>不同的是，进程会被暂停执行</li>
</ul>
<p>对于后台运行的进程组，在shell里面体现为job的概念，即一个后台进程组就是一个job，job有如下限制：</p>
<ul>
<li>默认情况下，只要后台进程组的任何一个进程读tty，将会使整个进程组的所有进程暂停</li>
<li>默认情况下，只要后台进程组的任何一个进程写tty，将有可能会使整个进程组的所有进程暂停（依赖于tty的配置，请参考<a href="/linux-tty-pts-summary/">TTY/PTS概述</a>）</li>
</ul>
<p>所有后台运行的进程组可以通过jobs命令查看到，也可以通过fg命令将后台进程组切换到前端，这样就可以继续接收用户的输入了。这两个命令的具体用法请参考它们的帮助文件，这里只给出一个简单的例子：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#通常情况下，sleep命令会一直等待在那里，直到指定的时间过去后才退出。</span></span><br><span class="line"><span class="comment">#shell启动sleep程序时，就将sleep放到了一个新的进程组，</span></span><br><span class="line"><span class="comment">#并且该进程组为前端进程组，虽然sleep不需要输入，也没有输出，</span></span><br><span class="line"><span class="comment">#但当前session的标准输入和输出还是归它，别人用不了，</span></span><br><span class="line"><span class="comment">#只有我们按下CTRL+C使sleep进程退出后，shell自己重新变成了前端进程组，</span></span><br><span class="line"><span class="comment">#于是shell重新具备了响应输入以及输出能力</span></span><br><span class="line">dev@debian:~$ <span class="built_in">sleep</span> 1000</span><br><span class="line">^C</span><br><span class="line"></span><br><span class="line"><span class="comment">#我们可以在命令行的后面加上&amp;符号，shell还是照样会创建新的进程组，</span></span><br><span class="line"><span class="comment">#并且sleep进程就是新进程组的leader，</span></span><br><span class="line"><span class="comment">#但是shell会将sleep进程组放到后端，让它成为后台进程组</span></span><br><span class="line"><span class="comment">#这里[1]是job id，1627是进程组的ID，即sleep进程的id</span></span><br><span class="line">dev@debian:~$ <span class="built_in">sleep</span> 1000 &amp;</span><br><span class="line">[1] 1627</span><br><span class="line"></span><br><span class="line"><span class="comment">#可以通过jobs命令看到当前有哪些后台进程组（job）</span></span><br><span class="line">dev@debian:~$ <span class="built_in">jobs</span></span><br><span class="line">[1]+  Running                 <span class="built_in">sleep</span> 1000 &amp;</span><br><span class="line"></span><br><span class="line"><span class="comment">#使用fg命令带上job id，即可让后端进程组回到前端，</span></span><br><span class="line"><span class="comment">#然后我们使用CTRL+Z命令可以让它再次回到后端，并暂停进程的执行</span></span><br><span class="line"><span class="comment">#CTRL+Z和&amp;不一样的地方就是CTRL+Z会让进程暂停执行，而&amp;不会</span></span><br><span class="line">dev@debian:~$ <span class="built_in">fg</span> 1</span><br><span class="line"><span class="built_in">sleep</span> 1000</span><br><span class="line">^Z</span><br><span class="line">[1]+  Stopped                 <span class="built_in">sleep</span> 1000</span><br><span class="line"><span class="comment">#Stopped状态表示进程在后台已经暂停执行了</span></span><br><span class="line">dev@debian:~$ <span class="built_in">jobs</span></span><br><span class="line">[1]+  Stopped                 <span class="built_in">sleep</span> 1000</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="session和进程组的关系"><a class="header-anchor" href="#session和进程组的关系"></a>session和进程组的关系</h2>
<p>deamon程序虽然也是一个session的leader，但一般它不会创建新的进程组，也没有job的管理功能，所以这种情况下一个session就只有一个进程组，所有的进程都属于同样的进程组和session。</p>
<p>我们这里看一下shell作为session leader的情况，假设我们在shell里面执行了这些命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">dev@debian:~$ <span class="built_in">sleep</span> 1000 &amp;</span><br><span class="line">[1] 1646</span><br><span class="line">dev@debian:~$ <span class="built_in">cat</span> | <span class="built_in">wc</span> -l &amp;</span><br><span class="line">[2] 1648</span><br><span class="line">dev@debian:~$ <span class="built_in">jobs</span></span><br><span class="line">[1]-  Running                 <span class="built_in">sleep</span> 1000 &amp;</span><br><span class="line">[2]+  Stopped                 <span class="built_in">cat</span> | <span class="built_in">wc</span> -l</span><br></pre></td></tr></table></figure>
<p>下面这张图标明了这种情况下它们之间的关系：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">+--------------------------------------------------------------+</span><br><span class="line">|                                                              |</span><br><span class="line">|      pg1             pg2             pg3            pg4      |</span><br><span class="line">|    +------+       +-------+        +-----+        +------+   |</span><br><span class="line">|    | bash |       | sleep |        | cat |        | jobs |   |</span><br><span class="line">|    +------+       +-------+        +-----+        +------+   |</span><br><span class="line">| session leader                     | wc  |                   |</span><br><span class="line">|                                    +-----+                   |</span><br><span class="line">|                                                              |</span><br><span class="line">+--------------------------------------------------------------+</span><br><span class="line">                            session</span><br></pre></td></tr></table></figure>
<blockquote>
<p>pg = process group(进程组)</p>
</blockquote>
<ul>
<li>bash是session的leader，sleep、cat、wc和jobs这四个进程都由bash fork而来，所以他们也属于这个session</li>
<li>bash也是自己所在进程组的leader</li>
<li>bash会为自己启动的每个进程都创建一个新的进程组，所以这里sleep和jobs进程属于自己单独的进程组</li>
<li>对于用管道符号“|”连接起来的命令，bash会将它们放到一个进程组中</li>
</ul>
<h2 id="nohup"><a class="header-anchor" href="#nohup"></a>nohup</h2>
<p>nohup是咋回事呢？nohup干了这么几件事：</p>
<ul>
<li>将stdin重定向到/dev/null，于是程序读标准输入将会返回EOF</li>
<li>将stdout和stderr重定向到nohup.out或者用户通过参数指定的文件，程序所有输出到stdout和stderr的内容将会写入该文件（有时在文件中看不到输出，有可能是程序没有调用flush）</li>
<li>屏蔽掉SIGHUP信号</li>
<li>调用exec启动指定的命令（nohup进程将会被新进程取代，但进程ID不变）</li>
</ul>
<p>从上面nohup干的事可以看出，通过nohup启动的程序有这些特点：</p>
<ul>
<li>nohup程序不负责将进程放到后台，这也是为什么我们经常在nohup命令后面要加上符号“<code>&amp;</code>”的原因</li>
<li>由于stdin、stdout和stderr都被重定向了，nohup启动的程序不会读写tty</li>
<li>由于stdin重定向到了/dev/null，程序读stdin的时候会收到EOF返回值</li>
<li>nohup启动的进程本质上还是属于当前session的一个进程组，所以在当前shell里面可以通过jobs看到nohup启动的程序</li>
<li>当session leader退出后，该进程会收到SIGHUP信号，但由于nohup帮我们忽略了该信号，所以该进程不会退出</li>
<li>由于session leader已经退出，而nohup启动的进程属于该session，于是出现了一种情况，那就是通过nohup启动的这个进程组所在的session没有leader，这是一种特殊的情况，内核会帮我们处理这种特殊情况，这里就不再深入介绍</li>
</ul>
<p>通过nohup，我们最后达到了就算session leader（一般是shell）退出后，进程还可以照常运行的目的。</p>
<h2 id="deamon"><a class="header-anchor" href="#deamon"></a>deamon</h2>
<p>通过nohup，就可以实现让进程在后台一直执行的功能，为什么我们还要写deamon进程呢？</p>
<p>从上面的nohup的介绍中可以看出来，虽然进程是在后台执行，但进程跟当前session还是有着千丝万缕的关系，至少其父进程还是被session管着的，所以我们还是需要一个跟任何session都没有关系的进程来实现deamon的功能。实现deamon进程的大概步骤如下：</p>
<ul>
<li>调用fork生成一个新进程，然后原来的进程退出，这样新进程就变成了孤儿进程，于是被init进程接收，这样新进程就和调用进程没有父子关系了。</li>
<li>调用setsid，创建新的session，新进程将成为新session的leader，同时该新session不和任何tty关联。</li>
<li>切换当前工作目录到其它地方，一般是切换到根目录，这样就取消了对原工作目录的引用，如果原工作目录是某个挂载点下面的目录，这样就不会影响该挂载点的卸载。</li>
<li>关闭一些从父进程继承过来而自己不需要的fd，避免不小心读写这些fd。</li>
<li>重定向stdin、stdout和stderr，避免读写它们出现错误。</li>
</ul>
<h2 id="参考"><a class="header-anchor" href="#参考"></a>参考</h2>
<ul>
<li><a href="https://www.win.tue.nl/~aeb/linux/lk/lk-10.html">Processes</a></li>
<li><a href="https://www.gnu.org/savannah-checkouts/gnu/libc/manual/html_node/Job-Control.html">Job Control</a></li>
<li><a href="https://www.ibm.com/developerworks/cn/linux/1702_zhangym_demo/index.html">那些永不消逝的进程</a></li>
</ul>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/linux-session-and-processgroup-summary/">http://xnerv.wang/linux-session-and-processgroup-summary/</a></strong><br>
转载自：<a href="https://segmentfault.com/a/1190000009152815">(SegmentFault) Linux session和进程组概述</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Linux</tag>
        <tag>Shell</tag>
        <tag>Session</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux TTY/PTS概述（转载）</title>
    <url>/linux-tty-pts-summary/</url>
    <content><![CDATA[<p>当我们在键盘上敲下一个字母的时候，到底是怎么发送到相应的进程的呢？我们通过ps、who等命令看到的类似tty1、pts/0这样的输出，它们的作用和区别是什么呢？</p>
<span id="more"></span>
<h2 id="TTY历史"><a class="header-anchor" href="#TTY历史"></a>TTY历史</h2>
<h3 id="支持多任务的计算机出现之前"><a class="header-anchor" href="#支持多任务的计算机出现之前"></a>支持多任务的计算机出现之前</h3>
<p>在计算机出来以前，人们就已经在使用一种叫teletype的设备，用来相互之间传递信息，看起来像下面这样：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">+----------+     Physical Line     +----------+</span><br><span class="line">| teletype |&lt;---------------------&gt;| teletype |</span><br><span class="line">+----------+                       +----------+</span><br></pre></td></tr></table></figure>
<p>两个teletype之间用线连接起来，线两端可能也有类似于调制解调器之类的设备（这里将它们忽略），在一端的teletype上敲键盘时，相应的数据会发送到另一端的teletype，具体功能是干什么的，我也不太了解。(我脑袋里面想到画面是在一端敲字，另一端打印出来)</p>
<blockquote>
<p>这些都是老古董了，完全没接触过，所以只能简单的推测。</p>
</blockquote>
<h3 id="支持多任务的计算机出现之后"><a class="header-anchor" href="#支持多任务的计算机出现之后"></a>支持多任务的计算机出现之后</h3>
<p>等到计算机支持多任务后，人们想到把这些teletype连到计算机上，作为计算机的终端，从而可以操作计算机。</p>
<p>使用teletype的主要原因有两个（个人见解）：</p>
<ul>
<li>现实中已经存在了大量不同厂商的teletype，可以充分利用现有资源</li>
<li>teletype的相关网络已经比较成熟，连起来方便</li>
</ul>
<p>于是连接就发展成这样：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">                                                                      +----------+</span><br><span class="line">+----------+   +-------+     Physical Line     +-------+   +------+   |          |</span><br><span class="line">| Terminal |&lt;-&gt;| Modem |&lt;---------------------&gt;| Modem |&lt;-&gt;| UART |&lt;-&gt;| Computer |</span><br><span class="line">+----------+   +-------+                       +-------+   +------+   |          |</span><br><span class="line">                                                                      +----------+</span><br></pre></td></tr></table></figure>
<ul>
<li>左边的Terminal就是各种各样的teletype</li>
<li>物理线路两边用上了Modem，就是我们常说的“猫”，那是因为后来网络已经慢慢的变发达了，大家可以共享连接了。（大概推测，可能不对）</li>
<li>UART可以理解为将teletype的信号转换成计算机能识别的信号的设备</li>
</ul>
<h3 id="内核TTY子系统"><a class="header-anchor" href="#内核TTY子系统"></a>内核TTY子系统</h3>
<p>计算机为了支持这些teletype，于是设计了名字叫做TTY的子系统，内部结构如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">    +-----------------------------------------------+</span><br><span class="line">    |                    Kernel                     |</span><br><span class="line">    |                                 +--------+    |</span><br><span class="line">    |   +--------+   +------------+   |        |    |       +----------------+</span><br><span class="line">    |   |  UART  |   |    Line    |   |  TTY   |&lt;----------&gt;| User process A |</span><br><span class="line">&lt;------&gt;|        |&lt;-&gt;|            |&lt;-&gt;|        |    |       +----------------+</span><br><span class="line">    |   | driver |   | discipline |   | driver |&lt;----------&gt;| User process B |</span><br><span class="line">    |   +--------+   +------------+   |        |    |       +----------------+</span><br><span class="line">    |                                 +--------+    |</span><br><span class="line">    |                                               |</span><br><span class="line">    +-----------------------------------------------+</span><br></pre></td></tr></table></figure>
<ul>
<li>UART driver对接外面的UART设备</li>
<li>Line discipline主要是对输入和输出做一些处理，可以理解它是TTY driver的一部分</li>
<li>TTY driver用来处理各种终端设备</li>
<li>用户空间的进程通过TTY driver来和终端打交道</li>
</ul>
<blockquote>
<p>为了简单起见，后面的介绍中不再单独列出UART driver和Line discipline，可以认为它们是TTY driver的一部分</p>
</blockquote>
<h3 id="TTY设备"><a class="header-anchor" href="#TTY设备"></a>TTY设备</h3>
<p>对于每一个终端，TTY driver都会创建一个TTY设备与它对应，如果有多个终端连接过来，那么看起来就是这个样子的：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">                     +----------------+</span><br><span class="line">                     |   TTY Driver   |</span><br><span class="line">                     |                |</span><br><span class="line">                     |   +-------+    |       +----------------+</span><br><span class="line">+------------+       |   |       |&lt;----------&gt;| User process A |</span><br><span class="line">| Terminal A |&lt;---------&gt;| ttyS0 |    |       +----------------+</span><br><span class="line">+------------+       |   |       |&lt;----------&gt;| User process B |</span><br><span class="line">                     |   +-------+    |       +----------------+</span><br><span class="line">                     |                |</span><br><span class="line">                     |   +-------+    |       +----------------+</span><br><span class="line">+------------+       |   |       |&lt;----------&gt;| User process C |</span><br><span class="line">| Terminal B |&lt;---------&gt;| ttyS1 |    |       +----------------+</span><br><span class="line">+------------+       |   |       |&lt;----------&gt;| User process D |</span><br><span class="line">                     |   +-------+    |       +----------------+</span><br><span class="line">                     |                |</span><br><span class="line">                     +----------------+</span><br></pre></td></tr></table></figure>
<p>当驱动收到一个终端的连接时，就会根据终端的型号和参数创建相应的tty设备（上图中设备名称叫ttyS0是因为大部分终端的连接都是串行连接），由于每个终端可能都不一样，有自己的特殊命令和使用习惯，于是每个tty设备的配置可能都不一样。比如按delete键的时候，有些可能是要删前面的字符，而有些可能是删后面的，如果没配置对，就会导致某些按键不是自己想要的行为，这也是我们在使用模拟终端时，如果默认的配置跟我们的习惯不符，需要做一些个性化配置的原因。</p>
<p>后来随着计算机的不断发展，teletype这些设备逐渐消失，我们不再需要专门的终端设备了，每个机器都有自己的键盘和显示器，每台机器都可以是其它机器的终端，远程的操作通过ssh来实现，但是内核TTY驱动这一架构没有发生变化，我们想要和系统中的进程进行I/O交互，还是需要通过TTY设备，于是出现了各种终端模拟软件，并且模拟的也是常见的几种终端，如VT100、VT220、XTerm等。</p>
<blockquote>
<ol>
<li>可以通过命令<code>toe -a</code>列出系统支持的所有终端类型</li>
<li>可以通过命令infocmp来比较两个终端的区别，比如<code>infocmp vt100 vt220</code>将会输出vt100和vt220的区别。</li>
</ol>
</blockquote>
<h2 id="程序如何和TTY打交道"><a class="header-anchor" href="#程序如何和TTY打交道"></a>程序如何和TTY打交道</h2>
<p>在讨论TTY设备是如何被创建及配置之前，我们先来看看TTY是如何被进程使用的：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#先用tty命令看看当前bash关联到了哪个tty</span></span><br><span class="line">dev@debian:~$ <span class="built_in">tty</span></span><br><span class="line">/dev/pts/1</span><br><span class="line"></span><br><span class="line"><span class="comment">#看tty都被哪些进程打开了</span></span><br><span class="line">dev@debian:~$ lsof /dev/pts/1</span><br><span class="line">COMMAND  PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME</span><br><span class="line">bash     907  dev    0u   CHR  136,1      0t0    4 /dev/pts/1</span><br><span class="line">bash     907  dev    1u   CHR  136,1      0t0    4 /dev/pts/1</span><br><span class="line">bash     907  dev    2u   CHR  136,1      0t0    4 /dev/pts/1</span><br><span class="line">bash     907  dev  255u   CHR  136,1      0t0    4 /dev/pts/1</span><br><span class="line">lsof    1118  dev    0u   CHR  136,1      0t0    4 /dev/pts/1</span><br><span class="line">lsof    1118  dev    1u   CHR  136,1      0t0    4 /dev/pts/1</span><br><span class="line">lsof    1118  dev    2u   CHR  136,1      0t0    4 /dev/pts/1</span><br><span class="line"></span><br><span class="line"><span class="comment">#往tty里面直接写数据跟写标准输出是一样的效果</span></span><br><span class="line">dev@dev:~$ <span class="built_in">echo</span> aaa &gt; /dev/pts/2</span><br><span class="line">aaa</span><br></pre></td></tr></table></figure>
<blockquote>
<p>pts也是tty设备，它们的关系后面会介绍到</p>
</blockquote>
<p>通过上面的lsof可以看出，当前运行的bash和lsof进程的stdin(0u)、stdout(1u)、stderr(2u)都绑定到了这个TTY上。</p>
<p>下面是tty和进程以及I/O设备交互的结构图：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">   Input    +--------------------------+    R/W     +------+</span><br><span class="line">-----------&gt;|                          |&lt;----------&gt;| bash |</span><br><span class="line">            |          pts/1           |            +------+</span><br><span class="line">&lt;-----------|                          |&lt;----------&gt;| lsof |</span><br><span class="line">   Output   | Foreground process group |    R/W     +------+</span><br><span class="line">            +--------------------------+</span><br></pre></td></tr></table></figure>
<ul>
<li>可以把tty理解成一个管道（pipe），在一端写的内容可以从另一端读取出来，反之亦然。</li>
<li>这里input和output可以简单的理解为键盘和显示器，后面会介绍在各种情况下input/ouput都连接的什么东西。</li>
<li>tty里面有一个很重要的属性，叫Foreground process group，记录了当前前端的进程组是哪一个。process group的概念会在下一篇文章中介绍，这里可以简单的认为process group里面只有一个进程。</li>
<li>当pts/1收到input的输入后，会检查当前前端进程组是哪一个，然后将输入放到进程组的leader的输入缓存中，这样相应的leader进程就可以通过read函数得到用户的输入</li>
<li>当前端进程组里面的进程往tty设备上写数据时，tty就会将数据输出到output设备上</li>
<li>当在shell中执行不同的命令时，前端进程组在不断的变化，而这种变化会由shell负责更新到tty设备中</li>
</ul>
<p>从上面可以看出，进程和tty打交道很简单，只要保证后台进程不要读写tty就可以了，即写后台程序时，要将stdin/stdout/stderr重定向到其它地方（当然deamon程序还需要做很多其它处理）。</p>
<p>先抛出两个问题(后面有答案)：</p>
<ul>
<li>当非前端进程组里面的进程（后台进程）往tty设备上写数据时，会发生什么？会输出到outpu上吗？</li>
<li>当非前端进程组里面的进程（后台进程）从tty设备上读数据时，会发生什么？进程会阻塞吗？</li>
</ul>
<h2 id="TTY是如何被创建的"><a class="header-anchor" href="#TTY是如何被创建的"></a>TTY是如何被创建的</h2>
<p>下面介绍几种常见的情况下tty设备是如何创建的，以及input和output设备都是啥。</p>
<h3 id="键盘显示器直连（终端）"><a class="header-anchor" href="#键盘显示器直连（终端）"></a>键盘显示器直连（终端）</h3>
<p>先看图再说话：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">                  +-----------------------------------------+</span><br><span class="line">                  |          Kernel                         |</span><br><span class="line">                  |                           +--------+    |       +----------------+</span><br><span class="line">+----------+      |   +-------------------+   |  tty1  |&lt;----------&gt;| User processes |</span><br><span class="line">| Keyboard |---------&gt;|                   |   +--------+    |       +----------------+</span><br><span class="line">+----------+      |   | Terminal Emulator |&lt;-&gt;|  tty2  |&lt;----------&gt;| User processes |</span><br><span class="line">| Monitor  |&lt;---------|                   |   +--------+    |       +----------------+</span><br><span class="line">+----------+      |   +-------------------+   |  tty3  |&lt;----------&gt;| User processes |</span><br><span class="line">                  |                           +--------+    |       +----------------+</span><br><span class="line">                  |                                         |</span><br><span class="line">                  +-----------------------------------------+</span><br></pre></td></tr></table></figure>
<p>键盘、显示器都和内核中的终端模拟器相连，由模拟器决定创建多少tty，比如你在键盘上输入ctrl+alt+F1时，模拟器首先捕获到该输入，然后激活tty1，这样键盘的输入会转发到tty1，而tty1的输出会转发到显示器，同理用输入ctrl+alt+F2，就会切换到tty2。</p>
<p>当模拟器激活tty时如果发现没有进程与之关联，意味着这是第一次打开该tty，于是会启动配置好的进程并和该tty绑定，一般该进程就是负责login的进程。</p>
<p>当切换到tty2后，tty1里面的输出会输出到哪里呢？tty1的输出还是会输出给模拟器，模拟器里会有每个tty的缓存，不过由于模拟器的缓存空间有限，所以下次切回tty1的时候，只能看到最新的输出，以前的输出已经不在了。</p>
<blockquote>
<p>不确定这里的终端模拟器对应内核中具体的哪个模块，但肯定有这么个东西存在</p>
</blockquote>
<h3 id="SSH远程访问"><a class="header-anchor" href="#SSH远程访问"></a>SSH远程访问</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">+----------+       +------------+</span><br><span class="line">| Keyboard |------&gt;|            |</span><br><span class="line">+----------+       |  Terminal  |</span><br><span class="line">| Monitor  |&lt;------|            |</span><br><span class="line">+----------+       +------------+</span><br><span class="line">                         |</span><br><span class="line">                         |  ssh protocol</span><br><span class="line">                         |</span><br><span class="line">                         ↓</span><br><span class="line">                   +------------+</span><br><span class="line">                   |            |</span><br><span class="line">                   | ssh server |--------------------------+</span><br><span class="line">                   |            |           fork           |</span><br><span class="line">                   +------------+                          |</span><br><span class="line">                       |   ↑                               |</span><br><span class="line">                       |   |                               |</span><br><span class="line">                 write |   | read                          |</span><br><span class="line">                       |   |                               |</span><br><span class="line">                 +-----|---|-------------------+           |</span><br><span class="line">                 |     |   |                   |           ↓</span><br><span class="line">                 |     ↓   |      +-------+    |       +-------+</span><br><span class="line">                 |   +--------+   | pts/0 |&lt;----------&gt;| shell |</span><br><span class="line">                 |   |        |   +-------+    |       +-------+</span><br><span class="line">                 |   |  ptmx  |&lt;-&gt;| pts/1 |&lt;----------&gt;| shell |</span><br><span class="line">                 |   |        |   +-------+    |       +-------+</span><br><span class="line">                 |   +--------+   | pts/2 |&lt;----------&gt;| shell |</span><br><span class="line">                 |                +-------+    |       +-------+</span><br><span class="line">                 |    Kernel                   |</span><br><span class="line">                 +-----------------------------+</span><br></pre></td></tr></table></figure>
<p>这里的Terminal可能是任何地方的程序，比如windows上的putty，所以不讨论客户端的Terminal程序是怎么和键盘、显示器交互的。由于Terminal要和ssh服务器打交道，所以肯定要实现ssh的客户端功能。</p>
<p>这里将建立连接和收发数据分两条线路解释，为了描述简洁，这里以sshd代替ssh服务器程序：</p>
<h4 id="建立连接"><a class="header-anchor" href="#建立连接"></a>建立连接</h4>
<ul>
<li>
<ol>
<li>Terminal请求和sshd建立连接</li>
</ol>
</li>
<li>
<ol start="2">
<li>如果验证通过，sshd将创建一个新的session</li>
</ol>
</li>
<li>
<ol start="3">
<li>调用API（posix_openpt()）请求ptmx创建一个pts，创建成功后，sshd将得到和ptmx关联的fd，并将该fd和session关联起来。</li>
</ol>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#pty（pseudo terminal device）由两部分构成，ptmx是master端，pts是slave端，</span><br><span class="line">#进程可以通过调用API请求ptmx创建一个pts，然后将会得到连接到ptmx的读写fd和一个新创建的pts，</span><br><span class="line">#ptmx在内部会维护该fd和pts的对应关系，随后往这个fd的读写会被ptmx转发到对应的pts。</span><br><span class="line"></span><br><span class="line">#这里可以看到sshd已经打开了/dev/ptmx</span><br><span class="line">dev@debian:~$ sudo lsof /dev/ptmx</span><br><span class="line">COMMAND  PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME</span><br><span class="line">sshd    1191  dev    8u   CHR    5,2      0t0 6531 /dev/ptmx</span><br><span class="line">sshd    1191  dev   10u   CHR    5,2      0t0 6531 /dev/ptmx</span><br><span class="line">sshd    1191  dev   11u   CHR    5,2      0t0 6531 /dev/ptmx</span><br></pre></td></tr></table></figure>
<ul>
<li>
<ol start="4">
<li>同时sshd创建shell进程，将新创建的pts和shell绑定</li>
</ol>
</li>
</ul>
<h4 id="收发消息"><a class="header-anchor" href="#收发消息"></a>收发消息</h4>
<ul>
<li>
<ol>
<li>Terminal收到键盘的输入，Terminal通过ssh协议将数据发往sshd</li>
</ol>
</li>
<li>
<ol start="2">
<li>sshd收到客户端的数据后，根据它自己管理的session，找到该客户端对应的关联到ptmx上的fd</li>
</ol>
</li>
<li>
<ol start="3">
<li>往找到的fd上写入客户端发过来的数据</li>
</ol>
</li>
<li>
<ol start="4">
<li>ptmx收到数据后，根据fd找到对应的pts（该对应关系由ptmx自动维护），将数据包转发给对应的pts</li>
</ol>
</li>
<li>
<ol start="5">
<li>pts收到数据包后，检查绑定到自己上面的当前前端进程组，将数据包发给该进程组的leader</li>
</ol>
</li>
<li>
<ol start="6">
<li>由于pts上只有shell，所以shell的read函数就收到了该数据包</li>
</ol>
</li>
<li>
<ol start="7">
<li>shell对收到的数据包进行处理，然后输出处理结果（也可能没有输出）</li>
</ol>
</li>
<li>
<ol start="8">
<li>shell通过write函数将结果写入pts</li>
</ol>
</li>
<li>
<ol start="9">
<li>pts将结果转发给ptmx</li>
</ol>
</li>
<li>
<ol start="10">
<li>ptmx根据pts找到对应的fd，往该fd写入结果</li>
</ol>
</li>
<li>
<ol start="11">
<li>sshd收到该fd的结果后，找到对应的session，然后将结果发给对应的客户端</li>
</ol>
</li>
</ul>
<h3 id="键盘显示器直连（图形界面）"><a class="header-anchor" href="#键盘显示器直连（图形界面）"></a>键盘显示器直连（图形界面）</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">+----------+       +------------+</span><br><span class="line">| Keyboard |------&gt;|            |</span><br><span class="line">+----------+       |  Terminal  |--------------------------+</span><br><span class="line">| Monitor  |&lt;------|            |           fork           |</span><br><span class="line">+----------+       +------------+                          |</span><br><span class="line">                       |   ↑                               |</span><br><span class="line">                       |   |                               |</span><br><span class="line">                 write |   | read                          |</span><br><span class="line">                       |   |                               |</span><br><span class="line">                 +-----|---|-------------------+           |</span><br><span class="line">                 |     |   |                   |           ↓</span><br><span class="line">                 |     ↓   |      +-------+    |       +-------+</span><br><span class="line">                 |   +--------+   | pts/0 |&lt;----------&gt;| shell |</span><br><span class="line">                 |   |        |   +-------+    |       +-------+</span><br><span class="line">                 |   |  ptmx  |&lt;-&gt;| pts/1 |&lt;----------&gt;| shell |</span><br><span class="line">                 |   |        |   +-------+    |       +-------+</span><br><span class="line">                 |   +--------+   | pts/2 |&lt;----------&gt;| shell |</span><br><span class="line">                 |                +-------+    |       +-------+</span><br><span class="line">                 |    Kernel                   |</span><br><span class="line">                 +-----------------------------+</span><br></pre></td></tr></table></figure>
<blockquote>
<p>为了简化起见，本篇不讨论Linux下图形界面里Terminal程序是怎么和键盘、显示器交互的。</p>
</blockquote>
<p>这里和上面的不同点就是，这里的Terminal不需要实现ssh客户端，但需要把ssh服务器要干的活也干了（当然ssh通信相关的除外）。</p>
<h3 id="SSH-Screen-Tmux"><a class="header-anchor" href="#SSH-Screen-Tmux"></a>SSH + Screen/Tmux</h3>
<p>常用Linux的同学应该对screen和tmux不陌生，通过它们启动的进程，就算网络断开了，也不会受到影响继续执行，下次连上去时还能看到进程的所有输出，还能继续接着干活。</p>
<p>这里以tmux为例介绍其原理：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">+----------+       +------------+</span><br><span class="line">| Keyboard |------&gt;|            |</span><br><span class="line">+----------+       |  Terminal  |</span><br><span class="line">| Monitor  |&lt;------|            |</span><br><span class="line">+----------+       +------------+</span><br><span class="line">                         |</span><br><span class="line">                         |  ssh protocol</span><br><span class="line">                         |</span><br><span class="line">                         ↓</span><br><span class="line">                   +------------+</span><br><span class="line">                   |            |</span><br><span class="line">                   | ssh server |--------------------------+</span><br><span class="line">                   |            |           fork           |</span><br><span class="line">                   +------------+                          |</span><br><span class="line">                       |   ↑                               |</span><br><span class="line">                       |   |                               |</span><br><span class="line">                 write |   | read                          |</span><br><span class="line">                       |   |                               |</span><br><span class="line">                 +-----|---|-------------------+           |</span><br><span class="line">                 |     ↓   |                   |           ↓</span><br><span class="line">                 |   +--------+   +-------+    |       +-------+  fork   +-------------+</span><br><span class="line">                 |   |  ptmx  |&lt;-&gt;| pts/0 |&lt;----------&gt;| shell |--------&gt;| tmux client |</span><br><span class="line">                 |   +--------+   +-------+    |       +-------+         +-------------+</span><br><span class="line">                 |   |        |                |                               ↑</span><br><span class="line">                 |   +--------+   +-------+    |       +-------+               |</span><br><span class="line">                 |   |  ptmx  |&lt;-&gt;| pts/2 |&lt;----------&gt;| shell |               |</span><br><span class="line">                 |   +--------+   +-------+    |       +-------+               |</span><br><span class="line">                 |     ↑   |  Kernel           |           ↑                   |</span><br><span class="line">                 +-----|---|-------------------+           |                   |</span><br><span class="line">                       |   |                               |                   |</span><br><span class="line">                       |w/r|   +---------------------------+                   |</span><br><span class="line">                       |   |   |            fork                               |</span><br><span class="line">                       |   ↓   |                                               |</span><br><span class="line">                   +-------------+                                             |</span><br><span class="line">                   |             |                                             |</span><br><span class="line">                   | tmux server |&lt;--------------------------------------------+</span><br><span class="line">                   |             |</span><br><span class="line">                   +-------------+</span><br></pre></td></tr></table></figure>
<blockquote>
<p>系统中的ptmx只有一个，上图中画出来了两个，目的是为了表明tmux服务器和sshd都用ptmx，但它们之间又互不干涉。</p>
</blockquote>
<p>这种情况要稍微复杂一点，不过原理都是一样的，前半部分和普通ssh的方式是一样的，只是pts/0关联的前端进程不是shell了，而是变成了tmux客户端，所以ssh客户端发过来的数据包都会被tmux客户端收到，然后由tmux客户端转发给tmux服务器，而tmux服务器干的活和ssh的类似，也是维护一堆的session，为每个session创建一个pts，然后将tmux客户端发过来的数据转发给相应的pts。</p>
<p>由于tmux服务器只和tmux客户端打交道，和sshd没有关系，当终端和sshd的连接断开时，虽然pts/0会被关闭，和它相关的shell和tmux客户端也将被kill掉，但不会影响tmux服务器，当下次再用tmux客户端连上tmux服务器时，看到的还是上次的内容。</p>
<h2 id="TTY和PTS的区别"><a class="header-anchor" href="#TTY和PTS的区别"></a>TTY和PTS的区别</h2>
<p>从上面的流程中应该可以看出来了，对用户空间的程序来说，他们没有区别，都是一样的；从内核里面来看，pts的另一端连接的是ptmx，而tty的另一端连接的是内核的终端模拟器，ptmx和终端模拟器都只是负责维护会话和转发数据包；再看看ptmx和内核终端模拟器的另一端，ptmx的另一端连接的是用户空间的应用程序，如sshd、tmux等，而内核终端模拟器的另一端连接的是具体的硬件，如键盘和显示器。</p>
<h2 id="常见的TTY配置"><a class="header-anchor" href="#常见的TTY配置"></a>常见的TTY配置</h2>
<p>先先来看看当前tty的所有配置：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dev@dev:~$ stty -a</span><br><span class="line">speed 38400 baud; rows 51; columns 204; line = 0;</span><br><span class="line">intr = ^C; quit = ^\; erase = ^?; kill = ^U; eof = ^D; eol = M-^?; eol2 = M-^?; swtch = &lt;undef&gt;; start = ^Q; stop = ^S; susp = ^Z; rprnt = ^R; werase = ^W; lnext = ^V; discard = ^O; min = 1; time = 0;</span><br><span class="line">-parenb -parodd -cmspar cs8 -hupcl -cstopb cread -clocal -crtscts</span><br><span class="line">-ignbrk -brkint -ignpar -parmrk -inpck -istrip -inlcr -igncr icrnl ixon -ixoff -iuclc ixany imaxbel -iutf8</span><br><span class="line">opost -olcuc -ocrnl onlcr -onocr -onlret -ofill -ofdel nl0 cr0 tab0 bs0 vt0 ff0</span><br><span class="line">isig icanon iexten echo echoe echok -echonl -noflsh -xcase -tostop -echoprt echoctl echoke -flusho -extproc</span><br></pre></td></tr></table></figure>
<blockquote>
<p>stty还可以用来修改tty的参数，用法请参考<code>man stty</code></p>
</blockquote>
<p>只要是有权限的程序，都可以通过Linux提供的API来修改TTY的配置，下面介绍一些常见的的配置项。</p>
<h4 id="rows-51-columns-204"><a class="header-anchor" href="#rows-51-columns-204"></a>rows 51; columns 204;</h4>
<p>这个配置一般由终端控制，当终端的窗口大小发生变化时，需要通过一定的手段修改该配置，比如ssh协议里面就有修改窗口大小的参数，sshd收到客户端的请求后，会通过API修改tty的这个参数，然后由tty通过信号SIGWINCH通知前端程序（比如shell或者vim），前端程序收到信号后，再去读tty的这个参数，然后就知道如何调整自己的输出排版了。</p>
<h4 id="intr-C"><a class="header-anchor" href="#intr-C"></a>intr = ^C</h4>
<p>tty除了在终端和前端进程之间转发数据之外，还支持很多控制命令，比如终端输入了CTRL+C，那么tty不会将该输入串转发给前端进程，而是将它转换成信号SIGINT发送给前端进程。这个就是用来配置控制命令对应的输入组合的，比如我们可以配置“intr = ^E”表示用CTRL+E代替CTRL+C。</p>
<h4 id="start-Q-stop-S"><a class="header-anchor" href="#start-Q-stop-S"></a>start = ^Q; stop = ^S;</h4>
<p>这是两个特殊的控制命令，估计经常有人会碰到，在键盘上不小心输入CTRL+S后，终端没反应了，即没输出，也不响应任何输入。这是因为这个命令会告诉TTY暂停，阻塞所有读写操作，即不转发任何数据，只有按了CTRL+Q后，才会继续。这个功能应该是历史遗留，以前终端和服务器之间没有流量控制功能，所以有可能服务器发送数据过快，导致终端处理不过来，于是需要这样一个命令告诉服务器不要再发了，等终端处理完了后在通知服务器继续。</p>
<p>该命令现在比较常用的一个场景就是用<code>tail -f</code>命令监控日志文件的内容时，可以随时按CTRL+S让屏幕停止刷新，看完后再按CTRL+Q让它继续刷，如果不这样的话，需要先CTRL+C退出，看完后在重新运行<code>tail -f</code>命令。</p>
<h4 id="echo"><a class="header-anchor" href="#echo"></a>echo</h4>
<p>在终端输入字符的时候，之所以我们能及时看到我们输入的字符，那是因为TTY在收到终端发过去的字符后，会先将字符原路返回一份，然后才交给前端进程处理，这样终端就能及时的显示输入的字符。echo就是用来控制该功能的配置项，如果是-echo的话表示disable echo功能。</p>
<h4 id="tostop"><a class="header-anchor" href="#tostop"></a>-tostop</h4>
<p>如果你在shell中运行程序的时候，后面添加了<code>&amp;</code>，比如<code>./myapp &amp;</code>，这样myapp这个进程就会在后台运行，但如果这个进程继续往tty上写数据呢？这个参数就用来控制是否将输出转发给终端，也即结果会不会在终端显示，这里“-tostop”表示会输出到终端，如果配置为“tostop”的话，将不输出到终端，并且tty会发送信号SIGTTOU给myapp，该信号的默认行为是将暂停myapp的执行。</p>
<h2 id="TTY相关信号"><a class="header-anchor" href="#TTY相关信号"></a>TTY相关信号</h2>
<p>除了上面介绍配置时提到的SIGINT，SIGTTOU，SIGWINCHU外，还有这么几个跟TTY相关的信号</p>
<h4 id="SIGTTIN"><a class="header-anchor" href="#SIGTTIN"></a>SIGTTIN</h4>
<p>当后台进程读tty时，tty将发送该信号给相应的进程组，默认行为是暂停进程组中进程的执行。暂停的进程如何继续执行呢？请参考下一篇文章中的SIGCONT。</p>
<h4 id="SIGHUP"><a class="header-anchor" href="#SIGHUP"></a>SIGHUP</h4>
<p>当tty的另一端挂掉的时候，比如ssh的session断开了，于是sshd关闭了和ptmx关联的fd，内核将会给和该tty相关的所有进程发送SIGHUP信号，进程收到该信号后的默认行为是退出进程。</p>
<h4 id="SIGTSTP"><a class="header-anchor" href="#SIGTSTP"></a>SIGTSTP</h4>
<p>终端输入CTRL+Z时，tty收到后就会发送SIGTSTP给前端进程组，其默认行为是将前端进程组放到后端，并且暂停进程组里所有进程的执行。</p>
<blockquote>
<p>跟tty相关的信号都是可以捕获的，可以修改它的默认行为</p>
</blockquote>
<h2 id="结束语"><a class="header-anchor" href="#结束语"></a>结束语</h2>
<p>本文介绍了常见的tty功能和特点，下一篇中将详细介绍和tty密切相关的进程session id，进程组，job，后台程序等，敬请期待。</p>
<h2 id="参考"><a class="header-anchor" href="#参考"></a>参考</h2>
<ul>
<li><a href="http://www.linusakesson.net/programming/tty/index.php">The TTY demystified</a></li>
</ul>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/linux-tty-pts-summary/">http://xnerv.wang/linux-tty-pts-summary/</a></strong><br>
转载自：<a href="https://segmentfault.com/a/1190000009082089">(SegmentFault) Linux TTY/PTS概述</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Linux</tag>
        <tag>Shell</tag>
        <tag>TTY</tag>
        <tag>PTS</tag>
      </tags>
  </entry>
  <entry>
    <title>关于Linux X-Window的一些名词深究</title>
    <url>/linux-xwindow-investigation/</url>
    <content><![CDATA[<p>一直以来对X-Window、Xrdp、KDE、VNC等词半懂不懂，因此大致地调查了下。这篇文章包括了一些我自己的总结，因此可能有一些地方有不准确之处，敬请谅解。参考了<a href="http://cn.linux.vbird.org/linux_basic/0590xwindow_1.php">http://cn.linux.vbird.org/linux_basic/0590xwindow_1.php</a>。</p>
<p><strong>X-Window/X Protocol</strong>：在<a href="https://jin-yang.github.io/post/linux-xwindows-introduce.html">XWindow 简介</a>中有比较好的解释，这其实是一套图形接口（协议）。不同于Windows已经将图形接口与操作系统完全融为一体的做法，Linux的图形接口是可选的。而X-Window就是这样的一种图形接口。这个图形接口是属于CS架构的（client/server）。X Server负责画面的绘制和显示，以及接收用户的输入并传到给X Client。X Client负责处理传递过来的用户输入并决定呈现数据，然后由X Server来进行绘制。这与通常的对于CS架构的理解是相反的，与用户直接沟通的其实是X Server。</p>
<p>X-Window是一种协议，因此还需要具体的实现，例如Xfree86、Xorg，Xming和Xnest。</p>
<p><strong>X11R6</strong>：X Protocol version 11 Release 6（X协议第11版第六次发行）。</p>
<span id="more"></span>
<p><strong>Window Manager（WM）</strong>：个人看法，每一个窗口程序可能就对应一个（或多个？）X Client，而WM就是管理这些窗口移动、窗口大小和重叠显示的管理程序，常见的WM有GNOME、KDE、XFCE。</p>
<p><strong>远程桌面</strong>：当你从另一台电脑上（主要是Windows）上想要通过图形化界面操作远程Linux时需要用到。常见的图形化远程桌面连接协议是RDP和VNC。Windows远程桌面用的就是RDP。RDP和VNC的区别可以参考<a href="https://blog.csdn.net/Cheese_pop/article/details/102958997">VNC与RDP的区别</a>。VNC主要传图像，适用于瘦客户端。RDP主要传指令，适用于低速网络。此外微软还有一项针对RDP的增强技术RemoteFX。</p>
<p>常见的VNC服务器软件有vnc4server、TightVNC，RealVNC等。</p>
<p>常见的VNC客户端有RealVNC Viewer、Ultra VNC等。</p>
<p>而如果你想用Windows自带的远程桌面连接Linux机器时，就必须用RDP协议了。需要在Linux上装兼容RDP的服务器，例如<a href="https://wiki.archlinux.org/index.php/Xrdp">Xrdp</a>。Xrdp使用Xvnc，X11rdp或xorgxrdp作为后端（<a href="https://blog.csdn.net/Robinsone/article/details/46686531">XRDP与VNC的关系</a>）。如果在Windows Hyper-V中安装Ubuntu等，在登录的时候就需要从几个选项中选择一个后端。根据<a href="https://www.linuxquestions.org/questions/ubuntu-63/what-is-x11rdp-4175556435/">What is x11rdp?</a>和<a href="https://tigervnc.org/doc/Xvnc.html">Xvnc</a>中所提到的，X11rdp和Xvnc都属于X Server，用于显示“虚拟屏幕”，而不是物理屏幕。而<a href="https://wiki.archlinux.org/index.php/Xorg">Xorg</a>中证实了Xorg是X-Window的一种实现，那感觉Xorg和Xvnc等并不是同一个层面上的概念，Xorg包括了X Server和X Client，而Xvnc只是X Server的一种实现。同时Xvnc对于用户而言又是VNC Server。</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/linux-xwindow-investigation/">http://xnerv.wang/linux-xwindow-investigation/</a></strong></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>Linux</tag>
        <tag>图形界面</tag>
        <tag>X-Window</tag>
        <tag>X协议</tag>
        <tag>远程桌面</tag>
      </tags>
  </entry>
  <entry>
    <title>Lock Escalations（转载）</title>
    <url>/lock-escalations/</url>
    <content><![CDATA[<p>In todays blog posting I want to talk about <strong>Lock Escalations</strong> in SQL Server. Lock Escalations are an optimization technique used by SQL Server to control the amount of locks that are held within the Lock Manager of SQL Server. Let’s start in the first step with the description of the so-called <strong>Lock Hierarchy</strong> in SQL Server, because that’s the reason why the concept of the Lock Escalations exists in a relational database like SQL Server.</p>
<h3 id="Lock-Hierarchy"><a class="header-anchor" href="#Lock-Hierarchy"></a>Lock Hierarchy</h3>
<p>The following picture shows you the lock hierarchy used by SQL Server:</p>
<p><img src="http://www.sqlpassion.at/wp-content/uploads/2014/02/LockHierarchy.png" alt="Lock Hierarchy in SQL Server" title="Lock Hierarchy in SQL Server"></p>
<span id="more"></span>
<p>As you can see from the picture, the lock hierarchy starts at the database level, and goes down to the row level. You always have a Shared Lock (S) on the database level itself. When your query is connected to a database (e.g. <strong>USE MyDatabase</strong>), the Shared Lock prevents the dropping of the database, or that backups are restored over that database. And underneath the database level, you have locks on the table, on the pages, and the records when you are performing an operation.</p>
<p>When you are executing a <strong>SELECT</strong> statement, you have an Intent Shared Lock (IS) on the table and page level, and a Shared Lock (S) on the record itself. When you are performing a data modification statement (<strong>INSERT</strong>, <strong>UPDATE</strong>, <strong>DELETE</strong>), you have an Intent Exclusive or Update Lock (IX or IU) on the table and page level, and a Exclusive or Update Lock (X or U) on the changed records. SQL Server always acquires locks from top to bottom to prevent so-called <a href="http://en.wikipedia.org/wiki/Race_condition">Race Conditions</a>, when multiple threads trying to acquire locks concurrently within the locking hierarchy. Imagine now how the lock hierarchy would look like, when you perform a <strong>DELETE</strong> operation on a table against 20.000 rows. Let’s assume that a row is 400 bytes long, means that 20 records fit onto one page of 8kb:</p>
<p><img src="http://www.sqlpassion.at/wp-content/uploads/2014/02/WithoutLockEscalation.png" alt="Without Lock Escalation" title="Without Lock Escalation"></p>
<p>You have one S Lock on the database, 1 IX Lock on the table, 1.000 IX locks on the pages (20.000 records are spread across 1.000 pages), and you have finally 20.000 X locks on the records itself. In sum you have acquired 21.002 locks for the <strong>DELETE</strong> operation. Every lock needs in SQL Server 96 bytes of memory, so we look at 1.9 MB of locks just for 1 simple query. This will not scale indefinitely when you run multiple queries in parallel. For that reason SQL Server implements now the so-called <strong>Lock Escalation</strong>.</p>
<h3 id="Lock-Escalations"><a class="header-anchor" href="#Lock-Escalations"></a>Lock Escalations</h3>
<p>As soon as you have more than 5.000 locks on one level in your locking hierarchy, SQL Server escalates these many fine-granularity locks into a simple coarse-granularity lock. By default SQL Server <em><strong>always</strong></em> escalates to the table level. This mean that your locking hierarchy from the previous example looks like the following after the Lock Escalation has been successfully performed.</p>
<p><img src="http://www.sqlpassion.at/wp-content/uploads/2014/02/WithLockEscalation1.png" alt="With Lock Escalation" title="With Lock Escalation"></p>
<p>As you can see, you have only one big lock on the table itself. In the case of the <strong>DELETE</strong> operation, you have one Exclusive Lock (X) on the table level. This will hurt the concurrency of your database in a very negative way! Holding an Exclusive Lock on the table level means that no other session is able anymore to access that table – every other query will just block. When you are running your <strong>SELECT</strong> statement in the Repeatable Read Isolation Level, you are also holding your Shared Locks till the end of the transaction, means you will have a Lock Escalation as soon as you have read more than 5.000 rows. The result is here one Shared Lock on the table itself! Your table is temporary readonly, because every other data modification on that table will be blocked!</p>
<p>There is also a misconception that SQL Server will escalate from the row level to the page level, and finally to the table level. Wrong! Such a code path doesn’t exist in SQL Server! SQL Server will by default <em><strong>always</strong></em> escalate directly to the table level. An escalation policy to the page level just doesn’t exist. If you have your table partitioned (Enterprise Edition only!), then you can configure an escalation to the partition level. But you have to test here very carefully your data access pattern, because a Lock Escalation to the partition level can cause a deadlock. Therefore this option is also not enabled by default.</p>
<p>Since SQL Server 2008 you can also control how SQL Server performs the Lock Escalation – through the <strong>ALTER TABLE</strong> statement and the property <strong>LOCK_ESCALATION</strong>. There are 3 different options available:</p>
<ul>
<li>TABLE</li>
<li>AUTO</li>
<li>DISABLE</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- Controllling Lock Escalation</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> Person.Person</span><br><span class="line"><span class="keyword">SET</span></span><br><span class="line">(</span><br><span class="line">	LOCK_ESCALATION <span class="operator">=</span> AUTO <span class="comment">-- or TABLE or DISABLE</span></span><br><span class="line">)</span><br><span class="line">GO</span><br></pre></td></tr></table></figure>
<p>The default option is <strong>TABLE</strong>, means that SQL Server <em><strong>always</strong></em> performs the Lock Escalation to the table level – even when the table is partitioned. If you have your table partitioned, and you want to have a Partition Level Lock Escalation (because you have tested your data access pattern, and you don’t cause deadlocks with it), then you can change the option to <strong>AUTO</strong>. <strong>AUTO</strong> means that the Lock Escalation is performed to the partition level, if the table is partitioned, and otherwise to the table level. And with the option <strong>DISABLE</strong> you can completely disable the Lock Escalation for that specific table. But disabling Lock Escalations is not the very best option, because the Lock Manager of SQL Server can then consume a huge amount of memory, if you are not very carefully with your queries and your indexing strategy.</p>
<h3 id="Conclusion"><a class="header-anchor" href="#Conclusion"></a>Conclusion</h3>
<p>Lock Escalation in SQL Server is mainly a nightmare. How will you delete more than 5.000 rows from a table without running into Lock Escalations? You can disable Lock Escalation temporarily, but you have to be very careful here. Another option (that I’m suggesting) is to make your <strong>DELETE</strong>/<strong>UPDATE</strong> statements in a loop as different, separate transactions: <strong>DELETE</strong>/<strong>UPDATE</strong> less than 5.000 rows, so that you can prevent Lock Escalations. As a very nice side-effect your huge, big transaction will be splitted into multiple smaller ones, which will also help you with Auto Growth issues that you maybe have with your transaction log.</p>
<p>Thanks for reading</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/lock-escalations/">http://xnerv.wang/lock-escalations/</a></strong><br>
转载自：<a href="http://www.sqlpassion.at/archive/2014/02/25/lock-escalations/">Lock Escalations</a></p>
]]></content>
      <categories>
        <category>DBMS</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>DBMS</tag>
        <tag>SQL Server</tag>
        <tag>Transaction</tag>
        <tag>Lock Escalations</tag>
      </tags>
  </entry>
  <entry>
    <title>无锁队列的实现（转载）</title>
    <url>/lock-free-queue-Implementation/</url>
    <content><![CDATA[<p>关于无锁队列的实现，网上有很多文章，虽然本文可能和那些文章有所重复，但是我还是想以我自己的方式把这些文章中的重要的知识点串起来和大家讲一讲这个技术。下面开始正文。</p>
<span id="more"></span>
<h2 id="关于CAS等原子操作"><a class="header-anchor" href="#关于CAS等原子操作"></a>关于CAS等原子操作</h2>
<p>在开始说无锁队列之前，我们需要知道一个很重要的技术就是CAS操作——Compare &amp; Set，或是 Compare &amp; Swap，<strong>现在几乎所有的CPU指令都支持CAS的原子操作，X86下对应的是 CMPXCHG 汇编指令</strong>。有了这个原子操作，我们就可以用其来实现各种无锁（lock free）的数据结构。</p>
<center>
<img src="/assets/lock-free-queue-Implementation/lock-free-bicycle.jpg" alt="lock free bicycle"/>
</center>
<p>这个操作用C语言来描述就是下面这个样子：（代码来自<a href="http://en.wikipedia.org/wiki/Compare-and-swap">Wikipedia的Compare And Swap</a>词条）意思就是说，看一看内存*reg里的值是不是oldval，如果是的话，则对其赋值newval。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">compare_and_swap</span> <span class="params">(<span class="type">int</span>* reg, <span class="type">int</span> oldval, <span class="type">int</span> newval)</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="type">int</span> old_reg_val = *reg;</span><br><span class="line">  <span class="keyword">if</span> (old_reg_val == oldval)</span><br><span class="line">     *reg = newval;</span><br><span class="line">  <span class="keyword">return</span> old_reg_val;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这个操作可以变种为返回bool值的形式（返回 bool值的好处在于，可以调用者知道有没有更新成功）：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">bool</span> <span class="title function_">compare_and_swap</span> <span class="params">(<span class="type">int</span> *accum, <span class="type">int</span> *dest, <span class="type">int</span> newval)</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">if</span> ( *accum == *dest ) &#123;</span><br><span class="line">      *dest = newval;</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>与CAS相似的还有下面的原子操作：（这些东西大家自己看Wikipedia吧）</p>
<ul>
<li>Fetch And Add，一般用来对变量做 +1 的原子操作</li>
<li>Test-and-set，写值到某个内存位置并传回其旧值。汇编指令BST</li>
<li>Test and Test-and-set，用来低低Test-and-Set的资源争夺情况<br>
**注：**在实际的C/C++程序中，CAS的各种实现版本如下：</li>
</ul>
<ol>
<li><strong>GCC的CAS</strong></li>
</ol>
<p>GCC4.1+版本中支持CAS的原子操作（完整的原子操作可参看 <a href="http://gcc.gnu.org/onlinedocs/gcc-4.1.1/gcc/Atomic-Builtins.html">GCC Atomic Builtins</a>）</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">bool</span> __sync_bool_compare_and_swap (type *ptr, type oldval type newval, ...)</span><br><span class="line">type __sync_val_compare_and_swap (type *ptr, type oldval type newval, ...)</span><br></pre></td></tr></table></figure>
<ol start="2">
<li><strong>Windows的CAS</strong></li>
</ol>
<p>在Windows下，你可以使用下面的Windows API来完成CAS：（完整的Windows原子操作可参看MSDN的 <a href="http://msdn.microsoft.com/en-us/library/windows/desktop/ms686360(v=vs.85).aspx#interlocked_functions">InterLocked Functions</a>）</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">InterlockedCompareExchange ( __inout LONG <span class="keyword">volatile</span> *Target,</span><br><span class="line">                                __in LONG Exchange,</span><br><span class="line">                                __in LONG Comperand);</span><br></pre></td></tr></table></figure>
<ol start="3">
<li><strong>C++11中的CAS</strong></li>
</ol>
<p>C++11中的STL中的atomic类的函数可以让你跨平台。（完整的C++11的原子操作可参看 <a href="http://en.cppreference.com/w/cpp/atomic">Atomic Operation Library</a>）</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">template</span>&lt; <span class="keyword">class</span> T &gt;</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">atomic_compare_exchange_weak</span><span class="params">( std::atomic* obj,</span></span></span><br><span class="line"><span class="params"><span class="function">                                   T* expected, T desired )</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt; <span class="keyword">class</span> T &gt;</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">atomic_compare_exchange_weak</span><span class="params">( <span class="keyword">volatile</span> std::atomic* obj,</span></span></span><br><span class="line"><span class="params"><span class="function">                                   T* expected, T desired )</span></span>;</span><br></pre></td></tr></table></figure>
<h2 id="无锁队列的链表实现"><a class="header-anchor" href="#无锁队列的链表实现"></a>无锁队列的链表实现</h2>
<p>下面的东西主要来自John D. Valois 1994年10月在拉斯维加斯的并行和分布系统系统国际大会上的一篇论文——《<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.53.8674&amp;rep=rep1&amp;type=pdf">Implementing Lock-Free Queues</a>》。</p>
<p>我们先来看一下进队列用CAS实现的方式：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">EnQueue(x) <span class="comment">//进队列</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">//准备新加入的结点数据</span></span><br><span class="line">    q = new record();</span><br><span class="line">    q-&gt;value = x;</span><br><span class="line">    q-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">do</span> &#123;</span><br><span class="line">        p = tail; <span class="comment">//取链表尾指针的快照</span></span><br><span class="line">    &#125; <span class="keyword">while</span>( CAS(p-&gt;next, <span class="literal">NULL</span>, q) != TRUE); <span class="comment">//如果没有把结点链在尾指针上，再试</span></span><br><span class="line"></span><br><span class="line">    CAS(tail, p, q); <span class="comment">//置尾结点</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>我们可以看到，程序中的那个 do- while 的 Re-Try-Loop。就是说，很有可能我在准备在队列尾加入结点时，别的线程已经加成功了，于是tail指针就变了，于是我的CAS返回了false，于是程序再试，直到试成功为止。这个很像我们的抢电话热线的不停重播的情况。</p>
<p>你会看到，为什么我们的“置尾结点”的操作（第12行）不判断是否成功，因为：</p>
<ol>
<li>如果有一个线程T1，它的while中的CAS如果成功的话，那么其它所有的 随后线程的CAS都会失败，然后就会再循环，</li>
<li>此时，如果T1 线程还没有更新tail指针，其它的线程继续失败，因为tail-&gt;next不是NULL了。</li>
<li>直到T1线程更新完tail指针，于是其它的线程中的某个线程就可以得到新的tail指针，继续往下走了。</li>
<li></li>
</ol>
<p>这里有一个潜在的问题——<strong>如果T1线程在用CAS更新tail指针的之前，线程停掉或是挂掉了，那么其它线程就进入死循环了</strong>。下面是改良版的EnQueue()</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">EnQueue</span>(x) <span class="comment">//进队列改良版</span></span><br><span class="line">&#123;</span><br><span class="line">    q = <span class="keyword">new</span> <span class="built_in">record</span>();</span><br><span class="line">    q-&gt;value = x;</span><br><span class="line">    q-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">    p = tail;</span><br><span class="line">    oldp = p</span><br><span class="line">    <span class="keyword">do</span> &#123;</span><br><span class="line">        <span class="keyword">while</span> (p-&gt;next != <span class="literal">NULL</span>)</span><br><span class="line">            p = p-&gt;next;</span><br><span class="line">    &#125; <span class="keyword">while</span>( <span class="built_in">CAS</span>(p.next, <span class="literal">NULL</span>, q) != TRUE); <span class="comment">//如果没有把结点链在尾上，再试</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">CAS</span>(tail, oldp, q); <span class="comment">//置尾结点</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>我们让每个线程，自己fetch 指针 p 到链表尾。但是这样的fetch会很影响性能。而通实际情况看下来，99.9%的情况不会有线程停转的情况，所以，更好的做法是，你可以接合上述的这两个版本，如果retry的次数超了一个值的话（比如说3次），那么，就自己fetch指针。</p>
<p>好了，我们解决了EnQueue，我们再来看看DeQueue的代码：（很简单，我就不解释了）</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">DeQueue</span>() <span class="comment">//出队列</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">do</span>&#123;</span><br><span class="line">        p = head;</span><br><span class="line">        <span class="keyword">if</span> (p-&gt;next == <span class="literal">NULL</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> ERR_EMPTY_QUEUE;</span><br><span class="line">        &#125;</span><br><span class="line">    <span class="keyword">while</span>( <span class="built_in">CAS</span>(head, p, p-&gt;next) != TRUE );</span><br><span class="line">    <span class="keyword">return</span> p-&gt;next-&gt;value;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>我们可以看到，DeQueue的代码操作的是 head-&gt;next，而不是head本身。这样考虑是因为一个边界条件，我们需要一个dummy的头指针来解决链表中如果只有一个元素，head和tail都指向同一个结点的问题，这样EnQueue和DeQueue要互相排斥了。</strong></p>
<center>
<img src="/assets/lock-free-queue-Implementation/lock-free-link.jpg" alt="Lock-Free Queue(Link)"/>
</center>
注：上图的tail正处于更新之前的装态。
<h2 id="CAS的ABA问题"><a class="header-anchor" href="#CAS的ABA问题"></a>CAS的ABA问题</h2>
<p>所谓ABA（<a href="http://en.wikipedia.org/wiki/ABA_problem">见维基百科的ABA词条</a>），问题基本是这个样子：</p>
<ol>
<li>进程P1在共享变量中读到值为A</li>
<li>P1被抢占了，进程P2执行</li>
<li>P2把共享变量里的值从A改成了B，再改回到A，此时被P1抢占。</li>
<li>P1回来看到共享变量里的值没有被改变，于是继续执行。</li>
</ol>
<p>虽然P1以为变量值没有改变，继续执行了，但是这个会引发一些潜在的问题。<strong>ABA问题最容易发生在lock free 的算法中的，CAS首当其冲，因为CAS判断的是指针的地址。如果这个地址被重用了呢，问题就很大了。</strong>（地址被重用是很经常发生的，一个内存分配后释放了，再分配，很有可能还是原来的地址）</p>
<p>比如上述的DeQueue()函数，因为我们要让head和tail分开，所以我们引入了一个dummy指针给head，当我们做CAS的之前，如果head的那块内存被回收并被重用了，而重用的内存又被EnQueue()进来了，这会有很大的问题。（<strong>内存管理中重用内存基本上是一种很常见的行为</strong>）</p>
<p>这个例子你可能没有看懂，维基百科上给了一个活生生的例子——</p>
<blockquote>
<p>你拿着一个装满钱的手提箱在飞机场，此时过来了一个火辣性感的美女，然后她很暖昧地挑逗着你，并趁你不注意的时候，把用一个一模一样的手提箱和你那装满钱的箱子调了个包，然后就离开了，你看到你的手提箱还在那，于是就提着手提箱去赶飞机去了。</p>
</blockquote>
<p>这就是ABA的问题。</p>
<h2 id="解决ABA的问题"><a class="header-anchor" href="#解决ABA的问题"></a>解决ABA的问题</h2>
<p>维基百科上给了一个解——使用double-CAS（双保险的CAS），例如，在32位系统上，我们要检查64位的内容</p>
<ol>
<li>一次用CAS检查双倍长度的值，前半部是指针，后半部分是一个计数器。</li>
<li>只有这两个都一样，才算通过检查，要吧赋新的值。并把计数器累加1。</li>
</ol>
<p>这样一来，ABA发生时，虽然值一样，但是计数器就不一样（但是在32位的系统上，这个计数器会溢出回来又从1开始的，这还是会有ABA的问题）</p>
<p>当然，我们这个队列的问题就是不想让那个内存重用，这样明确的业务问题比较好解决，论文《<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.53.8674&amp;rep=rep1&amp;type=pdf">Implementing Lock-Free Queues</a>》给出一这么一个方法——<strong>使用结点内存引用计数refcnt！</strong></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">SafeRead</span>(q)</span><br><span class="line">&#123;</span><br><span class="line">    loop:</span><br><span class="line">        p = q-&gt;next;</span><br><span class="line">        <span class="keyword">if</span> (p == <span class="literal">NULL</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> p;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function">Fetch&amp;<span class="title">Add</span><span class="params">(p-&gt;refcnt, <span class="number">1</span>)</span></span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (p == q-&gt;next)&#123;</span><br><span class="line">            <span class="keyword">return</span> p;</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            <span class="built_in">Release</span>(p);</span><br><span class="line">        &#125;</span><br><span class="line">    <span class="keyword">goto</span> loop;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中的<code>Fetch&amp;Add</code>和<code>Release</code>分是是加引用计数和减引用计数，都是原子操作，这样就可以阻止内存被回收了。</p>
<h2 id="用数组实现无锁队列"><a class="header-anchor" href="#用数组实现无锁队列"></a>用数组实现无锁队列</h2>
<p>本实现来自论文《<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.53.8674&amp;rep=rep1&amp;type=pdf">Implementing Lock-Free Queues</a>》</p>
<p>使用数组来实现队列是很常见的方法，因为没有内存的分部和释放，一切都会变得简单，实现的思路如下：</p>
<ol>
<li>数组队列应该是一个ring buffer形式的数组（环形数组）</li>
<li>数组的元素应该有三个可能的值：HEAD，TAIL，EMPTY（当然，还有实际的数据）</li>
<li>数组一开始全部初始化成EMPTY，有两个相邻的元素要初始化成HEAD和TAIL，这代表空队列。</li>
<li>EnQueue操作。假设数据x要入队列，定位TAIL的位置，使用double-CAS方法把(TAIL, EMPTY) 更新成 (x, TAIL)。需要注意，如果找不到(TAIL, EMPTY)，则说明队列满了。</li>
<li>DeQueue操作。定位HEAD的位置，把(HEAD, x)更新成(EMPTY, HEAD)，并把x返回。同样需要注意，如果x是TAIL，则说明队列为空。</li>
</ol>
<p>算法的一个关键是——如何定位HEAD或TAIL？</p>
<ol>
<li>我们可以声明两个计数器，一个用来计数EnQueue的次数，一个用来计数DeQueue的次数。</li>
<li>这两个计算器使用使用<code>Fetch&amp;ADD</code>来进行原子累加，在<code>EnQueue</code>或<code>DeQueue</code>完成的时候累加就好了。</li>
<li>累加后求个模什么的就可以知道TAIL和HEAD的位置了。</li>
</ol>
<p>如下图所示：</p>
<center>
<img src="/assets/lock-free-queue-Implementation/lock-free-array.jpg" alt="Lock-Free Queue(Array)"/>
</center>
<h2 id="小结"><a class="header-anchor" href="#小结"></a>小结</h2>
<p>以上基本上就是所有的无锁队列的技术细节，这些技术都可以用在其它的无锁数据结构上。</p>
<ol>
<li>无锁队列主要是通过CAS、FAA这些原子操作，和Retry-Loop实现。</li>
<li>对于Retry-Loop，我个人感觉其实和锁什么什么两样。只是这种“锁”的粒度变小了，主要是“锁”HEAD和TAIL这两个关键资源。而不是整个数据结构。</li>
</ol>
<p>还有一些和Lock Free的文章你可以去看看：</p>
<ul>
<li>Code Project 上的雄文 《<a href="http://www.codeproject.com/Articles/153898/Yet-another-implementation-of-a-lock-free-circular">Yet another implementation of a lock-free circular array queue</a>》</li>
<li>Herb Sutter的《<a href="http://www.drdobbs.com/parallel/writing-lock-free-code-a-corrected-queue/210604448?pgno=1">Writing Lock-Free Code: A Corrected Queue</a>》– 用C++11的std::atomic模板。</li>
<li>IBM developerWorks的《<a href="http://www.ibm.com/developerworks/cn/aix/library/au-multithreaded_structures2/index.html">设计不使用互斥锁的并发数据结构</a>》</li>
</ul>
<p>【注：我配了一张look-free的自行车，寓意为——如果不用专门的车锁，那么自行得自己锁自己！】</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/lock-free-queue-Implementation/">http://xnerv.wang/lock-free-queue-Implementation/</a></strong><br>
转载自：<a href="https://coolshell.cn/articles/8239.html">（ 酷 壳 – CoolShell）无锁队列的实现</a></p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>数据结构与算法</tag>
        <tag>无锁队列</tag>
      </tags>
  </entry>
  <entry>
    <title>我理解的逻辑地址、线性地址、物理地址和虚拟地址（转载）</title>
    <url>/logical-address-linear-address-physical-address-and-virtual-address/</url>
    <content><![CDATA[<p>本贴涉及的硬件平台是X86，如果是其它平台，嘻嘻，不保证能一一对号入座，但是举一反三，我想是完全可行的。</p>
<h2 id="概念"><a class="header-anchor" href="#概念"></a>概念</h2>
<h3 id="物理地址-physical-address"><a class="header-anchor" href="#物理地址-physical-address"></a>物理地址(physical address)</h3>
<p>用于内存芯片级的单元寻址，与处理器和CPU连接的地址总线相对应。<br>
——这个概念应该是这几个概念中最好理解的一个，但是值得一提的是，虽然可以直接把物理地址理解成插在机器上那根内存本身，把内存看成一个从0字节一直到最大空量逐字节的编号的大数组，然后把这个数组叫做物理地址，但是事实上，这只是一个硬件提供给软件的抽像，内存的寻址方式并不是这样。所以，说它是“与地址总线相对应”，是更贴切一些，不过抛开对物理内存寻址方式的考虑，直接把物理地址与物理的内存一一对应，也是可以接受的。也许错误的理解更利于形而上的抽像。</p>
<span id="more"></span>
<h3 id="虚拟内存-virtual-memory"><a class="header-anchor" href="#虚拟内存-virtual-memory"></a>虚拟内存(virtual memory)</h3>
<p>这是对整个内存（不要与机器上插那条对上号）的抽像描述。它是相对于物理内存来讲的，可以直接理解成“不直实的”，“假的”内存，例如，一个0x08000000内存地址，它并不对就物理地址上那个大数组中0x08000000 - 1那个地址元素；<br>
之所以是这样，是因为现代操作系统都提供了一种内存管理的抽像，即虚拟内存（virtual memory）。进程使用虚拟内存中的地址，由操作系统协助相关硬件，把它“转换”成真正的物理地址。这个“转换”，是所有问题讨论的关键。<br>
有了这样的抽像，一个程序，就可以使用比真实物理地址大得多的地址空间。（拆东墙，补西墙，银行也是这样子做的），甚至多个进程可以使用相同的地址。不奇怪，因为转换后的物理地址并非相同的。<br>
——可以把连接后的程序反编译看一下，发现连接器已经为程序分配了一个地址，例如，要调用某个函数A，代码不是call A，而是call 0x0811111111 ，也就是说，函数A的地址已经被定下来了。没有这样的“转换”，没有虚拟地址的概念，这样做是根本行不通的。<br>
打住了，这个问题再说下去，就收不住了。</p>
<h3 id="逻辑地址-logical-address"><a class="header-anchor" href="#逻辑地址-logical-address"></a>逻辑地址(logical address)</h3>
<p>Intel为了兼容，将远古时代的段式内存管理方式保留了下来。逻辑地址指的是机器语言指令中，用来指定一个操作数或者是一条指令的地址。以上例，我们说的连接器为A分配的0x08111111这个地址就是逻辑地址。<br>
——不过不好意思，这样说，好像又违背了Intel中段式管理中，对逻辑地址要求，“一个逻辑地址，是由一个段标识符加上一个指定段内相对地址的偏移量，表示为 [段标识符：段内偏移量]，也就是说，上例中那个0x08111111，应该表示为[A的代码段标识符: 0x08111111]，这样，才完整一些”。</p>
<h3 id="线性地址-linear-address-或也叫虚拟地址-virtual-address"><a class="header-anchor" href="#线性地址-linear-address-或也叫虚拟地址-virtual-address"></a>线性地址(linear address)或也叫虚拟地址(virtual address)</h3>
<p>跟逻辑地址类似，它也是一个不真实的地址，如果逻辑地址是对应的硬件平台段式管理转换前地址的话，那么线性地址则对应了硬件页式内存的转换前地址。</p>
<p><em>（编者注：有些文章也将<strong>段内偏移量</strong>描述为<strong>虚拟地址</strong>，从下文可以看出，在Linux中，逻辑地址/虚拟地址/线性地址 三者相等。）</em></p>
<hr>
<p>CPU将一个虚拟内存空间中的地址转换为物理地址，需要进行两步：首先将给定一个逻辑地址（其实是段内偏移量，这个一定要理解！！！），CPU要利用其段式内存管理单元，先将为个逻辑地址转换成一个线程地址，再利用其页式内存管理单元，转换为最终物理地址。</p>
<p>这样做两次转换，的确是非常麻烦而且没有必要的，因为直接可以把线性地址抽像给进程。之所以这样冗余，Intel完全是为了兼容而已。</p>
<h2 id="CPU段式内存管理，逻辑地址如何转换为线性地址"><a class="header-anchor" href="#CPU段式内存管理，逻辑地址如何转换为线性地址"></a>CPU段式内存管理，逻辑地址如何转换为线性地址</h2>
<p>一个逻辑地址由两部份组成，段标识符: 段内偏移量。段标识符是由一个16位长的字段组成，称为段选择符。其中前13位是一个索引号。后面3位包含一些硬件细节，如图：<br>
<img src="/assets/logical-address-linear-address-physical-address-and-virtual-address/1.jpg" alt=""></p>
<p>最后两位涉及权限检查，本贴中不包含。</p>
<p>索引号，或者直接理解成数组下标——那它总要对应一个数组吧，它又是什么东东的索引呢？这个东东就是“段描述符(segment descriptor)”，呵呵，段描述符具体地址描述了一个段（对于“段”这个字眼的理解，我是把它想像成，拿了一把刀，把虚拟内存，砍成若干的截——段）。这样，很多个段描述符，就组了一个数组，叫“段描述符表”，这样，可以通过段标识符的前13位，直接在段描述符表中找到一个具体的段描述符，这个描述符就描述了一个段，我刚才对段的抽像不太准确，因为看看描述符里面究竟有什么东东——也就是它究竟是如何描述的，就理解段究竟有什么东东了，每一个段描述符由8个字节组成，如下图：<br>
<img src="/assets/logical-address-linear-address-physical-address-and-virtual-address/2.jpg" alt=""></p>
<p>这些东东很复杂，虽然可以利用一个数据结构来定义它，不过，我这里只关心一样，就是Base字段，它描述了一个段的开始位置的线性地址。</p>
<p>Intel设计的本意是，一些全局的段描述符，就放在“全局段描述符表(GDT)”中，一些局部的，例如每个进程自己的，就放在所谓的“局部段描述符表(LDT)”中。那究竟什么时候该用GDT，什么时候该用LDT呢？这是由段选择符中的T1字段表示的，=0，表示用GDT，=1表示用LDT。</p>
<p>GDT在内存中的地址和大小存放在CPU的gdtr控制寄存器中，而LDT则在ldtr寄存器中。</p>
<p>好多概念，像绕口令一样。这张图看起来要直观些：<br>
<img src="/assets/logical-address-linear-address-physical-address-and-virtual-address/3.jpg" alt=""></p>
<p>首先，给定一个完整的逻辑地址[段选择符：段内偏移地址]，</p>
<ol>
<li>看段选择符的T1=0还是1，知道当前要转换是GDT中的段，还是LDT中的段，再根据相应寄存器，得到其地址和大小。我们就有了一个数组了。</li>
<li>拿出段选择符中前13位，可以在这个数组中，查找到对应的段描述符，这样，它了Base，即基地址就知道了。</li>
<li>把Base + offset，就是要转换的线性地址了。</li>
</ol>
<p>还是挺简单的，对于软件来讲，原则上就需要把硬件转换所需的信息准备好，就可以让硬件来完成这个转换了。OK，来看看Linux怎么做的。</p>
<h2 id="Linux的段式管理"><a class="header-anchor" href="#Linux的段式管理"></a>Linux的段式管理</h2>
<p>Intel要求两次转换，这样虽说是兼容了，但是却是很冗余，呵呵，没办法，硬件要求这样做了，软件就只能照办，怎么着也得形式主义一样。<br>
另一方面，其它某些硬件平台，没有二次转换的概念，Linux也需要提供一个高层抽像，来提供一个统一的界面。所以，Linux的段式管理，事实上只是“哄骗”了一下硬件而已。</p>
<p>按照Intel的本意，全局的用GDT，每个进程自己的用LDT——不过Linux则对所有的进程都使用了相同的段来对指令和数据寻址。即用户数据段，用户代码段，对应的，内核中的是内核数据段和内核代码段。这样做没有什么奇怪的，本来就是走形式嘛，像我们写年终总结一样。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">include/<span class="keyword">asm</span>-i386/segment.h</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> GDT_ENTRY_DEFAULT_USER_CS        14</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> __USER_CS (GDT_ENTRY_DEFAULT_USER_CS * 8 + 3)</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> GDT_ENTRY_DEFAULT_USER_DS        15</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> __USER_DS (GDT_ENTRY_DEFAULT_USER_DS * 8 + 3)</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> GDT_ENTRY_KERNEL_BASE        12</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> GDT_ENTRY_KERNEL_CS                (GDT_ENTRY_KERNEL_BASE + 0)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> __KERNEL_CS (GDT_ENTRY_KERNEL_CS * 8)</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> GDT_ENTRY_KERNEL_DS                (GDT_ENTRY_KERNEL_BASE + 1)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> __KERNEL_DS (GDT_ENTRY_KERNEL_DS * 8)</span></span><br></pre></td></tr></table></figure>
<p>把其中的宏替换成数值，则为：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> __USER_CS 115        [00000000 1110  0  11]</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> __USER_DS 123        [00000000 1111  0  11]</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> __KERNEL_CS 96      [00000000 1100  0  00]</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> __KERNEL_DS 104    [00000000 1101  0  00]</span></span><br></pre></td></tr></table></figure>
<p>方括号后是这四个段选择符的16位二制表示，它们的索引号和T1字段值也可以算出来了：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">__USER_CS              index= <span class="number">14</span>   T1=<span class="number">0</span></span><br><span class="line">__USER_DS               index= <span class="number">15</span>   T1=<span class="number">0</span></span><br><span class="line">__KERNEL_CS           index=  <span class="number">12</span>  T1=<span class="number">0</span></span><br><span class="line">__KERNEL_DS           index= <span class="number">13</span>   T1=<span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>T1均为0，则表示都使用了GDT，再来看初始化GDT的内容中相应的12-15项(arch/i386/head.S)：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">.quad <span class="number">0x00cf9a000000ffff</span>        <span class="comment">/* 0x60 kernel 4GB code at 0x00000000 */</span></span><br><span class="line">.quad <span class="number">0x00cf92000000ffff</span>        <span class="comment">/* 0x68 kernel 4GB data at 0x00000000 */</span></span><br><span class="line">.quad <span class="number">0x00cffa000000ffff</span>        <span class="comment">/* 0x73 user 4GB code at 0x00000000 */</span></span><br><span class="line">.quad <span class="number">0x00cff2000000ffff</span>        <span class="comment">/* 0x7b user 4GB data at 0x00000000 */</span></span><br></pre></td></tr></table></figure>
<p>按照前面段描述符表中的描述，可以把它们展开，发现其16-31位全为0，即四个段的基地址全为0。</p>
<p>这样，给定一个段内偏移地址，按照前面转换公式，0 + 段内偏移，转换为线性地址，可以得出重要的结论，“在Linux下，逻辑地址与线性地址总是一致（是一致，不是有些人说的相同）的，即逻辑地址的偏移量字段的值与线性地址的值总是相同的。！！！”</p>
<p>忽略了太多的细节，例如段的权限检查。呵呵。</p>
<p>Linux中，绝大部份进程并不例用LDT，除非使用Wine ，仿真Windows程序的时候。</p>
<h2 id="CPU的页式内存管理"><a class="header-anchor" href="#CPU的页式内存管理"></a>CPU的页式内存管理</h2>
<p>CPU的页式内存管理单元，负责把一个线性地址，最终翻译为一个物理地址。从管理和效率的角度出发，线性地址被分为以固定长度为单位的组，称为页(page)，例如一个32位的机器，线性地址最大可为4G，可以用4KB为一个页来划分，这页，整个线性地址就被划分为一个tatol_page[2^20]的大数组，共有2的20个次方个页。这个大数组我们称之为页目录。目录中的每一个目录项，就是一个地址——对应的页的地址。</p>
<p>另一类“页”，我们称之为物理页，或者是页框、页桢的。是分页单元把所有的物理内存也划分为固定长度的管理单位，它的长度一般与内存页是一一对应的。</p>
<p>这里注意到，这个total_page数组有2^20个成员，每个成员是一个地址（32位机，一个地址也就是4字节），那么要单单要表示这么一个数组，就要占去4MB的内存空间。为了节省空间，引入了一个二级管理模式的机器来组织分页单元。文字描述太累，看图直观一些：<br>
<img src="/assets/logical-address-linear-address-physical-address-and-virtual-address/4.jpg" alt=""></p>
<p>如上图，</p>
<ol>
<li>分页单元中，页目录是唯一的，它的地址放在CPU的cr3寄存器中，是进行地址转换的开始点。万里长征就从此长始了。</li>
<li>每一个活动的进程，因为都有其独立的对应的虚似内存（页目录也是唯一的），那么它也对应了一个独立的页目录地址。——运行一个进程，需要将它的页目录地址放到cr3寄存器中，将别个的保存下来。</li>
<li>每一个32位的线性地址被划分为三部份，面目录索引(10位)：页表索引(10位)：偏移(12位)<br>
依据以下步骤进行转换：</li>
<li>从cr3中取出进程的页目录地址（操作系统负责在调度进程的时候，把这个地址装入对应寄存器）；</li>
<li>根据线性地址前十位，在数组中，找到对应的索引项，因为引入了二级管理模式，页目录中的项，不再是页的地址，而是一个页表的地址。（又引入了一个数组），页的地址被放到页表中去了。</li>
<li>根据线性地址的中间十位，在页表（也是数组）中找到页的起始地址；</li>
<li>将页的起始地址与线性地址中最后12位相加，得到最终我们想要的葫芦；</li>
</ol>
<p>这个转换过程，应该说还是非常简单地。全部由硬件完成，虽然多了一道手续，但是节约了大量的内存，还是值得的。那么再简单地验证一下：</p>
<ol>
<li>
<p>这样的二级模式是否仍能够表示4G的地址；<br>
页目录共有：2^10项，也就是说有这么多个页表<br>
每个目表对应了：2^10页；<br>
每个页中可寻址：2^12个字节。<br>
还是2^32 = 4GB</p>
</li>
<li>
<p>这样的二级模式是否真的节约了空间；<br>
也就是算一下页目录项和页表项共占空间 (2^10 * 4 + 2 ^10 *4) = 8KB。哎，……怎么说呢！！！<br>
红色错误，标注一下，后文贴中有此讨论。。。。。。<br>
按&lt;深入理解计算机系统&gt;中的解释,二级模式空间的节约是从两个方面实现的:<br>
A、如果一级页表中的一个页表条目为空，那么那所指的二级页表就根本不会存在。这表现出一种巨大的潜在节约，因为对于一个典型的程序，4GB虚拟地址空间的大部份都会是未分配的；<br>
B、只有一级页表才需要总是在主存中。虚拟存储器系统可以在需要时创建，并页面调入或调出二级页表，这就减少了主存的压力。只有最经常使用的二级页表才需要缓存在主存中。——不过Linux并没有完全享受这种福利，它的页表目录和与已分配页面相关的页表都是常驻内存的。</p>
</li>
</ol>
<p>值得一提的是，虽然页目录和页表中的项，都是4个字节，32位，但是它们都只用高20位，低12位屏蔽为0——把页表的低12屏蔽为0，是很好理解的，因为这样，它刚好和一个页面大小对应起来，大家都成整数增加。计算起来就方便多了。但是，为什么同时也要把页目录低12位屏蔽掉呢？因为按同样的道理，只要屏蔽其低10位就可以了，不过我想，因为12&gt;10，这样，可以让页目录和页表使用相同的数据结构，方便。</p>
<p>本贴只介绍一般性转换的原理，扩展分页、页的保护机制、PAE模式的分页这些麻烦点的东东就不啰嗦了……可以参考其它专业书籍。</p>
<h2 id="Linux的页式内存管理"><a class="header-anchor" href="#Linux的页式内存管理"></a>Linux的页式内存管理</h2>
<p>原理上来讲，Linux只需要为每个进程分配好所需数据结构，放到内存中，然后在调度进程的时候，切换寄存器cr3，剩下的就交给硬件来完成了（呵呵，事实上要复杂得多，不过偶只分析最基本的流程）。</p>
<p>前面说了i386的二级页管理架构，不过有些CPU，还有三级，甚至四级架构，Linux为了在更高层次提供抽像，为每个CPU提供统一的界面。提供了一个四层页管理架构，来兼容这些二级、三级、四级管理架构的CPU。这四级分别为：</p>
<ul>
<li>页全局目录PGD（对应刚才的页目录）</li>
<li>页上级目录PUD（新引进的）</li>
<li>页中间目录PMD（也就新引进的）</li>
<li>页表PT（对应刚才的页表）。</li>
</ul>
<p>整个转换依据硬件转换原理，只是多了二次数组的索引罢了，如下图：<br>
<img src="/assets/logical-address-linear-address-physical-address-and-virtual-address/5.jpg" alt=""></p>
<p>那么，对于使用二级管理架构32位的硬件，现在又是四级转换了，它们怎么能够协调地工作起来呢？嗯，来看这种情况下，怎么来划分线性地址吧！<br>
从硬件的角度，32位地址被分成了三部份——也就是说，不管理软件怎么做，最终落实到硬件，也只认识这三位老大。<br>
从软件的角度，由于多引入了两部份，，也就是说，共有五部份。——要让二层架构的硬件认识五部份也很容易，在地址划分的时候，将页上级目录和页中间目录的长度设置为0就可以了。<br>
这样，操作系统见到的是五部份，硬件还是按它死板的三部份划分，也不会出错，也就是说大家共建了和谐计算机系统。</p>
<p>这样，虽说是多此一举，但是考虑到64位地址，使用四层转换架构的CPU，我们就不再把中间两个设为0了，这样，软件与硬件再次和谐——抽像就是强大呀！！！</p>
<p>例如，一个逻辑地址已经被转换成了线性地址，0x08147258，换成二制进，也就是：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">0000100000 0101000111 001001011000</span><br></pre></td></tr></table></figure>
<p>内核对这个地址进行划分</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">PGD = 0000100000</span><br><span class="line">PUD = 0</span><br><span class="line">PMD = 0</span><br><span class="line">PT = 0101000111</span><br><span class="line">offset = 001001011000</span><br></pre></td></tr></table></figure>
<p>现在来理解Linux针对硬件的花招，因为硬件根本看不到所谓PUD,PMD，所以，本质上要求PGD索引，直接就对应了PT的地址。而不是再到PUD和PMD中去查数组（虽然它们两个在线性地址中，长度为0，2^0 =1，也就是说，它们都是有一个数组元素的数组），那么，内核如何合理安排地址呢？<br>
从软件的角度上来讲，因为它的项只有一个，32位，刚好可以存放与PGD中长度一样的地址指针。那么所谓先到PUD，到到PMD中做映射转换，就变成了保持原值不变，一一转手就可以了。这样，就实现了“逻辑上指向一个PUD，再指向一个PDM，但在物理上是直接指向相应的PT的这个抽像，因为硬件根本不知道有PUD、PMD这个东西”。</p>
<p>然后交给硬件，硬件对这个地址进行划分，看到的是：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">页目录 = 0000100000</span><br><span class="line">PT = 0101000111</span><br><span class="line">offset = 001001011000</span><br></pre></td></tr></table></figure>
<p>嗯，先根据0000100000(32)，在页目录数组中索引，找到其元素中的地址，取其高20位，找到页表的地址，页表的地址是由内核动态分配的，接着，再加一个offset，就是最终的物理地址了。</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/logical-address-linear-address-physical-address-and-virtual-address/">http://xnerv.wang/logical-address-linear-address-physical-address-and-virtual-address/</a></strong><br>
转载自：<a href="http://bbs.chinaunix.net/thread-2083672-1-1.html">我理解的逻辑地址、线性地址、物理地址和虚拟地址</a></p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>操作系统</tag>
        <tag>内存管理</tag>
        <tag>虚拟内存</tag>
        <tag>页表</tag>
      </tags>
  </entry>
  <entry>
    <title>内存分配-----伙伴算法和slab算法（转载）</title>
    <url>/memory-allocation-buddy-system-and-slab-allocator/</url>
    <content><![CDATA[<h2 id="内存管理问题"><a class="header-anchor" href="#内存管理问题"></a>内存管理问题</h2>
<p>内存碎片大小和管理内存碎片的效率问题(即空间和时间效率的问题):<br>
内存碎片是指当回收一块内存时,一般将内存直接放入free链表中,由于内存越分配越小,内存块就会特别多而且特别小,当需要一块大的内存块的时候无法找到.原因就在于回收内存的时候,不能把相邻两块可用内存合并.</p>
<p>解决方法:</p>
<ol>
<li>小块内存单独分配,大块内存有系统自动分配.(nginx和stl就是使用这种方法)</li>
<li>伙伴算法.</li>
<li>slab算法.</li>
</ol>
<span id="more"></span>
<h2 id="伙伴算法"><a class="header-anchor" href="#伙伴算法"></a>伙伴算法</h2>
<ol>
<li>将空闲页面分为m个组,第1组存储2<sup>0个单位的内存块,第2组存储2</sup>1个单位的内存块,第3组存储2<sup>2个单位的内存块,第4组存储2</sup>3个单位的内存块,以此类推.直到m组.</li>
<li>每个组是一个链表,用于连接同等大小的内存块.</li>
<li>伙伴块的大小是相等的,并且第1块和第2块是伙伴,第三块和第四块是伙伴.以此类推.</li>
</ol>
<center>
<img src="/assets/memory-allocation-buddy-system-and-slab-allocator/buddy.png" alt="buddy system"/>
</center>
<h3 id="伙伴算法分配内存"><a class="header-anchor" href="#伙伴算法分配内存"></a>伙伴算法分配内存</h3>
<p>若申请的内存大小为n则将n向上取整为2的幂设次数为s,则需要分配s大小的内存块,定位大相应数组,</p>
<ol>
<li>如果该数组有剩余内存块,则分配出去.</li>
<li>若没有剩余内存块就沿数组向上查找,然后再将该内存块分割出来s并将剩余的内存块放入相应大小的数组中.</li>
</ol>
<p>例如分配5大小的内存块<br>
-----------&gt;定位到大小为8的链表中 --------&gt;若该链表中之中没有空余元素,则定位到16的链表中,16中有剩余元素,则取出该元素,并分割出大小为8的内存块供用户使用,然后将剩余的8连接到大小为8的数组中.</p>
<h3 id="伙伴算法的内存合并"><a class="header-anchor" href="#伙伴算法的内存合并"></a>伙伴算法的内存合并</h3>
<p>当用户用完内存后会归还,然后根据该内存块实际大小(向上取整为2的幂)归入链表中,在归入之前,</p>
<ol>
<li>我们还要检测他的伙伴内存块是否空闲,</li>
<li>如果空闲就合并在一起,合并后转到1,继续执行.</li>
<li>若果不是空闲的就直接归入链表中.</li>
</ol>
<p>一般来说,伙伴算法实现中会用位图记录内存块是否被使用,用于伙伴内存的合并.</p>
<h3 id="伙伴算法的特点"><a class="header-anchor" href="#伙伴算法的特点"></a>伙伴算法的特点</h3>
<p>显而易见,伙伴算法会浪费大量的内存,(如果需要大小为9的内存块必须分配大小为16的内存块).而优点也是明显的,分配和合并算法都很简单易行.但是,当分配和回收较快的时候,例如分配大小为9的内存块,此时分配16,然后又回收,即合并伙伴内存块,这样会造成不必要的cpu浪费,应该设置链表中内存块的低潮个数,即当链表中内存块个数小于某个值的时候,并不合并伙伴内存块,只要当高于低潮个数的时候才合并.</p>
<h2 id="slab算法"><a class="header-anchor" href="#slab算法"></a>slab算法</h2>
<p>一般来说,伙伴算法的改进算法用于操作系统分配和回收内存,而且内存块的单位较大,利于Linux使用的伙伴算法以页为单位.对于小块内存的分配和回收,伙伴算法就显得有些得不偿失了.</p>
<p>对于小块内存,一般采用slab算法,或者叫做slab机制.</p>
<p>Linux 所使用的 slab 分配器的基础是 Jeff Bonwick 为SunOS 操作系统首次引入的一种算法。Jeff的分配器是围绕对象缓存进行的。在内核中，会为有限的对象集（例如文件描述符和其他常见结构）分配大量内存。Jeff发现对内核中普通对象进行初始化所需的时间超过了对其进行分配和释放所需的时间。因此他的结论是不应该将内存释放回一个全局的内存池，而是将内存保持为针对特定目而初始化的状态。例如，如果内存被分配给了一个互斥锁，那么只需在为互斥锁首次分配内存时执行一次互斥锁初始化函数（mutex_init）即可。后续的内存分配不需要执行这个初始化函数，因为从上次释放和调用析构之后，它已经处于所需的状态中了。</p>
<p>Linux slab分配器使用了这种思想和其他一些思想来构建一个在空间和时间上都具有高效性的内存分配器。</p>
<center>
<img src="/assets/memory-allocation-buddy-system-and-slab-allocator/slab.png" alt="slab allocator"/>
</center>
<p>图中给出了 slab结构的高层组织结构。在最高层是 cache_chain，这是一个 slab 缓存的链接列表。这对于 best-fit算法非常有用，可以用来查找最适合所需要的分配大小的缓存（遍历列表）。cache_chain 的每个元素都是一个 kmem_cache 结构的引用（称为一个 cache）。它定义了一个要管理的给定大小的对象池。</p>
<p>每个缓存都包含了一个 slabs 列表，这是一段连续的内存块（通常都是页面）。存在3 种 slab：<br>
<strong>slabs_full</strong>: 完全分配的slab<br>
<strong>slabs_partial</strong>: 部分分配的slab<br>
<strong>slabs_empty</strong>: 空slab，或者没有对象被分配</p>
<p>slab 列表中的每个 slab都是一个连续的内存块（一个或多个连续页），它们被划分成一个个对象。这些对象是从特定缓存中进行分配和释放的基本元素。注意 slab 是 slab分配器进行操作的最小分配单位，因此如果需要对 slab 进行扩展，这也就是所扩展的最小值。通常来说，每个 slab 被分配为多个对象。</p>
<p>由于对象是从 slab 中进行分配和释放的，因此单个 slab 可以在 slab列表之间进行移动。例如，当一个 slab中的所有对象都被使用完时，就从slabs_partial 列表中移动到 slabs_full 列表中。当一个 slab完全被分配并且有对象被释放后，就从 slabs_full 列表中移动到slabs_partial 列表中。当所有对象都被释放之后，就从 slabs_partial 列表移动到 slabs_empty 列表中。</p>
<h3 id="slab背后的动机"><a class="header-anchor" href="#slab背后的动机"></a>slab背后的动机</h3>
<p>与传统的内存管理模式相比， slab缓存分配器提供了很多优点。首先，内核通常依赖于对小对象的分配，它们会在系统生命周期内进行无数次分配。slab缓存分配器通过对类似大小的对象进行缓存而提供这种功能，从而避免了常见的碎片问题。slab分配器还支持通用对象的初始化，从而避免了为同一目而对一个对象重复进行初始化。最后，slab分配器还可以支持硬件缓存对齐和着色，这允许不同缓存中的对象占用相同的缓存行，从而提高缓存的利用率并获得更好的性能。</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/memory-allocation-buddy-system-and-slab-allocator/">http://xnerv.wang/memory-allocation-buddy-system-and-slab-allocator/</a></strong><br>
转载自：<a href="http://blog.csdn.net/u013009575/article/details/17751147">内存分配-----伙伴算法和slab算法</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Heap</tag>
        <tag>Linux</tag>
        <tag>Memory Management</tag>
        <tag>Buddy System</tag>
        <tag>Slab Allocator</tag>
      </tags>
  </entry>
  <entry>
    <title>Memory Allocation Mechanism in Linux（转载）</title>
    <url>/memory-allocation-mechanism-in-linux/</url>
    <content><![CDATA[<p>Each Linux process has its own dedicated address space dynamically translated into physical memory address space by the MMU (and the kernel) [1]. To each individual process, the view is as if it alone has full access to the system’s physical memory [2]. More importantly, the address space of even a single process can be much larger than physical memory. However, the memory usage of each process is bounded with Linux resource limitation (via setrlimit()).</p>
<center>
<img src="/assets/memory-allocation-mechanism-in-linux/linux_malloc.png" alt="linux malloc"/>
</center>
<span id="more"></span>
<p>The space is divided into several parts, including text, data, heap and stack, etc. Stack and heap are the two parts we’ll talk about. At the time of creation, the system creates heap and stack segment for processes. While stack is the reserved memory as scratch space for thread execution, heap is memory set aside for dynamic allocation. <strong>Each thread gets a stack, while there’s typically only one heap for the application.</strong> The OS allocates the stack for each system-level thread when the thread is created, and the <strong>stack size is predetermined in creation</strong>. Typically, the OS is called by the language runtime to allocate the heap for the application. <strong>The heap size is set on application startup, but it can grow by calling allocators to request more memory from OS</strong>. [3]</p>
<p>In the runtime, dynamic memory management is operated on heap. Standard C functions <code>malloc()</code> and <code>free()</code> are used to allocate and deallocate memory blocks. <strong>malloc() is a library call, not a system call</strong>, which directly deals with <strong>paged virtual memory</strong> instead of physical memory (which is handled by the kernel). As the system creates heap and stack segment for processes at the time of creation, malloc() already has some memory to work with without having to call the OS for every memory request from the program. If more memory is needed (either due to malloc() or due to stack growing), then a system call <code>brk()/sbrk()/mmap()</code> is made to <u>obtain a contiguous (w.r.t virtual memory address) chunk of memory, which the malloc() further slices and dices in smaller chunks and hands out to the application</u>. [3,4]</p>
<p>Various different implementations of malloc() attempt to satisfy any given request from the <u>memory which has already been allocated to the process</u>. And, these allocators are categorized mainly by how they keep track of the free blocks that they can use to parcel out memory to applications. Main categories are first-fit, best-fit and worst-fit, etc. [5]</p>
<h2 id="Memory-allocation-inside-kernel"><a class="header-anchor" href="#Memory-allocation-inside-kernel"></a>Memory allocation inside kernel</h2>
<p><strong>Actual physical memory is managed by Linux kernel</strong>. The kernel treats physical pages as the basic unit of memory management. Although the processor’s smallest addressable unit is usually word (or even a byte), the MMU typically deals in pages. The MMU manages page tables with page-sized granularity. [2] The space in between the heap and the stack is unallocated space, therefore the top of the heap is often referred to as the “break point” because this is where the memory space is split. As more dynamic memory is needed, the application must inform the OS to move up the break point to allocate more memory for the process, thus increasing the heap size. The allocation is usually achieved by brk()/sbrk(). On a call to brk(), the Linux kernel performs a few checks and then allocates the new memory for the process. First, the kernel aligns the old and the new break point to be on page boundaries. <strong>A page (usually 4KB) is the smallest unit of memory that the OS will give to any process.</strong> Then, the system call checks the limits and the kernel verifies that it is safe to allocate the required memory, and finally the kernel calls <code>do_brk()</code> function to increase the memory for the process. <u>Each process has a map/page-table to take a certain range of addresses in the processes’ address space and to map it physical memory.</u> When the process calls brk(), the OS increases the map size for the heap, thus giving the process more memory to use.</p>
<p>When the map size is increased, the new pages that are mapped into the address space do not actually exist, i.e., no physical pages are allocated for the new mapping. The OS, by increasing the map size, <strong>only provides a mapping between the new addresses in the process space and the memory that those pages will occupy when they are used.</strong></p>
<h2 id="Summary-of-malloc-workflow"><a class="header-anchor" href="#Summary-of-malloc-workflow"></a>Summary of malloc() workflow</h2>
<p>The <code>malloc()</code> calls an internal helper, <code>chunk_alloc()</code>, to find the block to return to the user. This helper is the function that looks through the bins for a match to return. If its cannot find a suitable match, it calls <code>malloc_extend_top()</code>, another helper function, that actually calls <code>sbrk()</code>.</p>
<p>Once the memory is retrieved from the OS, chunk_alloc() splits off the piece that is required for the current location. It then adds the remainder to the appropriate bin for future use and returns the new block to malloc(), which then returns that block to the user. As it turns out, most of the work that malloc() does deals with deciding how to manage memory that has already been allocated by the OS.</p>
<p>[1] A Malloc Tutorial, 2009<br>
[2] <a href="http://www.makelinux.net/books/lkd2/?u=ch14">http://www.makelinux.net/books/lkd2/?u=ch14</a><br>
[3] <a href="http://stackoverflow.com/questions/79923/what-and-where-are-the-stack-and-heap">http://stackoverflow.com/questions/79923/what-and-where-are-the-stack-and-heap</a><br>
[4] <a href="http://cs.boisestate.edu/~amit/teaching/453/slides/memory-management-handout.pdf">http://cs.boisestate.edu/~amit/teaching/453/slides/memory-management-handout.pdf</a><br>
[5] <a href="http://www.linux-mag.com/id/827/">http://www.linux-mag.com/id/827/</a></p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/memory-allocation-mechanism-in-linux/">http://xnerv.wang/memory-allocation-mechanism-in-linux/</a></strong><br>
转载自：<a href="http://iarchsys.com/?p=692">Memory Allocation Mechanism in Linux</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Heap</tag>
        <tag>Linux</tag>
        <tag>Memory Management</tag>
        <tag>reprint</tag>
      </tags>
  </entry>
  <entry>
    <title>Memory Barriers Are Like Source Control Operations（转载）</title>
    <url>/memory-barriers-are-like-source-control-perations/</url>
    <content><![CDATA[<p>If you use source control, you’re on your way towards understanding memory ordering, an important consideration when writing lock-free code in C, C++ and other languages.</p>
<p>In my last post, I wrote about <a href="http://preshing.com/20120625/memory-ordering-at-compile-time">memory ordering at compile time</a>, which forms one half of the memory ordering puzzle. This post is about the other half: memory ordering at runtime, on the processor itself. Like compiler reordering, processor reordering is invisible to a single-threaded program. It only becomes apparent when <a href="http://preshing.com/20120612/an-introduction-to-lock-free-programming">lock-free techniques</a> are used – that is, when shared memory is manipulated without any mutual exclusion between threads. However, unlike compiler reordering, the effects of processor reordering are <a href="http://preshing.com/20120515/memory-reordering-caught-in-the-act">only visible in multicore and multiprocessor systems</a>.</p>
<span id="more"></span>
<p>You can enforce correct memory ordering on the processor by issuing any instruction which acts as a <strong>memory barrier</strong>. In some ways, this is the only technique you need to know, because when you use such instructions, compiler ordering is taken care of automatically. Examples of instructions which act as memory barriers include (but are not limited to) the following:</p>
<ul>
<li>Certain inline assembly directives in GCC, such as the PowerPC-specific <code>asm volatile(&quot;lwsync&quot; ::: &quot;memory&quot;)</code></li>
<li>Any <a href="http://msdn.microsoft.com/en-us/library/windows/desktop/ms684122.aspx">Win32 Interlocked operation</a>, except on Xbox 360</li>
<li>Many operations on <a href="http://en.cppreference.com/w/cpp/atomic/atomic">C++11 atomic types</a>, such as <code>load(std::memory_order_acquire)</code></li>
<li>Operations on POSIX mutexes, such as <a href="http://linux.die.net/man/3/pthread_mutex_lock"><code>pthread_mutex_lock</code></a></li>
</ul>
<p>Just as there are many instructions which act as memory barriers, there are many different types of memory barriers to know about. Indeed, not all of the above instructions produce the same kind of memory barrier – leading to another possible area of confusion when writing lock-free code. In an attempt to clear things up to some extent, I’d like to offer an analogy which I’ve found helpful in understanding the vast majority (but not all) of possible memory barrier types.</p>
<p>To begin with, consider the architecture of a typical multicore system. Here’s a device with two cores, each having 32 KiB of private L1 data cache. There’s 1 MiB of L2 cache shared between both cores, and 512 MiB of main memory.</p>
<center>
<img src="/assets/memory-barriers-are-like-source-control-perations/cpu-diagram.png" alt="cpu diagram"/>
</center>
<p>A multicore system is a bit like a group of programmers collaborating on a project using a bizarre kind of source control strategy. For example, the above dual-core system corresponds to a scenario with just two programmers. Let’s name them Larry and Sergey.</p>
<center>
<img src="/assets/memory-barriers-are-like-source-control-perations/source-control-analogy.png" alt="source control analogy"/>
</center>
<p>On the right, we have a shared, central repository – this represents a combination of main memory and the shared L2 cache. Larry has a complete working copy of the repository on his local machine, and so does Sergey – these (effectively) represent the L1 caches attached to each CPU core. There’s also a scratch area on each machine, to privately keep track of registers and/or local variables. Our two programmers sit there, feverishly editing their working copy and scratch area, all while making decisions about what to do next based on the data they see – much like a thread of execution running on that core.</p>
<p>Which brings us to the source control strategy. In this analogy, the source control strategy is very strange indeed. As Larry and Sergey modify their working copies of the repository, their modifications are constantly <strong>leaking</strong> in the background, to and from the central repository, at totally random times. Once Larry edits the file X, his change will leak to the central repository, but there’s no guarantee about when it will happen. It might happen immediately, or it might happen much, much later. He might go on to edit other files, say Y and Z, and those modifications might leak into the respository <em>before</em> X gets leaked. In this manner, stores are effectively reordered on their way to the repository.</p>
<p>Similarly, on Sergey’s machine, there’s no guarantee about the timing or the order in which those changes leak <em>back</em> from the repository into <em>his</em> working copy. In this manner, loads are effectively reordered on their way out of the repository.</p>
<p>Now, if each programmer works on completely separate parts of the repository, neither programmer will be aware of these background leaks going on, or even of the other programmer’s existence. That would be analogous to running two independent, single-threaded processes. In this case, the <a href="http://preshing.com/20120625/memory-ordering-at-compile-time">cardinal rule of memory ordering</a> is upheld.</p>
<p>The analogy becomes more useful once our programmers start working on the same parts of the repository. Let’s revisit the example I gave <a href="http://preshing.com/20120515/memory-reordering-caught-in-the-act">in an earlier post</a>. X and Y are global variables, both initially 0:</p>
<center>
<img src="/assets/memory-barriers-are-like-source-control-perations/marked-example2-2.png" alt="marked example 2-2"/>
</center>
<p>Think of X and Y as files which exist on Larry’s working copy of the repository, Sergey’s working copy, and the central repository itself. Larry writes 1 to his working copy of X and Sergey writes 1 to his working copy of Y at roughly the same time. If neither modification has time to leak to the repository and back before each programmer looks up his working copy of the <em>other</em> file, they’ll end up with both r1 = 0 and r2 = 0. This result, which may have seemed counterintuitive at first, actually becomes pretty obvious in the source control analogy.</p>
<center>
<img src="/assets/memory-barriers-are-like-source-control-perations/iriw-state.png" alt="iriw state"/>
</center>
<h2 id="Types-of-Memory-Barrier"><a class="header-anchor" href="#Types-of-Memory-Barrier"></a>Types of Memory Barrier</h2>
<p>Fortunately, Larry and Sergey are not entirely at the mercy of these random, unpredictable leaks happening in the background. They also have the ability to issue special instructions, called fence instructions, which act as memory barriers. For this analogy, it’s sufficient to define four types of memory barrier, and thus four different fence instructions. Each type of memory barrier is named after the type of memory reordering it’s designed to prevent: for example, <code>#StoreLoad</code> is designed to prevent the reordering of a store followed by a load.</p>
<center>
<img src="/assets/memory-barriers-are-like-source-control-perations/barrier-types.png" alt="barrier types"/>
</center>
<p>As <a href="http://g.oswego.edu/dl/jmm/cookbook.html">Doug Lea points out</a>, these four categories map pretty well to specific instructions on real CPUs – though not exactly. Most of the time, a real CPU instruction acts as some combination of the above barrier types, possibly in addition to other effects. In any case, once you understand these four types of memory barriers in the source control analogy, you’re in a good position to understand a large number of instructions on real CPUs, as well as several higher-level programming language constructs.</p>
<h3 id="LoadLoad"><a class="header-anchor" href="#LoadLoad"></a>#LoadLoad</h3>
<p>A LoadLoad barrier effectively prevents reordering of loads performed before the barrier with loads performed after the barrier.</p>
<p>In our analogy, the <code>#LoadLoad</code> fence instruction is basically equivalent to a <strong>pull</strong> from the central repository. Think <code>git pull</code>, <code>hg pull</code>, <code>p4 sync</code>, <code>svn update</code> or <code>cvs update</code>, all acting on the entire repository. If there are any merge conflicts with his local changes, let’s just say they’re resolved randomly.</p>
<center>
<img src="/assets/memory-barriers-are-like-source-control-perations/loadload.png" alt="loadload"/>
</center>
<p>Mind you, there’s no guarantee that <code>#LoadLoad</code> will pull the latest, or head, revision of the entire repository! It could very well pull an older revision than the head, as long as that revision is <em>at least as new as the newest value which leaked from the central repository into his local machine</em>.</p>
<p>This may sound like a weak guarantee, but it’s still a perfectly good way to prevent seeing stale data. Consider the classic example, where Sergey checks a shared flag to see if some data has been published by Larry. If the flag is true, he issues a <code>#LoadLoad</code> barrier before reading the published value:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (IsPublished)                   <span class="comment">// Load and check shared flag</span></span><br><span class="line">&#123;</span><br><span class="line">    LOADLOAD_FENCE();              <span class="comment">// Prevent reordering of loads</span></span><br><span class="line">    <span class="keyword">return</span> Value;                  <span class="comment">// Load published value</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Obviously, this example depends on having the <code>IsPublished</code> flag leak into Sergey’s working copy by itself. It doesn’t matter exactly when that happens; once the leaked flag has been observed, he issues a <code>#LoadLoad</code> fence to prevent reading some value of <code>Value</code> which is older than the flag itself.</p>
<h3 id="StoreStore"><a class="header-anchor" href="#StoreStore"></a>#StoreStore</h3>
<p>A StoreStore barrier effectively prevents reordering of stores performed before the barrier with stores performed after the barrier.</p>
<p>In our analogy, the <code>#StoreStore</code> fence instruction corresponds to a <strong>push</strong> to the central repository. Think <code>git push</code>, <code>hg push</code>, <code>p4 submit</code>, <code>svn commit</code> or <code>cvs commit</code>, all acting on the entire repository.</p>
<center>
<img src="/assets/memory-barriers-are-like-source-control-perations/storestore.png" alt="storestore"/>
</center>
<p>As an added twist, let’s suppose that <code>#StoreStore</code> instructions are <strong>not instant</strong>. They’re performed in a delayed, asynchronous manner. So, even though Larry executes a <code>#StoreStore</code>, we can’t make any assumptions about when all his previous stores finally become visible in the central repository.</p>
<p>This, too, may sound like a weak guarantee, but again, it’s perfectly sufficient to prevent Sergey from seeing any stale data published by Larry. Returning to the same example as above, Larry needs only to publish some data to shared memory, issue a <code>#StoreStore</code> barrier, then set the shared flag to true:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">Value = x;                         <span class="comment">// Publish some data</span></span><br><span class="line">STORESTORE_FENCE();</span><br><span class="line">IsPublished = <span class="number">1</span>;                   <span class="comment">// Set shared flag to indicate availability of data</span></span><br></pre></td></tr></table></figure>
<p>Again, we’re counting on the value of <code>IsPublished</code> to leak from Larry’s working copy over to Sergey’s, all by itself. Once Sergey detects that, he can be confident he’ll see the correct value of <code>Value</code>. What’s interesting is that, for this pattern to work, <code>Value</code> does not even need to be an atomic type; it could just as well be a huge structure with lots of elements.</p>
<h3 id="LoadStore"><a class="header-anchor" href="#LoadStore"></a>#LoadStore</h3>
<center>
<img src="/assets/memory-barriers-are-like-source-control-perations/get-back-to-later.png" alt="get back to later"/>
</center>
<p>Unlike <code>#LoadLoad</code> and <code>#StoreStore</code>, there’s no clever metaphor for <code>#LoadStore</code> in terms of source control operations. The best way to understand a <code>#LoadStore</code> barrier is, quite simply, in terms of instruction reordering.</p>
<p>Imagine Larry has a set of instructions to follow. Some instructions make him load data from his private working copy into a register, and some make him store data from a register back into the working copy. Larry has the ability to juggle instructions, but only in specific cases. Whenever he encounters a load, he looks ahead at any stores that are coming up after that; if the stores are <em>completely unrelated</em> to the current load, then he’s allowed to skip ahead, do the stores first, then come back afterwards to finish up the load. In such cases, the cardinal rule of memory ordering – never modify the behavior of a single-threaded program – is still followed.</p>
<p>On a real CPU, such instruction reordering might happen on certain processors if, say, there is a cache miss on the load followed by a cache hit on the store. But in terms of understanding the analogy, such hardware details don’t really matter. Let’s just say Larry has a boring job, and this is one of the few times when he’s allowed to get creative. Whether or not he chooses to do it is completely unpredictable. Fortunately, this is a relatively inexpensive type of reordering to prevent; when Larry encounters a <code>#LoadStore</code> barrier, he simply refrains from such reordering around that barrier.</p>
<p>In our analogy, it’s valid for Larry to perform this kind of LoadStore reordering even when there is a <code>#LoadLoad</code> or <code>#StoreStore</code> barrier between the load and the store. However, on a real CPU, instructions which act as a <code>#LoadStore</code> barrier typically act as at least one of those other two barrier types.</p>
<h3 id="StoreLoad"><a class="header-anchor" href="#StoreLoad"></a>#StoreLoad</h3>
<p>A StoreLoad barrier ensures that all stores performed before the barrier are visible to other processors, and that all loads performed after the barrier receive the latest value that is visible at the time of the barrier. In other words, it effectively prevents reordering of all stores before the barrier against all loads after the barrier, respecting the way a <a href="http://preshing.com/20120612/an-introduction-to-lock-free-programming#sequential-consistency">sequentially consistent</a> multiprocessor would perform those operations.</p>
<p><code>#StoreLoad</code> is unique. It’s the only type of memory barrier that will prevent the result r1 = r2 = 0 in the example given in <a href="http://preshing.com/20120515/memory-reordering-caught-in-the-act">Memory Reordering Caught in the Act</a>; the same example I’ve repeated earlier in this post.</p>
<p>If you’ve been following closely, you might wonder: How is <code>#StoreLoad</code> different from a <code>#StoreStore</code> followed by a <code>#LoadLoad</code>? After all, a <code>#StoreStore</code> pushes changes to the central repository, while <code>#LoadLoad</code> pulls remote changes back. However, those two barrier types are insufficient. Remember, the push operation may be delayed for an arbitrary number of instructions, and the pull operation might not pull from the head revision. This hints at why the PowerPC’s <code>lwsync</code> instruction – which acts as all three <code>#LoadLoad</code>, <code>#LoadStore</code> and <code>#StoreStore</code> memory barriers, but not <code>#StoreLoad</code> – is insufficient to prevent r1 = r2 = 0 in that example.</p>
<p>In terms of the analogy, a <code>#StoreLoad</code> barrier could be achieved by pushing all local changes to the central repostitory, waiting for that operation to complete, then pulling the absolute latest head revision of the repository. On most processors, instructions that act as a <code>#StoreLoad</code> barrier tend to be more expensive than instructions acting as the other barrier types.</p>
<center>
<img src="/assets/memory-barriers-are-like-source-control-perations/storeload.png" alt="storeload"/>
</center>
<p>If we throw a <code>#LoadStore</code> barrier into that operation, which shouldn’t be a big deal, then what we get is a full memory fence – acting as all four barrier types at once. <a href="http://g.oswego.edu/dl/jmm/cookbook.html">As Doug Lea also points out</a>, it just so happens that on all current processors, every instruction which acts as a <code>#StoreLoad</code> barrier also acts as a full memory fence.</p>
<h2 id="How-Far-Does-This-Analogy-Get-You"><a class="header-anchor" href="#How-Far-Does-This-Analogy-Get-You"></a>How Far Does This Analogy Get You?</h2>
<p>As I’ve mentioned previously, <a href="http://preshing.com/20120612/an-introduction-to-lock-free-programming#different-processors-have">every processor has different habits</a> when it comes to memory ordering. The x86/64 family, in particular, has a strong memory model; it’s known to keep memory reordering to a minimum. PowerPC and ARM have weaker memory models, and the Alpha is famous for being in a league of its own. Fortunately, the analogy presented in this post corresponds to a <a href="http://preshing.com/20120930/weak-vs-strong-memory-models">weak memory model</a>. If you can wrap your head around it, and enforce correct memory ordering using the fence instructions given here, you should be able to handle most CPUs.</p>
<p>The analogy also corresponds pretty well to the abstract machine targeted by both C++11 (formerly known as C++0x) and C11. Therefore, if you write lock-free code using the standard library of those languages while keeping the above analogy in mind, it’s more likely to function correctly on any platform.</p>
<p>In this analogy, I’ve said that each programmer represents a single thread of execution running on a separate core. On a real operating system, threads tend to move between different cores over the course of their lifetime, but the analogy still works. I’ve also alternated between examples in machine language and examples written in C/C++. Obviously, we’d prefer to stick with C/C++, or another high-level language; this is possible because again, any operation which acts as a memory barrier also prevents <a href="http://preshing.com/20120625/memory-ordering-at-compile-time">compiler reordering</a>.</p>
<p>I haven’t written about every type of memory barrier yet. For instance, there are also <a href="http://www.mjmwired.net/kernel/Documentation/memory-barriers.txt#305">data dependency barriers</a>. I’ll describe those further in a future post. Still, the four types given here are the big ones.</p>
<p>If you’re interested in how CPUs work under the hood – things like stores buffers, cache coherency protocols and other hardware implementation details – and why they perform memory reordering in the first place, I’d recommend the <a href="http://www.rdrop.com/users/paulmck/scalability/paper/whymb.2010.07.23a.pdf">fine</a> <a href="http://www.kernel.org/doc/Documentation/memory-barriers.txt">work</a> of Paul McKenney &amp; David Howells. Indeed, I suspect most programmers who have successfully written lock-free code have at least a passing familiarity with such hardware details.</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/memory-barriers-are-like-source-control-perations/">http://xnerv.wang/memory-barriers-are-like-source-control-perations/</a></strong><br>
转载自：<a href="http://preshing.com/20120710/memory-barriers-are-like-source-control-operations/">Memory Barriers Are Like Source Control Operations</a></p>
]]></content>
      <categories>
        <category>OS</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>OS</tag>
        <tag>Memory Barrier</tag>
      </tags>
  </entry>
  <entry>
    <title>关于MinGW和Cygwin的一些个人总结和推测</title>
    <url>/mingw-cygwin-summary-and-thinking/</url>
    <content><![CDATA[<p>本文主要是对MinGW和Cygwin相关的一些名词的研究和推测，以求澄清一些似乎而非的概念，并记录当前已经弄清楚的一些问题，以及还需要进一步调研的一些细节。所有调研都基于Windows平台。</p>
<h2 id="关于MinGW和Cygwin的关系"><a class="header-anchor" href="#关于MinGW和Cygwin的关系"></a>关于MinGW和Cygwin的关系</h2>
<p>网上大部分博文复制粘贴的文章都是讨论MinGW和Cygwin的区别和优劣。而我主要是分析两者的联系，以及一些需要同时用到MinGW和Cygwin的交叉编译场景。</p>
<p>从<a href="https://en.wikipedia.org/wiki/MinGW">MinGW的维基百科</a>上看，Cygwin是提供一个模拟的POSIX层（cygwin1.dll）。我推测Cygwin也提供了一系列基于Cygwin的编译工具，在将需要移植的Linux代码在Cygwin上重新编译后，可以获得可以在Windows上直接运行的exe，而这个exe调用的还是POSIX风格的API，只不过这些API由cygwin1.dll提供模拟实现。而MinGW也提供了一系列编译工具，但MinGW-GCC是在编译时将代码中的POSIX API调用直接修改为对应的Windows API调用，从而不需要一个额外的dll转换层。需要额外提到的是，gcc的这种在编译时直接修改调用的API的行为不仅不少见，而且非常常见，在64位Linux上编译C++程序时，例如调用open这个函数，实际上在gcc编译后，调用的是libc中的open64函数，这个可以通过objdump导出外部依赖符号表来确认。另外就是，MinGW并不提供某些难以用Windows API实现的POSIX API，例如fork()，mmap()和ioctl()。</p>
<span id="more"></span>
<h2 id="MinGW和MinGW-w64"><a class="header-anchor" href="#MinGW和MinGW-w64"></a>MinGW和MinGW-w64</h2>
<p>MinGW（mingw32）据说更新太慢代码太老，因此另一帮人就新搞了一个MinGW-w64，据说老的MinGW不支持编译64位程序。不知道是不是这就意味着可以完全放弃掉MinGW而直接采用MinGW-x64？</p>
<p>在安装MinGW时需要选择线程模型：posix或win32。从<a href="https://stackoverflow.com/questions/17242516/mingw-w64-threads-posix-vs-win32">mingw-w64 threads: posix vs win32</a>看来，win32是在C++11之前MinGW-GCC搞的一套基于win32 threads模型的多线程库，而posix则是基于libwinpthreads，支持C++11的一些新的头文件。有另外一个单独的GitHub项目<a href="https://github.com/meganz/mingw-std-threads">mingw-std-threads</a>可以让win32模型也支持这些C++11头文件。</p>
<p>MinGW-w64可以安装在Windows上，可以安装在Linux上，甚至可以安装在Cygwin里（<a href="https://cygwin.com/install.html">而CygWin看起来只能安装在Windows中</a>）。MinGW（mingw32）好像有另外一个相关项目<a href="http://www.mingw.org/wiki/linuxcrossmingw">MinGW cross compiling environment</a>提供Linux安装，但感觉项目不是很活跃。并且从这篇<a href="https://mxe.cc/#history">更新日志</a>来看，似乎作者已经放弃更新并转向MinGW-w64。</p>
<h2 id="MSYS"><a class="header-anchor" href="#MSYS"></a>MSYS</h2>
<p>根据<a href="http://www.mingw.org/wiki/msys">MinGW官网对于MSYS的描述</a>，MSYS是对MinGW的补充，提供了bash，make， gawk和grep等GNU工具来辅助编译。从网上可以找到的一些MinGW编译入门文章来看，完全可以在Windows cmd环境中调用MinGW的gcc命令行去编译基于MinGW的Windows程序，并不是一定需要在bash环境中进行，但是像bash脚本这种应该还是需要bash环境的。另外据说<a href="https://github.com/msys2/msys2/wiki/History">MSYS是从Cygwin派生出来的分支</a>，本来我推测像MSYS中的gcc应该是运行在cygwin1.dll或者类似名字的dll模拟层上。但是检查了gcc的dll依赖关系：<br>
<img src="/assets/mingw-cygwin-summary-and-thinking/mingw-gcc-dep.png" alt=""></p>
<p>发现MinGW上的gcc最终似乎是直接依赖于Windows的dlls，并没有类似cygwin1.dll的东西。这种有点奇怪了，难道这个gcc是通过Cygwin上的MinGW-GCC用自举（bootstrapping）的方式创建出来的？找到关于MinGW-x64有关自举编译的一篇文章<a href="https://sourceforge.net/p/mingw-w64/wiki2/Native%20Win64%20compiler/">Creating a native Win64 compiler</a>，我怀疑MinGW是不是也是用的类似的自举编译gcc。</p>
<p>但是再看bash的话，bash.exe却还是依赖于msys1.0.dll以及其它一些msys开头的dlls。猜测这些dlls应该就是类似于cygwin1.dll的模拟层。MinGW和MSYS是通过同一个安装程序来安装，推测由于gcc.exe属于MinGW，而bash.exe属于MSYS，而只有MSYS的工具才需要依赖msys相关的dlls。检查安装路径后果然发现，gcc.exe是在<code>C:\MinGW\bin</code>下面，而bash.exe是在<code>C:\MinGW\msys\1.0\bin</code>下面，印证了我的想法。<br>
<img src="/assets/mingw-cygwin-summary-and-thinking/mingw-bash-dep.png" alt=""></p>
<p>此外结合<a href="https://zh.wikipedia.org/wiki/MinGW">MinGW的中文维基百科</a>和我自己的MinGW-w64安装经历，选择i686工具链时可以从DWARF和SJLJ这两种异常实现机制中二选一，而选择x86_64时需要从SEH和SJLJ中二选一。</p>
<h2 id="MSYS2"><a class="header-anchor" href="#MSYS2"></a>MSYS2</h2>
<p>回过头来再看看MSYS2。MSYS2似乎是配套MinGW-w64出现的，提供三种配置的模式：msys2，mingw64（使用mingw-w64 x86_64 toolchain工具链）和mingw32（使用mingw-w64 i686 toolchain工具链）。个人推测msys2模式编译出来的程序需要依赖msys2.0.dll，就像Cygwin下编译出来的程序一样。据说MSYS2相对于Cygwin的最大区别是移植了包管理工具Pacman。据说三种模式的主要区别是在$PATH中的搜索优先顺序不同，msys2只使用<code>/usr/local/bin</code>和<code>/usr/bin</code>下的工具，mingw64优先使用<code>/mingw64/bin</code>下的工具，mingw32优先使用<code>/mingw32/bin</code>下的工具。</p>
<p>类似于MinGW和MSYS，安装MSYS2的时候也会自动安装MinGW-w64。而且看起来在x64平台上是mingw64和mingw32会同时被安装。</p>
<p>我首先单独安装了MinGW-w64，看起来其中的gcc等工具也是直接依赖于Windows的dlls，并没有一个中间层dll。并且在安装的时候需要选择是用x86_64工具链还是i686工具链，以及异常的处理方式。这么看来安装MSYS2的话就可以同时拥有两种工具链了。安装MSYS2时并没有要求选择异常处理机制和所使用的线程库，根据<a href="https://sourceforge.net/p/mingw-w64/discussion/723797/thread/ef7d51a4/">What’s the difference between Mingw-builds and Mingw packages in Msys2</a>这个帖子中的讨论，看起来</p>
<blockquote>
<p>MSYS2 only provides posix thread model, dwarf for i686, seh for x86_64</p>
</blockquote>
<p>使用Pacman直接安装的gcc依赖于msys2系列的dlls。我估计这就类似于在Cygwin上直接安装gcc，会依赖于cygwin1.dll。如果要安装只依赖于Windows native dlls的gcc，应该安装mingw版本的gcc。<br>
<img src="/assets/mingw-cygwin-summary-and-thinking/msys2-usr-gcc-dep.png" alt=""></p>
<p>安装mingw-w64-i686-toolchain和mingw-w64-x86_64-toolchain则分别会在<code>mingw32\bin</code>和<code>mingw64\bin</code>目录下产生gcc.exe，并且只依赖于Windows dlls和libwinpthread-1.dll，看来这个就是MinGW-w64版本的gcc，可以生成不依赖于任何dll的Windows程序。</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/mingw-cygwin-summary-and-thinking/">http://xnerv.wang/mingw-cygwin-summary-and-thinking/</a></strong></p>
]]></content>
      <categories>
        <category>编译器</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>MinGW</tag>
        <tag>编译器</tag>
        <tag>Cygwin</tag>
      </tags>
  </entry>
  <entry>
    <title>(Stack Overflow) mmap() vs. reading blocks</title>
    <url>/mmap-vs-reading-blocks/</url>
    <content><![CDATA[<h2 id="Question"><a class="header-anchor" href="#Question"></a>Question</h2>
<p>I’m working on a program that will be processing files that could potentially be 100GB or more in size. The files contain sets of variable length records. I’ve got a first implementation up and running and am now looking towards improving performance, particularly at doing I/O more efficiently since the input file gets scanned many times.</p>
<p>Is there a rule of thumb for using mmap() versus reading in blocks via C++'s fstream library? What I’d like to do is read large blocks from disk into a buffer, process complete records from the buffer, and then read more.</p>
<p>The mmap() code could potentially get very messy since mmap’d blocks need to lie on page sized boundaries (my understanding) and records could potentially like across page boundaries. With fstreams, I can just seek to the start of a record and begin reading again, since we’re not limited to reading blocks that lie on page sized boundaries.</p>
<p>How can I decide between these two options without actually writing up a complete implementation first? Any rules of thumb (e.g., mmap() is 2x faster) or simple tests?</p>
<span id="more"></span>
<h2 id="Answer-by-Dietrich-Epp"><a class="header-anchor" href="#Answer-by-Dietrich-Epp"></a>Answer by Dietrich Epp</h2>
<p>I was trying to find the final word on mmap / read performance on Linux and I came across a nice post (<a href="http://marc.info/?l=linux-kernel&amp;m=95496636207616&amp;w=2">link</a>) on the Linux kernel mailing list. It’s from 2000, so there have been many improvements to IO and virtual memory in the kernel since then, but it nicely explains the reason why <code>mmap</code> or <code>read</code> might be faster or slower.</p>
<ul>
<li>A call to <code>mmap</code> has more overhead than <code>read</code> (just like <code>epoll</code> has more overhead than <code>poll</code>, which has more overhead than <code>read</code>). Changing virtual memory mappings is a quite expensive operation on some processors for the same reasons that switching between different processes is expensive.</li>
<li>The IO system can already use the disk cache, so if you read a file, you’ll hit the cache or miss it no matter what method you use.</li>
</ul>
<p>However,</p>
<ul>
<li>Memory maps are generally faster for random access, especially if your access patterns are sparse and unpredictable.</li>
<li>Memory maps allow you to <em>keep</em> using pages from the cache until you are done. This means that if you use a file heavily for a long period of time, then close it and reopen it, the pages will still be cached. With <code>read</code>, your file may have been flushed from the cache ages ago. This does not apply if you use a file and immediately discard it. (If you try to <code>mlock</code> pages just to keep them in cache, you are trying to outsmart the disk cache and this kind of foolery rarely helps system performance).</li>
<li>Reading a file directly is very simple and fast.</li>
</ul>
<p>The discussion of mmap/read reminds me of two other performance discussions:</p>
<ul>
<li>
<p>Some Java programmers were shocked to discover that nonblocking I/O is often slower than blocking I/O, which made perfect sense if you know that nonblocking I/O requires making more syscalls.</p>
</li>
<li>
<p>Some other network programmers were shocked to learn that <code>epoll</code> is often slower than <code>poll</code>, which makes perfect sense if you know that managing <code>epoll</code> requires making more syscalls.</p>
</li>
</ul>
<p><strong>Conclusion:</strong> Use memory maps if you access data randomly, keep it around for a long time, or if you know you can share it with other processes (<code>MAP_SHARED</code> isn’t very interesting if there is no actual sharing). Read files normally if you access data sequentially or discard it after reading. And if either method makes your program less complex, do <em>that</em>. For many real world cases there’s no sure way to show one is faster without testing your actual application and NOT a benchmark.</p>
<p>(Sorry for necro’ing this question, but I was looking for an answer and this question kept coming up at the top of Google results.)</p>
<hr>
<p><strong>Article link: <a href="http://xnerv.wang/mmap-vs-reading-blocks/">http://xnerv.wang/mmap-vs-reading-blocks/</a></strong><br>
Reprinted from: <a href="https://stackoverflow.com/q/45972">(Stack Overflow) mmap() vs. reading blocks</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>OS</tag>
        <tag>Linux</tag>
        <tag>Stack Overflow</tag>
        <tag>Memory Management</tag>
        <tag>mmap</tag>
      </tags>
  </entry>
  <entry>
    <title>Monitoring Memory Clerk and Buffer Pool Allocations in SQL Server（转载）</title>
    <url>/monitoring-memory-clerk-and-buffer-pool-allocations-in-sql-server/</url>
    <content><![CDATA[<p>The following article applies to SQL Server versions 2008 +</p>
<p>Adequate memory is one of the most important factors for a well-functioning instance of SQL Server. By design SQL Server manages its own memory allocations via the SQLOS rather than having the servers Operating System perform this task.</p>
<p>Therefore it’s safe to say that monitoring SQL Servers memory use is a very important administrative task and in this post I am going to show you how to use Dynamic Management Views to take a closer look at how SQL is using memory and how these benefit troubleshooting activities.</p>
<p>Before we do that we need to see how much memory is on our server and how much is allocated to be used by SQL itself. This relates to the very first paragraph in this post, the difference between total memory and SQL memory is allocated to the operating system and how much that should be is really dependent on the total memory in the server. I have always started with a setting of 4Gb or 10% of the total memory, whichever is more and tested regularly.</p>
<span id="more"></span>
<p>To view the total server memory use the following query against the sys.dm_os_sys_memory DMV:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> total_physical_memory_kb <span class="operator">/</span> <span class="number">1024</span> <span class="keyword">AS</span> MemoryMb</span><br><span class="line"><span class="keyword">FROM</span> sys.dm_os_sys_memory</span><br></pre></td></tr></table></figure>
<p>To view SQLs allocation we can query the sys.configurations table to see how SQL has been configured:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> name, value_in_use <span class="keyword">FROM</span> sys.configurations</span><br><span class="line"><span class="keyword">WHERE</span> name <span class="keyword">LIKE</span> <span class="string">&#x27;max server memory%&#x27;</span></span><br></pre></td></tr></table></figure>
<p>This is an incredibly important setting for SQL Server because its default value at installation can cause performance problems. The reason is SQLOS and by default it will be allocated all of the RAM in the server and will dynamically release memory back to the Operating System by monitoring a memory thread. Whilst that is all well and good we can avoid this release of memory entirely be sensibly capping SQL Servers memory.</p>
<p>It’s also worth noting what else is running on your server. I’m a huge advocate of having dedicated SQL instances without anything else running on them and that applies to items like Analysis, Integration or Reporting services too. Whilst that is perfectly good advice it isn’t always possible for a number of reasons but again just make sure you have adequate resource.</p>
<p>A common misconception is that the maximum server memory setting applies to all of SQL Server, it doesn’t and its quite common to see, at the server level, SQL Server using more memory than this setting allows. The reason for this is that the configuration item only applies to the SQL Buffer Pool and various other components within SQL can consume more memory but it must be said that the Buffer Pool is mainly the biggest item of SQL memory allocation.</p>
<p>To see how SQL is using memory internally we can query the sys.dm_os_memory_clerks DMV to view currently active memory clerks within SQL Server. A memory clerk sits between memory nodes and the memory components within SQL Server. Each component has its own memory clerk that interfaces with the memory nodes to allocate memory; these clerks can then be used to track resource consumption. This architecture also means that threads cannot directly interface with the low level memory allocators but must go to the clerks for memory requests.</p>
<p>The test instance that will use has16Gb of RAM in the Server and I have allocated 8Gb to SQL Server, by running the following query I can see the top 5 memory consumers by clerk type and see how much they are using.</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> TOP(<span class="number">5</span>) [type] <span class="keyword">AS</span> [ClerkType],</span><br><span class="line"><span class="built_in">SUM</span>(pages_kb) <span class="operator">/</span> <span class="number">1024</span> <span class="keyword">AS</span> [SizeMb]</span><br><span class="line"><span class="keyword">FROM</span> sys.dm_os_memory_clerks <span class="keyword">WITH</span> (NOLOCK)</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> [type]</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> <span class="built_in">SUM</span>(pages_kb) <span class="keyword">DESC</span></span><br></pre></td></tr></table></figure>
<center>
<img src="https://www.sqlshack.com/wp-content/uploads/2017/02/word-image-59.png" />
</center>
<p>As I would expect the Buffer Pool is the largest consumer of memory within the instance with just over 4.5Gb allocated. The lock manager is next with just over 1Gb allocated for lock resources and the remaining clerks relate to allocations for the query plan. The CACHESTORE_OBJCP allocation refers to plans for stored procedures and functions. The CACHESTORE_SQLCP are plans not within those object types and refer to statements executed directly against SQL Server whilst the CACHESTORE_PHDR row shows algebrized trees for various objects.</p>
<p>On a busy SQL Server this information is really useful for us to capture at regular intervals so we can closely monitor memory allocation under normal workloads. If we were to experience performance problems where we suspect memory pressure we can repeat the query to see if memory is being allocated differently.</p>
<p>As an example here’s the same query taken when a full database consistency check is being ran against one of my test databases. We can see here that there’s a new memory clerk that is now in our top 5 allocations list, this particular clerk, SQLQERESERVATIONS is related to Memory Grant allocations within SQL Server.</p>
<center>
<img src="https://www.sqlshack.com/wp-content/uploads/2017/02/word-image-60.png" />
</center>
<p>Upon seeing the SQLQERESERVATIONS we can query the current memory grants using the sys.dm_exec_query_memory_grants DMV and by using the CROSS APPLY function to sys.dm_exec_sql_text we can return the query text that is associated with the process.</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> session_id, requested_memory_kb <span class="operator">/</span> <span class="number">1024</span> <span class="keyword">as</span> RequestedMemMb,</span><br><span class="line">granted_memory_kb <span class="operator">/</span> <span class="number">1024</span> <span class="keyword">as</span> GrantedMemMb, text</span><br><span class="line"><span class="keyword">FROM</span> sys.dm_exec_query_memory_grants qmg</span><br><span class="line"><span class="keyword">CROSS</span> APPLY sys.dm_exec_sql_text(sql_handle)</span><br></pre></td></tr></table></figure>
<p>The query returns the following single result and with only one process running we know the consistency check has had a direct effect on our memory allocations.</p>
<center>
<img src="https://www.sqlshack.com/wp-content/uploads/2017/02/word-image-61.png" />
</center>
<p>Here’s the query text:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">DECLARE</span> <span class="variable">@BlobEater</span> <span class="type">VARBINARY</span>(<span class="number">8000</span>)</span><br><span class="line"><span class="keyword">SELECT</span> <span class="variable">@BlobEater</span> <span class="operator">=</span> CheckIndex (ROWSET_COLUMN_FACT_BLOB)</span><br><span class="line"><span class="keyword">FROM</span> &#123; IRowset <span class="number">0xF022EAB907000000</span> &#125;</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> ROWSET_COLUMN_FACT_KEY</span><br><span class="line"><span class="operator">&gt;&gt;</span> <span class="keyword">WITH</span> <span class="keyword">ORDER</span> <span class="keyword">BY</span></span><br><span class="line">              ROWSET_COLUMN_FACT_KEY,</span><br><span class="line">              ROWSET_COLUMN_SLOT_ID,</span><br><span class="line">              ROWSET_COLUMN_COMBINED_ID,</span><br><span class="line">              ROWSET_COLUMN_FACT_BLOB</span><br><span class="line">OPTION (<span class="keyword">ORDER</span> <span class="keyword">GROUP</span>)</span><br></pre></td></tr></table></figure>
<p>This is one example of how a resource intensive process can affect the internal memory allocations within SQL Server but what about monitoring the allocations within the Buffer Pool itself?</p>
<p>For that we use the sys.dm_os_buffer_descriptors DMV to see memory allocation broken down by database. Similar to the memory clerk view it is incredibly useful to capture and record this information at regular intervals and observe significant changes from what you have observed as “the norm”.</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> TOP <span class="number">5</span> DB_NAME(database_id) <span class="keyword">AS</span> [Database Name],</span><br><span class="line"><span class="built_in">COUNT</span>(<span class="operator">*</span>) <span class="operator">*</span> <span class="number">8</span><span class="operator">/</span><span class="number">1024.0</span> <span class="keyword">AS</span> [Cached Size (MB)]</span><br><span class="line"><span class="keyword">FROM</span> sys.dm_os_buffer_descriptors <span class="keyword">WITH</span> (NOLOCK)</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> DB_NAME(database_id)</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> [Cached Size (MB)] <span class="keyword">DESC</span> OPTION (RECOMPILE);</span><br></pre></td></tr></table></figure>
<p>Here are the results on a test instance:</p>
<center>
<img src="https://www.sqlshack.com/wp-content/uploads/2017/02/word-image-62.png" />
</center>
<p>I like to record the results of this query at regular intervals taking note of database memory allocations at various points during the working day or when intensive activities or maintenance is being undertaken. The key is understanding how SQL is working so that once these baseline values have been captured we can compare back to them during troubleshooting to see if any databases are utilising (or have been allocated) memory differently.</p>
<p>By capturing memory clerk and buffer descriptor usage we can build a picture of how SQL is working under normal workloads. It also means we have this information readily available to us should we need to highlight issues and the effect that they are having on the system.</p>
<h2 id="See-more"><a class="header-anchor" href="#See-more"></a>See more</h2>
<p>To get 3 free licenses to a <a href="https://www.apexsql.com/sql_tools_monitor.aspx?utm_source=sqlshack&amp;utm_campaign=monitor&amp;utm_medium=native_link&amp;utm_content=monitoring-memory-clerk-and-buffer-pool-allocations-in-sql-server">SQL Server monitoring tool</a>, download <a href="https://www.apexsql.com/Download.aspx?utm_source=sqlshack&amp;utm_campaign=monitor&amp;utm_medium=native_link&amp;utm_content=monitoring-memory-clerk-and-buffer-pool-allocations-in-sql-server">ApexSQL Monitor</a> and fill out this <a href="https://docs.google.com/forms/d/e/1FAIpQLSddwQYREspM5H0gnOLl__iZkohSCtO_kkNCEBP-hiyZz2PXmg/viewform">simple survey</a></p>
<h2 id="Further-reading"><a class="header-anchor" href="#Further-reading"></a>Further reading:</h2>
<ul>
<li><a href="https://msdn.microsoft.com/en-us/library/ms175019.aspx">Sys.dm_os_memory_clerks</a></li>
<li><a href="https://msdn.microsoft.com/en-us/library/ms173442.aspx">Sys.dm_os_buffer_descriptors</a></li>
<li><a href="https://technet.microsoft.com/en-us/library/ms187499(v=sql.105).aspx">SQL Memory Architecture</a></li>
</ul>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/monitoring-memory-clerk-and-buffer-pool-allocations-in-sql-server/">http://xnerv.wang/monitoring-memory-clerk-and-buffer-pool-allocations-in-sql-server/</a></strong><br>
转载自：<a href="https://www.sqlshack.com/monitoring-memory-clerk-and-buffer-pool-allocations-in-sql-server/">Monitoring Memory Clerk and Buffer Pool Allocations in SQL Server</a></p>
]]></content>
      <categories>
        <category>DBMS</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>DBMS</tag>
        <tag>SQL Server</tag>
        <tag>Memory Clerk</tag>
        <tag>Buffer Pool</tag>
      </tags>
  </entry>
  <entry>
    <title>(MSDN) Give Me a Handle, and I&#39;ll Show You an Object</title>
    <url>/msdn-give-me-a-handle-and-i-ll-show-you-an-object/</url>
    <content><![CDATA[<p>Ruediger Asche<br>
Microsoft Developer Network Technology Group</p>
<p>Created: July 15, 1993</p>
<h2 id="Abstract"><a class="header-anchor" href="#Abstract"></a>Abstract</h2>
<p>This article discusses objects and handles under Microsoft® Windows™ version 3.1 and Windows NT™. The terms <em>objects</em> and <em>handles</em> have different meanings in each operating system and imply a variety of relationships between objects and their corresponding handles. This article elaborates on the differences between the way components of Windows NT treat objects as opposed to the way Windows 3.1 treats them, with particular emphasis on shareability issues.</p>
<span id="more"></span>
<h2 id="Introduction"><a class="header-anchor" href="#Introduction"></a>Introduction</h2>
<p><em>You got a smile so bright,<br>
You know you could have been a candle.<br>
I’m holding you so tight,<br>
You know you could have been a handle.</em></p>
<p><em>Smokey Robinson, “The Way You Do the Things You Do”</em></p>
<p>One of the masterpieces of contemporary American literature, <em>Webster’s New World Dictionary</em> (Paperback Edition), defines a handle as “that part of a tool, etc., by which it is held or lifted.” Now, is this a precise definition or what? What on earth is <em>etc</em>.? By intuitive knowledge, we know that <em>etc</em>. can cover anything from toothbrushes to tennis rackets to cookware. While I leave it up to the imagination of the reader to figure out what Smokey Robinson wanted to hold or lift, I will tell you right away what we will be handling in this article: objects.</p>
<p><em>Object</em> is one of the major buzzwords of today’s computer reality. You find objects everywhere, from object-oriented languages to object linking and embedding. Microsoft® Windows™ has used the term <em>Object</em> for a long time to describe several very different things. To further confuse the issue, things that are not explicitly labeled as objects behave the same way as some objects do.</p>
<p>Windows NT™ is essentially an object-centered operating system and has a very definite notion of what an object is. Unfortunately, Windows NT’s idea of an object is not related at all to the concept that 16-bit Windows has of an object; as a result, when writing a Win32®-based application for Windows NT, you will need to deal with even more “object types,” which will make the confusion about objects potentially even greater. This article untangles the different meanings of the term <em>Object</em> and the related term <em>handle</em>, and makes you aware of potential incompatibilities between applications written for Windows version 3.1 and for Win32.</p>
<p>We display the entire object and handle layout of Windows NT in the Appendix at the end of this article. Please refer to it as necessary as you read this article.</p>
<p>One more note: For the sake of this discussion, we will entirely leave out C++ and Microsoft Foundation Class Library objects. Although some Foundation class objects are directly mapped to objects provided by the operating system, the way Foundation class objects are referenced, maintained, and protected is exclusively a compiler issue. In this article we will focus on objects that are provided and maintained on the operating system level.</p>
<p>This article is not meant to be a supplement to the documentation of Windows NT. All that is described herein applies to version 3.1 of Windows NT and may change in future versions of the operating system. Please be aware that applications written for the Win32 API are meant to be portable between all platforms that support this API, and any assumptions about a particular implementation (such as the relationships between handles and objects as described in this article) will break applications that operate under such assumptions.</p>
<h2 id="Objects-in-16-Bit-Windows"><a class="header-anchor" href="#Objects-in-16-Bit-Windows"></a>Objects in 16-Bit Windows</h2>
<p>The idea of an object that Windows 3.1 introduced was roughly “something that is accessed through a handle.” In Windows 3.1, you create the object—a process that returns a magic cookie called a handle—and subsequently use the handle to access the object. This ensures that the actual implementation of the object can be changed without affecting the application.</p>
<p>If you have used objects and handles exactly like this, you are well off, and you will find that you will need to change almost nothing when porting your application from Windows 3.1 to 32-bit Windows NT. However, many developers for Windows 3.1 made assumptions about the relationship between handles and their objects—sometimes they had to because application programming interfaces (APIs) were missing for certain operations. Such assumptions will break applications under Windows NT.</p>
<p>Maybe you have used <strong>GlobalHandle</strong> to retrieve the handle of any given address and subsequently use the handle to reallocate the object? Works like a charm under 16-bit Windows. Maybe you have extracted the HIWORD of a given pointer and converted it into a handle, or peeked into memory without doing a <strong>GlobalLock</strong> using that handle? Maybe you were bold, retrieving the base of the local descriptor table and looking at descriptors by using the handle as an offset into the table? Beware, it’s these kinds of things that will leave you with major redesign work when you try to port your application.</p>
<p>Such things used to work under 16-bit Windows, mainly due to two widely known facts:</p>
<ul>
<li>First, objects under 16-bit Windows generally fall into two categories: objects that are stored in GDI’s and USER’s local heaps, and objects that are allocated from the global heap (that is, Windows internally calls <strong>GlobalAlloc</strong> to allocate memory for that object).</li>
<li>Second, the handles that belong to global heap objects are, in fact, selectors to those global memory segments, which implies an immediate relationship between the handle and its memory location.</li>
</ul>
<p>For example, there is no API under Windows 3.1 that returns the size of a resource, given its handle. No problem; because resources are allocated from the global heap, you can eventually use all of the global heap functions to party on the resources. You can call <strong>GlobalPageLock</strong> if, for whatever reason, you wish to permanently lock the resource; you can call <strong>GlobalSize</strong> to figure out its current size; you can <strong>GlobalRealloc</strong> it if you wish to dynamically change its size; and you can even <strong>GlobalLock</strong> it to write to or read from the resource data directly.</p>
<p>The entities that are explicitly labeled as objects under Windows 3.1 are GDI and USER objects. GDI objects are brushes, pens, bitmaps, fonts, palettes, and regions; USER objects are window classes, atoms, menus, and windows. Handles for those objects are, in fact, pointers into the default data segments of the GDI and USER modules, respectively. A relationship between the handles and the objects is implied in that the handles, when converted to pointers into USER’s and GDI’s default data segment, point to data structures that describe the objects internally.</p>
<p>Unfortunately, the API sets that treat those objects are fairly inconsistent. Although the <strong>Create_xxx_</strong> and corresponding <strong>DeleteObject</strong> APIs were originally designed to provide a uniform <strong>Create/<strong>Use</strong>/Delete</strong> sandwich for all GDI object types, not even palettes could be incorporated into the paradigm when they were introduced with Windows 3.0; <strong>SelectObject</strong> will not work on them. On the other hand, walking GDI’s local heap will reveal that palettes are stored in there the same way as brushes, pens, bitmaps, fonts, device contexts, and regions are; thus, although they are stored internally the same way, they have different operations that work on them.</p>
<p>One of the corollaries of the design of Windows 3.1 is that all objects are globally accessible. Because only one local descriptor table (LDT) is being used for all Windows-based applications, all global handles (that is, selectors) can be used by all applications and DLLs; and because all GDI and USER objects are references into the globally accessible GDI and USER default data segments, they can be seen and used by all applications as well.</p>
<p>This implementation detail is widely used by many applications, be it explicitly (for example, in order to share memory) or implicitly (for example, in order to enumerate windows or fonts). One of the unfortunate consequences of this design is that any application can (deliberately or inadvertently) modify or possibly destroy objects that belong to other applications. There is no protection mechanism against these kinds of practices. (“The Way We Used to Do the Things We Did.”)</p>
<h2 id="Object-Management-Under-Windows-NT"><a class="header-anchor" href="#Object-Management-Under-Windows-NT"></a>Object Management Under Windows NT</h2>
<p>Windows NT has a rather precise and orthogonal idea of what an object is. Windows NT has an API set that works on all kinds of objects; handles are maintained by the executive via a consistent mechanism that allows for secure access to objects, supports synchronization, and rejects attempts to delete objects that are still in use.</p>
<p>The objects that Windows NT knows about are processes, threads, files (including devices that look like files, such as communication devices, mail slots, or pipes), file mappings (or sections, as they are labeled on the executive level), events, semaphores, and mutexes. All of those object types have certain properties in common that we will elaborate on a bit later.</p>
<p>You can see that none of the things that Windows 3.1 calls objects (hereafter called “old objects”) are covered by the term <em>objects</em> in Windows NT. The equivalents of Windows 3.1 “old objects” are not implemented on the executive level under Windows NT, so next we’ll look a little bit more closely at how the Win32 subsystem implements “old objects.” In other words, a window or a brush or a pen does not have anything to do with a Windows NT object, and the Windows NT executive would be totally clueless if it were passed a handle to one of those objects.</p>
<h3 id="How-the-Subsystem-Realizes-Windows-GDI-Objects"><a class="header-anchor" href="#How-the-Subsystem-Realizes-Windows-GDI-Objects"></a>How the Subsystem Realizes Windows GDI Objects</h3>
<p>Let us begin with GDI objects. Under Windows 3.1, GDI objects are stored in GDI’s default data segment. They are designed to be global; that is, one application can create an object and pass it on to another application. There is no ownership of GDI objects in 16-bit Windows; thus, one application can destroy a GDI object that you created in another application.</p>
<p>Under Windows NT, GDI objects are stored in the client part of the Win32 subsystem’s GDI module. That means that any GDI object is valid only in the context of the application that created it. However, consider this: Create an object and pass its handle to another application. Let this other application call <strong>SelectObject</strong> on that newly created object, and the call may succeed! However, nothing might happen; or instead of a brush, a pen might be selected into the device context! What is happening?</p>
<p>Well, what happens here is that handles to GDI objects are internally implemented as offsets into a handle table that resides on the client side of the Win32 subsystem. (Remember that the Win32 client is a DLL that resides in a Win32-based application’s address space and is called by the application.) In other words, handle tables are kept on a per-process basis, but they are not process-tagged. That means that a handle to an object that belongs to process A might coincidentally look like a valid handle in process B’s context. Thus, a call to <strong>SelectObject</strong> from B might succeed, but B will actually have selected a totally different object into its device context—or worse, the right one. Selecting the right object may be worse because the objects might coincidentally be the same, so you think it works, but the application will behave weirdly later on. So, do not pass handles to GDI objects between applications; they have totally different meanings in different processes.</p>
<p>Actually, the picture is even more complex than that. Because all applications share the same physical output device, maintaining a device context cannot be left up to the client alone. Any output call will eventually end up in the server, and thus, the server has to know about its clients’ device contexts as well as their GDI objects. The subsystem divides the representation of the GDI object (including the device context) between the client and the server. For efficiency’s sake, as much work as possible is done by the client—in most cases, for example, a call to <strong>SelectObject</strong> will not make it to the server; the client will simply update an internal data structure. As soon as the server does the drawing, it knows how to retrieve and realize the objects on the client’s side.</p>
<p>The GDI part of the Win32 subsystem has a handle manager of its own through which all accesses to GDI objects go. This is also true for USER, as we will see later. A handle to a GDI object is, in fact, made up of two components: One part encodes the offset into an object table that resides in the client part of the subsystem, and one part is a uniqueness identifier. This identifier changes—as the name implies—whenever a handle is recycled and is stored both as part of the object and as part of the handle.</p>
<p>Validating an object involves, among other things, matching the unique part of the handle against the value in the object. If a handle is recycled, the new handle returned is different from the one that belonged to the destroyed object with the same table index. This mechanism is used to make sure that stray pointers or previously deleted object handles that are passed into a function that works on an object do not reference wrong objects. If the validation fails, an error 6, INVALID_HANDLE, is generated.</p>
<p>In future versions of Windows NT, it may well be that this implementation detail changes. Although a handle will most likely still be composed of two 16-bit components for compatibility reasons, the interpretation of the “uniqueness” part may change due to performance considerations.</p>
<p>You might wonder now why you don’t see the INVALID_HANDLE error when you pass a GDI object handle between applications in error. The reason is that initially the “uniqueness” value is the same for all handles in all address spaces; objects become unique only after the handle is recycled. Thus, two valid objects in different processes may very well have the same “uniqueness” value. “The Way We Do the Things We Do?” You betcha.</p>
<p>The downside of this implementation is that it cuts down on the number of available handles. A handle has the size of a DWORD—that is, it’s 32 bits. Thus, a maximum of 232 or 4 GB of objects can be theoretically addressed by a handle. Currently, the two components of the handle—the table index and the uniqueness identifier—take up 16 bits of the handle each, such that theoretically a maximum of 64K (216) of GDI objects could be accessed per process, but the maximum size of the client’s handle table is currently hardcoded to 16K of entries.</p>
<h3 id="And-Now-for-Something-Completely-Different-USER-Objects"><a class="header-anchor" href="#And-Now-for-Something-Completely-Different-USER-Objects"></a>And Now for Something Completely Different: USER Objects</h3>
<p>The story of USER objects is different from GDI’s story. Under Windows 3.1, the definition of <em>Object</em> covers both objects internal to USER’s default data segment (windows, window classes, menus, and so on) and resources that are actually allocated from the global heap. Windows NT still maintains both object types in the USER module, but because there is no global heap anymore as there was in Windows 3.1, resources behave a little bit differently.</p>
<p>One of the main goals in the implementation of the USER part of Windows NT’s Win32 subsystem was compatibility. Under Windows 3.1, an application has a high degree of control over USER-maintained objects. For example, through the <strong>EnumWindows</strong> function, an application for Windows 3.1 can get access to all top-level windows in the system; with the window handle, the menu of an application can be modified, messages can be monitored, device contexts obtained, and so on. In order for Windows NT to maintain this degree of control, USER objects are maintained on the server side of the Win32 subsystem, and the functions that access the objects (such as <strong>DrawIcon</strong>) need to do more work. For example, if the object were located on the client side, accessing it would mainly be a task of translating the handle into a pointer, but in the USER implementation, memory in the server process must be referenced.</p>
<p>Just like its GDI counterpart, the Windows NT USER component keeps a handle manager that works pretty much like the one described in the GDI discussion, but the object tables are maintained on the server side of the subsystem, and therefore the object limit is global. Currently, it is 64K entries.</p>
<h4 id="Resources"><a class="header-anchor" href="#Resources"></a>Resources</h4>
<p>The good news is that under Windows NT, resources are not handled differently from the other USER objects at all. Under Windows 3.<em>x</em>, the local heaps of USER and GDI turned out to be severe system bottlenecks for object-intensive applications. If you have worked with 16-bit Windows intensively, chances are that at more than one point you have seen the free system resources decreasing severely when you worked with large menus or many windows. Windows 3.1 somewhat widened that bottleneck by making menus resources instead of objects within USER’s default data segment. Windows NT implements all USER objects orthogonally.</p>
<p>From the user’s point of view, the major differences between resources and other objects is that at times resources need to be accessed directly, without using the API functions that operate on them. (This holds especially true for user-defined “raw” resources.)</p>
<p>There are actually two different ways to access resources under Windows NT—one in which the resource resides in the server process and one in which it resides in the client. To exemplify the first case, let’s assume your application calls <strong>LoadIcon</strong> and passes the returned handle on to application B, which then calls <strong>DrawIcon</strong> on that handle. Guess what? Works fine. Just like under Windows 3.1. This seems to be strange at first glance because the two applications have disjoint address spaces, so how can the target application see something that the source application loaded?</p>
<p>Note that you cannot do much more with that handle. In particular, you cannot get your hands on the memory that describes the icon because the handle has no meaning whatsoever to either your application or application B. It is a handle local to the server part of the Win32 subsystem. <strong>DrawIcon</strong> eventually executes in the server part as well, and thus it knows how to interpret the handle. In this case, the icon is a real object in the strict sense of the word: The handle is a true magic cookie without any meaning to anyone except for the operations that are allowed on it (such as <strong>DrawIcon</strong>).</p>
<p>As a side effect of this modular approach, using this technique to access resources is fairly limited. You cannot modify the resource or look at its memory. (We will look at ways to work around this in a second.) Also, there is no way for the subsystem to determine if the object is in use by anybody but the process that owns it. In our example, the subsystem cannot know if somebody is using the icon, so as soon as your application terminates, the icon is gone from the server subsystem address space, and a subsequent attempt to call <strong>DrawIcon</strong> on it will return with an error code of ERROR_INVALID_CURSOR_HANDLE. Do not be confused about “CURSOR” in that error message—as far as USER32 is concerned, icons and cursors are basically the same; internally, they are represented as the same data structures.</p>
<p>So how does one share resources among processes? Well, the bad news is that there is no easy way for applications to share resources dynamically at run time so that a change in the resource that one application makes appears in the other application. Aside from using the <strong>CopyIcon</strong>, <strong>CopyAcceleratorTable</strong>, and <strong>CopyCursor</strong> functions, which are especially designed to create local copies of resources, the best one can do about this is to have one application map an image of the other application’s executable into its own memory space, locate the resource in the image, and party on it. To aid this process, the <strong>LoadResource</strong> API family has been modified for Windows NT.</p>
<p>If application HAND wants to access a resource in application FOOT, it needs to use the <strong>LoadLibrary</strong>, <strong>FindResource</strong>, and <strong>LoadResource</strong> APIs as described in the Win32 API Help file under the documentation for <strong>FindResource</strong>. If you want to permanently change resources in the target executable file, you should use the <strong>UpdateResource</strong>, <strong>BeginUpdateResource</strong>, and <strong>EndUpdateResource</strong> APIs.</p>
<p>The trick here is that <strong>LoadLibrary</strong> will map the executable file into the address space of the process that calls it and return a pointer to that image. All that <strong>FindResource</strong> and <strong>LoadResource</strong> do is examine the executable header in that image, figure out where within the image the resource is located, and return a pointer to the resource image.</p>
<p>The part that will probably confuse you here is that <strong>LoadLibrary</strong> also works on .EXE files. Under Windows 3.1, if you load an executable file, it will execute right away, whereas a DLL will linger in memory until it is called. <strong>LoadLibrary</strong>, <strong>LoadModule</strong>, and <strong>WinExec</strong> are very closely interrelated under Windows 3.1, but they are totally different under Windows NT, where <strong>LoadLibrary</strong> basically maps the executable file into the process’s address space. <strong>LoadLibrary</strong> also executes the DLL entry point routine when a library is loaded, but it does not execute anything when an application is loaded. The return value from <strong>WinExec</strong>, which is a stripped-down version of <strong>CreateProcess</strong>, is a handle to a Windows NT executive object, whereas an instance handle, the value returned from <strong>LoadLibrary</strong>, is a virtual pointer.</p>
<h3 id="Win32-Kernel-Objects"><a class="header-anchor" href="#Win32-Kernel-Objects"></a>Win32 Kernel Objects</h3>
<p>The preceding discussion on virtual pointers leads us right into the remaining category of objects in the Win32 subsystem—kernel objects. Now, here we run into a terminology problem: Under Windows 3.1, the component that is responsible for memory management and system services is called the “kernel.” Unfortunately, the same term is used for the component in Windows NT that executes in privileged mode at the lowest level. Windows NT renames the part of the Win32 subsystem that corresponds to the kernel in Windows 3.1 as the “base.” Thus, this section does not really deal with kernel objects, but with base objects. Most of the objects that you access through the base are, in fact, native Windows NT objects, which we will discuss in the following section.</p>
<p>The only entity that the kernel component of Windows 3.1 dubs an object is a memory object from which a number of other object types derive, such as modules or instances; in the rest of this section, we will look at these in more detail and see how those are implemented in Windows NT.</p>
<p>Let us elaborate on the last statement of the preceding section a little bit more. Windows 3.1 knows instance handles, task handles, and module handles. Instance handles are, in fact, selectors of the default data segments of the application instance. (This fact is sometimes used to change the data segment so that an operation can work on the default data segment of a different application—an ugly practice, but it works.) The task handle is the selector of a global memory block that contains task-specific parameters (such as the input queue that is associated with the task). The module handle is the selector of a global memory block that contains a modified version of the executable header associated with the module. (This memory block is also known as the module database.)</p>
<p>For applications in Windows 3.1, there is only one module database in the system for all instances of the application, whereas both the task database and the default data segment exist separately for each instance of the application. The <strong>GetModuleHandle</strong> API returns the handle (selector) of the module database, whereas a call to <strong>GetWindowWord</strong> with GWW_HINSTANCE passed as the second parameter returns the instance handle, and the <strong>GetCurrentTask</strong> API returns the task database handle. For other applications, the <strong>TaskFirst</strong>/<strong>TaskNext</strong> Toolhelp API functions can be employed to retrieve the task database handles.</p>
<p>For more information on modules, tasks, and instances under Windows 3.1, please consult the Knowledge Base articles Q76676, “Differences Between Task Handles and Instance Handles,” and Q78327, “HANDLEs Returned by GetModuleHandle and LoadLibrary,” as well as Bob Gunderson’s technical article “Modules, Instances, and Tasks.”!Alink(Knowledge Base, MSDN™ Library)</p>
<p>Windows NT does not use task databases or module databases anymore, and the default data segment is built on top of an application’s virtual address space. The <em>hInstance</em> value that is being passed to an application upon startup is basically the same as the value returned from <strong>LoadLibrary</strong>: a virtual address in the application’s address space that contains the memory-mapped image of the executable file. Incidentally, <strong>GetModuleHandle</strong>(NULL) returns the same value. It is fairly easy to confuse this value with a process handle, which is something totally different (namely, a native Windows NT object) and cannot be used interchangeably with those virtual pointers.</p>
<p>The remaining kernel object type is the <em>heap object type</em>, which we’ll look at now. As Randy Kath’s technical article <a href="https://msdn.microsoft.com/en-us/library/ms810603.aspx">“Managing Heap Memory in Win32”</a> outlines, the Windows NT heap memory manager resides on top of the virtual memory manager; that is, a heap is essentially a chunk of virtual memory that consists of the heap itself and some administrative information that is used to maintain it. The handle returned from the <strong>HeapCreate</strong> API is essentially the virtual address of this memory chunk, and a call to <strong>HeapAlloc</strong> will look into the administration header and return a pointer to the memory chunk. You should never attempt to write to a memory location that belongs to the heap header because it would seriously confuse the heap manager. Also, due to the very nature of disjoint address spaces, one application’s local heap is of no relevance to other applications.</p>
<p>Because heap handles are virtual pointers, and no record is kept of the local heaps allocated by the base part of the Win32 subsystem, there is really no limit on the number of heaps you can theoretically allocate, except for the limits that the executive imposes on the number of virtual memory chunks that an application can use. For details on virtual memory management, please refer to Randy Kath’s technical articles <a href="https://msdn.microsoft.com/en-us/library/ms810616.aspx">“The Virtual-Memory Manager in Windows NT”</a> and <a href="https://msdn.microsoft.com/en-us/library/ms810627.aspx">“Managing Virtual Memory in Win32.”</a> It is worthwhile mentioning here, however, that you cannot allocate more than 32K of virtual memory blocks in any process because the virtual address space of a process is limited to 2 GB, and the minimum size for each allocation is 64K; thus, the maximum number of allocations that can be made is 2G/64K, or 32K of virtual memory blocks.</p>
<p>Note that this is different from the number of allocations that can be drawn from heaps. Because heaps themselves are virtual memory blocks, you cannot create more than 32K-worth of heaps per application, but from a given heap, you can allocate as many memory blocks as you want to.</p>
<h3 id="Native-Windows-NT-Objects"><a class="header-anchor" href="#Native-Windows-NT-Objects"></a>Native Windows NT Objects</h3>
<p>We will now look at <em>native objects</em> in Windows NT. As Helen Custer describes in depth in <em>Inside Windows NT</em> (Microsoft Press, 1993), the object manager is an integral and central part of Windows NT. It is responsible for accepting and processing requests to create, access, and destroy objects—both from a process and from the executive. Some of the objects that Windows NT knows about are not directly visible to applications, such as driver objects or symbolic link objects, but internally they work in exactly the same way as the aforementioned objects. In <em>Inside Windows NT</em>, these invisible objects are called <em>kernel objects</em>, as opposed to <em>executive objects</em>.</p>
<p>We have already enumerated the native Windows NT objects that are visible to Win32 applications: processes, threads, files, file mappings, events, semaphores, and mutexes. We will not elaborate too much on these here because Chapter Three of <em>Inside Windows NT</em> already gives a comprehensive overview of these objects and how to use them. The worthwhile aspects to mention about them are the following:</p>
<ul>
<li>They can attain a signaled state so that you can call <strong>WaitForSingleObject</strong> or <strong>WaitForMultipleObjects</strong> on them.</li>
<li>You can use <strong>DuplicateHandle</strong> to access the object from inside other processes. (Some restrictions apply! Refer to the Win32 API Help file for details.)</li>
<li>The Windows NT executive keeps a reference count for each object and removes the object only after the last handle is closed.</li>
<li>Access to the objects is monitored by the security subsystem. (I will cover “security and how you can make use of it” in a future article.)</li>
<li>Most objects can be optionally named so that other processes can access them by name if security allows.</li>
</ul>
<p>Handles to executive objects are always associated with a particular process—this statement does not always hold true for kernel objects; for example, objects that describe the drivers for bootable hard drives must exist before the system has started up. The association of handles to processes is the reason you cannot use an existing handle to access an object from another process; you need to either obtain another handle using <strong>DuplicateHandle</strong> to create a handle table entry for the same object in another process or open an object by name in the other process.</p>
<p>Unlike the handles that are maintained by the Win32 USER and GDI subsystem components, handles to native objects under Windows NT are not unique; that is, upon destruction of an object, the corresponding handle may be recycled and will look exactly like the handle to the destroyed object. There is one unintuitive consequence of this implementation: Process IDs under Windows NT are actually handles into a dummy system table—that is, a table that does not associate its handles with any objects. If you create a process and store its ID away, then after termination of the process, the ID may be recycled for other types of global objects. You therefore cannot use process IDs to uniquely identify processes.</p>
<p>Finally, there is no hardcoded limit on the number of entries a handle table can have. A handle table maintained by the executive may grow dynamically if necessary; thus, the number of handles that can be allocated per process depends only on the memory available on your machine. (Note that Windows NT may further limit this number on a per-user basis by reducing the user’s quota on nonpageable memory.)</p>
<h2 id="Conclusion"><a class="header-anchor" href="#Conclusion"></a>Conclusion</h2>
<p>We have discussed several types of objects and their handles under Windows NT, and how they relate to corresponding object types under Windows 3.1. The most important result from this discussion is that any assumption about the implementation of objects and the meaning of handles is very likely to break code compatibility between platforms and should, therefore, be avoided. Another important point to mention is that the shareability of an object between processes is a matter of the implementation of the operating system and varies from object type to object type and from operating system to operating system. The table below lists the object types discussed in this article, as well as their locations and their shareability.</p>
<p>From the point of view of implementation, a handle under Windows NT is always realized in one of two categories:</p>
<ul>
<li>An offset into a table that is being maintained by either the executive or a subsystem component.</li>
<li>A virtual address in the address space of a process.<br>
The concept that makes this implementation possible is the memory-mapped file (or section object). Whereas Windows 3.1 needs to copy data from an executable file into main memory to build code segments or load resources, Windows NT only needs to create a memory-mapped file object that is backed by the executable file instead of the system pagefile. Thus, a resource can be retrieved by calculating a pointer into the memory-mapped file object that represents the executable. The USER part of the Win32 subsystem uses this technique to implement both methods of resource access: A call to <strong>LoadIcon</strong>, for example, will map the executable into the server’s address space so that a subsequent call to <strong>DrawIcon</strong> will retrieve the icon data from the memory-mapped image, whereas <strong>LoadLibrary</strong> maps the executable into the client’s address space so that <strong>FindResource</strong> and <strong>LoadResource</strong> will retrieve the data from there (which is why resources retrieved this way will not have any meaning to other processes).</li>
</ul>
<p>Also, it is important to emphasize the disjoint API sets that are available for the different types of objects. You cannot call <strong>DeleteObject</strong> on a resource or an executive object; conversely, <strong>CloseHandle</strong> will fail on GDI objects and resources. A good way to look at it is to classify each type of object as a member of something one could call an “object type class,” a category of objects that are roughly characterized by being maintained by the same component of Windows NT. Following this approach, there are the following object type classes in Windows NT:</p>
<ul>
<li>Executive objects (processes, threads, sections, file objects, events, semaphores, and mutexes)</li>
<li>Win32 GDI objects (pens, brushes, fonts, palettes, regions, device contexts, bitmap headers)</li>
<li>Win32 USER objects
<ul>
<li>WIN32 resources (accelerator tables, bitmap resources, dialog box templates, font resources, menu resources, raw data resources, string table entries, message table entries, cursors/icons)</li>
<li>Other USER objects (windows, menus)</li>
</ul>
</li>
<li>Win32 base objects (heaps)</li>
</ul>
<p><strong>Summary of Object Properties</strong></p>
<table>
<thead>
<tr>
<th></th>
<th>Executive objects</th>
<th>Win32 base objects</th>
<th>Win32 GDI objects</th>
<th>Win32 USER objects</th>
</tr>
</thead>
<tbody>
<tr>
<td>Shareable</td>
<td>Via APIs (<strong>DuplicateHandle</strong> or <strong>Open_xxx_</strong>)</td>
<td>No</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td>Validated</td>
<td>Yes</td>
<td>No</td>
<td>Yes, by uniqueness</td>
<td>Yes, by uniqueness</td>
</tr>
<tr>
<td>Limit</td>
<td>Only by physical memory</td>
<td>32K of heaps</td>
<td>16K per process</td>
<td>64K systemwide (including resources and internal types</td>
</tr>
</tbody>
</table>
<blockquote>
<p><strong>Note</strong>Shareable indicates whether an object of that type can be accessed by several processes. Validated indicates whether the handle protects the object against invalid access to it, possibly due to an invalid handle.</p>
</blockquote>
<h2 id="Appendix"><a class="header-anchor" href="#Appendix"></a>Appendix</h2>
<p>In this diagram, three processes are running in a particular Windows NT session—the Win32 subsystem server process and two clients (that is, Win32-based applications). Note that by design of Windows NT, all processes’ virtual addresses over 2 GB are mapped globally (that is, are mapped to the same physical addresses in all processes).</p>
<p><img src="/assets/msdn-give-me-a-handle-and-i-ll-show-you-an-object/1.gif" alt=""></p>
<p>Use these notes to interpret the numbers in the diagram:</p>
<ol>
<li>An instance handle is a pointer to the image of an executable file in a client process.</li>
<li>A resource handle as obtained by <strong>FindResource</strong> and <strong>LoadResource</strong> is a pointer to that process within the image.</li>
<li>A handle returned from <strong>VirtualAlloc</strong> or <strong>HeapCreate</strong> is a pointer to the beginning of the memory block in the client’s address space.</li>
<li>A handle returned from <strong>HeapAlloc</strong> is a pointer into the chunk of memory allocated by 3.</li>
<li>A GDI handle is a relative offset into a table located in the client’s address space.</li>
<li>A USER handle is a relative offset into a table located in the server’s address space.</li>
<li>A handle to a native Windows NT object is a relative offset into a table located in system space. There are several of those tables—one per process and a few tables maintained by the system.</li>
<li>A USER object itself is located in the server’s address space.</li>
<li>In the case of resources, 8 still holds true, but just as in 2, the resource is referenced through a memory-mapped image of the file that holds the executable, only the image resides in the server’s address space this time. This is the scenario you encounter, for example, when calling <strong>LoadIcon</strong>.</li>
<li>The data structures that describe native Windows NT objects reside in system address space. Depending on the object type, part of the object may also be located in a process’s address space. (This holds true, for example, for section objects.)</li>
<li>The data that describes a GDI object resides in the client’s address space. Please also observe the restriction mentioned earlier in this article under “How the Subsystem Realizes Window GDI Objects.”</li>
</ol>
<hr>
<p><strong>Article link: <a href="http://xnerv.wang/msdn-give-me-a-handle-and-i-ll-show-you-an-object/">http://xnerv.wang/msdn-give-me-a-handle-and-i-ll-show-you-an-object/</a></strong><br>
Reprinted from: <a href="https://msdn.microsoft.com/en-us/library/ms810501.aspx">(MSDN) Give Me a Handle, and I’ll Show You an Object</a></p>
]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Windows</tag>
        <tag>MSDN</tag>
        <tag>Memory Management</tag>
      </tags>
  </entry>
  <entry>
    <title>(MSDN) Heap Functions</title>
    <url>/msdn-heap-functions/</url>
    <content><![CDATA[<p>Each process has a default heap provided by the system. Applications that make frequent allocations from the heap can improve performance by using private heaps.</p>
<p>A private heap is a block of one or more pages in the address space of the calling process. After creating the private heap, the process uses functions such as <strong><a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366597(v=vs.85).aspx">HeapAlloc</a></strong> and <strong><a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366701(v=vs.85).aspx">HeapFree</a></strong> to manage the memory in that heap.</p>
<span id="more"></span>
<p>The heap functions can also be used to manage memory in the process’s default heap, using the handle returned by the <strong><a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366569(v=vs.85).aspx">GetProcessHeap</a></strong> function. New applications should use the heap functions instead of the <strong><a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366596(v=vs.85).aspx">global and local functions</a></strong> for this purpose.</p>
<p>There is no difference between memory allocated from a private heap and that allocated by using the other memory allocation functions. For a complete list of functions, see the table in <strong><a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366781(v=vs.85).aspx">Memory Management Functions</a></strong>.</p>
<blockquote>
<p>A thread should call heap functions only for the process’s default heap and private heaps that the thread creates and manages, using handles returned by the <strong><a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366569(v=vs.85).aspx">GetProcessHeap</a></strong> or <strong><a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366599(v=vs.85).aspx">HeapCreate</a></strong> function.</p>
</blockquote>
<p>The <strong><a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366599(v=vs.85).aspx">HeapCreate</a></strong> function creates a private heap object from which the calling process can allocate memory blocks by using the <strong><a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366597(v=vs.85).aspx">HeapAlloc</a></strong> function. <strong>HeapCreate</strong> specifies both an initial size and a maximum size for the heap. The initial size determines the number of committed, read/write pages initially allocated for the heap. The maximum size determines the total number of reserved pages. These pages create a contiguous block in the virtual address space of a process into which the heap can grow. Additional pages are automatically committed from this reserved space if requests by <strong>HeapAlloc</strong> exceed the current size of committed pages, assuming that the physical storage for it is available. Once the pages are committed, they are not decommitted until the process is terminated or until the heap is destroyed by calling the <strong><a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366700(v=vs.85).aspx">HeapDestroy</a></strong> function.</p>
<p>The memory of a private heap object is accessible only to the process that created it. If a dynamic-link library (DLL) creates a private heap, it does so in the address space of the process that called the DLL. It is accessible only to that process.</p>
<p>The <strong><a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366597(v=vs.85).aspx">HeapAlloc</a></strong> function allocates a specified number of bytes from a private heap and returns a pointer to the allocated block. This pointer can be used in the <strong><a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366701(v=vs.85).aspx">HeapFree</a></strong>, <strong><a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366704(v=vs.85).aspx">HeapReAlloc</a></strong>, <strong><a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366706(v=vs.85).aspx">HeapSize</a></strong>, and <strong><a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366708(v=vs.85).aspx">HeapValidate</a></strong> functions.</p>
<p>Memory allocated by <strong><a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366597(v=vs.85).aspx">HeapAlloc</a></strong> is not movable. The address returned by <strong>HeapAlloc</strong> is valid until the memory block is freed or reallocated; the memory block does not need to be locked.</p>
<p>Because the system cannot compact a private heap, it can become fragmented. Applications that allocate large amounts of memory in various allocation sizes can use the <strong><a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366750(v=vs.85).aspx">low-fragmentation heap</a></strong> to reduce heap fragmentation.</p>
<p>A possible use for the heap functions is to create a private heap when a process starts up, specifying an initial size sufficient to satisfy the memory requirements of the process. If the call to the <strong><a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366599(v=vs.85).aspx">HeapCreate</a></strong> function fails, the process can terminate or notify the user of the memory shortage; if it succeeds, however, the process is assured of having the memory it needs.</p>
<p>Memory requested by <strong><a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366599(v=vs.85).aspx">HeapCreate</a></strong> may or may not be contiguous. Memory allocated within a heap by <strong><a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366597(v=vs.85).aspx">HeapAlloc</a></strong> is contiguous. You should not write to or read from memory in a heap except that allocated by <strong>HeapAlloc</strong>, nor should you assume any relationship between two areas of memory allocated by <strong>HeapAlloc</strong>.</p>
<p>You should not refer in any way to memory that has been freed by <strong><a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366701(v=vs.85).aspx">HeapFree</a></strong>. After the memory is freed, any information that may have been in it is gone forever. If you require information, do not free memory containing the information. Function calls that return information about memory (such as <strong><a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366706(v=vs.85).aspx">HeapSize</a></strong>) may not be used with freed memory, as they may return bogus data.</p>
<p>The <strong><a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366700(v=vs.85).aspx">HeapDestroy</a></strong> function destroys a private heap object. It decommits and releases all the pages of the heap object, and it invalidates the handle to the heap.</p>
<h2 id="Related-topics"><a class="header-anchor" href="#Related-topics"></a>Related topics</h2>
<p><strong><a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366533(v=vs.85).aspx">Comparing Memory Allocation Methods</a></strong></p>
<hr>
<p><strong>Article link: <a href="http://xnerv.wang/msdn-heap-functions/">http://xnerv.wang/msdn-heap-functions/</a></strong><br>
Reprinted from: <a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366711.aspx">(MSDN) Heap Functions</a></p>
]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Windows</tag>
        <tag>Heap</tag>
        <tag>MSDN</tag>
        <tag>Memory Management</tag>
      </tags>
  </entry>
  <entry>
    <title>(MSDN) Heap: Pleasures and Pains</title>
    <url>/msdn-heap-pleasures-and-pains/</url>
    <content><![CDATA[<p>Murali R. Krishnan<br>
Microsoft Corporation</p>
<p>February 1999</p>
<p><strong>Summary:</strong> Discusses common heap performance problems and how to protect against them. (9 printed pages)</p>
<h2 id="Introduction"><a class="header-anchor" href="#Introduction"></a>Introduction</h2>
<p>Are you a happy-go-lucky user of dynamically allocated C/C++ objects? Do you use Automation extensively for communicating back and forth between modules? Is it possible that your program is slow because of heap allocation? You are not alone. Almost all projects run into heap issues sooner or later. The common tendency is to say, “It’s the heap that’s slow and my code is really good.” Well, that is partially right. It pays to understand more about heap, its usage, and what can happen.</p>
<span id="more"></span>
<h2 id="a-id-heap3-whatis-a-What-Is-a-Heap"><a class="header-anchor" href="#a-id-heap3-whatis-a-What-Is-a-Heap"></a><a id="heap3_whatis"></a>What Is a Heap?</h2>
<p>(If you already know what a heap is, you can jump ahead to the section <a href="#heap3_commonproblems">“What Are Common Heap Performance Problems?”</a>)</p>
<p>A heap is used for allocating and freeing objects dynamically for use by the program. Heap operations are called for when:</p>
<ol>
<li>The number and size of objects needed by the program are not known ahead of time.</li>
<li>An object is too large to fit into a stack allocator.</li>
</ol>
<p>A heap uses parts of memory outside of what is allocated for the code and stack during run time. The following graph shows the different layers of heap allocators.</p>
<p><img src="/assets/msdn-heap-pleasures-and-pains/1.gif" alt=""></p>
<p><strong>GlobalAlloc/GlobalFree:</strong> Heap calls that talk directly to the per-process default heap.</p>
<p><strong>LocalAlloc/LocalFree:</strong> Heap calls that talk directly to the per-process default heap.</p>
<p><strong>COM’s IMalloc allocator (or CoTaskMemAlloc / CoTaskMemFree):</strong> Functions use the default per-process heap. Automation uses the Component Object Model (COM)'s allocator, and the requests use the per-process heap.</p>
<p><strong>C/C++ Run-time (CRT) allocator:</strong> Provides <strong>malloc()</strong> and <strong>free()</strong> as well as <strong>new</strong> and <strong>delete</strong> operators. Languages like Microsoft Visual Basic® and Java also offer new operators and use garbage collection instead of heaps. CRT creates its own private heap, which resides on top of the Windows heap.</p>
<p>The Windows heap is a thin layer surrounding the Windows run-time allocator. All APIs forward their requests to the NTDLL.</p>
<p>The Windows run-time allocator provides the core heap allocator within Windows. It consists of a front-end allocator with 128 free lists for sizes ranging from 8 to 1,024 bytes. The back-end allocator uses virtual memory to reserve and commit pages.</p>
<p>At the bottom of the chart is the Virtual Memory Allocator, which reserves and commits pages used by the OS. All allocators use the virtual memory facility for accessing the data.</p>
<p>Shouldn’t it be simple to allocate and free blocks? Why would this take a long time?</p>
<h2 id="a-id-heap3-heapimplementation-a-Notes-on-Heap-Implementation"><a class="header-anchor" href="#a-id-heap3-heapimplementation-a-Notes-on-Heap-Implementation"></a><a id="heap3_heapimplementation"></a>Notes on Heap Implementation</h2>
<p>Traditionally, the operating system and run-time libraries come with an implementation of the heap. At the beginning of a process, the OS creates a default heap called <em>Process heap</em>.The Process heap is used for allocating blocks if no other heap is used. Language run times also can create separate heaps within a process. (For example, C run time creates a heap of its own.) Besides these dedicated heaps, the application program or one of the many loaded dynamic-link libraries (DLLs) may create and use separate heaps. Windows offers a rich set API for creating and using private heaps.</p>
<p>When applications or DLLs create private heaps, these live in the process space and are accessible process-wide. Any allocation of data made from a given heap should be freed for the same heap. (Allocation from one heap and free to another makes no sense.)</p>
<p>The heap sits on top of the operating system’s Virtual Memory Manager in all virtual memory systems. The language run-time heaps reside on top of the virtual memory, as well. In some cases, these are layered on OS heaps, but the language run-time heap performs its own memory management by allocating large blocks. Bypassing the OS heap to use the virtual memory functions may enable a heap to do a better job of allocating and using blocks.</p>
<p>Typical heap implementations consist of front-end and back-end allocators. The front-end allocator maintains a free list of fixed-sized blocks. On an allocation call, the heap attempts to find a free block from the front-end list. If this fails, the heap is forced to allocate a large block from the back end (reserving and committing virtual memory) to satisfy the request. Common implementations have per-block allocation overhead, which costs execution cycles and also reduces available storage.</p>
<p>The Knowledge Base article Q10758, “Managing Memory with calloc() and malloc()” (search on article ID number), contains more background on these topics. Also, a detailed discussion on the heap implementations and designs can be found in “Dynamic Storage Allocation: A Survey and Critical Review” by Paul R. Wilson, Mark S. Johnstone, Michael Neely, and David Boles. In <em>International Workshop on Memory Management</em>,Kinross, Scotland, UK, September 1995 (<a href="http://www.cs.utexas.edu/users/oops/papers.html">http://www.cs.utexas.edu/users/oops/papers.html</a>).</p>
<p>The implementation (Windows NT version 4.0 and later) uses 127 free lists of 8-byte aligned blocks ranging from 8 to 1,024 bytes and a grab-bag list. The grab-bag list (free list[0]) holds blocks greater than 1,024 bytes in size. The free list contains objects linked together in a doubly linked list. By default, the Process heap performs coalescing operations. (Coalescing is the act of combining adjacent free blocks to build a larger block.) Coalescing costs additional cycles but reduces internal fragmentation of heap blocks.</p>
<p>A single global lock protects the heap against multithreaded usage. (See the first commandment in <a href="https://msdn.microsoft.com/en-us/library/ms951773.aspx">Server Performance and Scalability Killers</a> by George Reilly.) This lock is essential to protecting the heap data structures from random access across multiple threads. This lock can have an adverse impact on performance when heap operations are too frequent.</p>
<h2 id="a-id-heap3-commonproblems-a-What-Are-Common-Heap-Performance-Problems"><a class="header-anchor" href="#a-id-heap3-commonproblems-a-What-Are-Common-Heap-Performance-Problems"></a><a id="heap3_commonproblems"></a>What Are Common Heap Performance Problems?</h2>
<p>Here are the most common obstacles you will encounter when working with the heap:</p>
<ul>
<li>
<p><strong>Slowdown as a result of allocation operations.</strong> It simply takes a long time to allocate. The most likely cause of the slowdown is that the free lists do not have the blocks, and hence the run-time allocator code spends cycles hunting for a larger free block or allocating a fresh block from the back-end allocator.</p>
</li>
<li>
<p><strong>Slowdown as a result of free operations.</strong> Free operations consume more cycles, mainly if coalescing is enabled. During coalescing, each free operation should “find” its neighbors, pull them out to construct a larger block, and reinsert the larger block into the free list. During that find, memory may be touched in a random order, causing cache misses and performance slowdown.</p>
</li>
<li>
<p><strong>Slowdown as a result of heap contention.</strong> Contention occurs when two or more threads try to access data at the same time and one must wait for the other to complete before it can proceed. Contention always causes trouble; it’s by far the biggest problem that one encounters on multiprocessor systems. An application or DLL with heavy use of memory blocks will slow down when run with multiple threads (and on multiprocessor systems). The use of single lock—the common solution—means that all operations using the heap are serialized. The serialization causes threads to switch context while waiting for the lock. Imagine the slowdown caused by stop-and-go at a flashing red stoplight.</p>
<p>Contention usually leads to context switch of the threads and processes. Context switches are very costly, but even more costly is the loss of data from the processor cache and the rebuilding of that data when the thread is brought to life afterwards.</p>
</li>
<li>
<p><strong>Slowdown as a result of heap corruption.</strong> Corruption occurs when the application does not use the heap blocks properly. Common scenarios include double free or use of a block after a free, and the obvious problems of overwriting beyond block boundaries.</p>
</li>
<li>
<p><strong>Slowdown as a result of frequent allocs and reallocs.</strong> This is a very common phenomenon when you use scripting languages. The strings are repeatedly allocated, grown with reallocation, and freed up. Don’t do this. Try to allocate large strings, if possible, and use the buffer. An alternative is to minimize concatenation operations.</p>
</li>
</ul>
<p>Contention is the problem that introduces slowdown in the allocation as well as free operations. Ideally we would like to have a heap with no contention and fast alloc/free. Alas, such a general-purpose heap does not exist yet, though it might sometime in the future.</p>
<p>In all the server systems (such as IIS, MSProxy, DatabaseStacks, Network servers, Exchange, and others), the heap lock is a BIG bottleneck. The larger the number of processors, the worse the contention.</p>
<h2 id="a-id-heap3-protect-a-Protecting-Yourself-from-the-Heap"><a class="header-anchor" href="#a-id-heap3-protect-a-Protecting-Yourself-from-the-Heap"></a><a id="heap3_protect"></a>Protecting Yourself from the Heap</h2>
<p>Now that you understand the problems with heap, don’t you want the magic wand that can eliminate these problems? I wish there were one. But there is no magic to make the heap go faster—so don’t expect to make things faster in the last week before shipping the product. Plan your heap strategy earlier, and you will be far better off. Altering the way you use the heap, and reducing the number of heap operations, is a solid strategy for improving performance.</p>
<p>How do you reduce the use of heap operations? You can reduce the number of heap operations by exploiting locality inside data structures. Consider the following example:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">ObjectA</span> &#123;</span></span><br><span class="line">   <span class="comment">// data for objectA</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">ObjectB</span> &#123;</span></span><br><span class="line">   <span class="comment">// data for objectB</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Use of ObjectA and ObjectB together.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Use pointers</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">ObjectB</span> &#123;</span></span><br><span class="line">   <span class="class"><span class="keyword">struct</span> <span class="title">ObjectA</span> * <span class="title">pObjA</span>;</span></span><br><span class="line">   <span class="comment">// data for objectB</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Use embedding</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">ObjectB</span> &#123;</span></span><br><span class="line">   <span class="class"><span class="keyword">struct</span> <span class="title">ObjectA</span> <span class="title">pObjA</span>;</span></span><br><span class="line">   <span class="comment">// data for objectB</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Aggregation – use ObjectA and ObjectB inside another object</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">ObjectX</span> &#123;</span></span><br><span class="line">   <span class="class"><span class="keyword">struct</span> <span class="title">ObjectA</span>  <span class="title">objA</span>;</span></span><br><span class="line">   <span class="class"><span class="keyword">struct</span> <span class="title">ObjectB</span>  <span class="title">objB</span>;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ol>
<li><strong>Avoid using pointers for associating two data structures.</strong> If you use pointers to associate two data structures, the objects A and B from the preceding example will be allocated and freed separately. This is an additional cost—and is <em>the practice we want to avoid</em>.</li>
<li><strong>Embed pointed child objects into the parent object.</strong> Anytime we have a pointer in an object, it means we have a dynamic element (80 percent) and a new location to be dereferenced. Embedding increases locality and reduces the need for further allocation/free. This will improve the performance of your application.</li>
<li><strong>Combine smaller objects to form bigger objects (aggregation).</strong> Aggregation reduces the number of blocks allocated and freed up. If you have multiple developers working on various parts of a design, you may end up with many small objects that can be combined. The challenge of this integration is to find the right aggregation boundaries.</li>
<li><strong>Inline a buffer that can satisfy 80 percent of your needs (aka the 80-20 rule).</strong> In several situations, memory buffers are required for storing string/binary data and the total number of bytes is not known ahead of time. Take measurements and inline a buffer of a size that can satisfy 80 percent of your needs. For the remaining 20 percent, you can allocate a new buffer and have a pointer for that buffer. This way, you reduce the allocation and free calls as well as increase spatial locality of data, which ultimately will improve the performance of your code.</li>
<li><strong>Allocate objects in chunks (chunking).</strong> Chunking is a way of allocating objects in groups of more than one object at a time. If you have to keep track of a list of items, for example a list of {name, value} pairs, you have two options: Option 1 is to allocate one node per name-value pair. Option 2 is to allocate a structure that can hold, say, five name-value pairs. And if, for example, storing four pairs is a common scenario, you would reduce the number of nodes and the amount of extra space needed for additional linked-list pointers.<br>
Chunking is processor cache-friendly, especially for the L1-cache, because of the increased locality it offers—not to mention that some of the data blocks are located in the same virtual page for chunked allocations.</li>
<li><strong>Use _amblksiz appropriately.</strong> The C run time (CRT) has its custom front-end allocator that allocates blocks in sizes of _amblksiz from the back end (Windows heap). Setting _amblksiz to a higher value can potentially reduce the number of calls made to the back end. This is applicable only to programs using the CRT extensively.</li>
</ol>
<p>The savings you will gain by using the preceding techniques will vary with object types, sizes, and workload. But you will always gain in performance and scalability. On the downside, the code will be a bit specialized, but it can be manageable if well-thought-out.</p>
<h3 id="More-Performance-Boosters"><a class="header-anchor" href="#More-Performance-Boosters"></a>More Performance Boosters</h3>
<p>The following are a few more techniques for enhancing speed:</p>
<ol>
<li><strong>Use the Windows heap</strong><br>
Thanks to the efforts and hard work of several folks, a few significant improvements went into Microsoft Windows 2000:</li>
</ol>
<ul>
<li><strong>Improved locking inside the heap code.</strong> The heap code uses one lock per heap. This global lock is used for protecting the heap data structure for multithreaded usage. Unfortunately, in high-traffic scenarios, a heap can still get bogged down in this global lock, leading to high contention and poor performance. On Windows 2000, the critical region of code inside locks is reduced to minimize the probability of contention, thus improving scalability.</li>
<li><strong>Use of Lookaside lists.</strong> The heap data structure uses a fast cache for all free items of blocks sized between 8 and 1,024 bytes (in 8-byte increments). The fast cache was originally protected within the global lock. Now lookaside lists are used to access the fast cache free list. These lists do not require locking, and instead use 64-bit interlocked operations, thus improving performance.</li>
<li><strong>Internal data structure algorithms</strong> are improved as well.</li>
</ul>
<p>These improvements eliminate the need for allocation caches, but do not preclude other optimizations. Evaluate your code with the Windows heap; it should be optimal for blocks of less than 1,024 bytes (1 KB) (blocks from front-end allocator). <strong>GlobalAlloc()</strong> and <strong>LocalAlloc()</strong> build on the same heap and are common mechanisms to access the per-process heaps. Use Heap* APIs to access the per-process heap, or to create your own heaps for allocation operations if high localized performance is desired. You can also use <strong>VirtualAlloc()</strong> / <strong>VirtualFree()</strong> operations directly if needed for large block operations.</p>
<p>The described improvements made their way into Windows 2000 beta 2 and Windows NT 4.0 SP4. After the changes, the rate of heap lock contention fell significantly. This benefits all direct users of Windows heaps. The CRT heap is built on top of the Windows heap, but uses its own small-block heap and hence does not benefit from Windows changes. (Visual C++ version 6.0 also has an improved heap allocator.)</p>
<ol start="2">
<li><strong>Use allocation caches</strong><br>
An allocation cache allows you to cache allocated blocks for future reuse. This can reduce the number of alloc/free calls to the process heap (or global heap), as well as allow maximum reuse of the blocks once allocated. In addition, allocation caches permit you to gather statistics to gain a better understanding of object usage at the higher level.</li>
</ol>
<p>Typically, a custom heap allocator is implemented on top of the process heap. The custom heap allocator behaves much like the system heap. The major difference is that it provides a cache on top of the process heap for the allocated objects. The caches are designed for a fixed set of sizes (for example, 32 bytes, 64 bytes, 128 bytes, and so on). This is a good strategy, but this sort of custom heap allocator misses the <em>semantic information</em> related to the objects that are allocated and freed.</p>
<p>In contrast to the custom heap allocators, “Alloc-caches” are implemented as a per-class allocation cache. They can retain a lot of semantic information_,_ in addition to providing all the goodies of the custom heap allocator. Each allocation cache handler is associated with one object in the target binary. It can be initialized with a set of parameters indicating the concurrency level, size of the object, number of elements to keep in the free list, and so on. The allocation cache handler object maintains its own private pool of freed entities (not exceeding the specified threshold) and uses private lock for protection. Together, the allocation cache and private locks reduce the traffic to the main system heap, thus providing increased concurrency, maximum reuse, and higher scalability.</p>
<p>A scavenger is required periodically to check the activity of all the allocation cache handlers and reclaim unused resources. If and when no activity is found, the pool of allocated objects can be freed, thus improving performance.</p>
<p>Each alloc/free activity can be audited. The first level of information includes a total count of objects, allocations, and free calls made. You can derive the semantic relationship between various objects by looking at their statistics. The relationship can be used to reduce memory allocation using one of the many techniques just explained.</p>
<p>Allocation caches also act as a debugging aid in helping you track down the number of objects that are not properly cleaned up. You can even find exact callers in fault by looking at dynamic stack back traces and signatures in addition to the objects that were not cleaned up.</p>
<ol start="3">
<li><strong>MP heap</strong><br>
MP heap is a package for multiprocessor-friendly distributed allocation. Originally implemented by JVert, the heap abstraction here is built on top of the Windows heap package. MP heap creates multiple heaps and attempts to distribute allocation calls to different heaps with the goal of reducing the contention on any single lock.</li>
</ol>
<p>This package is a good step—sort of an improved MP-friendly custom heap allocator. However, it offers no semantic information and lacks in statistics. A common way to use the MP heap is as an SDK library. You can benefit greatly if you create a reusable component with this SDK. If you build this SDK library into every DLL, however, you will increase your working set.</p>
<ol start="4">
<li><strong>Rethink algorithms and data structures</strong><br>
To scale on multiprocessor machines, algorithms, implementation, data structures, and hardware have to scale dynamically. Look at the data structures most commonly allocated and freed. Ask yourself, “Can I get the job done with a different data structure?” For example, if you have a list of read-only items that is loaded at application initialization time, this list does not need to be a linear-linked list. It can very well be a dynamically allocated array. A dynamically allocated array would reduce heap blocks in memory, reduce fragmentation, and therefore give you a performance boost.</li>
</ol>
<p>Reducing the number of small objects needed reduces the load on the heap allocator. For example, we used five different objects in our server’s critical processing path, each separately allocated and freed. Caching the objects together reduced heap calls from five to one and dramatically reduced the load on the heap, especially when we were processing more than 1,000 requests per second.</p>
<p>If you make extensive use of Automation structures, consider factoring out Automation BSTRs from your mainline code, or at least avoid repeated operations on BSTR. (BSTR concatenation leads to excessive reallocs and alloc/free operations.)</p>
<h2 id="Summary"><a class="header-anchor" href="#Summary"></a>Summary</h2>
<p>Heap implementations tend to stay general for all platforms, and hence have heavy overhead. Each individual’s code has specific requirements, but design can accommodate the principles discussed in this article to reduce heap interaction.</p>
<ol>
<li>Evaluate the use of heap in your code.</li>
<li>Streamline your code to use fewer heap calls: Analyze the critical paths and fix data structures.</li>
<li>Make measurements to quantify the costs of heap calls before implementing custom wrappers.</li>
<li>If you are unhappy about performance, ask the OS group to improve the heap. More requests of this sort mean more attention toward improving the heap.</li>
<li>Ask the C run-time group to make the allocators thin wrappers on heaps provided by the OS. As a result, the cost of C run-time heap calls is reduced as the OS heap is improved.</li>
<li>Heap improvements are continuously made in the operating system. Stay tuned and take advantage of the same.</li>
</ol>
<p><em>Murali Krishnan is a lead software design engineer with the Internet Information Server (IIS) team. He has worked on IIS since version 1.0 and has successfully shipped versions 1.0 through 4.0. Murali formed and led the IIS performance team for three years (1995-1998), and has influenced IIS performance from day one. He holds an M.S. from the University of Wisconsin-Madison and a B.S. from Anna University, India, both in Computer Science. Outside work, he reads, plays volleyball, and cooks at home.</em></p>
<hr>
<p><strong>Article link: <a href="http://xnerv.wang/msdn-heap-pleasures-and-pains/">http://xnerv.wang/msdn-heap-pleasures-and-pains/</a></strong><br>
Reprinted from: <a href="https://msdn.microsoft.com/en-us/library/ms810466.aspx">(MSDN) Heap: Pleasures and Pains</a></p>
]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Windows</tag>
        <tag>Heap</tag>
        <tag>MSDN</tag>
        <tag>Memory Management</tag>
      </tags>
  </entry>
  <entry>
    <title>(MSDN) Managing Heap Memory</title>
    <url>/msdn-managing-heap-memory/</url>
    <content><![CDATA[<p>Randy Kath<br>
Microsoft Developer Network Technology Group</p>
<p>Created: April 3, 1993</p>
<h2 id="Abstract"><a class="header-anchor" href="#Abstract"></a>Abstract</h2>
<p>Determining which function or set of functions to use for managing memory in your application is difficult without a solid understanding of how each group of functions works and the overall impact they each have on the operating system. In an effort to simplify these decisions, this technical article focuses on the use of heaps in Windows: the functions that are available, the way they are used, and the impact their use has on operating system resources. The following topics are discussed:</p>
<ul>
<li>The purpose of heaps</li>
<li>General heap behavior</li>
<li>The two types of heaps</li>
<li>Global and local memory functions</li>
<li>Heap memory functions</li>
<li>Overhead on heap memory allocations</li>
<li>Summary and recommendations</li>
</ul>
<p>In addition to this technical article, a sample application called ProcessWalker is included on the Microsoft Developer Network CD. This sample application explores the behavior of heap memory functions in a process, and it provides several useful implementation examples.</p>
<span id="more"></span>
<h2 id="Introduction"><a class="header-anchor" href="#Introduction"></a>Introduction</h2>
<p>This is one of three related technical articles—“Managing Virtual Memory,” “Managing Memory-Mapped Files,” and “Managing Heap Memory”—that explain how to manage memory using the Windows API (application programming interface). This introduction identifies the basic memory components in the programming model and indicates which article to reference for specific areas of interest.</p>
<p>The first version of the Microsoft® Windows™ operating system introduced a method of managing dynamic memory based on a single <em>global heap</em>, which all applications and the system share, and multiple, private <em>local heaps</em>, one for each application. Local and global memory management functions were also provided, offering extended features for this new memory management system. More recently, the Microsoft C run-time (CRT) libraries were modified to include capabilities for managing these heaps in Windows using native CRT functions such as <strong>malloc</strong> and <strong>free</strong>. Consequently, developers are now left with a choice—learn the new API provided as part of Windows version 3.1 or stick to the portable, and typically familiar, CRT functions for managing memory in applications written for 16-bit Windows.</p>
<p>Windows offers three groups of functions for managing memory in applications: memory-mapped file functions, heap memory functions, and virtual memory functions.</p>
<p><img src="/assets/msdn-managing-heap-memory/1.gif" alt=""></p>
<p><strong>Figure 1. The Windows API provides different levels of memory management for versatility in application programming.</strong></p>
<p>Six sets of memory management functions exist in Windows, as shown in Figure 1, all of which were designed to be used independently of one another. So which set of functions should you use? The answer to this question depends greatly on two things: the type of memory management you want, and how the functions relevant to it are implemented in the operating system. In other words, are you building a large database application where you plan to manipulate subsets of a large memory structure? Or maybe you’re planning some simple dynamic memory structures, such as linked lists or binary trees? In both cases, you need to know which functions offer the features best suited to your intention and exactly how much of a resource hit occurs when using each function.</p>
<p>The following table categorizes the memory management function groups and indicates which of the three technical articles in this series describes each group’s behavior. Each technical article emphasizes the impact these functions have on the system by describing the behavior of the system in response to using the functions.</p>
<table>
<thead>
<tr>
<th>Memory set</th>
<th>System resource affected</th>
<th>Related technical article</th>
</tr>
</thead>
<tbody>
<tr>
<td>Virtual memory functions</td>
<td>A process’s virtual address space<br/>System pagefile<br/>System memory<br/>Hard disk space</td>
<td>“Managing Virtual Memory”</td>
</tr>
<tr>
<td>Memory-mapped file functions</td>
<td>A process’s virtual address space<br/>System pagefile<br/>Standard file I/O<br/>System memory<br/>Hard disk space</td>
<td>“Managing Memory-Mapped Files”</td>
</tr>
<tr>
<td>Heap memory functions</td>
<td>A process’s virtual address space<br/>System memory<br/>Process heap resource structure</td>
<td>“Managing Heap Memory”</td>
</tr>
<tr>
<td>Global heap memory functions</td>
<td>A process’s heap resource structure</td>
<td>“Managing Heap Memory”</td>
</tr>
<tr>
<td>Local heap memory functions</td>
<td>A process’s heap resource structure</td>
<td>“Managing Heap Memory”</td>
</tr>
<tr>
<td>C run-time reference library</td>
<td>A process’s heap resource structure</td>
<td>“Managing Heap Memory”</td>
</tr>
</tbody>
</table>
<p>Each technical article discusses issues surrounding the use of Windows-specific functions.</p>
<h2 id="The-Purpose-of-Heaps"><a class="header-anchor" href="#The-Purpose-of-Heaps"></a>The Purpose of Heaps</h2>
<p>The Windows subsystem on Windows NT provides high-level memory management functions that make it easy for applications to build dynamic data structures, provide compatibility with previous versions of Windows, and create buffers and temporary placeholders for system functions. These memory management functions return handles and pointers to blocks of memory that are allocated at run time and managed by an entity called the <em>heap</em>. The heap’s primary function is to efficiently manage the memory and address space of a process for an application.</p>
<p>A tall order, considering the heap has absolutely no idea what the application intends to do with its memory and address space. Yet the heap manages to provide a robust set of functions that allow developers to overlook some of the finer details of system resources (such as the difference between reserved, free, and committed memory) so that they can turn their attention to the more important task at hand, that of implementing their applications.</p>
<p>In Windows NT, heaps provide a smaller granularity for the size of the smallest allocatable chunk of memory than the virtual memory management functions do. Applications typically need to allocate a specific number of bytes to fulfill a parameter request or to act as a temporary buffer. For example, when loading a string resource with the <strong>LoadString</strong> function, an application passes a pointer to a buffer that receives the string resource. The size of the buffer must be large enough to hold the string and a null terminator. Without the heap manager, applications would be forced to use the virtual memory management functions, which allocate a minimum of one page of memory at a time.</p>
<h2 id="General-Heap-Behavior"><a class="header-anchor" href="#General-Heap-Behavior"></a>General Heap Behavior</h2>
<p>While the heap does provide support for managing smaller chunks of memory, it is itself nothing more than a chunk of memory implemented in the Windows NT virtual memory system. Consequently, the techniques that the heap uses to manage memory are based on the virtual memory management functions available to the heap. Evidence of this is found in the way heaps manifest themselves in a process, if only we could observe this behavior…</p>
<p>The ProcessWalker (PW) sample application explores each of the components within a process, including all of its heaps. PW identifies the heaps in a process and shows the amount of reserved and committed memory associated with a particular heap. As with all other regions of memory in a process, the smallest region of committed memory within a heap is one page (4096 bytes).</p>
<p>This does not mean that the smallest amount of memory that can be allocated in a heap is 4096 bytes; rather, the heap manager commits pages of memory as needed to satisfy specific allocation requests. If, for example, an application allocates 100 bytes via a call to <strong>GlobalAlloc</strong>, the heap manager allocates a 100-byte chunk of memory within its committed region for this request. If there is not enough committed memory available at the time of the request, the heap manager simply commits another page to make the memory available.</p>
<p>Ideally, then, if an application repetitively allocates 100-byte chunks of memory, the heap will commit an additional page of memory every forty-first request (40 * 100 bytes = 4000 bytes). Upon the forty-first request for a chunk of 100 bytes, the heap manager realizes there is not enough committed memory to satisfy the request, so it commits another page of memory and then completes the requested allocation. In this way, the heap manager is responsible for managing the virtual memory environment completely transparent of the application.</p>
<p>In reality, though, the heap manager requires additional memory for managing the memory in the heap. So instead of allocating only 100 bytes as requested, it also allocates some space for managing each particular chunk of memory. The type of memory and the size of the allocation determine the size of this additional memory. I’ll discuss these issues later in this article.</p>
<h2 id="The-two-Types-of-Heaps"><a class="header-anchor" href="#The-two-Types-of-Heaps"></a>The two Types of Heaps</h2>
<p>Every process in Windows has one heap called the <em>default heap</em>. Processes can also have as many other <em>dynamic heaps</em> as they wish, simply by creating and destroying them on the fly. The system uses the default heap for all global and local memory management functions, and the C run-time library uses the default heap for supporting <strong>malloc</strong> functions. The heap memory functions, which indicate a specific heap by its handle, use dynamic heaps. The behavior of dynamic heaps is discussed in the “Heap Memory API” section later in this article.</p>
<p>The default and dynamic heaps are basically the same thing, but the default heap has the special characteristic of being identifiable as the default. This is how the C run-time library and the system identify which heap to allocate from. The <strong>GetProcessHeap</strong> function returns a handle to the default heap for a process. Since functions such as <strong>GlobalAlloc</strong> or <strong>malloc</strong> are executed within the context of the thread that called them, they can simply call <strong>GetProcessHeap</strong> to retrieve a handle to the default heap, and then manage memory accordingly.</p>
<h3 id="Managing-the-Default-Heap"><a class="header-anchor" href="#Managing-the-Default-Heap"></a>Managing the Default Heap</h3>
<p>Both default and dynamic heaps have a specific amount of reserved and committed memory regions associated with them, but they behave differently with respect to these limits. The default heap’s reserved and committed memory region sizes are designated when the application is linked. Each application carries this information about itself within its executable image information. You can view this information by dumping header information for the executable image. For example, type the following command at a Windows NT command prompt (PWALK.EXE is used here to complete the example; you will need to substitute your own path and executable file):</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">link32 -dump -headers d:\samples\walker\pwalk.exe</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line">OPTIONAL HEADER VALUES</span><br><span class="line">     10B magic #</span><br><span class="line">    2.29 linker version</span><br><span class="line">    B000 size of code</span><br><span class="line">   1E800 size of initialized data</span><br><span class="line">     600 size of uninitialized data</span><br><span class="line">   18470 address of entry point</span><br><span class="line">   10000 base of code</span><br><span class="line">   20000 base of data</span><br><span class="line">         ----- new -----</span><br><span class="line">  400000 image base</span><br><span class="line">   10000 section alignment</span><br><span class="line">     200 file alignment</span><br><span class="line">       2 subsystem (Windows GUI)</span><br><span class="line">     0.B operating system version</span><br><span class="line">     1.0 image version</span><br><span class="line">     3.A subsystem version</span><br><span class="line">   C0000 size of image</span><br><span class="line">     400 size of headers</span><br><span class="line">       0 checksum</span><br><span class="line">   10000 size of stack reserve</span><br><span class="line">    1000 size of stack commit</span><br><span class="line">   10000 size of heap reserve</span><br><span class="line">    1000 size of heap commit</span><br><span class="line">   ...</span><br></pre></td></tr></table></figure>
<p>The last two entries are hexadecimal values specifying the amount of reserved and committed space initially needed by the application.</p>
<p>There are two ways to tell the linker what to use for these values. You can link your application with a module definition file and include a statement in the file like the following:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">HEAPSIZE   0x10000 0x1000</span><br></pre></td></tr></table></figure>
<p>Or you can directly inform the linker by using the <strong>/HEAP</strong> linker switch, as in:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">/HEAP: 0x10000, 0x1000</span><br></pre></td></tr></table></figure>
<p>In both examples, the heap is specified to initially have 0x10000 (64K) bytes reserved address space and 0x1000 (4K) bytes committed memory. If you fail to indicate the heap size in either method, the linker uses the default values of 0x100000 (1 MB) reserved address space and 0x1000 (4K) committed memory.</p>
<p>The linker accepts almost any value for heap reserve space, because the application loader ensures that the application will meet certain minimum requirements during the load process. In other words, you can link an application with an initial heap value of 1 page reserved address space. The linker doesn’t perform any data validation; it simply marks the executable with the given value. Yet, since the minimum range of address space that can be reserved is 16 pages (64K), the loader compensates by reserving 16 pages for the application heap at load time.</p>
<p>As indicated above, options exist that indicate how much memory should initially be committed for an application’s default heap. The problem is they don’t seem to work yet. The linker for the second beta release of Windows NT marks all executable applications with 0x1000 (4K) initial committed memory for the default heap size, regardless of the value indicated as an option. Yet this is not that big a deal because it actually may be better for an application to commit as it needs to, rather than to commit memory that is not being used.</p>
<h3 id="A-Default-Heap-That-Grows-and-Spreads"><a class="header-anchor" href="#A-Default-Heap-That-Grows-and-Spreads"></a>A Default Heap That Grows and Spreads</h3>
<p>In its simplest form, the default heap spans a range of addresses. Some ranges are reserved, while others are committed and have pages of memory associated with them. In this case the addresses are contiguous, and they all originated from the same base allocation address. In some cases the default heap needs to allocate more memory than is available in its current reserved address space. For these cases the heap can either fail the call that requests the memory, or reserve an additional address range elsewhere in the process. The default heap manager opts for the second choice.</p>
<p>When the default heap needs more memory than is currently available, it reserves another 1-MB address range in the process. It also initially commits as much memory as it needs from this reserved address range to satisfy the allocation request. The default heap manager is then responsible for managing this new memory region as well as the original heap space. If necessary, it will repeat this throughout the application until the process runs out of memory and address space. You could end up with a default heap that manifests itself in your process in a manner similar to the heap represented in Figure 2.</p>
<p><img src="/assets/msdn-managing-heap-memory/2.gif" alt=""></p>
<p><strong>Figure 2. The default heap for each process can expand into free address regions within the process.</strong></p>
<p>So the default heap is not really a static heap at all. In fact, it may seem like a waste of energy to bother with managing the size of the initial heap since the heap always behaves in the same way after initialization. Managing the size of the default heap offers one advantage, though. It takes time to locate and reserve a new range of addresses in a process; you can save time by simply reserving a large enough address range initially. If you expect your application to require more heap space than the 1-MB default, reserve more address space initially to avoid allocating another region of addresses in your process later. Remember, each application has 2 gigabytes (GB) of address space to work with, and requires very little physical memory to support it.</p>
<h2 id="Global-and-Local-Memory-Functions"><a class="header-anchor" href="#Global-and-Local-Memory-Functions"></a>Global and Local Memory Functions</h2>
<p>At first glance it appears that the local and global memory management functions exist in Windows purely for backward compatibility with Windows version 3.1. This may be true, but the functions are managed as efficiently as the new heap functions discussed below. In fact, porting an application from 16-bit Windows does not necessarily include migrating from global and local memory functions to heap memory functions. The global and local functions offer the same basic capabilities (and then some) and are just as fast to work with. If anything, they are probably more convenient to work with because you do not have to keep track of a heap handle.</p>
<p>Nonetheless, the implementation of these functions is not the same as it was for 16-bit Windows. 16-bit Windows had a global heap, and each application had a local heap. Those two heap managers implemented the global and local functions. Allocating memory via <strong>GlobalAlloc</strong> meant retrieving a chunk of memory from the global heap, while <strong>LocalAlloc</strong> allocated memory from the local heap. Windows now has a single heap for both types of functions—the default heap described above.</p>
<p>Now you’re probably wondering if there is any difference between the local and global functions themselves. Well, the answer is no, they are now the same. In fact, they are interchangeable. Memory allocated via a call to <strong>LocalAlloc</strong> can be reallocated with <strong>GlobalReAlloc</strong> and then locked by <strong>LocalLock</strong>. The following table lists the global and local functions now available.</p>
<table>
<thead>
<tr>
<th>Global memory functions</th>
<th>Local memory functions</th>
</tr>
</thead>
<tbody>
<tr>
<td>GlobalAlloc</td>
<td>LocalAlloc</td>
</tr>
<tr>
<td>GlobalDiscard</td>
<td>LocalDiscard</td>
</tr>
<tr>
<td>GlobalFlags</td>
<td>LocalFlags</td>
</tr>
<tr>
<td>GlobalFree</td>
<td>LocalFree</td>
</tr>
<tr>
<td>GlobalHandle</td>
<td>LocalHandle</td>
</tr>
<tr>
<td>GlobalLock</td>
<td>LocalLock</td>
</tr>
<tr>
<td>GlobalReAlloc</td>
<td>LocalReAlloc</td>
</tr>
<tr>
<td>GlobalSize</td>
<td>LocalSize</td>
</tr>
<tr>
<td>GlobalUnlock</td>
<td>LocalUnlock</td>
</tr>
</tbody>
</table>
<p>It seems redundant to have two sets of functions that perform exactly the same, but that’s where the backward compatibility comes in. Whether you used the global or local functions in a 16-bit Windows application before doesn’t matter now—they are equally efficient.</p>
<h3 id="Types-of-Global-and-Local-Memory"><a class="header-anchor" href="#Types-of-Global-and-Local-Memory"></a>Types of Global and Local Memory</h3>
<p>In the Windows API, the global and local memory management functions provide two types of memory, MOVEABLE and FIXED. MOVEABLE memory can be further qualified as DISCARDABLE memory. When you allocate memory with either <strong>GlobalAlloc</strong> or <strong>LocalAlloc</strong>, you designate the type of memory you want by supplying the appropriate memory flag. The following table lists and describes each memory flag for global and local memory.</p>
<p>| Global memory flag | Local memory flag | Allocation meaning |<br>
| — | — |<br>
| GMEM_FIXED | LMEM_FIXED | Allocate fixed memory. |<br>
| GMEM_MOVEABLE | LMEM_MOVEABLE | Allocate movable memory. |<br>
| GMEM_DISCARDABLE | LMEM_DISCARDABLE | Allocate discardable, movable memory. |<br>
| GMEM_ZEROINIT | LMEM_ZEROINIT | Initialize memory to zeros during allocation. |<br>
| GMEM_NODISCARD | LMEM_NODISCARD | Do not discard other memory to meet the needs of this allocation; instead, fail this request. |<br>
| GMEM_NOCOMPACT | LMEM_NOCOMPACT | Do not discard or move other memory to meet the needs of this allocation; instead, fail this request. |<br>
| GMEM_SHARE, GMEM_DDESHARE | N/A | Allocate global memory that is more efficient to use with DDE. |</p>
<p>It is surprising that the distinction between FIXED and MOVEABLE memory still exists in these functions. In 16-bit Windows, MOVEABLE memory compacted the local and global heaps to reduce fragmentation and make more memory available to all applications. Yet the Windows NT virtual memory system does not rely on these techniques for efficient memory management and has little to gain by applications using them. In any case, they still exist and could actually be used in some circumstances.</p>
<p>When allocating FIXED memory in Windows, the <strong>GlobalAlloc</strong> and <strong>LocalAlloc</strong> functions return a 32-bit pointer to the memory block rather than a handle as they do for MOVEABLE memory. The pointer can directly access the memory without having to lock it first. This pointer can also be passed to the <strong>GlobalFree</strong> and <strong>LocalFree</strong> functions to release the memory without having to first retrieve the handle by calling the <strong>GlobalHandle</strong> function. With FIXED memory, allocating and freeing memory is similar to using the C run-time functions <strong>_malloc</strong> and <strong>_free</strong>.</p>
<p>MOVEABLE memory, on the other hand, cannot provide this luxury. Because MOVEABLE memory can be moved (and DISCARDABLE memory can be discarded), the heap manager needs a handle to identify the chunk of memory to move or discard. To access the memory, the handle must first be locked by calling either <strong>GlobalLock</strong> or <strong>LocalLock</strong>. As in 16-bit Windows, the memory cannot be moved or discarded while the handle is locked.</p>
<h3 id="The-MOVEABLE-Memory-Handle-Table"><a class="header-anchor" href="#The-MOVEABLE-Memory-Handle-Table"></a>The MOVEABLE Memory Handle Table</h3>
<p>As it turns out, each handle to MOVEABLE memory is actually a pointer into the MOVEABLE memory handle table. The handle table exists outside the heap, elsewhere in the process’s address space. To learn more about this behavior, we created a test application that allocates several MOVEABLE memory blocks from the default heap. The handle table was created only upon allocation of the first MOVEABLE chunk of memory. This is nice, because if you never allocate any MOVEABLE memory, the table is never created and does not waste memory. ProcessWalker reveals that when this handle table is created, 1 page of memory is committed for the initial table and 512K of address space is reserved (see Figure 3).</p>
<p><img src="/assets/msdn-managing-heap-memory/3.gif" alt=""></p>
<p><strong>Figure 3. ProcessWalker highlights changes in the address space of a process. The heap memory handle table is shown as it looks immediately after it is created.</strong></p>
<p>If you work out the math you can see that the number of memory handles available for MOVEABLE memory is limited. 512K bytes / 8 bytes per handle = 65,535 handles. In fact, the system imposes this limitation on each process. Fortunately, this only applies to MOVEABLE memory. You can allocate as many chunks of FIXED memory as you like, provided the memory and address space are available in your process.</p>
<p>Each handle requires 8 bytes of committed memory in the handle table to represent information, including the virtual address of the memory, the lock count on the handle, and the type of memory. Figure 4 shows how the handle table looks when viewed in ProcessWalker.</p>
<p><img src="/assets/msdn-managing-heap-memory/4.gif" alt=""></p>
<p><strong>Figure 4. Each MOVEABLE memory handle is 8 bytes and represents the location of the chunk of memory.</strong></p>
<blockquote>
<p><strong>Note</strong>   In the ProcessWalker view window, each line is 16 bytes (two memory handles). The far-left column represents the address of each line within the process. The addresses in white indicate the lines in which data changed since the last refresh. Red text shows exactly which bytes changed. This feature allows you to easily track changes in memory in response to certain events within the child process. A very useful debugging tool, to say the least.</p>
</blockquote>
<p>The first 8 bytes in the view window—at address 0x000f0000—show the first handle allocated in the table. The handle value for this example would actually be 0x000f0004, which is a 4-byte offset into the 8-byte handle table entry. At the 4-byte offset in the table entry is the current 32-bit address representing the location of the chunk of memory. In this example, the 32-bit address is 0x00042A70, reading 4 bytes from right to left starting at 0x000f0008 and ending at 0x000f0004. If the memory is moved to a new location, this address changes to reflect the new location.</p>
<p>If you back up 4 bytes from the handle to the first byte in this handle table entry, you’ll find the lock count for the handle. Remember, a block of memory can be moved or discarded only if its handle’s lock count is zero. Since there is only 1 byte to record the lock count, it stands to reason that a handle can be locked only 256 (0xFF) times. Unfortunately, the system currently does not warn you when you reach that limit. If you lock a handle a 257th time, you receive a valid pointer to the memory, but the lock count remains at 256. It is possible, then, that you could unlock the handle 256 times and expect the memory to be locked. Yet the lock count is decremented to 0, and the memory could be moved or discarded. So what happens if you try to access the pointer you believe to be valid? Well, it depends on what is now at the address where you believe the memory to be. The memory could still be there, or some other memory could have been moved there. This is not the desired behavior, and we hope the system will be fixed to prevent this from happening. Incidentally, how should the system be fixed? The easiest thing to do would be to fail the call to <strong>GlobalLock</strong> or <strong>LocalLock</strong> on any attempt beyond 256, so check the return value to make sure the function succeeds.</p>
<p>The third and fourth bytes of the handle represent the memory type, that is, MOVEABLE, DDESHARE, or DISCARDABLE. Presumably because of compatibility with 16-bit Windows, local and global memory flags that have the same name and meaning do not have the same value. (The WINBASE.H header file defines each flag.) Yet once the memory is allocated, the handle table entry records no difference. Whether you use LMEM_DISCARDABLE or GMEM_DISCARDABLE does not matter—the handle table identifies all DISCARDABLE memory the same way. A little exploring in ProcessWalker shows the following type value identifiers.</p>
<table>
<thead>
<tr>
<th>Memory type</th>
<th>Byte 3</th>
<th>Byte 4</th>
</tr>
</thead>
<tbody>
<tr>
<td>MOVEABLE</td>
<td>02</td>
<td>–</td>
</tr>
<tr>
<td>DISCARDABLE</td>
<td>06</td>
<td>–</td>
</tr>
<tr>
<td>DDESHARE</td>
<td>–</td>
<td>08</td>
</tr>
</tbody>
</table>
<p>Keep in mind that these values as represented in the handle table are not documented, so they could change with a new release of Windows NT. But it would be easy to use ProcessWalker to view the handle table to see the changes.</p>
<p>Returning to the test application example… After allocating the first MOVEABLE memory block and thereby creating the handle table, we used the test application to allocate 15 more handles from the table. A quick view of the memory window showed the first eight lines had data associated with them, while the rest of the committed page was filled with zeros. Then we allocated one more handle, making a total of 17 handles. The view window was refreshed to indicate what changes occurred in the table as a result of allocating the seventeenth handle only. Figure 4 (above) shows the results.</p>
<p>As you can see, more than 8 bytes changed during the last allocation. In fact, 8 lines were updated for a total of 128 bytes. The first 8 bytes represent the seventeenth handle entry information as expected. The following 120 bytes indicate that the heap manager initializes the handle table every sixteenth handle. Examining this initialization data shows that the next 15 available handle table entries are identified in the table. When allocating the eighteenth handle, the location of the nineteenth handle is identified by the address location portion of the eighteenth handle table entry. As expected, then, if a handle is removed from the table (the memory is freed), the address location in that entry is replaced with the location of the next available handle after it. This behavior indicates that the heap manager keeps the location of the next available handle table entry in a static variable and uses that entry itself to store the location of the subsequent entry. Notice also that the last initialized entry has a null location for the next address. The heap manager uses this as an indicator to initialize another 16 handle table entries during the next handle allocation.</p>
<p>Another efficiency in the heap manager is its ability to commit pages of memory for the handle table as it needs them, not all 128 pages (512K) at once. Since the heap manager initializes its handle table in 16-handle (128-byte) increments, it is easy to determine when to commit a new page of memory. Every thirty-second (4096 / 128 = 32) initialization requires a new page of committed memory. Also, the entries do not straddle page boundaries, so their management is easier and potentially more efficient.</p>
<h3 id="CRT-Library"><a class="header-anchor" href="#CRT-Library"></a>CRT Library</h3>
<p>Managing memory in 16-bit Windows involved a great deal of uncertainty about using the C run-time (CRT) library. Now, there should be little hesitation. The current CRT library is implemented in a manner similar to FIXED memory allocated via the local and global memory management functions. The CRT library is also implemented using the same default heap manager as the global and local memory management functions.</p>
<p>Subsequent memory allocations via <strong>malloc</strong>, <strong>GlobalAlloc</strong>, and <strong>LocalAlloc</strong> return pointers to memory allocated from the same heap. The heap manager does not divide its space among the CRT and global/local memory functions, and it does not maintain separate heaps for these functions. Instead, it treats them the same, promoting consistent behavior across the types of functions. As a result, you can now write code using the functions you’re most comfortable with. And, if you’re interested in portability, you can safely use the CRT functions exclusively for managing heap memory.</p>
<h2 id="Heap-Memory-API"><a class="header-anchor" href="#Heap-Memory-API"></a>Heap Memory API</h2>
<p>As mentioned earlier, you can create as many dynamic heaps as you like by simply calling <strong>HeapCreate</strong>. You must specify the maximum size of the heap so that the function knows how much address space to reserve. You can also indicate how much memory to commit initially. In the following example, a heap is created in your process that reserves 1 MB of address space and initially commits two pages of memory:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">hHeap = HeapCreate (<span class="number">0</span>, <span class="number">0x2000</span>, <span class="number">0x100000</span>);</span><br></pre></td></tr></table></figure>
<p>Since you can have many dynamic heaps in your process, you need a handle to identify each heap when you access it. The <strong>HeapCreate</strong> function returns this handle. Each heap you create returns a unique handle so that several dynamic heaps may coexist in your process. Having to identify your heap by handle also makes managing dynamic heaps more difficult than managing the default heap, since you have to keep each heap handle around for the life of the heap.</p>
<p>If you’re bothered by having to keep this handle around, there is an alternative. You can use the heap memory functions on the default heap instead of creating a dynamic heap explicitly for them. To do this, simply use the <strong>GetProcessHeap</strong> function to get the handle of the default heap. For simple allocations of short-term memory, the following example taken from the ProcessWalker sample application illustrates how easy this is to do:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">char</span>    *szCaption;</span><br><span class="line"><span class="type">int</span>     nCaption = GetWindowTextLength (hWnd);</span><br><span class="line"></span><br><span class="line"><span class="comment">/* retrieve view memory range */</span></span><br><span class="line">szCaption = HeapAlloc (GetProcessHeap (),</span><br><span class="line">                       HEAP_ZERO_MEMORY,</span><br><span class="line">                       nCaption+<span class="number">1</span>);</span><br><span class="line">GetWindowText (hViewWnd, szCaption, nCaption);</span><br></pre></td></tr></table></figure>
<p>In this example the default heap is chosen because the allocation is independent of other memory management needs, and there is no reason to create a dynamic heap just for this one allocation. Note that you could achieve the same result by using the global, local, or CRT functions since they allocate only from the default heap.</p>
<p>As shown earlier, the first parameter to <strong>HeapCreate</strong> allows you to specify an optional HEAP_NO_SERIALIZE flag. A serialized heap does not allow two threads to access it simultaneously. The default behavior is to serialize access to the heap. If you plan to use a heap strictly within one thread, specifying the HEAP_NO_SERIALIZE flag improves overall heap performance slightly.</p>
<p>Like all of the heap memory functions, <strong>HeapAlloc</strong> requires a heap handle as its first argument. The example uses the <strong>GetProcessHeap</strong> function instead of a dynamic heap handle. The second parameter to <strong>HeapAlloc</strong> is an optional flag that indicates whether the memory should be zeroed first and whether to generate exceptions on error. To get zeroed memory, specify the HEAP_ZERO_MEMORY flag as shown above. The generate exceptions flag (HEAP_GENERATE_EXCEPTIONS) is a useful feature if you have exception handling built into your application. When using this flag, the function raises an exception on failure rather than just returning NULL. Depending on your use, exception handling can be an effective way of triggering special events—such as low memory situations—in your application.</p>
<p><strong>HeapAlloc</strong> has a cousin called <strong>HeapReAlloc</strong> that works in much the same way as the standard global and local memory management functions described earlier. Use <strong>HeapReAlloc</strong> primarily to resize a previous allocation. This function has four parameters, three of which are the same as for <strong>HeapAlloc</strong>. The new parameter, <em>lpMem</em>, is a pointer to the chunk of memory being resized.</p>
<p>It is important to note that although heap memory is not movable as in global and local memory, it may be moved during the <strong>HeapReAlloc</strong> function. This function returns a pointer to the resized chunk of memory, which may or may not be at the same location as initially indicated by the pointer passed to the function. This is the only time memory can be moved in dynamic heaps, and the only chunk of memory affected is the one identified by <em>lpMem</em> in the function. You can also override this behavior by specifying the HEAP_REALLOC_IN_PLACE_ONLY flag. With this flag, if there is not enough room to reallocate the memory in place, the function returns with failure status rather than move the memory.</p>
<p>Memory allocated with <strong>HeapAlloc</strong> or reallocated with <strong>HeapReAlloc</strong> can be freed by calling <strong>HeapFree</strong>. This function is easy to use: simply indicate the heap handle and a pointer to the chunk of memory to free. Completing the example above, here is how you can use <strong>HeapFree</strong> with the default heap:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* free default heap memory */</span></span><br><span class="line">HeapFree (GetProcessHeap (), szCaption);</span><br></pre></td></tr></table></figure>
<p>This example shows how easy it can be to work with heaps in Windows. However, you may still want to create a dynamic heap specifically to manage complex dynamic data structures in your application. In fact, one nice benefit of heap memory is how well it caters to the needs of traditional data structures such as binary trees, linked lists, and dynamic arrays. Having the heap handle provides a way of uniquely identifying these structures independently. One example that comes to mind is when you’re building a multiwindow application—perhaps a multiple document interface (MDI) application. Simply create and store a heap handle in the window extra bytes or window property list for each window during the WM_CREATE message. Then it is easy to write a window procedure that manages data structures from its own heap by retrieving the heap handle when necessary. When the window goes away, simply have it destroy the heap in the WM_DESTROY message.</p>
<p>You can easily destroy dynamic heaps by calling <strong>HeapDestroy</strong> on a specific heap handle. This powerful function will remove a heap regardless of its state. The <strong>HeapDestroy</strong> function doesn’t care whether you have outstanding allocations in the heap or not.</p>
<p>To make heap memory management most efficient, you would only create a heap of the size you need. In some cases it is easy to determine the heap size you need—if you’re allocating a buffer to read a file into, simply check the size of the file. In other cases, heap size is more difficult to figure—if you’re creating a dynamic data structure that grows according to user interaction, it is difficult to predict what the user will do. Dynamic heaps have a provision for this latter circumstance. By specifying a maximum heap size of zero, you make the heap assume a behavior like the default heap. That is, it will grow and spread in your process as much as necessary, limited only by available memory. In this case, available memory means available address space in your process and available pagefile space on your hard disk.</p>
<h2 id="Overhead-on-Heap-Memory-Allocations"><a class="header-anchor" href="#Overhead-on-Heap-Memory-Allocations"></a>Overhead on Heap Memory Allocations</h2>
<p>With all types of heap memory, an overhead is associated with each memory allocation. This overhead is due to:</p>
<ul>
<li>Granularity on memory allocations within the heap.</li>
<li>The overhead necessary to manage each memory segment within the heap.</li>
</ul>
<p>The granularity of heap allocations in 32-bit Windows is 16 bytes. So if you request a global memory allocation of 1 byte, the heap returns a pointer to a chunk of memory, guaranteeing that the 1 byte is available. Chances are, 16 bytes will actually be available because the heap cannot allocate less than 16 bytes at a time.</p>
<h3 id="Global-and-Local-Memory-Functions-v2"><a class="header-anchor" href="#Global-and-Local-Memory-Functions-v2"></a>Global and Local Memory Functions</h3>
<p>For global and local memory functions, the documentation suggests that you use the <strong>GlobalSize</strong> and <strong>LocalSize</strong> functions to determine the exact size of the allocation, but in my tests this function consistently returned the size I requested and not the size actually allocated.</p>
<p>To confirm this finding, turn to ProcessWalker again and view the committed memory in your default heap. For the sake of observation, perform consecutive allocations of 1, 2, 3, 14, 15, and 16 bytes using either <strong>GlobalAlloc</strong> or <strong>LocalAlloc</strong>. In this particular example, we used <strong>GlobalAlloc</strong> with the GMEM_MOVEABLE flag, but the result is the same for memory allocated as GMEM_FIXED. Then, refresh your view of the committed memory in the heap. Finally, scroll the view window so that the addresses of the allocated blocks of memory are all in view. You should see something similar to the window in Figure 5.</p>
<p><img src="/assets/msdn-managing-heap-memory/5.gif" alt=""></p>
<p><strong>Figure 5. A ProcessWalker view of the default heap after making consecutive allocations of 1, 2, 3, 14, 15, and 16 bytes using the <em>GlobalAlloc</em> function.</strong></p>
<p>In Figure 5, the first line represents the header for the 1-byte allocation, followed immediately by the minimum 16 bytes allocated for the 1-byte request. Just to add visual clarity, the letter <em>m</em> appears in each allocated byte beginning at the address of the allocation. The <em>m</em>’s are visible in the ASCII representation of memory to the right of each line. At the end of all heap allocations is a heap tail, as indicated by the last line of new information in Figure 5.</p>
<p>So, although you request only 1 byte and <strong>GlobalSize</strong> returns a size of 1 byte, there are actually 16 bytes allocated and available. Similarly, for the 3-byte allocation, 13 additional bytes are available. Even more interesting is the apparent waste of memory for allocations of 14, 15, and 16 bytes. In these allocations an additional 16 bytes were allocated for no reason. These are the lines immediately following the lines with 14, 15, and 16 <em>m</em> characters. Presumably you could also use these extra 16 bytes, but again <strong>GlobalSize</strong> does not indicate their existence.</p>
<p>So what is the cost of allocating from a heap? Well, it depends on the size of the allocation. Every 1-byte allocation uses a total of 32 bytes, and a 16-byte allocation uses a total of 48 bytes. This is a considerable amount of overhead on smaller allocations. Therefore, it would not be a good idea to accumulate a number of small heap allocations because they would cost a great deal in actual memory used. On the other hand, there is nothing wrong with allocating a large chunk of memory from the heap and dividing it into smaller pieces.</p>
<h3 id="Heap-Memory-Functions"><a class="header-anchor" href="#Heap-Memory-Functions"></a>Heap Memory Functions</h3>
<p>Similar to the global and local memory functions, the heap memory functions have a minimum 16-byte granularity and the same overhead on memory allocations. Figure 6 presents a ProcessWalker view of a dynamic heap using the same allocations of 1, 2, 3, 14, 15, and 16 bytes, but this time using the <strong>HeapAlloc</strong> function.</p>
<p><img src="/assets/msdn-managing-heap-memory/6.gif" alt=""></p>
<p><strong>Figure 6. A ProcessWalker view of a dynamic heap after making consecutive allocations of 1, 2, 3, 14, 15, and 16 bytes using the <em>HeapAlloc</em> function.</strong></p>
<p>For this example, the letter <em>h</em> appears in the allocated memory for comparison with the global memory allocations shown in Figure 5. A comparison of Figures 5 and 6 shows that the two heaps behave in an identical manner for the test allocations. Also, as in the global and local memory functions, a <strong>HeapSize</strong> function determines the exact amount of memory allocated for a given request. Unfortunately, this function seems to be implemented exactly like the <strong>GlobalSize</strong> and <strong>LocalSize</strong> functions. In my tests, <strong>HeapSize</strong> always returned the amount of the allocation request, while actually allocating with the same 16-byte granularity.</p>
<h3 id="C-Run-Time-Memory-Functions"><a class="header-anchor" href="#C-Run-Time-Memory-Functions"></a>C Run-Time Memory Functions</h3>
<p>Can you guess how the C run-time library memory functions will behave on this same test? Yes, the C run-time functions exhibit the same heap memory behavior. Figure 7 represents the same allocations using the <strong>malloc</strong> function.</p>
<p><img src="/assets/msdn-managing-heap-memory/7.gif" alt=""></p>
<p><strong>Figure 7. A ProcessWalker view of the default heap after making consecutive allocations of 1, 2, 3, 14, 15, and 16 bytes using the C run-time <em>malloc</em> function.</strong></p>
<p>Unlike the global/local and heap memory functions, the C run-time library does not provide a means for retrieving the exact number of bytes allocated. Then again, how useful is that information anyway, since the <strong>GlobalSize</strong>, <strong>LocalSize</strong>, and <strong>HeapSize</strong> functions fail to perform accurately?</p>
<h2 id="Summary-and-Recommendations"><a class="header-anchor" href="#Summary-and-Recommendations"></a>Summary and Recommendations</h2>
<p>Heap memory management in Windows is greatly improved over 16-bit Windows. Instead of a systemwide global heap and application-specific local heaps, each application has a default heap and as many dynamic heaps as the application wants to create. Both types of heaps can grow dynamically and use as much of the address space as they need to satisfy an allocation request.</p>
<p>The default heap provides all dynamic memory allocations for the C run-time library <strong>malloc</strong> functions as well as the global and local memory functions. The heap memory functions can also allocate from the default heap by using its handle, which they retrieve by calling the <strong>GetProcessHeap</strong> function.</p>
<p>The dynamic heap provides serialization to avoid conflict among multiple threads accessing the same heap. To support the management of multiple dynamic heaps, each heap is identified by a unique handle returned by the <strong>HeapCreate</strong> function.</p>
<p>Heaps do at least one thing well—they allocate smaller chunks of memory rather quickly. So whenever you are reluctant to create an automatic variable in a window procedure simply for an occasional <strong>LoadString</strong> buffer, why not use <strong>GlobalAlloc</strong> or <strong>LocalAlloc</strong>, <strong>malloc</strong> or <strong>HeapAlloc</strong>? Heaps are also very good at allocating storage for dynamic data structures. Dynamic heaps lend themselves particularly well to managing several distinct dynamic data structures in an application.</p>
<p>Finally, what is the cost of using a heap? Well, if you never use any MOVEABLE (including DISCARDABLE) memory, the cost is considerably lower, and MOVEABLE memory probably doesn’t buy you much in a 32-bit linear address space. Not to mention that at 8 bytes per MOVEABLE memory handle, the system limits processes to 65,535 handles. Each chunk of heap memory allocated in either the default heap or a dynamic heap is subject to a 16-byte granularity and is charged a 16-byte header. In total, then, allocating 1 byte of MOVEABLE memory costs 40 bytes (8 bytes for the handle table entry, 16 bytes for granularity, and 16 bytes for the header). Happy heaping.</p>
<hr>
<p><strong>Article link: <a href="http://xnerv.wang/msdn-managing-heap-memory/">http://xnerv.wang/msdn-managing-heap-memory/</a></strong><br>
Reprinted from: <a href="https://msdn.microsoft.com/en-us/library/ms810603.aspx">(MSDN) Managing Heap Memory</a></p>
]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Windows</tag>
        <tag>Heap</tag>
        <tag>MSDN</tag>
        <tag>Memory Management</tag>
      </tags>
  </entry>
  <entry>
    <title>(MSDN) Managing Memory-Mapped Files</title>
    <url>/msdn-managing-memory-mapped-files/</url>
    <content><![CDATA[<p>Randy KathMicrosoft Developer Network Technology Group</p>
<p>Created: February 9, 1993</p>
<h2 id="Abstract"><a class="header-anchor" href="#Abstract"></a>Abstract</h2>
<p>Determining which function or set of functions to use for managing memory in your application is difficult without a solid understanding of how each group of functions works and the overall impact they each have on the operating system. In an effort to simplify these decisions, this technical article focuses on the use of the memory-mapped file functions in Windows: the functions that are available, the way they are used, and the impact their use has on operating system resources. The following topics are discussed in this article:</p>
<ul>
<li>Introduction to managing memory in Windows operating systems</li>
<li>What are memory-mapped files?</li>
<li>How are memory-mapped files implemented?</li>
<li>Sharing memory with memory-mapped files</li>
<li>Using memory-mapped file functions</li>
</ul>
<p>In addition to this technical article, a sample application called ProcessWalker is included on the Microsoft Developer Network CD. This sample application is useful for exploring the behavior of memory-mapped files in a process, and it provides several useful implementation examples.</p>
<span id="more"></span>
<h2 id="Introduction"><a class="header-anchor" href="#Introduction"></a>Introduction</h2>
<p>This is one of three related technical articles—“Managing Virtual Memory,” “Managing Memory-Mapped Files,” and “Managing Heap Memory”—that explain how to manage memory in applications for Windows. In each article, this introduction identifies the basic memory components in the Windows API programming model and indicates which article to reference for specific areas of interest.</p>
<p>The first version of the Windows operating system introduced a method of managing dynamic memory based on a single <em>global heap</em>, which all applications and the system share, and multiple, private <em>local heaps</em>, one for each application. Local and global memory management functions were also provided, offering extended features for this new memory management system. More recently, the Microsoft C run-time (CRT) libraries were modified to include capabilities for managing these heaps in Windows using native CRT functions such as <strong>malloc</strong> and <strong>free</strong>. Consequently, developers are now left with a choice—learn the new application programming interface (API) provided as part of Windows or stick to the portable, and typically familiar, CRT functions for managing memory in applications written for Windows.</p>
<p>Window offers three groups of functions for managing memory in applications: memory-mapped file functions, heap memory functions, and virtual-memory functions.</p>
<p><img src="/assets/msdn-managing-memory-mapped-files/1.gif" alt=""></p>
<p><strong>Figure 1. The Windows API provides different levels of memory management for versatility in application programming.</strong></p>
<p>In all, six sets of memory management functions exist in Windows, as shown in Figure 1, all of which were designed to be used independently of one another. So which set of functions should you use? The answer to this question depends greatly on two things: the type of memory management you want and how the functions relevant to it are implemented in the operating system. In other words, are you building a large database application where you plan to manipulate subsets of a large memory structure? Or maybe you’re planning some simple dynamic memory structures, such as linked lists or binary trees? In both cases, you need to know which functions offer the features best suited to your intention and exactly how much of a resource hit occurs when using each function.</p>
<p>Table 1 categorizes the memory management function groups and indicates which of the three technical articles in this series describes each group’s behavior. Each technical article emphasizes the impact these functions have on the system by describing the behavior of the system in response to using the functions.</p>
<p><strong>Table 1. Various Memory Management Functions Available</strong></p>
<table>
<thead>
<tr>
<th>Memory set</th>
<th>System resource affected</th>
<th>Related technical article</th>
</tr>
</thead>
<tbody>
<tr>
<td>Virtual memory functions</td>
<td>A process’s virtual address space<br/>System pagefile<br/>System memory<br/>Hard disk space</td>
<td>“Managing Virtual Memory”</td>
</tr>
<tr>
<td>Memory-mapped file functions</td>
<td>A process’s virtual address space<br/>System pagefile<br/>Standard file I/O<br/>System memory<br/>Hard disk space</td>
<td>“Managing Memory-Mapped Files”</td>
</tr>
<tr>
<td>Heap memory functions</td>
<td>A process’s virtual address space<br/>System memory<br/>Process heap resource structure</td>
<td>“Managing Heap Memory”</td>
</tr>
<tr>
<td>Global heap memory functions</td>
<td>A process’s heap resource structure</td>
<td>“Managing Heap Memory”</td>
</tr>
<tr>
<td>Local heap memory functions</td>
<td>A process’s heap resource structure</td>
<td>“Managing Heap Memory”</td>
</tr>
<tr>
<td>C run-time reference library</td>
<td>A process’s heap resource structure</td>
<td>“Managing Heap Memory”</td>
</tr>
</tbody>
</table>
<p>Each technical article discusses issues surrounding the use of Windows-specific functions.</p>
<h2 id="What-Are-Memory-Mapped-Files"><a class="header-anchor" href="#What-Are-Memory-Mapped-Files"></a>What Are Memory-Mapped Files?</h2>
<p>Memory-mapped files (MMFs) offer a unique memory management feature that allows applications to access files on disk in the same way they access dynamic memory—through pointers. With this capability you can map a view of all or part of a file on disk to a specific range of addresses within your process’s address space. And once that is done, accessing the content of a memory-mapped file is as simple as dereferencing a pointer in the designated range of addresses. So, writing data to a file can be as simple as assigning a value to a dereferenced pointer as in:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">*pMem = <span class="number">23</span>;</span><br></pre></td></tr></table></figure>
<p>Similarly, reading from a specific location within the file is simply:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">nTokenLen = *pMem;</span><br></pre></td></tr></table></figure>
<p>In the above examples, the pointer <em>pMem</em> represents an arbitrary address in the range of addresses that have been mapped to a view of a file. Each time the address is referenced (that is, each time the pointer is dereferenced), the memory-mapped file is the actual memory being addressed.</p>
<blockquote>
<p><strong>Note</strong>While memory-mapped files offer a way to read and write directly to a file at specific locations, the actual action of reading/writing to the disk is handled at a lower level. Consequently, data is not actually transferred at the time the above instructions are executed. Instead, much of the file input/output (I/O) is cached to improve general system performance. You can override this behavior and force the system to perform disk transactions immediately by using the memory-mapped file function <strong>FlushViewOfFile</strong> explained later.</p>
</blockquote>
<h2 id="What-Do-Memory-Mapped-Files-Have-to-Offer"><a class="header-anchor" href="#What-Do-Memory-Mapped-Files-Have-to-Offer"></a>What Do Memory-Mapped Files Have to Offer?</h2>
<p>One advantage to using MMF I/O is that the system performs all data transfers for it in 4K pages of data. Internally all pages of memory are managed by the virtual-memory manager (VMM). It decides when a page should be paged to disk, which pages are to be freed for use by other applications, and how many pages each application can have out of the entire allotment of physical memory. Since the VMM performs all disk I/O in the same manner—reading or writing memory one page at a time—it has been optimized to make it as fast as possible. Limiting the disk read and write instructions to sequences of 4K pages means that several smaller reads or writes are effectively cached into one larger operation, reducing the number of times the hard disk read/write head moves. Reading and writing pages of memory at a time is sometimes referred to as <em>paging</em> and is common to virtual-memory management operating systems.</p>
<p>Another advantage to using MMF I/O is that all of the actual I/O interaction now occurs in RAM in the form of standard memory addressing. Meanwhile, disk paging occurs periodically in the background, transparent to the application. While no gain in performance is observed when using MMFs for simply reading a file into RAM, other disk transactions can benefit immensely. Say, for example, an application implements a flat-file database file structure, where the database consists of hundreds of sequential records. Accessing a record within the file is simply a matter of determining the record’s location (a byte offset within the file) and reading the data from the file. Then, for every update, the record must be written to the file in order to save the change. For larger records, it may be advantageous to read only part of the record into memory at a time as needed. Unfortunately, though, each time a new part of the record is needed, another file read is required. The MMF approach works a little differently. When the record is first accessed, the entire 4K page(s) of memory containing the record is read into memory. All subsequent accesses to that record deal directly with the page(s) of memory in RAM. No disk I/O is required or enforced until the file is later closed or flushed.</p>
<blockquote>
<p><strong>Note</strong>During normal system paging operations, memory-mapped files can be updated periodically. If the system needs a page of memory that is occupied by a page representing a memory-mapped file, it may free the page for use by another application. If the page was dirty at the time it was needed, the act of writing the data to disk will automatically update the file at that time. (A dirty page is a page of data that has been written to, but not saved to, disk; for more information on types of virtual-memory pages, see “The Virtual-Memory Manager in Windows NT” on the Developer Network CD.)</p>
</blockquote>
<p>The flat-file database application example is useful in pointing out another advantage of using memory-mapped files. MMFs provide a mechanism to map portions of a file into memory as needed. This means that applications now have a way of getting to a small segment of data in an extremely large file without having to read the entire file into memory first. Using the above example of a large flat-file database, consider a database file housing 1,000,000 records of 125 bytes each. The file size necessary to store this database would be 1,000,000 * 125 = 125,000,000 bytes. To read a file that large would require an extremely large amount of memory. With MMFs, the entire file can be opened (but at this point no memory is required for reading the file) and a view (portion) of the file can be mapped to a range of addresses. Then, as mentioned above, each page in the view is read into memory only when addresses within the page are accessed.</p>
<h2 id="How-Are-They-Implemented"><a class="header-anchor" href="#How-Are-They-Implemented"></a>How Are They Implemented?</h2>
<p>Since Windows NT is a page-based virtual-memory system, memory-mapped files represent little more than an extension of an existing, internal memory management component. Essentially all applications in Windows NT are represented in their entirety by one or more files on disk and a subset of those files resident in random access memory (RAM) at any given time. For example, each application has an executable file that represents pages of executable code and resources for the application. These pages are swapped into and out of RAM, as they are needed, by the operating system. When a page of memory is no longer needed, the operating system relinquishes control over the page on behalf of the application that owns it and frees it for use by another. When that page becomes needed again, it is re-read from the executable file on disk. This is called backing the memory with a file, in this case, the executable file. Similarly, when a process starts, pages of memory are used to store static and dynamic data for that application. Once committed, these pages are backed by the system pagefile, similar to the way the executable file is used to back the pages of code. Figure 2 is a graphical representation of how pages of code and data are backed on the hard disk.</p>
<p><img src="/assets/msdn-managing-memory-mapped-files/2.gif" alt=""></p>
<p><strong>Figure 2. Memory used to represent pages of code in processes for Windows NT are backed directly by the application’s executable module while memory used for pages of data are backed by the system pagefile.</strong></p>
<p>Treating both code and data in the same manner paves the way for propagating this functionality to a level where applications can use it, too—which is what Windows does through memory-mapped files.</p>
<h3 id="Shared-Memory-in-Windows-NT"><a class="header-anchor" href="#Shared-Memory-in-Windows-NT"></a>Shared Memory in Windows NT</h3>
<p>Both code and data are treated the same way in Windows NT—both are represented by pages of memory and both have their pages backed by a file on disk. The only real difference is the file by which they are backed—code by the executable image and data by the system pagefile. Because of this, memory-mapped files are also able to provide a mechanism for sharing data between processes. By extending the memory-mapped file capability to include portions of the system pagefile, applications are able to share data that is backed by the pagefile. Shown in Figure 3, each application simply maps a view of the same portion of the pagefile, making the same pages of memory available to each application.</p>
<p><img src="/assets/msdn-managing-memory-mapped-files/3.gif" alt=""></p>
<p><strong>Figure 3. Processes share memory by mapping independent views of a common region in the system pagefile.</strong></p>
<p>Windows NT’s tight security system prevents processes from directly sharing information among each other, but MMFs provide a mechanism that works with the security system. In order for one process to share data with another via MMFs, each process must have common access to the file. This is achieved by giving the MMF object a name that both processes use to open the file.</p>
<p>Internally, a shared section of the pagefile translates into pages of memory that are addressable by more than one process. To do this, Windows NT uses an internal resource called a prototype page-table entry (PPTE). PPTEs enable more than one process to address the same physical page of memory. A PPTE is a system resource, so their availability and security is controlled by the system alone. This way processes can share data and still exist on a secure operating system. Figure 4 indicates how PPTEs are used in Windows NT’s virtual addressing scheme.</p>
<p><img src="/assets/msdn-managing-memory-mapped-files/4.gif" alt=""></p>
<p><strong>Figure 4. Prototype page-table entries are the mechanism that permits pages of memory to be shared among processes.</strong></p>
<p>One of the best ways to use an MMF for sharing data is to use it in a DLL (dynamic-link library). The PortTool application serves as a useful illustration. PortTool uses a DLL to provide its porting functionality and relies on the main application for the user interface. The reason for this is simple: Other applications can then also use the DLL functionality. That is, other editors that are programmable can import the porting functionality. Because it is entirely feasible for PortTool to be running while another editor that imports the PortTool DLL is also running, it is best to economize system resources as much as possible between the applications. PortTool does this by using an MMF for sharing the porting information with both processes. Otherwise, both applications would be required to load their own set of porting information while running at the same time, a waste of system resources. The PortTool code demonstrates sharing memory via an MMF in a DLL.</p>
<h2 id="Using-Memory-Mapped-File-Functions"><a class="header-anchor" href="#Using-Memory-Mapped-File-Functions"></a>Using Memory-Mapped File Functions</h2>
<p>Memory-mapped file functions can be thought of as second cousins to the virtual-memory management functions in Windows. Like the virtual-memory functions, these functions directly affect a process’s address space and pages of physical memory. No overhead is required to manage the file views, other than the basic virtual-memory management that exists for all processes. These functions deal in reserved pages of memory and committed addresses in a process. The entire set of memory-mapped file functions are:</p>
<ul>
<li><strong>CreateFileMapping</strong></li>
<li><strong>OpenFileMapping</strong></li>
<li><strong>MapViewOfFile</strong></li>
<li><strong>MapViewOfFileEx</strong></li>
<li><strong>UnmapViewOfFile</strong></li>
<li><strong>FlushViewOfFile</strong></li>
<li><strong>CloseHandle</strong></li>
</ul>
<p>Each of these functions is individually discussed below, along with code examples that demonstrate their use.</p>
<h3 id="Creating-a-File-Mapping"><a class="header-anchor" href="#Creating-a-File-Mapping"></a>Creating a File Mapping</h3>
<p>To use a memory-mapped file, you start by creating a memory-mapped file object. The act of creating an MMF object has very little impact on system resources. It does not affect your process’s address space, and no virtual memory is allocated for the object (other than for the internal resources that are necessary in representing the object). One exception, however, is that, if the MMF object represents shared memory, an adequate portion of the system pagefile is reserved for use by the MMF during the creation of the object.</p>
<p>The <strong>CreateFileMapping</strong> function is used to create the file-mapping object as demonstrated in the example listed below, a portion of PMEM.C, the source module from the ProcessWalker sample application.</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">case</span> IDM_MMFCREATENEW:</span><br><span class="line">    &#123;</span><br><span class="line">    <span class="type">char</span>    szTmpFile[<span class="number">256</span>];</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Create temporary file for mapping. */</span></span><br><span class="line">    GetTempPath (<span class="number">256</span>, szTmpFile);</span><br><span class="line">    GetTempFileName (szTmpFile,</span><br><span class="line">                     <span class="string">&quot;PW&quot;</span>,</span><br><span class="line">                     <span class="number">0</span>,</span><br><span class="line">                     MMFiles[wParam-IDM_MMFCREATE].szMMFile);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* If file created, continue to map file. */</span></span><br><span class="line">    <span class="keyword">if</span> ((MMFiles[wParam-IDM_MMFCREATE].hFile =</span><br><span class="line">           CreateFile (MMFiles[wParam-IDM_MMFCREATE].szMMFile,</span><br><span class="line">                       GENERIC_WRITE | GENERIC_READ,</span><br><span class="line">                       FILE_SHARE_WRITE,</span><br><span class="line">                       <span class="literal">NULL</span>,</span><br><span class="line">                       CREATE_ALWAYS,</span><br><span class="line">                       FILE_ATTRIBUTE_TEMPORARY,</span><br><span class="line">                       <span class="literal">NULL</span>)) != (HANDLE)INVALID_HANDLE_VALUE)</span><br><span class="line">        <span class="keyword">goto</span> MAP_FILE;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> IDM_MMFCREATEEXIST:</span><br><span class="line">    &#123;</span><br><span class="line">    <span class="type">char</span>   szFilePath[MAX_PATH];</span><br><span class="line">    OFSTRUCT   of;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Get existing filename for mapfile. */</span></span><br><span class="line">    *szFilePath = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span> (!GetFileName (hWnd, szFilePath, <span class="string">&quot;*&quot;</span>))</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* If file opened, continue to map file. */</span></span><br><span class="line">    <span class="keyword">if</span> ((MMFiles[wParam-IDM_MMFCREATE].hFile =</span><br><span class="line">            (HANDLE)OpenFile (szFilePath, &amp;of, OF_READWRITE)) !=</span><br><span class="line">                (HANDLE)HFILE_ERROR)</span><br><span class="line">        <span class="keyword">goto</span> MAP_FILE;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> IDM_MMFCREATE:</span><br><span class="line">    <span class="comment">/* Associate shared memory file handle value. */</span></span><br><span class="line">    MMFiles[wParam-IDM_MMFCREATE].hFile = (HANDLE)<span class="number">0xffffffff</span>;</span><br><span class="line"></span><br><span class="line">MAP_FILE:</span><br><span class="line">    <span class="comment">/* Create 20MB file mapping. */</span></span><br><span class="line">    <span class="keyword">if</span> (!(MMFiles[wParam-IDM_MMFCREATE].hMMFile =</span><br><span class="line">        CreateFileMapping (MMFiles[wParam-IDM_MMFCREATE].hFile,</span><br><span class="line">                           <span class="literal">NULL</span>,</span><br><span class="line">                           PAGE_READWRITE,</span><br><span class="line">                           <span class="number">0</span>,</span><br><span class="line">                           <span class="number">0x01400000</span>,</span><br><span class="line">                           <span class="literal">NULL</span>)))</span><br><span class="line">        &#123;</span><br><span class="line">        ReportError (hWnd);</span><br><span class="line">        <span class="keyword">if</span> (MMFiles[wParam-IDM_MMFCREATE].hFile)</span><br><span class="line">            &#123;</span><br><span class="line">            CloseHandle (MMFiles[wParam-IDM_MMFCREATE].hFile);</span><br><span class="line">            MMFiles[wParam-IDM_MMFCREATE].hFile = <span class="literal">NULL</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    <span class="keyword">break</span>; <span class="comment">/* from IDM_MMFCREATE */</span></span><br></pre></td></tr></table></figure>
<p>In the sample code above, three cases are demonstrated. They represent creating a memory-mapped file by first creating a temporary disk file, creating a memory-mapped file from an existing file, and creating a memory-mapped file out of part of the system pagefile. In case IDM_MMFCREATENEW, a temporary file is created first, before the memory-mapped file. For case IDM_MMFCREATEEXIST, the File Open dialog is used to retrieve a filename, and that file is then opened before the memory-mapped file is created. In the third case, IDM_MMFCREATE, the memory-mapped file is created either using the system pagefile or using one of the standard files created in the two earlier cases.</p>
<p>Notice that the <strong>CreateFileMapping</strong> function need only be called once for all three different cases. The first parameter to the <strong>CreateFileMapping</strong> function, <em>hFile</em>, is used to supply the handle to the file that is to be memory-mapped. If the system pagefile is to be used, the value 0xFFFFFFFF must be specified instead. In the above examples, a structure is used to represent both the standard file and memory-mapped file information. In the example above, the <em>hMMFile</em> field in the structure <em>MMFiles[wParam-IDM_MMFCREATE]</em> is either 0xFFFFFFFF (its default value), or it is the value of the file handle retrieved in either of the earlier cases.</p>
<p>In all three cases, the memory-mapped file is specified to be 20 MB (0x01400000) in size, regardless of the size of any files created or opened for mapping. The fourth and fifth parameters, <em>dwMaximumSizeHigh</em> and <em>dwMaximumSizeLow</em>, are used to indicate the size of the file mapping. If these parameters indicate a specific size for the memory-mapped file when memory mapping a file other than the pagefile, the file on disk is fitted to this new size—whether larger or smaller makes no difference. As an alternative, when memory mapping a file on disk, you can set the size parameters to 0. In this case, the memory-mapped file will be the same size as the original disk file. When mapping a section of the pagefile, you must specify the size of the memory-mapped file.</p>
<p>The second parameter to the <strong>CreateFileMapping</strong> function, <em>lpsa</em>, is used to supply a pointer to a <strong>SECURITY_ATTRIBUTES</strong> structure. Since memory-mapped files are an object, they have the same security attributes that can be applied to every other object. A NULL value indicates that no security attributes are relevant to your use of the memory-mapped file.</p>
<p>The third parameter, <em>fdwProtect</em>, is used to indicate the type of protection to place on the entire memory-mapped file. You can use this parameter to protect the memory-mapped file from writes by specifying PAGE_READONLY or to permit read and write access with PAGE_READWRITE.</p>
<p>One other parameter of interest is the <em>lpszMapName</em> parameter, which can be used to give the MMF object a name. In order to open a handle to an existing file-mapping object, the object must be named. All that is required of the name is a simple string that is not already being used to identify another object in the system.</p>
<h3 id="Obtaining-a-File-Mapping-Object-Handle"><a class="header-anchor" href="#Obtaining-a-File-Mapping-Object-Handle"></a>Obtaining a File-Mapping Object Handle</h3>
<p>In order to map a view of a memory-mapped file, all you need is a valid handle to the MMF object. You can obtain a valid handle in one of several ways: by creating the object as described above, by opening the object with the <strong>OpenFileMapping</strong> function, by inheriting the object handle, or by duplicating the handle.</p>
<h4 id="Opening-a-memory-mapped-file-object"><a class="header-anchor" href="#Opening-a-memory-mapped-file-object"></a>Opening a memory-mapped file object</h4>
<p>To open a file-mapping object, the object must have been given a name during the creation of the object. A name uniquely identifies the object to this and other processes that wish to share the MMF object. The following portion of code from PORT.C shows how to open a file-mapping object by name.</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* Load name for file-mapping object. */</span></span><br><span class="line">LoadString (hDLL, IDS_MAPFILENAME, szMapFileName, MAX_PATH);</span><br><span class="line"></span><br><span class="line"><span class="comment">/* After first process initializes, port data. */</span></span><br><span class="line"><span class="keyword">if</span> ((hMMFile = OpenFileMapping (FILE_MAP_WRITE,</span><br><span class="line">                                FALSE,</span><br><span class="line">                                szMapFileName)))</span><br><span class="line">    <span class="comment">/* Exit now since initialization was already performed by</span></span><br><span class="line"><span class="comment">       another process. */</span></span><br><span class="line">     <span class="keyword">return</span> TRUE;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Retrieve path and file for ini file. */</span></span><br><span class="line"><span class="keyword">if</span> (!GetIniFile (hDLL, szIniFilePath))</span><br><span class="line">    <span class="keyword">return</span> FALSE;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Test for ini file existence and get length of file. */</span></span><br><span class="line"><span class="keyword">if</span> ((<span class="type">int</span>)(hFile = (HANDLE)OpenFile (szIniFilePath,</span><br><span class="line">                                    &amp;of,</span><br><span class="line">                                    OF_READ)) == <span class="number">-1</span>)</span><br><span class="line">    <span class="keyword">return</span> FALSE;</span><br><span class="line"></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">    nFileSize = GetFileSize (hFile, <span class="literal">NULL</span>);</span><br><span class="line">    CloseHandle (hFile);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Allocate a segment of the swap file for shared memory 2*Size</span></span><br><span class="line"><span class="comment">   of ini file. */</span></span><br><span class="line"><span class="keyword">if</span> (!(hMMFile = CreateFileMapping ((HANDLE)<span class="number">0xFFFFFFFF</span>,</span><br><span class="line">                                    <span class="literal">NULL</span>,</span><br><span class="line">                                    PAGE_READWRITE,</span><br><span class="line">                                    <span class="number">0</span>,</span><br><span class="line">                                    nFileSize * <span class="number">2</span>,</span><br><span class="line">                                    szMapFileName)))</span><br><span class="line">    <span class="keyword">return</span> FALSE;</span><br></pre></td></tr></table></figure>
<p>The <strong>OpenFileMapping</strong> function requires only three arguments, the most important of these being the name of the object. As shown in the example, the name is simply a unique string. If the string is not unique to the system, the MMF object will not be created. Once the object exists, however, the name is guaranteed for the life of the object.</p>
<p>Also, note in the above example that the MMF object is opened first, possibly before the object has been created. This logic relies on the fact that, if the object does not already exist, the <strong>OpenFileMapping</strong> function will fail. This is useful in a DLL where the DLL’s initialization code is called repeatedly, once for every process that attaches to it.</p>
<p>The sample from PORT.C above occurs in the DLL’s initialization code that is called every time a DLL gets attached to another process. The first time it is called, the <strong>OpenFileMapping</strong> function fails because the object does not already exist. The logic, then, continues execution until it reaches the <strong>CreateFileMapping</strong> function, and it is there that the object is first created. Immediately after initially creating the object, the PortTool code initializes the data in the file mapping by writing porting-specific information to the memory-mapped file. To do this, the memory-mapped file is created with PAGE_READWRITE protection. All subsequent calls to the DLL’s initialization function result in the <strong>OpenFileMapping</strong> function successfully returning a valid object handle. This way the DLL does not need to keep track of which process is the first to attach to the DLL.</p>
<p>Note that for every process that attaches to the DLL, the object name is retrieved from the same source—a string from the DLL’s resource string table. Since the DLL is able to retrieve the object name from its own resource string table, the name is global to all processes, yet no process is actually aware of the name used. The DLL is able to effectively encapsulate this functionality while at the same time providing the benefit of shared memory to each process that attaches to the DLL.</p>
<p>The PortTool example presents a useful context for sharing memory. Yet, keep in mind that any file on disk could have been used in the same way. If an application were to implement some database services to several other applications, it could set up memory-mapped files using basic disk files, instead of the pagefile, and share that information in the same way. And as the first code listing illustrates, a temporary file could be used to share data instead of the pagefile.</p>
<h4 id="Inheriting-and-duplicating-memory-mapped-file-object-handles"><a class="header-anchor" href="#Inheriting-and-duplicating-memory-mapped-file-object-handles"></a>Inheriting and duplicating memory-mapped file object handles</h4>
<p>Ordinarily, for two processes to share a memory-mapped file, they must both be able to identify it by name. An exception to this is child processes, which can inherit their parent’s handles. Most objects in Windows can be explicitly targeted for inheritance or not. (Some objects are not inheritable, such as GDI object handles.) When creating an MMF object, a Boolean field in the optional <strong>SECURITY_ATTRIBUTES</strong> structure can be used to designate whether the handle is to be inheritable or not. If the MMF object handle is designated as inheritable, any child processes of the process that created the object can access the object through the same handle as their parent.</p>
<p>Literally, this means the child process can access the object by supplying the same handle value as the parent. Communicating that handle to the child process is another concern. The child process is still another process after all, having its own address space, so the handle variable itself is not transferable. Either some interprocess communication (IPC) mechanism or the command line can be used to communicate handle values to child processes.</p>
<p>Further, the <strong>DuplicateHandle</strong> function is provided to offer more control as to when handles can be inherited and not. This function can be used to create a duplicate handle of the original and can be used to change the inheritance state of the handle. An application can invoke this function to change an MMF object handle state to inheritable before passing the handle along to a child process, or it can do the opposite—it can take an inheritable handle and preserve it from being inherited.</p>
<h3 id="Viewing-Part-of-a-Memory-Mapped-File"><a class="header-anchor" href="#Viewing-Part-of-a-Memory-Mapped-File"></a>Viewing Part of a Memory-Mapped File</h3>
<p>Once obtained, the handle to the memory-mapped file object is used to map views of the file to your process’s address space. Views can be mapped and unmapped at will while the MMF object exists. When a view of the file is mapped, system resources are finally allocated. A contiguous range of addresses, large enough to span the size of the file view, are now committed in your process’s address space. Yet, even though the addresses have been committed for the file view, physical pages of memory are still only committed on a demand basis when using the memory. So, the only way to allocate a page of physical memory for a committed page of addresses in your memory-mapped file view is to generate a page fault for that page. This is done automatically the first time you read or write to any address in the page of memory.</p>
<p>To map a view of a memory-mapped file, use either the <strong>MapViewOfFile</strong> or the <strong>MapViewOfFileEx</strong> function. With both of these functions, a handle to a memory-mapped file object is a required parameter. The following example shows how the PortTool sample application implements this function.</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* Map a view of this file for writing. */</span></span><br><span class="line">lpMMFile = (<span class="type">char</span> *)MapViewOfFile (hMMFile,</span><br><span class="line">                                  FILE_MAP_WRITE,</span><br><span class="line">                                  <span class="number">0</span>,</span><br><span class="line">                                  <span class="number">0</span>,</span><br><span class="line">                                  <span class="number">0</span>);</span><br></pre></td></tr></table></figure>
<p>In this example, the entire file is mapped, so the final three parameters are less meaningful. The first parameter specifies the file-mapping object handle. The second parameter indicates the access mode for the view of the file. This can be FILE_MAP_READ, FILE_MAP_WRITE, or FILE_MAP_ALL_ACCESS, provided the protection on the file-mapping object permits it. If the object is created with PAGE_READWRITE protection, all of these access types are available. If, on the other hand, the file is created with PAGE_READONLY protection, the only access type available is FILE_MAP_READ. This allows the object creator control over how the object can be viewed.</p>
<p>The second and third parameters are used to indicate the low and high halves, respectively, of a 64-bit offset into the memory-mapped file. This offset from the start of the memory-mapped file is where the view is to begin. The final parameter indicates how much of the file is to be viewed. This parameter can be set to 0 to indicate that the entire file is to be mapped. In that case, the 64-bit offset value is ignored.</p>
<p>The function returns a pointer to the location in the process’s address space where the file view has been mapped. This is an arbitrary location in your process, depending on where the contiguous range of addresses are available. If you want to map the file view to a specific set of addresses in your process, the <strong>MapViewOfFileEx</strong> function provides this capability. This function simply adds an additional parameter, <em>lpvBase</em>, to indicate the location in your process to map the view. The return value to <strong>MapViewOfFileEx</strong> is the same value as <em>lpvBase</em> if the function is successful; otherwise, it is NULL. Similarly, for <strong>MapViewOfFile</strong> the return value is NULL if the function fails.</p>
<p>Multiple views of the same file-mapping object can coexist and overlap each other as shown in Figure 5.</p>
<p><img src="/assets/msdn-managing-memory-mapped-files/5.gif" alt=""></p>
<p><strong>Figure 5. Memory-mapped file objects permit multiple, overlapped views of the file from one or more processes at the same time.</strong></p>
<p>Notice that multiple views of a memory-mapped file can overlap, regardless of what process maps them. In a single process with overlapping views, you simply end up with two or more virtual addresses in a process that refer to the same location in physical memory. So, it’s possible to have several PTEs referencing the same page frame. Remember, each page of a shared memory-mapped file is represented by only one physical page of memory. To view that page of memory, a process needs a page directory entry and page-table entry to reference the page frame.</p>
<p>There are two ways in which needing only one physical page of memory for a shared page benefits applications in the system. First, there is an obvious savings of resources because both processes share both the physical page of memory and the page of hard disk storage used to back the memory-mapped file. Second, there is only one set of data, so all views are always coherent with one another. This means that changes made to a page in the memory-mapped file via one process’s view are automatically reflected in a common view of the memory-mapped file in another process. Essentially, Windows NT is not required to do any special bookkeeping to ensure the integrity of data to both applications.</p>
<h3 id="Unmapping-a-View-of-a-Memory-Mapped-File"><a class="header-anchor" href="#Unmapping-a-View-of-a-Memory-Mapped-File"></a>Unmapping a View of a Memory-Mapped File</h3>
<p>Once a view of the memory-mapped file has been mapped, the view can be unmapped at any time by calling the <strong>UnmapViewOfFile</strong> function. As you can see below, there is nothing tricky about this function. Simply supply the one parameter that indicates the base address, where the view of the file begins in your process</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* Load tokens for APIS section. */</span></span><br><span class="line">LoadString (hDLL, IDS_PORTAPIS, szSection, MAX_PATH);</span><br><span class="line"><span class="keyword">if</span> (!LoadSection (szIniFilePath,</span><br><span class="line">                  szSection,</span><br><span class="line">                  PT_APIS,</span><br><span class="line">                  &amp;nOffset,</span><br><span class="line">                  lpMMFile))</span><br><span class="line">        &#123;</span><br><span class="line">        <span class="comment">/* Clean up memory-mapped file. */</span></span><br><span class="line">        UnmapViewOfFile (lpMMFile);</span><br><span class="line">        CloseHandle (hMMFile);</span><br><span class="line">        <span class="keyword">return</span> FALSE;</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>
<p>As mentioned above, you can have multiple views of the same memory-mapped file, and they can overlap. But what about mapping two identical views of the same memory-mapped file? After learning how to unmap a view of a file, you could come to the conclusion that it would not be possible to have two identical views in a single process because their base address would be the same, and you wouldn’t be able to distinguish between them. This is not true. Remember that the base address returned by either the <strong>MapViewOfFile</strong> or the <strong>MapViewOfFileEx</strong> function is not the base address of the file view. Rather, it is the base address in your process where the view begins. So mapping two identical views of the same memory-mapped file will produce two views having different base addresses, but nonetheless identical views of the same portion of the memory-mapped file.</p>
<p>The point of this little exercise is to emphasize that every view of a single memory-mapped file object is always mapped to a unique range of addresses in the process. The base address will be different for each view. For that reason the base address of a mapped view is all that is required to unmap the view.</p>
<h3 id="Flushing-Views-of-Files"><a class="header-anchor" href="#Flushing-Views-of-Files"></a>Flushing Views of Files</h3>
<p>An important feature for memory-mapped files is the ability to write any changes to disk immediately if necessary. This feature is provided through the <strong>FlushViewOfFile</strong> function. Changes made to a memory-mapped file through a view of the file, other than the system pagefile, are automatically written to disk when the view is unmapped or when the file-mapping object is deleted. Yet, if an application needs to force the changes to be written immediately, <strong>FlushViewOfFile</strong> can be used for that purpose.</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* Force changes to disk immediately. */</span></span><br><span class="line">FlushViewOfFile (lpMMFile, nMMFileSize);</span><br></pre></td></tr></table></figure>
<p>The example listed above flushes an entire file view to disk. In doing so, the system only writes the dirty pages to disk. Since the Windows NT virtual-memory manager automatically tracks changes made to pages, it is a simple matter for it to enumerate all dirty pages in a range of addresses, writing them to disk. The range of addresses is formed by taking the base address of the file view supplied by the first parameter to the <strong>FlushViewOfFile</strong> function as the starting point and extending to the size supplied by the second parameter, <em>cbFlush</em>. The only requirement is that the range be within the bounds of a single file view.</p>
<h3 id="Releasing-a-Memory-Mapped-File"><a class="header-anchor" href="#Releasing-a-Memory-Mapped-File"></a>Releasing a Memory-Mapped File</h3>
<p>Like most other objects, a memory-mapped file object is closed by calling the <strong>CloseHandle</strong> function. It is not necessary to unmap all views of the memory-mapped file before closing the object. As mentioned above, dirty pages are written to disk before the object is freed. To close a memory-mapped file, call the <strong>CloseHandle</strong> function, which supplies the memory-mapped file object handle for the function parameter.</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* Close memory-mapped file. */</span></span><br><span class="line">CloseHandle (hMMFile);</span><br></pre></td></tr></table></figure>
<p>It is worth noting that closing a memory-mapped file does nothing more than free the object. If the memory-mapped file represents a file on disk, the file must still be closed using standard file I/O functions. Also, if you create a temporary file explicitly for use as a memory-mapped file as in the initial ProcessWalker example, you are responsible for removing the temporary file yourself. To illustrate what the entire cleanup process may look like, consider the following example from the ProcessWalker sample application.</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">case</span> IDM_MMFFREE:</span><br><span class="line"><span class="keyword">case</span> IDM_MMFFREENEW:</span><br><span class="line"><span class="keyword">case</span> IDM_MMFFREEEXIST:</span><br><span class="line">    &#123;</span><br><span class="line">    HCURSOR    hOldCursor;</span><br><span class="line">    OFSTRUCT   of;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Put hourglass cursor up. */</span></span><br><span class="line">    hOldCursor = (HCURSOR)SetClassLong (hWnd, GCL_HCURSOR, <span class="number">0</span>);</span><br><span class="line">    SetCursor (LoadCursor (<span class="number">0</span>, IDC_WAIT));</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Release memory-mapped file and associated file if any. */</span></span><br><span class="line">    CloseHandle (MMFiles[wParam-IDM_MMFFREE].hMMFile);</span><br><span class="line">    MMFiles[wParam-IDM_MMFFREE].hMMFile = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (MMFiles[wParam-IDM_MMFFREE].hFile)</span><br><span class="line">        &#123;</span><br><span class="line">        CloseHandle (MMFiles[wParam-IDM_MMFFREE].hFile);</span><br><span class="line">        MMFiles[wParam-IDM_MMFFREE].hFile = <span class="literal">NULL</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* If temporary file, delete here. */</span></span><br><span class="line">    <span class="keyword">if</span> (wParam == IDM_MMFFREENEW)</span><br><span class="line">        &#123;</span><br><span class="line">        OpenFile (MMFiles[wParam-IDM_MMFFREE].szMMFile,</span><br><span class="line">                  &amp;of,</span><br><span class="line">                  OF_DELETE);</span><br><span class="line">        *(MMFiles[wParam-IDM_MMFFREE].szMMFile) = <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Replace wait cursor with old cursor. */</span></span><br><span class="line">    SetClassLong (hWnd, GCL_HCURSOR, (LONG)hOldCursor);</span><br><span class="line">    SetCursor (hOldCursor);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">break</span>;</span><br></pre></td></tr></table></figure>
<p>In this example, the memory-mapped file can be one of three types: the system pagefile, a temporary file, or an existing file on disk. If the file is the system pagefile, the memory-mapped file object is simply closed, and no additional cleanup is necessary. If the memory-mapped file is mapped from an existing file, that file is closed right after closing the memory-mapped file. If the memory-mapped file is a mapping of a temporary file, it is no longer needed and is deleted using standard file I/O immediately after closing the temporary file handle, which cannot occur until after closing the memory-mapped file object handle.</p>
<h2 id="Conclusion"><a class="header-anchor" href="#Conclusion"></a>Conclusion</h2>
<p>Memory-mapped files provide unique methods for managing memory in the Windows application programming interface. They permit an application to map its virtual address space directly to a file on disk. Once a file has been memory-mapped, accessing its content is reduced to dereferencing a pointer.</p>
<p>A memory-mapped file can also be mapped by more than one application simultaneously. This represents the only mechanism for two or more processes to directly share data in Windows NT. With memory-mapped files, processes can map a common file or portion of a file to unique locations in their own address space. This technique preserves the integrity of private address spaces for all processes in Windows NT.</p>
<p>Memory-mapped files are also useful for manipulating large files. Since creating a memory mapping file consumes few physical resources, extremely large files can be opened by a process and have little impact on the system. Then, smaller portions of the file called “views” can be mapped into the process’s address space just before performing I/O.</p>
<p>There are many techniques for managing memory in applications for Windows. Whether you need the benefits of memory sharing or simply wish to manage virtual memory backed by a file on disk, memory-mapped file functions offer the support you need.</p>
<hr>
<p><strong>Article link: <a href="http://xnerv.wang/msdn-managing-memory-mapped-files/">http://xnerv.wang/msdn-managing-memory-mapped-files/</a></strong><br>
Reprinted from: <a href="https://msdn.microsoft.com/en-us/library/ms810613.aspx">(MSDN) Managing Memory-Mapped Files</a></p>
]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Windows</tag>
        <tag>Heap</tag>
        <tag>MSDN</tag>
        <tag>Memory Management</tag>
      </tags>
  </entry>
  <entry>
    <title>(MSDN) Managing Virtual Memory</title>
    <url>/msdn-managing-virtual-memory/</url>
    <content><![CDATA[<p>Randy Kath<br>
Microsoft Developer Network Technology Group</p>
<p>Created: January 20, 1993</p>
<h2 id="Abstract"><a class="header-anchor" href="#Abstract"></a>Abstract</h2>
<p>Determining which function or set of functions to use for managing memory in your application is difficult without a solid understanding of how each group of functions works and the overall impact they each have on the operating system. In an effort to simplify these decisions, this technical article focuses on the virtual memory management functions: which ones are available, how they are used, and how their use affects the operating system. The following topics are discussed in this article:</p>
<ul>
<li>Reserving, committing, and freeing virtual memory</li>
<li>Changing protection on pages of virtual memory</li>
<li>Locking pages of virtual memory</li>
<li>Querying a process’s virtual memory</li>
</ul>
<p>A sample application called ProcessWalker accompanies this technical article on the Microsoft Developer Network CD. This sample application is useful for exploring the virtual address space of a process. It also employs the use of virtual memory functions for implementing a linked list structure.</p>
<span id="more"></span>
<h2 id="Introduction"><a class="header-anchor" href="#Introduction"></a>Introduction</h2>
<p>This is one of three related technical articles—“Managing Virtual Memory,” “Managing Memory-Mapped Files,” and “Managing Heap Memory”—that explain how to manage memory in applications for Windows. In each article, this introduction identifies the basic memory components in the Windows programming model and indicates which article to reference for specific areas of interest.</p>
<p>The first version of the Microsoft Windows operating system introduced a method of managing dynamic memory based on a single <em>global heap</em>, which all applications and the system share, and multiple, private <em>local heaps</em>, one for each application. Local and global memory management functions were also provided, offering extended features for this new memory management system. More recently, the Microsoft C run-time (CRT) libraries were modified to include capabilities for managing these heaps in Windows using native CRT functions such as <strong>malloc</strong> and <strong>free</strong>. Consequently, developers are now left with a choice—learn the new application programming interface (API) provided as part of Windows or stick to the portable, and typically familiar, CRT functions for managing memory in applications written for Windows.</p>
<p>The Windows API offers three groups of functions for managing memory in applications: memory-mapped file functions, heap memory functions, and virtual memory functions.</p>
<p><img src="/assets/msdn-managing-virtual-memory/1.gif" alt=""></p>
<p><strong>Figure 1. The Windows API provides different levels of memory management for versatility in application programming.</strong></p>
<p>In all, six sets of memory management functions exist in Windows, as shown in Figure 1, all of which were designed to be used independently of one another. So, which set of functions should you use? The answer to this question depends greatly on two things: the type of memory management you want and how the functions relevant to it are implemented in the operating system. In other words, are you building a large database application where you plan to manipulate subsets of a large memory structure? Or maybe you’re planning some simple dynamic memory structures, such as linked lists or binary trees? In both cases, you need to know which functions offer the features best suited to your intention and exactly how much of a resource hit occurs when using each function.</p>
<p>Table 1 categorizes the memory management function groups and indicates which of the three technical articles in this series describes each group’s behavior. Each technical article emphasizes the impact these functions have on the system by describing the behavior of the system in response to using the functions.</p>
<p><strong>Table 1. Memory Management Functions</strong></p>
<table>
<thead>
<tr>
<th>Memory set</th>
<th>System resource affected</th>
<th>Related technical article</th>
</tr>
</thead>
<tbody>
<tr>
<td>Virtual memory functions</td>
<td>A process’ virtual address space<br/>System pagefile<br/>System memory<br/>Hard disk space</td>
<td>“Managing Virtual Memory”</td>
</tr>
<tr>
<td>Memory-mapped file functions</td>
<td>A process’s virtual address space<br/>System pagefile<br/>Standard file I/O<br/>System memory<br/>Hard disk space</td>
<td>“Managing Memory-Mapped Files”</td>
</tr>
<tr>
<td>Heap memory functions</td>
<td>A process’s virtual address space<br/>System memory<br/>Process heap resource structure</td>
<td>“Managing Heap Memory”</td>
</tr>
<tr>
<td>Global heap memory functions</td>
<td>A process’s heap resource structure</td>
<td>“Managing Heap Memory”</td>
</tr>
<tr>
<td>Local heap memory functions</td>
<td>A process’s heap resource structure</td>
<td>“Managing Heap Memory”</td>
</tr>
<tr>
<td>C run-time reference library</td>
<td>A process’s heap resource structure</td>
<td>“Managing Heap Memory”</td>
</tr>
</tbody>
</table>
<h2 id="Windows-Memory-System-Overview"><a class="header-anchor" href="#Windows-Memory-System-Overview"></a>Windows Memory System Overview</h2>
<p>Windows employs a page-based virtual memory system that uses linear addressing. Internally, the system manages all memory in segments called <em>pages</em>. Each page of physical memory is backed by either a pagefile for volatile pages of memory or a disk file for read-only memory pages. There can be as many as 16 separate pagefiles at a time. Code, resources, and other read-only data are backed directly by the files from which they originated.</p>
<p>Windows NT provides an independent, 2 gigabyte (GB) user address space for each application (process) in the system. To the application, it appears that there is 2 GB of memory available, regardless of the amount of physical memory that is actually available. When an application requests more memory than is available, Windows NT satisfies the request by paging noncritical pages of memory—from this and/or other processes—to a pagefile and freeing those physical pages of memory. Conceptually, the global heap no longer exists in Windows NT. Instead, each process has a private 32-bit address space from which all of the memory for the process is allocated—including code, resources, data, DLLs (dynamic-link libraries), and dynamic memory. Realistically, the system is still limited by whatever hardware resources are available, but the management of available resources is performed independently of the applications in the system.</p>
<h2 id="Virtual-Memory"><a class="header-anchor" href="#Virtual-Memory"></a>Virtual Memory</h2>
<p>Windows NT makes a distinction between memory and address space. Each process is attributed 2 GB of user address space no matter how much physical memory is actually available for the process. Also, all processes use the same range of linear 32-bit addresses ranging from 0000000016-7FFFFFFF16, regardless of what memory is available. Windows NT takes care of paging memory to and from disk at appropriate times so that each process is sure to be able to address the memory it needs. Although two processes may attempt to access memory at the same <em>virtual address</em> simultaneously, the Windows NT virtual memory manager actually represents these two memory locations at different physical locations where neither is likely to coincide with the original virtual address. This is virtual memory.</p>
<p>Because of virtual memory, an application is able to manage its own address space without having to consider the impact on other processes in the system. The memory manager in Windows NT is responsible for seeing that all applications have enough physical memory to operate effectively at any given moment. Applications for the Windows NT operating system do not have to be concerned with sharing system memory with other applications as they did in Windows version 3.1 or earlier. Yet even with their own address space, applications still have the ability to share memory with other applications.</p>
<p>One benefit of distinguishing between memory and address space is the capability it provides to applications for loading extremely large files into memory. Instead of having to read a large file into memory, Windows NT provides support for the application to reserve the range of addresses that the file needs. Then, sections of the file can be viewed (physically read into memory) as needed. The same can be done for large allocations of dynamic memory through virtual memory support.</p>
<p>In previous versions of Windows, an application had to allocate memory before being able to manipulate the addresses in that memory. In Windows NT, the address space of each process is already allocated; whether there is any memory associated with the addresses in the address space is a different issue. The virtual memory management functions provide low-level support for independently managing both the addresses and memory of a process.</p>
<p>The key virtual memory functions are:</p>
<ul>
<li>VirtualAlloc and VirtualFree</li>
<li>VirtualLock and VirtualUnlock</li>
<li>VirtualQuery or VirtualQueryEx</li>
<li>VirtualProtect or VirtualProtectEx</li>
</ul>
<p>Each function is grouped with its counterpart if it has one. Memory is allocated using <strong>VirtualAlloc</strong> and, once allocated, must be freed with <strong>VirtualFree</strong>. Similarly, pages that have been locked with <strong>VirtualLock</strong> must be unlocked with <strong>VirtualUnlock</strong> when no longer needed. <strong>VirtualQuery</strong> and <strong>VirtualProtect</strong> have no counterparts, but they both have complementary functions (indicated by the <strong>Ex</strong> extension on the function names) that allow them to be used on processes other than the calling process, if the calling process has the appropriate privilege to do so. These functions are explained below in their appropriate context.</p>
<h2 id="Free-Reserved-and-Committed-Virtual-Memory"><a class="header-anchor" href="#Free-Reserved-and-Committed-Virtual-Memory"></a>Free, Reserved, and Committed Virtual Memory</h2>
<p>Every address in a process can be thought of as either free, reserved, or committed at any given time. A process begins with all addresses free, meaning they are free to be committed to memory or reserved for future use. Before any free address may be used, it must first be allocated as reserved or committed. Attempting to access an address that is either reserved or free generates an access violation exception.</p>
<p>The entire 2 GB of addresses in a process are either free for use, reserved for future use, or committed to specific memory (in use). Figure 2 represents a hypothetical process consisting of free, reserved, and committed addresses.</p>
<p><img src="/assets/msdn-managing-virtual-memory/2.gif" alt=""></p>
<p><strong>Figure 2. A process’s 2 GB of virtual address space is divided into regions of free, reserved, and committed memory locations.</strong></p>
<h3 id="Reserved-Addresses"><a class="header-anchor" href="#Reserved-Addresses"></a>Reserved Addresses</h3>
<p>When reserving addresses in a process, no pages of physical memory are committed, and perhaps more importantly, no space is reserved in the pagefile for backing the memory. Also, reserving a range of addresses is no guarantee that at a later time there will be physical memory available to commit to those addresses. Rather, it is simply saving a specific free address range until needed, protecting the addresses from other allocation requests. Without this type of protection, routine operations such as loading a DLL or resource could occupy specific addresses and jeopardize their availability for later use.</p>
<p>Reserving addresses is a quick operation, completely independent of the size of the address range being reserved. Whether reserving a 1 GB or a 4K range of addresses, the function is relatively speedy. This is not surprising considering that no resources are allocated during the operation. The function merely makes an entry into the process’s virtual address descriptor (VAD) tree.</p>
<p>To reserve a range of addresses, invoke the <strong>VirtualAlloc</strong> function as shown in the following code fragment:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* Reserve a 10 MB range of addresses */</span></span><br><span class="line">lpBase = VirtualAlloc (<span class="literal">NULL</span>,</span><br><span class="line">                       <span class="number">10485760</span>,</span><br><span class="line">                       MEM_RESERVE,</span><br><span class="line">                       PAGE_NOACCESS);</span><br></pre></td></tr></table></figure>
<p>As shown here, a value of NULL used for the first parameter, <em>lpAddress</em>, directs the function to reserve the range of addresses at whichever location is most convenient. Alternatively, a specific address could have been passed indicating a precise starting address for the reserved range. Either way, the return value to this function indicates the address at the beginning of the reserved range of addresses, unless the function is unable to complete the request. Then, the return value for the <strong>VirtualAlloc</strong> function is an error-status value.</p>
<p>The second parameter indicates the range of addresses the function should allocate. This value can be anywhere from one page to 2 GB in size, but <strong>VirtualAlloc</strong> is actually constrained to a smaller range than that. The minimum size that can be reserved is 64K, and the maximum that can be reserved is the largest contiguous range of free addresses in the process. Requesting one page of reserved addresses results in a 64K address range. Conversely, requesting 2 GB will certainly fail because it is not possible to have that much address space free at any given time. (Remember that the act of loading an application consumes part of the initial 2 GB address space.)</p>
<blockquote>
<p><strong>Note</strong><br>
Windows NT builds a safeguard into every process’s address space. Both the upper and lower 65,536 bytes of each process are permanently reserved by the system. These portions of the address space are reserved to trap stray pointers—pointers that attempt to address memory in the range 0000000016-0000FFFF16 or 7FFF000016-7FFFFFFF16. Not coincidentally, it is easy to detect pointers in this range by simply ignoring the lower four nibbles (the rightmost two bytes) in these addresses. Essentially, a pointer is invalid if the upper four nibbles are 000016 or 7FFF16; all other values represent valid addresses.</p>
</blockquote>
<p>The final two parameters in the <strong>VirtualAlloc</strong> function, <em>dwAllocationType</em> and <em>dwProtect</em>, are used to determine how to allocate the addresses and the protection to associate with them. Addresses can be allocated as either type MEM_COMMIT or MEM_RESERVE. PAGE_READONLY, PAGE_READWRITE, and PAGE_NOACCESS are the three protections that can be applied to virtual memory. Reserved addresses are always PAGE_NOACCESS, a default enforced by the system no matter what value is passed to the function. Committed pages can be either read-only, read-write, or no-access.</p>
<h3 id="Committed-Memory"><a class="header-anchor" href="#Committed-Memory"></a>Committed Memory</h3>
<p>To use reserved addresses, memory must first be committed to the addresses. Committing memory to addresses is similar to reserving it—call <strong>VirtualAlloc</strong> with the <em>dwAllocation</em> parameter equal to MEM_COMMIT. At this point, resources become committed to addresses. Memory can be committed as little as one page at a time. The maximum amount of memory that can be committed is based solely on the maximum range of contiguous free or reserved addresses (but not a combination of both), regardless of the amount of physical memory available to the system.</p>
<p>When memory is committed, physical pages of memory are allocated and space is reserved in a pagefile. That is, pages of committed memory always exist as either physical pages of memory or as pages that have been paged to the pagefile on disk. It is also possible that, while committing a chunk of memory, part or all of that memory will not reside in physical memory initially. Some pages of memory reside initially in the pagefile until accessed. Once pages of memory are committed, the virtual memory manager treats them like all other pages of memory in the system.</p>
<p>In the Windows NT virtual memory system, page tables are used to access physical pages of memory. Each page table is itself a page of memory, like committed pages. Occasionally, when committing memory, additional pages must be allocated for page tables at the same time. So a request to commit a page of memory can require one page commitment for a page table, one page for the requested page, and two pages of space in the pagefile to back each of these pages. Consequently, the time it takes <strong>VirtualAlloc</strong> to complete a memory-commit request varies widely, depending on the state of the system and the size of the request.</p>
<p>The following example demonstrates how to commit a specific page of reserved addresses from the previous example to a page of memory.</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* Commit memory for 3rd page of addresses. */</span></span><br><span class="line">lpPage3 = VirtualAlloc (lpBase + (<span class="number">2</span> * <span class="number">4096</span>),</span><br><span class="line">                        <span class="number">4096</span>,</span><br><span class="line">                        MEM_COMMIT,</span><br><span class="line">                        PAGE_READWRITE);</span><br></pre></td></tr></table></figure>
<p>Notice that instead of specifying NULL for <em>lpAddress</em>, a specific address is given to indicate exactly which page of reserved addresses becomes committed to memory. Also, this page of memory is initially given PAGE_READWRITE protection instead of PAGE_NOACCESS as in the previous example. The return address from the function is the virtual address of the first pages of committed addresses.</p>
<h3 id="Freeing-Virtual-Memory"><a class="header-anchor" href="#Freeing-Virtual-Memory"></a>Freeing Virtual Memory</h3>
<p>Once addresses have been allocated as either reserved or committed, <strong>VirtualFree</strong> is the only way to release them—that is, return them to free addresses. <strong>VirtualFree</strong> can also be used to decommit committed pages and, at the same time, return the addresses to reserved status. When decommitting addresses, all physical memory and pagefile space associated with the addresses is released. The following example demonstrates how to decommit the page of memory committed in the previous example.</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* Decommit memory for 3rd page of addresses. */</span></span><br><span class="line">VirtualFree (lpBase + (<span class="number">2</span> * <span class="number">4096</span>),</span><br><span class="line">             <span class="number">4096</span>,</span><br><span class="line">             MEM_DECOMMIT,</span><br><span class="line">             PAGE_NOACCESS);</span><br></pre></td></tr></table></figure>
<p>Only addresses that are committed can be decommitted. This is important to remember when you need to decommit a large range of addresses. Say, for example, you have a range of addresses where several subsets of the addresses are committed and others are reserved. The only way to make the entire range reserved is to independently decommit each subset of committed addresses one by one. Attempting to decommit the entire range of addresses will fail because reserved addresses cannot be decommitted.</p>
<p>Conversely, the same range of addresses can be freed in one fell swoop. It doesn’t matter what the state of an address is when the address is freed. The following example demonstrates freeing the 10 MB range of addresses reserved in the first example.</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* Free entire 10 MB range of addresses. */</span></span><br><span class="line">VirtualFree (lpBase,</span><br><span class="line">             <span class="number">10485760</span>,</span><br><span class="line">             MEM_RELEASE,</span><br><span class="line">             PAGE_NOACCESS);</span><br></pre></td></tr></table></figure>
<h2 id="Changing-Protection-on-Pages-of-Virtual-Memory"><a class="header-anchor" href="#Changing-Protection-on-Pages-of-Virtual-Memory"></a>Changing Protection on Pages of Virtual Memory</h2>
<p>Use the <strong>VirtualProtect</strong> function as a method for changing the protection on committed pages of memory. An application can, for example, commit a page of addresses as PAGE_READWRITE and immediately fill the page with data. Then, the protection on the page could be changed to PAGE_READONLY, effectively protecting the data from being overwritten by any thread in the process. The following example uses the <strong>VirtualProtect</strong> function to make an inaccessible page available.</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* Change page protection to read/write. */</span></span><br><span class="line">VirtualProtect (lpStack + <span class="number">4096</span>,</span><br><span class="line">                <span class="number">4096</span>,</span><br><span class="line">                PAGE_READWRITE,</span><br><span class="line">                lpdwOldProt);</span><br></pre></td></tr></table></figure>
<p>Consider the following as a context for using this function. A data-buffering application receives a varying flow of data. Depending on specific hardware configurations and other software applications competing for CPU time, the flow of data may at times exceed the capability of the process. To prevent this from happening, the application designs a memory system that initially commits some pages of memory for a buffer. The application then protects the upper page of memory with PAGE_NOACCESS protection so that any attempt to access this memory generates an exception. The application also surrounds this code with an exception handler to handle access violations.</p>
<p>When an access violation exception occurs, the application is able to determine that the buffer is approaching its upper limit. It responds by changing the protection on the page to PAGE_READWRITE, allowing the buffer to receive any additional data and continue uninterrupted. At the same time, the application spawns another thread to slow the data flow until the buffer is back down to a reasonable operating range. When things are back to normal, the upper page is returned to PAGE_NOACCESS and the additional thread goes away. This scenario describes how combining page protection and exception handling can be used to provide unique memory management opportunities.</p>
<h2 id="Locking-Pages-of-Virtual-Memory"><a class="header-anchor" href="#Locking-Pages-of-Virtual-Memory"></a>Locking Pages of Virtual Memory</h2>
<p>Processes in Windows NT have a minimal set of pages called a <em>working set</em> that, in order for the process to run properly, must be present in memory when running. Windows NT assigns a default number of pages to a process at startup and gradually tunes that number to achieve a balanced optimum performance among all active processes in the system. When a process is running (actually, when the threads of a process are running), Windows NT works hard at making sure that the process has its working set of pages resident in physical memory at all times.</p>
<p>Processes in Windows NT are granted subtle influence into this system behavior with the <strong>VirtualLock</strong> and <strong>VirtualUnlock</strong> functions. Essentially, a process can establish specific pages to lock into its working set. However, this does not give the process free reign over its working set. It cannot affect the number of pages that make up its working set (the system adjusts the working set for each process routinely), and it cannot control when the working set is in memory and when it is not. The maximum number of pages that can be locked into a process’s working set at one time is limited to 32. An application could do more harm than good by locking pages of committed memory into the working set because doing so may force other critical pages in the process to become replaced. In that case, the pages could become paged to disk, causing page faults to occur whenever they were accessed. Then the process would spend much of its CPU allotment just paging critical pages in and out of memory.</p>
<p>Below is an example that locks a range of addresses into memory when the process is running.</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* Lock critical addresses into memory. */</span></span><br><span class="line">VirtualLock (lpCriticalData, <span class="number">1024</span>);</span><br></pre></td></tr></table></figure>
<p>Notice the range of addresses being locked into memory in this example is less than one page. It is not necessary for the entire range to be in a single page of memory. The net result is that the entire page of memory containing the data for the addresses, not just the data for the addresses indicated, is locked into memory. If the data straddles a page boundary, both pages are locked.</p>
<h2 id="Querying-a-Process’s-Virtual-Memory"><a class="header-anchor" href="#Querying-a-Process’s-Virtual-Memory"></a>Querying a Process’s Virtual Memory</h2>
<p>Given a process’s 2 GB of address space, managing the entire range of addresses would be difficult without the ability to query address information. Because the addresses themselves are represented independent of the memory that may or may not be committed to them, querying them is simply a matter of accessing the data structure that maintains their state. In Windows NT, this structure is the virtual address descriptor tree mentioned earlier. Windows exposes the capability of “walking the VAD structure” in the <strong>VirtualQuery</strong> and <strong>VirtualQueryEx</strong> functions. Again, the <strong>Ex</strong> suffix indicates which function can be called from one process to query another—if the calling process has the security privilege necessary to perform this function. The following example is extracted from the ProcessWalker sample:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* Query next region of memory in child process. */</span></span><br><span class="line">VirtualQueryEx (hChildProcess,</span><br><span class="line">                lpMem,</span><br><span class="line">                lpList,</span><br><span class="line">                <span class="keyword">sizeof</span> (MEMORY_BASIC_INFORMATION));</span><br></pre></td></tr></table></figure>
<p>The ProcessWalker application’s primary function is to walk a process’s address space, identifying each of its distinct address regions and representing specific state information about each region. It does this by enumerating each region one at a time from the bottom of the process to the top. <em>lpMem</em> is used to indicate the location of each region. Initially it is set to 0, and after returning from each query of a new region, it is incremented by the size of the region it queried. This process is repeated until <em>lpMem</em> reaches the upper system reserved area.</p>
<p><em>lpList</em> is a pointer to a <strong>MEMORY_BASIC_INFORMATION</strong> structure to be filled in by the <strong>VirtualQueryEx</strong> function. When the function returns, this structure represents information about the region queried. The structure has the following members:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> _<span class="title">MEMORY_BASIC_INFORMATION</span> &#123;</span> <span class="comment">/* mbi */</span></span><br><span class="line">    PVOID BaseAddress;       <span class="comment">/* Base address of region    */</span></span><br><span class="line">    PVOID AllocationBase;    <span class="comment">/* Allocation base address   */</span></span><br><span class="line">    DWORD AllocationProtect; <span class="comment">/* Initial access protection */</span></span><br><span class="line">    DWORD RegionSize;        <span class="comment">/* Size in bytes of region   */</span></span><br><span class="line">    DWORD State;             <span class="comment">/* Committed, reserved, free */</span></span><br><span class="line">    DWORD Protect;           <span class="comment">/* Current access protection */</span></span><br><span class="line">    DWORD Type;              <span class="comment">/* Type of pages             */</span></span><br><span class="line">&#125; MEMORY_BASIC_INFORMATION;</span><br></pre></td></tr></table></figure>
<p>The <strong>VirtualQuery</strong> function returns this state information for any contiguous address region. The function determines the lower bound of the region and the size of the region, along with the exact state of the addresses in the region. The address it uses to determine the region can be any address in the region. So, if you wish to determine how much stack space has been committed at any given time, follow these steps:</p>
<ol>
<li>Get the thread context for the thread in question.</li>
<li>Call the <strong>VirtualQuery</strong> function, supplying the address of the stack pointer in the thread context information as the <em>lpMem</em> parameter in the function.<br>
The query returns the size of the committed memory and the address of the base of the stack in the <strong>MEMORY_BASIC_INFORMATION</strong> structure in the form of the <em>RegionSize</em> and <em>BaseAddress</em>, respectively.</li>
</ol>
<p>Regions of memory, as defined by <strong>VirtualQuery</strong>, are a contiguous range of addresses whose protection, type, and base allocation are the same. The type and protection values are described earlier in this technical article. The base allocation is the <em>lpAddress</em> parameter value that is used when the entire region of memory was first allocated via the <strong>VirtualAlloc</strong> function. It is represented in the <strong>MEMORY_BASIC_INFORMATION</strong> structure as the <strong>AllocationBase</strong> field.</p>
<p>When free addresses become either reserved or committed, their base allocation is determined at that time. A region of memory is not static by any means. Once a single page in a region of reserved addresses becomes committed, the region is broken into one or more reserved regions and one committed region. This continues as pages of memory change state. Similarly, when one of several PAGE_READWRITE committed pages is changed to PAGE_READONLY protection, the region is broken into multiple, smaller regions.</p>
<h2 id="Conclusion"><a class="header-anchor" href="#Conclusion"></a>Conclusion</h2>
<p>The virtual memory management functions in Windows offer direct management of virtual memory in Windows NT. Each process’s 2 GB user address space is divided into regions of memory that are either reserved, committed, or free virtual addresses. A region is defined as a contiguous range of addresses in which the protection, type, and base allocation of each address is the same. Within each region are one or more pages of addresses that also carry protection and pagelock flag status bits.</p>
<p>The virtual memory management functions provide capabilities for applications to alter the state of pages in the virtual address space. An application can change the type of memory from committed to reserved or change the protection from PAGE_READWRITE to PAGE_READONLY to prevent access to a region of addresses. An application can lock a page into the working set for a process to minimize paging for a critical page of memory. The virtual memory functions are considered low-level functions, meaning they are relatively fast but they lack many high-level features.</p>
<hr>
<p><strong>Article link: <a href="http://xnerv.wang/msdn-managing-virtual-memory/">http://xnerv.wang/msdn-managing-virtual-memory/</a></strong><br>
Reprinted from: <a href="https://msdn.microsoft.com/en-us/library/ms810627.aspx">(MSDN) Managing Virtual Memory</a></p>
]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Windows</tag>
        <tag>MSDN</tag>
        <tag>Memory Management</tag>
        <tag>Virtual Memory</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL - Index Condition Pushdown (ICP)（转载）</title>
    <url>/mysql-index-condition-pushdown/</url>
    <content><![CDATA[<h2 id="前言"><a class="header-anchor" href="#前言"></a>前言</h2>
<p><a href="http://mysql.taobao.org/monthly/2015/11/07/">上一篇文章</a> 提过，我们在之后的文章中会从 optimizer 的选项出发，系统的介绍 optimizer 的各个变量，包括变量的原理、作用以及源码实现等，然后再进一步的介绍优化器的工作过程（SQL 语句扁平化处理、索引选择、代价计算、多表连接顺序选择以及物理执行等内容），本期我们先看一下众所周知的 ICP，官方文档请参考<a href="https://dev.mysql.com/doc/refman/5.6/en/condition-pushdown-optimization.html">这里</a>。</p>
<h2 id="ICP-测试"><a class="header-anchor" href="#ICP-测试"></a>ICP 测试</h2>
<p>首先，咱们来看一下打开 ICP 与关闭 ICP 之间的性能区别，以下是测试过程：</p>
<p>准备数据：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> icp(id <span class="type">int</span>, age <span class="type">int</span>, name <span class="type">varchar</span>(<span class="number">30</span>), memo <span class="type">varchar</span>(<span class="number">600</span>)) engine<span class="operator">=</span>innodb;</span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> icp <span class="keyword">add</span> index aind(age, name, memo);</span><br><span class="line"><span class="comment">--let $i= 100000</span></span><br><span class="line">while ($i)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="comment">--eval insert into icp values($i, 1, &#x27;a$i&#x27;, repeat(&#x27;a$i&#x27;, 100))</span></span><br><span class="line">  <span class="comment">--dec $i</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>PS: MySQL 有一个叫profile的东东，可以用来监视 SQL 语句在各个阶段的执行情况，咱们可以使用这个工具来观察 SQL 语句在各个阶段的运行情况，关于 profile 的详细说明可以参考<a href="http://dev.mysql.com/doc/refman/5.7/en/show-profile.html">官方文档</a>。</p>
<span id="more"></span>
<p>打开 ICP 的性能测试：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">set</span> profiling<span class="operator">=</span><span class="keyword">on</span>;</span><br><span class="line"><span class="keyword">set</span> optimizer_switch<span class="operator">=</span><span class="string">&#x27;index_condition_pushdown=on&#x27;</span>; （<span class="keyword">default</span> enabled）</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> icp <span class="keyword">where</span> age <span class="operator">=</span> <span class="number">1</span> <span class="keyword">and</span> memo <span class="keyword">like</span> <span class="string">&#x27;%9999%&#x27;</span>;</span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">show</span> profile cpu,block io <span class="keyword">for</span> query <span class="number">7</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------+-----------+-----------+------------+--------------+---------------+</span></span><br><span class="line"><span class="operator">|</span> Status               <span class="operator">|</span> Duration  <span class="operator">|</span> CPU_user  <span class="operator">|</span> CPU_system <span class="operator">|</span> Block_ops_in <span class="operator">|</span> Block_ops_out <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------+-----------+-----------+------------+--------------+---------------+</span></span><br><span class="line"><span class="operator">|</span> executing            <span class="operator">|</span>  <span class="number">0.000009</span> <span class="operator">|</span>  <span class="number">0.000000</span> <span class="operator">|</span>   <span class="number">0.000000</span> <span class="operator">|</span>            <span class="number">0</span> <span class="operator">|</span>             <span class="number">0</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> Sending data         <span class="operator">|</span> <span class="number">3.225383</span> <span class="operator">|</span> <span class="number">3.507467</span> <span class="operator">|</span>   <span class="number">0.037994</span> <span class="operator">|</span>            <span class="number">0</span> <span class="operator">|</span>             <span class="number">0</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------+-----------+-----------+------------+--------------+---------------+</span></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">show</span> session status <span class="keyword">like</span> <span class="string">&#x27;%handler%&#x27;</span>;<span class="keyword">show</span> session status <span class="keyword">like</span> <span class="string">&#x27;%handler%&#x27;</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------+--------+</span></span><br><span class="line"><span class="operator">|</span> Handler_read_next          <span class="operator">|</span> <span class="number">19</span>    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> Handler_read_rnd_next      <span class="operator">|</span> <span class="number">30</span>    <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------+--------+</span></span><br><span class="line"><span class="number">18</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>
<p>关闭 ICP 的性能测试：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">set</span> optimizer_switch<span class="operator">=</span><span class="string">&#x27;index_condition_pushdown=off&#x27;</span>;</span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> icp <span class="keyword">where</span> age <span class="operator">=</span> <span class="number">1</span> <span class="keyword">and</span> memo <span class="keyword">like</span> <span class="string">&#x27;%9999%&#x27;</span>;</span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">show</span> profile cpu, block io <span class="keyword">for</span> query <span class="number">20</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------+----------+----------+------------+--------------+---------------+</span></span><br><span class="line"><span class="operator">|</span> Status               <span class="operator">|</span> Duration <span class="operator">|</span> CPU_user <span class="operator">|</span> CPU_system <span class="operator">|</span> Block_ops_in <span class="operator">|</span> Block_ops_out <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------+----------+----------+------------+--------------+---------------+</span></span><br><span class="line"><span class="operator">|</span> Sending data         <span class="operator">|</span> <span class="number">15.327345</span> <span class="operator">|</span> <span class="number">17.443348</span> <span class="operator">|</span>   <span class="number">0.165975</span> <span class="operator">|</span>            <span class="number">0</span> <span class="operator">|</span>             <span class="number">0</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------+----------+----------+------------+--------------+---------------+</span></span><br><span class="line"><span class="number">15</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span>, <span class="number">1</span> warning (<span class="number">0.00</span> sec)</span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">show</span> session status <span class="keyword">like</span> <span class="string">&#x27;%handler%&#x27;</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------+--------+</span></span><br><span class="line"><span class="operator">|</span> Variable_name              <span class="operator">|</span> <span class="keyword">Value</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------+--------+</span></span><br><span class="line"><span class="operator">|</span> Handler_read_next          <span class="operator">|</span> <span class="number">100019</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> Handler_read_rnd_next      <span class="operator">|</span> <span class="number">47</span>     <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------+--------+</span></span><br><span class="line"><span class="number">18</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.01</span> sec)</span><br></pre></td></tr></table></figure>
<p>测试结论：由以上测试情况可以看到，在二级索引是复合索引且前面的条件过滤性较低的情况下，打开 ICP 可以有效的降低 server 层和 engine 层之间交互的次数，从而有效的降低在运行时间。</p>
<h2 id="ICP-原理"><a class="header-anchor" href="#ICP-原理"></a>ICP 原理</h2>
<p>5.6 之前，在 SQL 语句的执行过程中，server 层通过 engine 的 api 获取数据，然后再进行 where_cond 的判断（具体判断逻辑在: <code>evaluate_join_record</code>），每一条数据都需要从engine层返回server层做判断。我们回顾一下上面把 ICP 关掉的测试，可以看到 <code>Handler_read_next</code> 的值陡增，其原因是第 1 个字段区分度不高，且 memo 字段无法使用索引，造成了类似 index 扫描的的情况，性能较低。</p>
<p>5.6 之后，在利用索引扫描的过程中，如果发现 where_cond 中含有这个 index 相关的条件，则将此条件记录在 handler 接口中，在索引扫描的过程中，只有满足索引与handler接口的条件时，才会返回到 server 层做进一步的处理，在前缀索引区分度不够，其它字段区分度高的情况下可以有效的减少 server &amp; engine之间的开销，提升查询性能。</p>
<h2 id="ICP-源码实现"><a class="header-anchor" href="#ICP-源码实现"></a>ICP 源码实现</h2>
<p>我们在上小节提到，index condition down 所用的条件是记在handler接口中的，咱们分析一下“记录”的过程是如何实现的。</p>
<p>首先，优化器计算代价后会生成一个 JOIN_TAB 的左支树，每一个 JOIN_TAB 包含相关表的指针、表的读取方式、访问表所包含的索引等信息，优化器会在 <code>make_join_readinfo</code> 中对JOIN_TAB中表的访问方式进行相应的修正，并进一步将 where cond 中和索引相关的条件记录到 table 的句柄中，堆栈如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">#<span class="number">0</span>  <span class="built_in">make_cond_for_index</span> (cond=<span class="number">0x2b69680179e8</span>, table=<span class="number">0x2b6968012100</span>, keyno=<span class="number">0</span>, other_tbls_ok=<span class="literal">true</span>)</span><br><span class="line">#<span class="number">1</span>  <span class="function">in <span class="title">push_index_cond</span> <span class="params">(tab=<span class="number">0x2b696802aa48</span>, keyno=<span class="number">0</span>, other_tbls_ok=<span class="literal">true</span>, trace_obj=<span class="number">0x2b696413ec30</span>)</span></span></span><br><span class="line"><span class="function">#2  in <span class="title">make_join_readinfo</span> <span class="params">(join=<span class="number">0x2b6968017db0</span>, options=<span class="number">0</span>, no_jbuf_after=<span class="number">4294967295</span>)</span></span></span><br><span class="line"><span class="function">#3  in <span class="title">JOIN::optimize</span> <span class="params">(<span class="keyword">this</span>=<span class="number">0x2b6968017db0</span>)</span></span></span><br><span class="line"><span class="function">#4  in <span class="title">mysql_execute_select</span> <span class="params">(thd=<span class="number">0x3176760</span>, select_lex=<span class="number">0x3179470</span>, free_join=<span class="literal">true</span>)</span></span></span><br><span class="line"><span class="function"></span></span><br></pre></td></tr></table></figure>
<p>其次， <code>make_cond_for_index</code> 是一个递归的过程，对 where_cond中的每一个条件进行判断，对满足条件的 cond 重新组合成一个新的cond，最后将新的 cond 挂在table-&gt;file 下面（table-&gt;file 指的是操作物理表的接口函数，此变量为thd下私有的，不共享，共享的是tab-&gt;table-&gt;s），详细参考<code>make_cond_for_index</code> 的详细实现，设置的堆栈如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">#<span class="number">0</span>  ha_innobase::<span class="built_in">idx_cond_push</span> (<span class="keyword">this</span>=<span class="number">0x2b696800e810</span>, keyno=<span class="number">0</span>, idx_cond=<span class="number">0x2b69680179e8</span>)</span><br><span class="line">#<span class="number">1</span>  <span class="number">0x0000000000a60a55</span> <span class="function">in <span class="title">push_index_cond</span> <span class="params">(tab=<span class="number">0x2b696802aa48</span>, keyno=<span class="number">0</span>, other_tbls_ok=<span class="literal">true</span>, trace_obj=<span class="number">0x2b696413ec30</span>)</span></span></span><br><span class="line"><span class="function">#2  0x0000000000a6362f in <span class="title">make_join_readinfo</span> <span class="params">(join=<span class="number">0x2b6968017db0</span>, options=<span class="number">0</span>, no_jbuf_after=<span class="number">4294967295</span>)</span></span></span><br><span class="line"><span class="function">#3  0x0000000000d9b8bd in <span class="title">JOIN::optimize</span> <span class="params">(<span class="keyword">this</span>=<span class="number">0x2b6968017db0</span></span></span></span><br><span class="line"><span class="params"><span class="function">#<span class="number">4</span>  <span class="number">0x0000000000a5b9ae</span> in mysql_execute_select (thd=<span class="number">0x3176760</span>, select_lex=<span class="number">0x3179470</span>, free_join=<span class="literal">true</span>)</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br></pre></td></tr></table></figure>
<p>再次，server 层根据生成的 JOIN_TAB 读取engine层的内容，在engine读取的时候，会进行<code>index_condition_pushdown</code>的调用，即 ICP 的调用，堆栈如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">#<span class="number">0</span>  Item_func_like::<span class="built_in">val_int</span> (<span class="keyword">this</span>=<span class="number">0x2b6978005a28</span>)</span><br><span class="line">#<span class="number">1</span>  <span class="number">0x0000000001187b66</span> <span class="function">in <span class="title">innobase_index_cond</span> <span class="params">(file=<span class="number">0x2b696800e810</span>)</span></span></span><br><span class="line"><span class="function">#2  0x0000000001393566 in <span class="title">row_search_idx_cond_check</span> <span class="params">(mysql_rec=<span class="number">0x2b69680129f0</span>  &lt;incomplete sequence \<span class="number">361</span>&gt;, prebuilt=<span class="number">0x2b69680130f8</span>, rec=<span class="number">0x2b692b56e4cf</span> <span class="string">&quot;\200&quot;</span>, offsets=<span class="number">0x2b697008d450</span>)</span></span></span><br><span class="line"><span class="function">#3  0x0000000001397e2b in <span class="title">row_search_for_mysql</span> <span class="params">(buf=<span class="number">0x2b69680129f0</span>  &lt;incomplete sequence \<span class="number">361</span>&gt;, mode=<span class="number">2</span>, prebuilt=<span class="number">0x2b69680130f8</span>, match_mode=<span class="number">1</span>, direction=<span class="number">0</span>)</span></span></span><br><span class="line"><span class="function">#4  0x00000000011696b9 in <span class="title">ha_innobase::index_read</span> <span class="params">(<span class="keyword">this</span>=<span class="number">0x2b696800e810</span>, buf=<span class="number">0x2b69680129f0</span>  &lt;incomplete sequence \<span class="number">361</span>&gt;, key_ptr=<span class="number">0x2b697800a660</span> <span class="string">&quot;&quot;</span>, key_len=<span class="number">5</span>, find_flag=HA_READ_KEY_EXACT)</span></span></span><br><span class="line"><span class="function">#5  0x00000000006ecc58 in <span class="title">handler::index_read_map</span> <span class="params">(<span class="keyword">this</span>=<span class="number">0x2b696800e810</span>, buf=<span class="number">0x2b69680129f0</span>  &lt;incomplete sequence \<span class="number">361</span>&gt;, key=<span class="number">0x2b697800a660</span> <span class="string">&quot;&quot;</span>, keypart_map=<span class="number">1</span>, find_flag=HA_READ_KEY_EXACT)</span></span></span><br><span class="line"><span class="function">#6  0x00000000006d6bb4 in <span class="title">handler::ha_index_read_map</span> <span class="params">(<span class="keyword">this</span>=<span class="number">0x2b696800e810</span>, buf=<span class="number">0x2b69680129f0</span>  &lt;incomplete sequence \<span class="number">361</span>&gt;, key=<span class="number">0x2b697800a660</span> <span class="string">&quot;&quot;</span>, keypart_map=<span class="number">1</span>, find_flag=HA_READ_KEY_EXACT)</span></span></span><br><span class="line"><span class="function">#7  0x00000000009a1870 in <span class="title">join_read_always_key</span> <span class="params">(tab=<span class="number">0x2b697800a1b8</span>)</span></span></span><br><span class="line"><span class="function">#8  0x000000000099d480 in <span class="title">sub_select</span> <span class="params">(join=<span class="number">0x2b6978005df0</span>, join_tab=<span class="number">0x2b697800a1b8</span>, end_of_records=<span class="literal">false</span>)</span></span></span><br><span class="line"><span class="function">#9  0x000000000099c6c0 in <span class="title">do_select</span> <span class="params">(join=<span class="number">0x2b6978005df0</span>)</span></span></span><br><span class="line"><span class="function">#10 0x00000000009980a4 in <span class="title">JOIN::exec</span> <span class="params">(<span class="keyword">this</span>=<span class="number">0x2b6978005df0</span>)</span></span></span><br><span class="line"><span class="function">#11 0x0000000000a5bac0 in <span class="title">mysql_execute_select</span> <span class="params">(thd=<span class="number">0x32801a0</span>, select_lex=<span class="number">0x3282eb0</span>, free_join=<span class="literal">true</span>)</span></span></span><br><span class="line"><span class="function"></span></span><br></pre></td></tr></table></figure>
<p>可见在 ICP 的判断是调用相关item的函数的，虽然同是调用 server 层的函数，但是没有 ICP 的调用需要根据主建找到记录，然后再匹配，而有了 ICP 可以省略一次主键查找数据的过程，进而提升效率。</p>
<h2 id="ICP-使用限制及问题"><a class="header-anchor" href="#ICP-使用限制及问题"></a>ICP 使用限制及问题</h2>
<ul>
<li>
<p>只支持 select 语句；</p>
</li>
<li>
<p>5.6 中只支持 MyISAM 与 InnoDB 引擎;</p>
</li>
<li>
<p>ICP的优化策略可用于range、ref、eq_ref、ref_or_null 类型的访问数据方法；</p>
</li>
<li>
<p>不支持主建索引的 ICP；</p>
</li>
<li>
<p>当 SQL 使用覆盖索引时但只检索部分数据时，ICP 无法使用，详细的分析可以参考 <a href="http://bugs.mysql.com/bug.php?id=68554">bug#68554</a> 中 Olav Sandstå的分析，代码实现部分可以参考 <code>make_join_readinfo</code>；</p>
</li>
<li>
<p>在查询的时候即使正确的使用索引的前Ｎ个字段（即遵循前缀索引的原则），还是会用到 ICP，无故的多了 ICP 相关的判断，这应该是一个退化的问题，例：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql&gt; explain select * from icp where age=1 and name = &#x27;a1&#x27;;</span><br><span class="line">+----+-------------+-------+------+---------------+------+---------+-------------+------+-----------------------+</span><br><span class="line">| id | select_type | table | type | possible_keys | key  | key_len | ref         | rows | Extra                 |</span><br><span class="line">+----+-------------+-------+------+---------------+------+---------+-------------+------+-----------------------+</span><br><span class="line">|  1 | SIMPLE      | icp   | ref  | aind          | aind | 38      | const,const |    1 | Using index condition |</span><br><span class="line">+----+-------------+-------+------+---------------+------+---------+-------------+------+-----------------------+</span><br><span class="line">1 row in set (3.26 sec)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>PS: engine condition pushdown 是 NDB 使用的，其它引擎不支持。</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/mysql-index-condition-pushdown/">http://xnerv.wang/mysql-index-condition-pushdown/</a></strong><br>
转载自：<a href="http://mysql.taobao.org/monthly/2015/12/08/">Index Condition Pushdown (ICP)</a></p>
]]></content>
      <categories>
        <category>DBMS</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>DBMS</tag>
        <tag>MySQL</tag>
        <tag>Index Condition Pushdown</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL - InnoDB Adaptive hash index介绍（转载）</title>
    <url>/mysql-introduction-innodb-adaptive-hash-index/</url>
    <content><![CDATA[<h2 id="前言"><a class="header-anchor" href="#前言"></a>前言</h2>
<p>我们知道InnoDB的索引组织结构为Btree。通常情况下，我们需要根据查询条件，从根节点开始寻路到叶子节点，找到满足条件的记录。为了减少寻路开销，InnoDB本身做了几点优化。</p>
<p>首先，对于连续记录扫描，InnoDB在满足比较严格的条件时采用row cache的方式连续读取8条记录（并将记录格式转换成MySQL Format），存储在线程私有的<code>row_prebuilt_t::fetch_cache</code>中；这样一次寻路就可以获取多条记录，在server层处理完一条记录后，可以直接从cache中取数据而无需再次寻路，直到cache中数据取完，再进行下一轮。</p>
<p>另一种方式是，当一次进入InnoDB层获得数据后，在返回server层前，当前在btree上的cursor会被暂时存储到<code>row_prebuilt_t::pcur</code>中，当再次返回InnoDB层捞数据时，如果对应的Block没有发生任何修改，则可以继续沿用之前存储的cursor，无需重新定位。</p>
<p>上面这两种方式都是为了减少了重新寻路的次数，而对于一次寻路的开销，则使用Adaptive hash index来解决。AHI是一个内存结构，严格来说不是传统意义上的索引，可以把它理解为建立在Btree索引上的“索引”。</p>
<span id="more"></span>
<p>本文代码分析基于MySQL 5.7.7-rc，描述的逻辑适用于5.7.7之前及5.6版本。但在即将发布的MySQL-5.7.8版本中， InnoDB根据索引id对AHI进行了分区处理，以此来降低btr_search_latch读写锁竞争，由于尚未发布，本文暂不覆盖相关内容。</p>
<p>我们以一个干净启动的实例作为起点，分析下如何进行AHI构建的过程。</p>
<h2 id="初始化"><a class="header-anchor" href="#初始化"></a>初始化</h2>
<p>AHI在内存中表现就是一个普通的哈希表对象，存储在<code>btr_search_sys_t::hash_index</code>中，对AHI的查删改操作都是通过一个全局读写锁<code>btr_search_latch</code>来保护。</p>
<p>在实例启动，完成buffer pool初始化后，会初始化AHI子系统相关对象，并分配AHI内存，大小为buffer pool的1/64。</p>
<p>参考函数：<code>btr_search_sys_create</code></p>
<p>Tips：MySQL 5.7已经开始支持InnoDB buffer pool的动态调整，其策略是buffer pool的大小改变超过1倍，就重新分配AHI Hash内存（<code>btr_search_sys_resize</code>）。</p>
<h2 id="触发AHI信息统计"><a class="header-anchor" href="#触发AHI信息统计"></a>触发AHI信息统计</h2>
<p>在系统刚启动时，索引对象上没有足够的信息来启发是否适合进行AHI缓存，因此开始有个信息搜集的阶段，在索引对象上维护了<code>dict_index_t::search_info</code>，类型为<code>btr_search_t</code>，用于跟踪当前索引使用AHI的关键信息。</p>
<p>在第一次执行SQL时，需要从btree的root节点开始，当寻址到匹配的叶子节点时，会走如下逻辑：</p>
<p>btr_cur_search_to_nth_level：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (btr_search_enabled &amp;&amp; !index-&gt;disable_ahi) &#123;</span><br><span class="line">        <span class="built_in">btr_search_info_update</span>(index, cursor);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里会判断脏读AHI开关（btr_search_enabled）是否打开，以及<code>index-&gt;diable_ahi</code>是否为false。第二个条件是MySQL5.7对临时表的优化，避免临时表操作对全局对象的影响，针对临时表不做AHI构建。</p>
<p>我们看看函数btr_search_info_update的逻辑：</p>
<ol>
<li>对<code>info-&gt;hash_analysis++</code>，当<code>info-&gt;hash_analysis</code>值超过<code>BTR_SEARCH_HASH_ANALYSIS</code>（17）时，也就是说对该索引寻路到叶子节点17次后，才会去做AHI分析（进入步骤2）</li>
<li>进入函数<code>btr_search_info_update_slow</code></li>
</ol>
<p>在连续执行17次对相同索引的操作后，满足<code>info-&gt;hash_analysis</code>大于等于<code>BTR_SEARCH_HASH_ANALYSIS</code>的条件，就会调用函数<code>btr_search_info_update_slow</code>来更新search_info，这主要是为了避免频繁的索引查询分析产生的过多CPU开销。</p>
<p>InnoDB通过索引条件构建一个可用于查询的tuple，而AHI需要根据tuple定位到叶子节点上记录的位置，既然AHI是构建在Btree索引上的索引，它的键值就是通过索引的前N列的值计算的来，所有的信息搜集统计都是为了确定一个合适的”Ｎ” ，这个值也是个动态的值，会跟随应用的负载自适应调整并触发block上的AHI重构建。</p>
<p><code>btr_search_info_update_slow</code>包含三个部分：更新索引查询信息、block上的查询信息以及为当前block构建AHI，下面几小节分别介绍。</p>
<h2 id="更新索引上的查询信息"><a class="header-anchor" href="#更新索引上的查询信息"></a>更新索引上的查询信息</h2>
<p>参考函数：<code>btr_search_info_update_hash</code></p>
<p>这里涉及到的几个search_info变量包括： <code>btr_search_t::n_hash_potential</code> 表示如果使用AHI构建索引，潜在的可能成功的次数； <code>btr_search_t::hash_analysis</code> 若设置了新的建议前缀索引模式，则重置为0，随后的17次查询分析可以忽略更新search_info。</p>
<p>下面两个字段表示推荐的前缀索引模式： <code>btr_search_t::n_fields</code> 推荐构建AHI的索引列数； <code>btr_search_t::left_side</code> 表示是否在相同索引前缀的最左索引记录构建AHI；值为true时，则对于相同前缀索引的记录，只存储最右的那个记录。 通过n_fields和left_side可以指导选择哪些列作为索引前缀来构建（fold, rec）哈希记录。如果用户的SQL的索引前缀列的个数大于等于构建AHI时的前缀索引，就可以用上AHI。</p>
<p>Tip1：在５.7之前的版本中，还支持索引中的字符串前缀作为构建AHI的键值的一部分，但上游认为带来的好处并不明显，因此将<code>btr_search_t::n_bytes</code> 移除了(参见commit <a href="https://github.com/mysql/mysql-server/commit/6f5f19b338543277a108a97710de8dd59b9dbb60" title="Bug#16852278 SIMPLIFY RECORD COMPARISONS">6f5f19b338543277a108a97710de8dd59b9dbb60</a>, <a href="https://github.com/mysql/mysql-server/commit/42499d9394bf103a27d63cd38b0c3c6bd738a7c7" title="Remove support for byte-level prefix granularity in searches.">42499d9394bf103a27d63cd38b0c3c6bd738a7c7</a>）。 Tip2：然而上游在测试中发现，如果把n_bytes移除，可能在诸如顺序插入这样的场景存在性能退化(参阅commit <a href="https://github.com/mysql/mysql-server/commit/00ec81a9efc1108376813f15935b52c451a268cf" title="Bug#21198396 REINTRODUCE ADAPTIVE HASH INDEX FIELD PREFIXES">00ec81a9efc1108376813f15935b52c451a268cf</a>)，因此在新发布的MySQL5.7.8版本中又重新引入，本文分析代码时统一基于MySQL5.7.7版本。</p>
<p>两种情况需要构建建议的前缀索引列：</p>
<ol>
<li>当前是第一次为该索引做AHI分析，<code>btr_search_t::n_hash_potential</code>值为0，需要构建建议的前缀索引列；</li>
<li>新的记录匹配模式发生了变化<code>(info-&gt;left_side == (info-&gt;n_fields &lt;=cursor-&gt;low_match))</code>，需要重新设置前缀索引列。</li>
</ol>
<p>相关代码段：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (cursor-&gt;up_match == cursor-&gt;low_match) &#123;</span><br><span class="line">        info-&gt;n_hash_potential = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* For extra safety, we set some sensible values here */</span></span><br><span class="line"></span><br><span class="line">        info-&gt;n_fields = <span class="number">1</span>;</span><br><span class="line">        info-&gt;left_side = TRUE;</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (cursor-&gt;up_match &gt; cursor-&gt;low_match) &#123;</span><br><span class="line">        info-&gt;n_hash_potential = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (cursor-&gt;up_match &gt;= n_unique) &#123;</span><br><span class="line">                info-&gt;n_fields = n_unique;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (cursor-&gt;low_match &lt; cursor-&gt;up_match) &#123;</span><br><span class="line">                info-&gt;n_fields = cursor-&gt;low_match + <span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                info-&gt;n_fields = cursor-&gt;low_match;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        info-&gt;left_side = TRUE;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        info-&gt;n_hash_potential = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (cursor-&gt;low_match &gt;= n_unique) &#123;</span><br><span class="line"></span><br><span class="line">                info-&gt;n_fields = n_unique;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (cursor-&gt;low_match &gt; cursor-&gt;up_match) &#123;</span><br><span class="line"></span><br><span class="line">                info-&gt;n_fields = cursor-&gt;up_match + <span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                info-&gt;n_fields = cursor-&gt;up_match;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        info-&gt;left_side = FALSE;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>从上述代码可以看到，在low_match和up_match之间，选择小一点match的索引列数的来进行设置，但不超过唯一确定索引记录值的列的个数：</p>
<ol>
<li>当low_match小于up_match时，left_side设置为true，表示相同前缀索引的记录只缓存最左记录；</li>
<li>当low_match大于up_match时，left_side设置为false，表示相同前缀索引的记录只缓存最右记录。</li>
</ol>
<p>如果不是第一次进入seach_info分析，有两种情况会递增<code>btr_search_t::n_hash_potential</code>：</p>
<ul>
<li>
<p>本次查询的up_match和当前推荐的前缀索引都能唯一决定一条索引记录(例如唯一索引)，则根据search_info推荐的前缀索引列构建AHI肯定能命中，递增 <code>info-&gt;n_hash_potential</code>；</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (info-&gt;n_fields &gt;= n_unique &amp;&amp; cursor-&gt;up_match &gt;= n_unique) &#123;</span><br><span class="line">increment_potential:</span><br><span class="line">        info-&gt;n_hash_potential++;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>本次查询的tuple可以通过建议的前缀索引列构建的AHI定位到。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (info-&gt;left_side == (info-&gt;n_fields &lt;= cursor-&gt;up_match)) &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">goto</span> increment_potential;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>很显然，如果对同一个索引的查询交替使用不同的查询模式，可能上次更新的search_info很快就会被重新设置，具有固定模式的索引查询将会受益于AHI索引。</p>
<h2 id="更新block上的查询信息"><a class="header-anchor" href="#更新block上的查询信息"></a>更新block上的查询信息</h2>
<p>参考函数：<code>btr_search_update_block_hash_info</code></p>
<p>更新数据页block上的查询信息，涉及到修改的变量包括：</p>
<p><code>btr_search_info::last_hash_succ</code> 最近一次成功(或可能成功)使用AHI； <code>buf_block_t::n_hash_helps</code> 计数值，如果使用当前推荐的前缀索引列构建AHI可能命中的次数，用于启发构建／重新构建数据页上的AHI记录项； <code>buf_block_t::n_fields</code> 推荐在block上构建AHI的前缀索引列数； <code>buf_block_t::left_side</code> 和search_info上对应字段含义相同。</p>
<p>函数主要流程包括：</p>
<ol>
<li>
<p>首先设置<code>btr_search_info::last_hash_succ</code> 为FALSE 这会导致在分析过程中无法使用AHI进行检索，感觉这里的设置不是很合理。这意味着每次分析一个新的block，都会导致AHI短暂不可用。</p>
</li>
<li>
<p>初始化或更新block上的查询信息</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> ((block-&gt;n_hash_helps &gt; <span class="number">0</span>)</span><br><span class="line">    &amp;&amp; (info-&gt;n_hash_potential &gt; <span class="number">0</span>)</span><br><span class="line">    &amp;&amp; (block-&gt;n_fields == info-&gt;n_fields)</span><br><span class="line">    &amp;&amp; (block-&gt;left_side == info-&gt;left_side)) &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> ((block-&gt;index)</span><br><span class="line">            &amp;&amp; (block-&gt;curr_n_fields == info-&gt;n_fields)</span><br><span class="line">            &amp;&amp; (block-&gt;curr_left_side == info-&gt;left_side)) &#123;</span><br><span class="line"></span><br><span class="line">                <span class="comment">/* The search would presumably have succeeded using</span></span><br><span class="line"><span class="comment">                the hash index */</span></span><br><span class="line"></span><br><span class="line">                info-&gt;last_hash_succ = TRUE;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        block-&gt;n_hash_helps++;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        block-&gt;n_hash_helps = <span class="number">1</span>;</span><br><span class="line">        block-&gt;n_fields = info-&gt;n_fields;</span><br><span class="line">        block-&gt;left_side = info-&gt;left_side;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当block第一次被touch到并进入该函数时，设置block上的建议索引列值；以后再进入时，如果和索引上的全局search_info相匹配，则递增<code>block-&gt;n_hash_helps</code>，启发后续的创建或重构建AHI。</p>
<p>如果当前数据页block上已经构建了AHI记录项，且<code>buf_block_t::curr_n_fields</code>等字段和<code>btr_search_info</code>上对应字段值相同时，则认为当前SQL如果使用AHI索引能够命中，因此将<code>btr_search_info::last_hash_succ</code>设置为true，下次再使用相同索引检索btree时就会尝试使用AHI。</p>
</li>
<li>
<p>在初始化或更新block上的变量后，需要判断是否为整个page构建AHI索引：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> ((block-&gt;n_hash_helps &gt; <span class="built_in">page_get_n_recs</span>(block-&gt;frame)</span><br><span class="line">     / BTR_SEARCH_PAGE_BUILD_LIMIT)</span><br><span class="line">    &amp;&amp; (info-&gt;n_hash_potential &gt;= BTR_SEARCH_BUILD_LIMIT)) &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> ((!block-&gt;index)</span><br><span class="line">            || (block-&gt;n_hash_helps</span><br><span class="line">                &gt; <span class="number">2</span> * <span class="built_in">page_get_n_recs</span>(block-&gt;frame))</span><br><span class="line">            || (block-&gt;n_fields != block-&gt;curr_n_fields)</span><br><span class="line">            || (block-&gt;left_side != block-&gt;curr_left_side)) &#123;</span><br><span class="line"></span><br><span class="line">                <span class="comment">/* Build a new hash index on the page */</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">return</span>(TRUE);</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>简单来说，当满足下面三个条件时，就会去为整个block上构建AHI记录项：</p>
<ul>
<li>分析使用AHI可以成功查询的次数(<code>buf_block_t::n_hash_helps</code>)超过block上记录数的16(<code>BTR_SEARCH_PAGE_BUILD_LIMIT</code>)分之一；</li>
<li><code>btr_search_info::n_hash_potential</code>大于等于<code>BTR_SEARCH_BUILD_LIMIT</code> (100)，表示连续100次潜在的成功使用AHI可能性；</li>
<li>尚未为当前block构造过索引、或者当前block上已经构建了AHI索引且<code>block-&gt;n_hash_helps</code>大于page上记录数的两倍、或者当前block上推荐的前缀索引列发生了变化 。</li>
</ul>
</li>
</ol>
<h2 id="为数据页构建AHI索引"><a class="header-anchor" href="#为数据页构建AHI索引"></a>为数据页构建AHI索引</h2>
<p>如果在上一阶段判断认为可以为当前page构建AHI索引（函数<code>btr_search_update_block_hash_info</code>返回值为TRUE），则根据当前推荐的索引前缀进行AHI构建。</p>
<p>参考函数：<code>btr_search_build_page_hash_index</code></p>
<p>分为三个阶段：</p>
<ol>
<li>
<p><strong>检查阶段</strong>：加btr_search_latch的S锁，判断AHI开关是否打开；如果block上已经构建了老的AHI但前缀索引列和当前推荐的不同，则清空Block对应的AHI记录项（<code>btr_search_drop_page_hash_index</code>）；检查n_fields和page上的记录数；然后释放btr_search_latch的S锁；</p>
</li>
<li>
<p><strong>搜集阶段</strong>：根据推荐的索引列数计算记录fold值，将对应的数据页记录内存地址到数组里；</p>
<p>根据left_mode值，相同的前缀索引列值会有不同的行为，举个简单的例子，假设page上记录为 (2,1), (2,2), (5, 3), (5, 4), (7, 5), (8, 6)，n_fields＝１</p>
<ul>
<li>若left_most为true，则hash存储的记录为(2,1) , (5, 3), (7, 5), (8,6)</li>
<li>若left_most为false，则hash存储的记录为(2, 2), (5, 4), (7,5), (8, 6)</li>
</ul>
</li>
<li>
<p><strong>插入阶段</strong>：加btr_search_latch的X锁，将第二阶段搜集的(fold, rec)插入到AHI中，并更新：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (!block-&gt;index) &#123;</span><br><span class="line">        index-&gt;search_info-&gt;ref_count++;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">block-&gt;n_hash_helps = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">block-&gt;curr_n_fields = n_fields;</span><br><span class="line">block-&gt;curr_left_side = left_side;</span><br><span class="line">block-&gt;index = index;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>PS：由于第二阶段释放了btr_search_latch锁，这里还得判断block上的AHI信息是否发生了变化，如果block上已经构建了AHI且block-&gt;curr_*几个变量和当前尝试构建的检索模式不同，则放弃本次构建。</p>
<h2 id="使用AHI"><a class="header-anchor" href="#使用AHI"></a>使用AHI</h2>
<p>AHI的目的是根据用户提供的查询条件加速定位到叶子节点，一般如果有固定的查询pattern，都可以通过AHI受益，尤其是Btree高度比较大的时候。</p>
<p>入口函数：<code>btr_cur_search_to_nth_level</code></p>
<p>相关代码：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">        <span class="comment">/* Use of AHI is disabled for intrinsic table as these tables re-use</span></span><br><span class="line"><span class="comment">        the index-id and AHI validation is based on index-id. */</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">rw_lock_get_writer</span>(&amp;btr_search_latch) == RW_LOCK_NOT_LOCKED</span><br><span class="line">            &amp;&amp; latch_mode &lt;= BTR_MODIFY_LEAF</span><br><span class="line">            &amp;&amp; info-&gt;last_hash_succ</span><br><span class="line">            &amp;&amp; !index-&gt;disable_ahi</span><br><span class="line">            &amp;&amp; !estimate</span><br><span class="line"><span class="meta"># <span class="keyword">ifdef</span> PAGE_CUR_LE_OR_EXTENDS</span></span><br><span class="line">            &amp;&amp; mode != PAGE_CUR_LE_OR_EXTENDS</span><br><span class="line"><span class="meta"># <span class="keyword">endif</span> <span class="comment">/* PAGE_CUR_LE_OR_EXTENDS */</span></span></span><br><span class="line">            &amp;&amp; !<span class="built_in">dict_index_is_spatial</span>(index)</span><br><span class="line">            <span class="comment">/* If !has_search_latch, we do a dirty read of</span></span><br><span class="line"><span class="comment">            btr_search_enabled below, and btr_search_guess_on_hash()</span></span><br><span class="line"><span class="comment">            will have to check it again. */</span></span><br><span class="line">            &amp;&amp; <span class="built_in">UNIV_LIKELY</span>(btr_search_enabled)</span><br><span class="line">            &amp;&amp; !modify_external</span><br><span class="line">            &amp;&amp; <span class="built_in">btr_search_guess_on_hash</span>(index, info, tuple, mode,</span><br><span class="line">                                        latch_mode, cursor,</span><br><span class="line">                                        has_search_latch, mtr)) &#123;</span><br></pre></td></tr></table></figure>
<p>从代码段可以看出，需要满足如下条件才能够使用AHI：</p>
<ul>
<li>没有加btr_search_latch写锁。如果加了写锁，可能操作时间比较耗时，走AHI检索记录就得不偿失了；</li>
<li>latch_mode &lt;= BTR_MODIFY_LEAF，表明本次只是一次不变更BTREE结构的DML或查询（包括等值、RANGE等查询）操作；</li>
<li><code>btr_search_info::last_hash_succ</code>为true表示最近一次使用AHI成功（或可能成功）了；</li>
<li>打开AHI开关；</li>
<li>查询优化阶段的估值操作，例如计算range范围等，典型的堆栈包括：<code>handler::multi_range_read_info_const</code>　–&gt; <code>ha_innobase::records_in_range</code> –&gt; <code>btr_estimate_n_rows_in_range</code> –&gt; <code>btr_cur_search_to_nth_level</code>；</li>
<li>不是spatial索引；</li>
<li>调用者无需分配外部存储页(BTR_MODIFY_EXTERNAL，主要用于辅助写入大的blob数据，参考struct btr_blob_log_check_t)。</li>
</ul>
<p>当满足上述条件时，进入函数<code>btr_search_guess_on_hash</code>，根据当前的查询tuple对象计算fold，并查询AHI；只有当前检索使用的tuple列的个数大于等于构建AHI的列的个数时，才能够使用AHI索引。</p>
<p><code>btr_search_guess_on_hash</code>：</p>
<ul>
<li>首先用户提供的前缀索引查询条件必须大于等于构建AHI时的前缀索引列数，这里存在一种可能性：索引上的search_info的n_fields 和block上构建AHI时的cur_n_fields值已经不相同了，但是我们并不知道本次查询到底落在哪个block上，这里一致以search_info上的n_fields为准来计算fold，去查询AHI；</li>
<li>在检索AHI时需要加&amp;btr_search_latch的S锁；</li>
<li>如果本次无法命中AHI，就会将<code>btr_search_info::last_hash_succ</code>设置为false，这意味着随后的查询都不会去使用AHI了，只能等待下一路查询信息分析后才可能再次启动（<code>btr_search_failure</code>）；</li>
<li>对于从ahi中获得的记录指针，还需要根据当前的查询模式检查是否是正确的记录位置（<code>btr_search_check_guess</code>）。</li>
</ul>
<p>如果本次查询使用了AHI，但查询失败了（<code>cursor-&gt;flag == BTR_CUR_HASH_FAIL</code>），并且当前block构建AHI索引的curr_n_fields等字段和btr_search_info上的相符合，则根据当前cursor定位到的记录插入AHI。参考函数：<code>btr_search_update_hash_ref</code>。</p>
<p>从上述分析可见，AHI如其名，完全是自适应的，如果检索模式不固定，很容易就出现无法用上AHI或者AHI失效的情况。</p>
<h2 id="维护AHI"><a class="header-anchor" href="#维护AHI"></a>维护AHI</h2>
<ol>
<li>
<p>关闭选项innodb_adaptive_hash_index；</p>
<ul>
<li>持有<code>dict_sys-&gt;mutex</code>和<code>btr_search_latch</code>的X锁；</li>
<li>遍历<code>dict_sys-&gt;table_LRU</code>和<code>dict_sys-&gt;table_non_LRU</code>链表，将每个表上的所有索引的<code>index-&gt;search_info-&gt;ref_count</code>设置为0；</li>
<li>释放<code>dict_sys-&gt;mutex</code>；</li>
<li>遍历buffer pool，将block上的index标记(<code>buf_block_t::index</code>)清空为NULL；</li>
<li>清空AHI中的哈希项，并释放为记录项分配的Heap；</li>
<li>释放btr_search_latch。</li>
</ul>
<p>参考函数：<code>btr_search_disable</code></p>
</li>
<li>
<p><code>index-&gt;search_info</code>的ref_count不为0时，无法从数据集词典cache中将对应的表驱逐，workaround的方式是临时关闭AHI开关；</p>
<p>参考函数：<code>dict_table_can_be_evicted</code>、<code>dict_index_remove_from_cache_low</code></p>
</li>
<li>
<p>删除索引页上的记录，或者更新的是二级索引、或者更新了主键且影响了排序键值，则需要从AHI上将对应的索引记录删除；</p>
<p>参考函数：<code>btr_search_update_hash_on_delete</code></p>
</li>
<li>
<p>插入新的记录时，如果本次插入未产生页面重组、操作的page为叶子节点，且本次插入操作使用过AHI定位成功，则先尝试更新再尝试插入，否则直接插入对应的AHI记录项；</p>
<p>参考函数：<code>btr_search_update_hash_node_on_insert</code>、<code>btr_search_update_hash_on_insert</code></p>
</li>
<li>
<p>涉及索引树分裂或者节点合并，或从LRU中驱逐page（buf_LRU_free_page）时，需要清空AHI对应的page。</p>
<p>参考函数：<code>btr_search_drop_page_hash_index</code></p>
</li>
</ol>
<h2 id="shortcut查询模式"><a class="header-anchor" href="#shortcut查询模式"></a>shortcut查询模式</h2>
<p>在<code>row_search_mvcc</code>函数中，首先会去判断在满足一定条件时，使用shortcut模式，利用AHI索引来进行检索。</p>
<p>只有满足严苛的条件时（例如需要唯一键查询、使用聚集索引、长度不超过八分之一的page size、隔离级别在RC及RC之上、活跃的Read view等等条件，具体的参阅代码），才能使用shortcut：</p>
<ul>
<li>加<code>btr_search_latch</code>的S锁；</li>
<li>然后通过<code>row_sel_try_search_shortcut_for_mysql</code>检索记录；如果找到满足条件的记录，本次查询可以不释放 btr_search_latch，这意味着InnoDB/server层交互期间可能持有AHI锁，但最多在10000次（BTR_SEA_TIMEOUT）交互后释放AHI latch。一旦发现有别的线程在等待AHI X 锁，也会主动释放其拥有的S锁。</li>
</ul>
<p>然而， Percona的开发Alexey Kopytov认为这种长时间拥有的<code>btr_search_latch</code>的方式是没有必要的，这种设计方式出现在很久之前加锁、解锁非常昂贵的时代，然而现在的CPU已经很先进了，完全没有必要，在Percona的版本中，一次shortcut的查询操作后都直接释放掉<code>btr_search_latch</code>（参阅<a href="https://bugs.launchpad.net/percona-server/+bug/1218347">bug#1218347</a>）。</p>
<h2 id="AHI监控项"><a class="header-anchor" href="#AHI监控项"></a>AHI监控项</h2>
<p>我们可以通过<code>information_schema.innodb_metrics</code>来监控AHI模块的运行状态</p>
<p>首先打开监控：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span>  <span class="keyword">set</span> <span class="keyword">global</span> innodb_monitor_enable <span class="operator">=</span> module_adaptive_hash;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">select</span> status, name, subsystem <span class="keyword">from</span> INNODB_METRICS <span class="keyword">where</span> subsystem <span class="keyword">like</span> <span class="string">&#x27;%adaptive_hash%&#x27;</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">---------+------------------------------------------+---------------------+</span></span><br><span class="line"><span class="operator">|</span> status  <span class="operator">|</span> name                                     <span class="operator">|</span> subsystem           <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------+------------------------------------------+---------------------+</span></span><br><span class="line"><span class="operator">|</span> enabled <span class="operator">|</span> adaptive_hash_searches                   <span class="operator">|</span> adaptive_hash_index <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> enabled <span class="operator">|</span> adaptive_hash_searches_btree             <span class="operator">|</span> adaptive_hash_index <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> enabled <span class="operator">|</span> adaptive_hash_pages_added                <span class="operator">|</span> adaptive_hash_index <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> enabled <span class="operator">|</span> adaptive_hash_pages_removed              <span class="operator">|</span> adaptive_hash_index <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> enabled <span class="operator">|</span> adaptive_hash_rows_added                 <span class="operator">|</span> adaptive_hash_index <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> enabled <span class="operator">|</span> adaptive_hash_rows_removed               <span class="operator">|</span> adaptive_hash_index <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> enabled <span class="operator">|</span> adaptive_hash_rows_deleted_no_hash_entry <span class="operator">|</span> adaptive_hash_index <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> enabled <span class="operator">|</span> adaptive_hash_rows_updated               <span class="operator">|</span> adaptive_hash_index <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------+------------------------------------------+---------------------+</span></span><br><span class="line"><span class="number">8</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>
<p>重置所有的计数</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">set</span> <span class="keyword">global</span> innodb_monitor_reset_all <span class="operator">=</span> <span class="string">&#x27;adaptive_hash%&#x27;</span>;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>
<p>该表搜集了AHI子系统诸如AHI查询次数，更新次数等信息，可以很好的监控其运行状态，在某些负载下，AHI并不适合打开，关闭AHI可以避免额外的维护开销。当然这取决于你针对具体负载的性能测试。</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/mysql-introduction-innodb-adaptive-hash-index/">http://xnerv.wang/mysql-introduction-innodb-adaptive-hash-index/</a></strong><br>
转载自：<a href="http://mysql.taobao.org/monthly/2015/09/01/">InnoDB Adaptive hash index介绍</a></p>
]]></content>
      <categories>
        <category>DBMS</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>DBMS</tag>
        <tag>MySQL</tag>
        <tag>InnoDB</tag>
        <tag>Adaptive hash index</tag>
        <tag>Hash</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL Row Format(MySQL行格式详解)（转载）</title>
    <url>/mysql-row-format/</url>
    <content><![CDATA[<p><img src="/assets/mysql-row-format/1.jpg" alt=""></p>
<span id="more"></span>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/mysql-row-format/">http://xnerv.wang/mysql-row-format/</a></strong><br>
转载自：<a href="http://hedengcheng.com/?p=127">MySQL Row Format(MySQL行格式详解)</a></p>
]]></content>
      <categories>
        <category>DBMS</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>DBMS</tag>
        <tag>MySQL</tag>
        <tag>Row Format</tag>
      </tags>
  </entry>
  <entry>
    <title>【MySQL】MySQL5.6新特性之Multi-Range Read（转载）</title>
    <url>/mysql56-new-feature-multi-range-read/</url>
    <content><![CDATA[<h2 id="一-介绍"><a class="header-anchor" href="#一-介绍"></a>一 介绍</h2>
<p>MySQL 5.6版本提供了很多性能优化的特性，其中之一就是 Multi-Range Read 多范围读(MRR) , 它的作用针对基于辅助/第二索引的查询，减少随机IO，并且将随机IO转化为顺序IO，提高查询效率。</p>
<h2 id="二-原理"><a class="header-anchor" href="#二-原理"></a>二 原理</h2>
<p><strong>在没有MRR之前</strong>,或者没有开启MRR特性时，MySQL 针对基于辅助索引的查询策略是这样的：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> non_key_column <span class="keyword">from</span> tb wherekey_column<span class="operator">=</span>x;</span><br></pre></td></tr></table></figure>
<p>MySQL 执行查询的伪代码</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">第一步 先根据<span class="keyword">where</span>条件中的辅助索引获取辅助索引与主键的集合，结果集为rest。</span><br><span class="line">    <span class="keyword">select</span> key_column, pk_column <span class="keyword">from</span> tb <span class="keyword">where</span> key_column<span class="operator">=</span>x <span class="keyword">order</span> <span class="keyword">by</span> key_column</span><br><span class="line"></span><br><span class="line">第二步 通过第一步获取的主键来获取对应的值。</span><br><span class="line">    <span class="keyword">for</span> <span class="keyword">each</span> pk_column <span class="keyword">value</span> <span class="keyword">in</span> rest do:</span><br><span class="line">           <span class="keyword">select</span> non_key_column <span class="keyword">from</span> tb <span class="keyword">where</span> pk_column<span class="operator">=</span>val</span><br></pre></td></tr></table></figure>
<span id="more"></span>
<p><img src="http://blog.itpub.net/attachment/201505/31/22664653_1433003451kky2.png" alt=""></p>
<p>由于MySQL存储数据的方式： 辅助索引的存储顺序并非与主键的顺序一致，从图中可以看出,根据辅助索引获取的主键来访问表中的数据会导致随机的IO . 不同主键不在同一个page 里面时必然导致多次IO 和随机读。</p>
<p><strong>在使用MRR优化特性</strong>的情况下，MySQL 针对基于辅助索引的查询策略是这样的：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">第一步 先根据<span class="keyword">where</span>条件中的辅助索引获取辅助索引与主键的集合，结果集为rest</span><br><span class="line">    <span class="keyword">select</span> key_column, pk_column <span class="keyword">from</span> tb <span class="keyword">where</span> key_column <span class="operator">=</span> x <span class="keyword">order</span> <span class="keyword">by</span> key_column</span><br><span class="line"></span><br><span class="line">第二步 将结果集rest放在buffer里面(`read_rnd_buffer_size`大小直到buffer满了)，然后对结果集rest按照pk_column排序，得到结果集是rest_sort</span><br><span class="line"></span><br><span class="line">第三步 利用已经排序过的结果集，访问表中的数据，此时是顺序IO<span class="operator">&lt;</span>span style<span class="operator">=</span>&quot;color:#0000CC;&quot;<span class="operator">&gt;</span>.<span class="operator">&lt;</span><span class="operator">/</span>span<span class="operator">&gt;</span></span><br><span class="line">    <span class="keyword">select</span> non_key_column fromtb <span class="keyword">where</span> pk_column <span class="keyword">in</span> ( rest_sort )</span><br></pre></td></tr></table></figure>
<p><img src="http://blog.itpub.net/attachment/201505/31/22664653_1433003467T2Pp.png" alt=""></p>
<p>从图示MRR原理，<strong><u><span style="color:#E53333;">MySQL 将根据辅助索引获取的结果集根据主键进行排序，将乱序化为有序，可以用主键顺序访问基表，将随机读转化为顺序读，多页数据记录可一次性读入或根据此次的主键范围分次读入，以减少IO操作</span></u></strong>，提高查询效率。</p>
<h2 id="三-相关参数"><a class="header-anchor" href="#三-相关参数"></a>三 相关参数</h2>
<p>我们可以通过参数 optimizer_switch 的标记来控制是否使用MRR，当设置mrr=on时，表示启用MRR优化。mrr_cost_based 表示是否通过 cost base 的方式来启用MRR。如果选择mrr=on，mrr_cost_based=off，则表示总是开启MRR优化。<br>
参数 read_rnd_buffer_size 用来控制键值缓冲区的大小。</p>
<h2 id="四-案例介绍"><a class="header-anchor" href="#四-案例介绍"></a>四  案例介绍</h2>
<p>当开启MRR时</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">MySQL <span class="operator">&gt;</span> explain <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> tbl <span class="keyword">where</span> tbl.key1 <span class="keyword">between</span> <span class="number">1000</span> <span class="keyword">and</span> <span class="number">2000</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">----+-------------+-------+-------+---------------+------+---------+------+------+-------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> id <span class="operator">|</span> select_type <span class="operator">|</span> <span class="keyword">table</span> <span class="operator">|</span> type  <span class="operator">|</span> possible_keys <span class="operator">|</span> key  <span class="operator">|</span> key_len <span class="operator">|</span> <span class="keyword">ref</span>  <span class="operator">|</span> <span class="keyword">rows</span> <span class="operator">|</span> Extra                                     <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----+-------------+-------+-------+---------------+------+---------+------+------+-------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">1</span>  <span class="operator">|</span> SIMPLE      <span class="operator">|</span> tbl   <span class="operator">|</span> <span class="keyword">range</span> <span class="operator">|</span> key1          <span class="operator">|</span> key1 <span class="operator">|</span> <span class="number">5</span>       <span class="operator">|</span> <span class="keyword">NULL</span> <span class="operator">|</span> <span class="number">960</span>  <span class="operator">|</span> <span class="keyword">Using</span> index <span class="keyword">condition</span>; <span class="keyword">Using</span> MRR          <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----+-------------+-------+-------+---------------+------+---------+------+------+-------------------------------------------+</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.03</span> sec)</span><br></pre></td></tr></table></figure>
<h2 id="五-MRR的使用限制"><a class="header-anchor" href="#五-MRR的使用限制"></a>五 MRR的使用限制</h2>
<p>MRR 适用于以下两种情况。</p>
<ul>
<li>1 range access</li>
<li>2 ref and eq_ref access, when they are using Batched Key Access</li>
</ul>
<h2 id="六-参考文章"><a class="header-anchor" href="#六-参考文章"></a>六  参考文章</h2>
<p><a href="http://https://mariadb.com/kb/en/mariadb/multi-range-read-optimization/">《MariaDB Multi-Range Read Optimization》</a><br>
<a href="http://dev.mysql.com/doc/refman/5.6/en/mrr-optimization.html">《MySQL Multi-Range Read Optimization》</a><br>
<a href="https://www.percona.com/blog/2012/03/21/multi-range-read-mrr-in-mysql-5-6-and-mariadb-5-5/">《Multi Range Read (MRR) in MySQL 5.6 and MariaDB 5.5》</a></p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/mysql56-new-feature-multi-range-read/">http://xnerv.wang/mysql56-new-feature-multi-range-read/</a></strong><br>
转载自：<a href="http://blog.itpub.net/22664653/viewspace-1673682/">【MySQL】MySQL5.6新特性之Multi-Range Read</a></p>
]]></content>
      <categories>
        <category>DBMS</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>DBMS</tag>
        <tag>MySQL</tag>
        <tag>Multi-Range Read</tag>
      </tags>
  </entry>
  <entry>
    <title>Overriding the virtual table in a C++ object（转载）</title>
    <url>/overriding-the-virtual-table-in-a-cpp-object/</url>
    <content><![CDATA[<p>Yesterday I was discussing with a friend of mine about how polymorphism is implemented in C++, and that is, using a virtual table ( remember the “virtual” keyword in method definitions? ). A virtual table is, rawly speaking, just like an array of function pointers. Each created object with virtual methods needs a virtual table. So, where does the virtual table is stored?, I really don’t know, but I do know where I can find the address of the virtual table associated to an object ( at least in g++ 4.1.1 ), the first sizeof(void*) bytes of an object are used to store a pointer to the virtual table. With this knowledge, one could think that is possible to override the virtual table pointer of the object and call arbitrary functions, and yes, we can. Let’s see some fun code.</p>
<span id="more"></span>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Parent</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">VirtFunc1</span><span class="params">()</span> </span>&#123; cout &lt;&lt; <span class="string">&quot;Parent::VirtFunc1&quot;</span> &lt;&lt; endl; &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">VirtFunc2</span><span class="params">()</span> </span>&#123; cout &lt;&lt; <span class="string">&quot;Parent::VirtFunc2&quot;</span> &lt;&lt; endl; &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Child</span> : <span class="keyword">public</span> Parent</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="type">void</span> <span class="title">VirtFunc1</span><span class="params">()</span> </span>&#123; cout &lt;&lt; <span class="string">&quot;Child::VirtFunc1&quot;</span> &lt;&lt; endl; &#125;</span><br><span class="line">        <span class="function"><span class="type">void</span> <span class="title">VirtFunc2</span><span class="params">()</span> </span>&#123; cout &lt;&lt; <span class="string">&quot;Child::VirtFunc2&quot;</span> &lt;&lt; endl; &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">typedef</span> <span class="title">void</span> <span class="params">(*virtual_function)</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">FakeVirtualTable</span> &#123;</span><br><span class="line">    virtual_function virtual_one;</span><br><span class="line"></span><br><span class="line">    virtual_function virtual_two;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">fake_virtual_one</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;Faked virtual call 1&quot;</span> &lt;&lt; endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">fake_virtual_two</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;Faked virtual call 2&quot;</span> &lt;&lt; endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">/* declare a Child class and a base pointer to it. */</span></span><br><span class="line">    Child child_class_obj;</span><br><span class="line">    Parent* parent_class_ptr = &amp;child_class_obj;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* create our fake virtual table with pointers to our fake methods */</span></span><br><span class="line">    FakeVirtualTable custom_table;</span><br><span class="line">    custom_table.virtual_one = fake_virtual_one;</span><br><span class="line"></span><br><span class="line">    custom_table.virtual_two = fake_virtual_two;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* take the address of our stack virtual table and override the real object pointer to the virtual table */</span></span><br><span class="line">    FakeVirtualTable* table_ptr = &amp;custom_table;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">memcpy</span>(parent_class_ptr, &amp;table_ptr, <span class="built_in">sizeof</span>(<span class="type">void</span>*));</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* call the methods ( but we&#x27;re really calling the faked functions ) */</span></span><br><span class="line"></span><br><span class="line">    parent_class_ptr-&gt;<span class="built_in">VirtFunc1</span>();</span><br><span class="line">    parent_class_ptr-&gt;<span class="built_in">VirtFunc2</span>();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>So, try to run that code and, of course, the expected result is having fake_virtual_one() and fake_virtual_two() functions called. No magic there, we just replace the first sizeof(void*) bytes of the object with our own table pointer. There is not a use I can think of right now, but it is funny ….</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/overriding-the-virtual-table-in-a-cpp-object/">http://xnerv.wang/overriding-the-virtual-table-in-a-cpp-object/</a></strong><br>
转载自：<a href="https://moythreads.com/wordpress/2007/09/14/overriding-the-virtual-table-in-a-c-object/">Overriding the virtual table in a C++ object</a></p>
]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>C++</tag>
        <tag>Programing</tag>
      </tags>
  </entry>
  <entry>
    <title>进程内存布局（转载）</title>
    <url>/process-memory-layout/</url>
    <content><![CDATA[<h2 id="进程的用户空间"><a class="header-anchor" href="#进程的用户空间"></a>进程的用户空间</h2>
<p>Windows系统中，系统空间与用户空间的分界线为0x80000000,该地址以上为系统空间，以下为用户空间，各占2GB（默认情况下）。2GB的用户空间不是全部可访问的，它被划分成了以下几个部分：</p>
<center>
<img src="/assets/process-memory-layout/1.jpg" />
</center>
<p><strong>用户空间的两端各有64KB的隔离区，是不允许访问的。上端的隔离区将用户空间与系统空间隔离开，下端的隔离区就是我们编程时遇到的NULL，因此NULL实际所表示的区域不是一个地址</strong>，而是一个64KB的地址范围。这样，实际可访问的用户空间地址范围为0x10000-0x7ffeffff。</p>
<span id="more"></span>
<h2 id="进程的内存布局"><a class="header-anchor" href="#进程的内存布局"></a>进程的内存布局</h2>
<p>程序加载到内存后的布局如下图所示：</p>
<center>
<img src="/assets/process-memory-layout/2.png" />
</center>
<p>（注：图片来自潘爱民编著的《Windows内核原理与实现》）</p>
<p>程序中不同的部分在上图中占据不同的空间。主要为以下几部分：</p>
<ol>
<li>代码段。为程序编译后的机器码指令，然后映射到进程地址空间。</li>
<li>已初始化数据段。在程序中已经显式初始化的全局变量和静态变量。这些变量的值在编译时保存于可执行文件中，程序加载到进程中时读取这些变量的值，映射到相应的内存空间。</li>
<li>未初始化数据段。程序中声明而没有初始化的全局变量和静态变量。为了缩小可执行文件的大小，这些变量的值在编译时是不会保存到可执行文件中，可执行文件中只记录了所需要的大小，加载程序时才分配空间，映射到相应的内存空间。</li>
<li>堆。运行时动态为变量分配的内存，如new和malloc,堆是由低地址向高地址增长的。</li>
<li>栈。运行时函数调用占用的内存，每个当前调用的函数占据一个栈帧，其中保存了局部变量，参数，返回地址等。栈是由高地址向低地址增长的。</li>
</ol>
<p>《Linux/UNIX编程手册》第6章中用实例进行了讲解，这里就不重复列出来了。该章的末尾有一个练习，说示例中声明了一个10MB的数组，为什么编译后的可执行文件大小远小于10MB？如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">static</span> <span class="type">char</span> mbuf[<span class="number">10240000</span>];</span><br></pre></td></tr></table></figure>
<p>这就是前面所说的未初始化的静态变量，在可执行文件中不会保存实际的数据，因而只占用很少的空间。</p>
<h2 id="程序可自由分配的空间"><a class="header-anchor" href="#程序可自由分配的空间"></a>程序可自由分配的空间</h2>
<p>不知道大家有没有产生这样的疑问，结合前面所述的，用户空间除去隔离区域，其它都是编程时可以自由支配的吗？首先明确一点，可自由支配的空间是一定的，因此，不要认为new一定会成功，如果不断地分配而不释放，它总会失败的。而且，大家编程时也遇到过无限递归的错误，无限递归同样造成栈帧的分配导致空间耗尽，所以同样会失败。所以，我们到底可以支配多少空间呢？</p>
<p>回答这个问题之前，先看上面的图，想想编程时几乎必不可少的一个东西——动态链接库（DLL），我们知道，一般情况下，进程只能访问自己的地址空间，而程序要访问动态链接库（包括Windows提供的和我们自己定义的）中的函数和变量，就必须把DLL映射到自己的地址空间，因而，这些动态链接库会消耗一部分空间。此处讲一点题外话，不同的进程使用同一个DLL都会映射到自己的地址空间，但是同一个DLL在物理页面上只有一份，这是通过共享映射区（Section）实现的，使用了同一个DLL的进程的虚拟页面对应同一组物理页面。</p>
<p>如果程序使用到大量DLL，则会占用比较多的空间。同时，进程还有一些自己的数据需要保存，如用户空间的进程结构，这些空间会从堆上分配。因此，程序实际可以自由支配的空间还要压缩。</p>
<p>下面我们实际对一个进程的虚拟地址空间中的空闲页面进行统计，看看有多少可以分配的空间。Windows提供了函数VirtualQuery可以查询当前进程空间中虚拟页面的信息，具体的用法就不说了。下面是代码：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;Windows.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">( <span class="type">int</span> argc, <span class="type">char</span>* argv[] )</span></span><br><span class="line">&#123;</span><br><span class="line">    SIZE_T retVal; <span class="comment">// VirtualQuery返回值</span></span><br><span class="line">    MEMORY_BASIC_INFORMATION mbi; <span class="comment">// 返回页面信息</span></span><br><span class="line">    DWORD dwStartAddress = <span class="number">0x0</span>; <span class="comment">// 起始地址</span></span><br><span class="line">    DWORD dwTotalFreeSize = <span class="number">0</span>; <span class="comment">// 空闲页面总大小</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span>( <span class="literal">true</span> )</span><br><span class="line">    &#123;</span><br><span class="line">        ZeroMemory(&amp;mbi, <span class="keyword">sizeof</span>(MEMORY_BASIC_INFORMATION));</span><br><span class="line">        retVal = VirtualQuery( (LPCVOID)dwStartAddress, &amp;mbi, <span class="keyword">sizeof</span>(MEMORY_BASIC_INFORMATION) );</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>( <span class="number">0</span> == retVal ) <span class="comment">// 返回0表示失败</span></span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 判断mbi中的State标识，累加为MEM_FREE的区间</span></span><br><span class="line">        <span class="keyword">if</span>( MEM_FREE == mbi.State )</span><br><span class="line">        &#123;</span><br><span class="line">            dwTotalFreeSize += mbi.RegionSize;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 下一个区间</span></span><br><span class="line">        dwStartAddress += mbi.RegionSize;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 输出总的空闲页面大小</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%lfGB\n&quot;</span>, (<span class="type">double</span>)dwTotalFreeSize/<span class="number">1024</span>/<span class="number">1024</span>/<span class="number">1024</span>);</span><br><span class="line"></span><br><span class="line">    system(<span class="string">&quot;pause...&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>运行结果：</p>
<center>
<img src="/assets/process-memory-layout/3.png" />
</center>
<p>你可以分配全局变量来查看结果的变化。说明一点，上面我写的程序只统计了MEM_FREE的页面，实际上还要判断页面的访问类型，除去特殊如无法访问的页面。</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/process-memory-layout/">http://xnerv.wang/process-memory-layout/</a></strong><br>
转载自：<a href="http://blog.csdn.net/hustd10/article/details/50816175">进程内存布局</a></p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>操作系统</tag>
        <tag>内存管理</tag>
        <tag>进程</tag>
      </tags>
  </entry>
  <entry>
    <title>Read Committed Snapshot Isolation（转载）</title>
    <url>/read-committed-snapshot-isolation/</url>
    <content><![CDATA[<p>SQL Server provides two physical implementations of the <strong>read committed</strong> isolation level defined by the SQL standard, locking read committed and read committed snapshot isolation (<strong>RCSI</strong>). While both implementations meet the requirements laid down in the SQL standard for read committed isolation behaviours, RCSI has quite different physical behaviours from the locking implementation we looked at in <a href="/2014/04/t-sql-queries/the-read-committed-isolation-level">the previous post in this series</a>.</p>
<span id="more"></span>
<h2 id="Logical-Guarantees"><a class="header-anchor" href="#Logical-Guarantees"></a>Logical Guarantees</h2>
<p>The SQL standard requires that a transaction operating at the read committed isolation level not experience any dirty reads. Another way to express this requirement is to say a read committed transaction <strong>must only encounter committed data</strong>.</p>
<p>The standard also says that read committed transactions <strong>might</strong> experience the concurrency phenomena known as non-repeatable reads and phantoms (though they are not actually required to do so). As it happens, both physical implementations of read committed isolation in SQL Server can experience non-repeatable reads and phantom rows, though the precise details are quite different.</p>
<h2 id="A-point-in-time-view-of-committed-data"><a class="header-anchor" href="#A-point-in-time-view-of-committed-data"></a>A point-in-time view of committed data</h2>
<p>If the database option <code>READ_COMMITTED_SNAPSHOT</code> in <code>ON</code>, SQL Server uses a <a href="http://msdn.microsoft.com/en-us/library/ms177404.aspx">row-versioning implementation</a> of the read committed isolation level. When this is enabled, transactions requesting read committed isolation automatically use the RCSI implementation; no changes to existing T-SQL code is required to use RCSI. Note carefully though that this is <strong>not the same</strong> as saying that code <strong>will behave the same</strong> under RCSI as when using the locking implementation of read committed, in fact this is quite generally <strong>not the case</strong>.</p>
<p>There is nothing in the SQL standard that requires the data read by a read committed transaction to be the <strong>most-recently</strong> committed data. The SQL Server RCSI implementation takes advantage of this to provide transactions with a <strong>point-in-time view</strong> of committed data, where that point in time is the moment the <strong>current statement began</strong> execution (not the moment any containing transaction started).</p>
<p>This is quite different from the behaviour of the SQL Server locking implementation of read committed, where the statement sees the most-recently committed data as of <strong>the moment each item is physically read</strong>. Locking read committed releases shared locks as quickly as possible, so the set of data encountered may come from very different points in time.</p>
<p>To summarize, locking read committed sees <strong>each row</strong> as it was at the time it was briefly locked and physically read; RCSI sees <strong>all rows</strong> as they were at the time the statement began. Both implementations are guaranteed to never see uncommitted data, but the data they encounter can be very different.</p>
<h3 id="The-implications-of-a-point-in-time-view"><a class="header-anchor" href="#The-implications-of-a-point-in-time-view"></a>The implications of a point-in-time view</h3>
<p>Seeing a point-in-time view of committed data might seem self-evidently superior to the more complex behaviour of the locking implementation. It is clear, for example, that a point-in-time view cannot suffer from the problems of <strong>missing rows</strong> or encountering the <strong>same row multiple times</strong>, which are both possible under locking read committed isolation.</p>
<p>A second important advantage of RCSI is that it <strong>does not acquire shared locks</strong> when reading data, because the data comes from the row version store rather than being accessed directly. The lack of shared locks can dramatically <strong>improve concurrency</strong> by eliminating conflicts with concurrent transactions looking to acquire incompatible locks. This advantage is commonly summarized by saying that readers do not block writers under RCSI, and vice-versa. As a further consequence of reducing blocking due to incompatible lock requests, the opportunity for <strong>deadlocks</strong> is usually greatly reduced when running under RCSI.</p>
<p>However, these benefits do not come without <strong>costs and caveats</strong>. For one thing, maintaining versions of committed rows consumes system resources, so it is important that the physical environment is configured to cope with this, primarily in terms of <em>tempdb</em> performance and memory/disk space requirements.</p>
<p>The second caveat is a little more subtle: RCSI provides a snapshot view of committed data <strong>as it was</strong> at the start of the statement, but there is nothing to prevent the real data from being changed (and those changes committed) while the RCSI statement is executing. There are no shared locks, remember. An immediate consequence of this second point is that T-SQL code running under RCSI might <strong>make decisions based on out of date information</strong>, as compared with the current committed state of the database. We will talk more about this shortly.</p>
<p>There is one last (implementation-specific) observation I want to make about RCSI before we move on. <strong>Scalar and multi-statement functions</strong> execute using a different internal T-SQL context from the containing statement. This means that the point-in-time view seen inside a scalar or multi-statement function invocation can be later than the point-in-time view seen by the rest of the statement. This can result in unexpected inconsistencies, as different parts of the same statement see <strong>data from different points in time</strong>. This weird and confusing behaviour does <strong>not</strong> apply to in-line functions, which see the same snapshot as the statement they appear in.</p>
<h3 id="Non-repeatable-reads-and-phantoms"><a class="header-anchor" href="#Non-repeatable-reads-and-phantoms"></a>Non-repeatable reads and phantoms</h3>
<p>Given a statement-level point-in-time view of the committed state of the database, it might not be immediately apparent how a read committed transaction under RCSI might experience the non-repeatable read or phantom row phenomena. Indeed, if we limit our thinking to the scope of a <strong>single statement</strong>, neither of these phenomena are possible under RCSI.</p>
<p>Reading the same data multiple times within the <strong>same statement</strong> under RCSI will always return the same data values, no data will disappear between those reads, and no new data will appear either. If you are wondering what sort of statement might read the same data more than once, think about queries that reference the same table more than once, perhaps in a subquery.</p>
<p>Statement-level read consistency is an obvious consequence of the reads being issued against a fixed snapshot of the data. The reason that RCSI does <strong>not</strong> provide protection from non-repeatable reads and phantoms is that these SQL standard phenomena are defined at the transaction level. Multiple statements within a transaction running at RCSI may see different data, because each statement sees a point-in-time view as of the moment <strong>that particular statement</strong> started.</p>
<p>To summarize, each <strong>statement</strong> within an RCSI transaction sees a static committed data set, but that set can change between statements inside the same transaction.</p>
<h2 id="Out-of-date-data"><a class="header-anchor" href="#Out-of-date-data"></a>Out-of-date data</h2>
<p>The possibility of our T-SQL code making an important decision based on out-of-date information is more than a little unsettling. Consider for a moment that the point-in-time snapshot used by a single statement running under RCSI might be <strong>arbitrarily old</strong>.</p>
<p>A statement that runs for a considerable period a time will continue to see the committed state of the database as it was when the statement began. Meanwhile, the statement is missing all the committed changes that occurred in the database since that time.</p>
<p>This is not to say that problems associated with accessing stale data under RCSI are limited to <strong>long-running</strong> statements, but the issues certainly might be more pronounced in such cases.</p>
<h3 id="A-question-of-timing"><a class="header-anchor" href="#A-question-of-timing"></a>A question of timing</h3>
<p>This issue of out-of-date data applies to all RCSI statements in principle, no matter how quickly they might complete. How ever small the time window is, there is always a chance that a concurrent operation might modify the data set we are working with, without us being aware of that change. Let us look again at one of the simple examples we used before when exploring the behaviour of locking read committed:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> dbo.OverdueInvoices</span><br><span class="line"><span class="keyword">SELECT</span> I.InvoiceNumber</span><br><span class="line"><span class="keyword">FROM</span> dbo.Invoices <span class="keyword">AS</span> I</span><br><span class="line"><span class="keyword">WHERE</span> I.TotalDue <span class="operator">&gt;</span></span><br><span class="line">(</span><br><span class="line">    <span class="keyword">SELECT</span> <span class="built_in">SUM</span>(P.Amount)</span><br><span class="line">    <span class="keyword">FROM</span> dbo.Payments <span class="keyword">AS</span> P</span><br><span class="line">    <span class="keyword">WHERE</span> P.InvoiceNumber <span class="operator">=</span> I.InvoiceNumber</span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<p>When run under RCSI, this statement <strong>cannot</strong> see any committed database modifications that occur after the statement starts executing. While we will not encounter the problems of missed or multiply-encountered rows possible under the locking implementation, a concurrent transaction might add a payment that <strong>ought</strong> to prevent a customer from being sent a stern warning letter about an overdue payment after the statement above starts executing.</p>
<p>You can probably think of many other potential problems that might occur in this scenario, or in others that are conceptually similar. The longer the statement runs for, the more out-of-date its view of the database becomes, and the greater the scope for possibly-unintended consequences.</p>
<p>Of course, there are plenty of mitigating factors in this specific example. The behaviour might well be seen as perfectly acceptable. After all, sending a reminder letter because a payment arrived a few seconds too late is an easily defended action. The principle remains however.</p>
<h3 id="Business-Rule-Failures-and-Integrity-Risks"><a class="header-anchor" href="#Business-Rule-Failures-and-Integrity-Risks"></a>Business Rule Failures and Integrity Risks</h3>
<p>More serious issues can arise from the use of out-of-date information than sending a warning letter a few seconds early. A good example of this class of weakness can be seen with <strong>trigger code</strong> used to enforce an integrity rule that is perhaps too complex to enforce with declarative referential integrity constraints. To illustrate, consider the following code, which uses a trigger to enforce a variation of a foreign key constraint, but one that enforces the relationship for only certain child table rows:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> DATABASE Sandpit</span><br><span class="line"><span class="keyword">SET</span> READ_COMMITTED_SNAPSHOT <span class="keyword">ON</span></span><br><span class="line"><span class="keyword">WITH</span> <span class="keyword">ROLLBACK</span> IMMEDIATE;</span><br><span class="line">GO</span><br><span class="line"><span class="keyword">SET</span> TRANSACTION ISOLATION LEVEL READ COMMITTED;</span><br><span class="line">GO</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> dbo.Parent (ParentID <span class="type">integer</span> <span class="keyword">PRIMARY</span> KEY);</span><br><span class="line">GO</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> dbo.Child</span><br><span class="line">(</span><br><span class="line">    ChildID <span class="type">integer</span> <span class="keyword">IDENTITY</span> <span class="keyword">PRIMARY</span> KEY,</span><br><span class="line">    ParentID <span class="type">integer</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    CheckMe bit <span class="keyword">NOT</span> <span class="keyword">NULL</span></span><br><span class="line">);</span><br><span class="line">GO</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TRIGGER</span> dbo.Child_AI</span><br><span class="line"><span class="keyword">ON</span> dbo.Child</span><br><span class="line">AFTER <span class="keyword">INSERT</span></span><br><span class="line"><span class="keyword">AS</span></span><br><span class="line"><span class="keyword">BEGIN</span></span><br><span class="line">    <span class="comment">-- Child rows with CheckMe = true</span></span><br><span class="line">    <span class="comment">-- must have an associated parent row</span></span><br><span class="line">    IF <span class="keyword">EXISTS</span></span><br><span class="line">    (</span><br><span class="line">        <span class="keyword">SELECT</span> ins.ParentID</span><br><span class="line">        <span class="keyword">FROM</span> inserted <span class="keyword">AS</span> ins</span><br><span class="line">        <span class="keyword">WHERE</span> ins.CheckMe <span class="operator">=</span> <span class="number">1</span></span><br><span class="line">        <span class="keyword">EXCEPT</span></span><br><span class="line">        <span class="keyword">SELECT</span> P.ParentID</span><br><span class="line">        <span class="keyword">FROM</span> dbo.Parent <span class="keyword">AS</span> P</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">BEGIN</span></span><br><span class="line">    	RAISERROR (<span class="string">&#x27;Integrity violation!&#x27;</span>, <span class="number">16</span>, <span class="number">1</span>);</span><br><span class="line">        <span class="keyword">ROLLBACK</span> TRANSACTION;</span><br><span class="line">    <span class="keyword">END</span></span><br><span class="line"><span class="keyword">END</span>;</span><br><span class="line">GO</span><br><span class="line"><span class="comment">-- Insert parent row #1</span></span><br><span class="line"><span class="keyword">INSERT</span> dbo.Parent (ParentID) <span class="keyword">VALUES</span> (<span class="number">1</span>);</span><br></pre></td></tr></table></figure>
<p>Now consider a transaction running in another session (use another SSMS window for this if you are following along) which deletes parent row #1, but does not commit yet:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SET</span> TRANSACTION ISOLATION LEVEL READ COMMITTED;</span><br><span class="line"><span class="keyword">BEGIN</span> TRANSACTION;</span><br><span class="line"><span class="keyword">DELETE</span> <span class="keyword">FROM</span> dbo.Parent</span><br><span class="line"><span class="keyword">WHERE</span> ParentID <span class="operator">=</span> <span class="number">1</span>;</span><br></pre></td></tr></table></figure>
<p>Back in our original session, we try to insert a (checked) child row that references this parent:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> dbo.Child (ParentID, CheckMe)</span><br><span class="line"><span class="keyword">VALUES</span> (<span class="number">1</span>, <span class="number">1</span>);</span><br></pre></td></tr></table></figure>
<p>The the trigger code executes, but because RCSI sees only <strong>committed</strong> data as of the time the statement started, it still sees the parent row (not the uncommitted deletion) and the <strong>insert succeeds</strong>!</p>
<p>The transaction that deleted the parent row can now commit its change successfully, leaving the database in an <strong>inconsistent</strong> state in terms of our trigger logic:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">COMMIT</span> TRANSACTION;</span><br><span class="line"><span class="keyword">SELECT</span> P.<span class="operator">*</span> <span class="keyword">FROM</span> dbo.Parent <span class="keyword">AS</span> P;</span><br><span class="line"><span class="keyword">SELECT</span> C.<span class="operator">*</span> <span class="keyword">FROM</span> dbo.Child <span class="keyword">AS</span> C;</span><br></pre></td></tr></table></figure>
<p><img src="/assets/read-committed-snapshot-isolation/1.png" alt="Integrity violation" title="Integrity violation"></p>
<p>This is a simplified example of course, and one which could easily be circumvented using the built-in constraint facilities. Much more complex business rules and pseudo-integrity constraints can be written inside and <strong>outside of triggers</strong>. The potential for incorrect behaviour under RCSI should be obvious.</p>
<h3 id="Blocking-behaviour-and-latest-committed-data"><a class="header-anchor" href="#Blocking-behaviour-and-latest-committed-data"></a>Blocking behaviour and latest-committed data</h3>
<p>I mentioned earlier that T-SQL code is not guaranteed to behave in the same way under RCSI read committed as it did using the locking implementation. The preceding trigger code example is a good illustration of that, but I need to emphasise that <strong>the general problem is not limited to triggers</strong>.</p>
<p>RCSI is typically not a good choice for any T-SQL code whose correctness depends on blocking if a concurrent uncommitted change exists. RCSI might also not be the right choice if the code depends on reading <strong>current</strong> committed data, rather than the latest committed data as at the time the statement started. These two considerations are related, but they are not the same thing.</p>
<h3 id="Locking-read-committed-under-RCSI"><a class="header-anchor" href="#Locking-read-committed-under-RCSI"></a>Locking read committed under RCSI</h3>
<p>SQL Server provides one way to request <strong>locking</strong> read committed when RCSI is enabled, using the table hint <code>READCOMMITTEDLOCK</code>. We can modify our trigger to avoid the problems shown above by adding this hint to the table that needs blocking behaviour to perform correctly:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TRIGGER</span> dbo.Child_AI</span><br><span class="line"><span class="keyword">ON</span> dbo.Child</span><br><span class="line">AFTER <span class="keyword">INSERT</span></span><br><span class="line"><span class="keyword">AS</span></span><br><span class="line"><span class="keyword">BEGIN</span></span><br><span class="line">    <span class="comment">-- Child rows with CheckMe = true</span></span><br><span class="line">    <span class="comment">-- must have an associated parent row</span></span><br><span class="line">    IF <span class="keyword">EXISTS</span></span><br><span class="line">    (</span><br><span class="line">        <span class="keyword">SELECT</span> ins.ParentID</span><br><span class="line">        <span class="keyword">FROM</span> inserted <span class="keyword">AS</span> ins</span><br><span class="line">        <span class="keyword">WHERE</span> ins.CheckMe <span class="operator">=</span> <span class="number">1</span></span><br><span class="line">        <span class="keyword">EXCEPT</span></span><br><span class="line">        <span class="keyword">SELECT</span> P.ParentID</span><br><span class="line">        <span class="keyword">FROM</span> dbo.Parent <span class="keyword">AS</span> P <span class="keyword">WITH</span> (READCOMMITTEDLOCK) <span class="comment">-- NEW!!</span></span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">BEGIN</span></span><br><span class="line">        RAISERROR (<span class="string">&#x27;Integrity violation!&#x27;</span>, <span class="number">16</span>, <span class="number">1</span>);</span><br><span class="line">        <span class="keyword">ROLLBACK</span> TRANSACTION;</span><br><span class="line">    <span class="keyword">END</span></span><br><span class="line"><span class="keyword">END</span>;</span><br></pre></td></tr></table></figure>
<p>With this change in place, the attempt to insert the potentially-orphaned child row blocks until the deleting transaction commits (or aborts). If the delete commits, the trigger code detects the integrity violation and raises the expected error.</p>
<p>Identifying queries that <strong>might not perform correctly</strong> under RCSI is a non-trivial task that may require <strong>extensive testing</strong> to get right (and please remember these issues are quite general and not confined to trigger code!) Also, adding the <code>READCOMMITTEDLOCK</code> hint to every table that needs it can be a tedious and error-prone process. Until SQL Server provides a more broadly-scoped option to request the locking implementation where needed, we are stuck with using the table hints.</p>
<h3 id="Next-Time"><a class="header-anchor" href="#Next-Time"></a>Next Time</h3>
<p><a href="https://sqlperformance.com/2014/05/t-sql-queries/data-modifications-under-rcsi">The next post in this series</a> continues our examination of read committed snapshot isolation, with a look at the surprising behaviour of data modification statements under RCSI.</p>
<p>[ <a href="https://sqlperformance.com/2014/07/t-sql-queries/isolation-levels">See the index for the whole series</a> ]</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/read-committed-snapshot-isolation/">http://xnerv.wang/read-committed-snapshot-isolation/</a></strong><br>
转载自：<a href="https://sqlperformance.com/2014/05/t-sql-queries/read-committed-snapshot-isolation">Read Committed Snapshot Isolation</a></p>
]]></content>
      <categories>
        <category>DBMS</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>DBMS</tag>
        <tag>SQL Server</tag>
        <tag>Transaction</tag>
        <tag>Isolation Level</tag>
      </tags>
  </entry>
  <entry>
    <title>一个模块分配的内存由另外一个模块释放~引发的血案（转载）</title>
    <url>/release-memory-allocated-by-another-module/</url>
    <content><![CDATA[<p>exe调用了cglover.dll中的一个导出类成员函数，是一个读取lua配置文件类，其中一个函数是读取int数组，并通知参数std::vector<int>传递。<br>
结果一出调用函数作用域，就挂调用，挂在std::vector的析构释放内存上~ 郁闷找不到原因，往床上一躺，突然想起关于很早以前就在游戏编程精粹上看到过exe释放dll分配的内存会有问题，但一直没明白为什么，也没有深究，应该是这个问题了。于是上网查了下，然后用windbg跟了下，总算整明白了。</p>
<span id="more"></span>
<p>Malloc和Free由CRT提供，分别是</p>
<ul>
<li>DEBUG版本：
<ul>
<li>MSVCR71D.DLL  (C运行时库)</li>
<li>MSVCP71D.DLL  (C++运行时库)</li>
</ul>
</li>
<li>RELEASE版本：
<ul>
<li>MSVCR71.DLL  (C运行时库)</li>
<li>MSVCP71.DLL  (C++运行时库)</li>
</ul>
</li>
</ul>
<p>Malloc和Free内部实际是调用系统提供的HeapAlloc和HeapFree来实现的（Kernel32.dll），这两个API需要HeapCreate创建返回的内存堆HANDLE。<br>
但却不是使用缺省的进程堆（GetProcessHeap）， 而是在XXXCRTStartUp入口函数中创建的一个全局句柄<code>HANDLE _crtheap</code>（入口函数中调用CreateHeap）；<br>
其实也并不一定是入口函数中创建，这只是针对静态链接CRT库而已，对于动态链接CRT库的，在整个应用程序中，所有动态链接CRT库的使用同一个<code>_crtheap</code>（即CRT模块中的<code>_crtheap</code>）,它在ntdll!LdrpCallInitRoutine中调用，并且之后动态链接CRT的模块不再调用heap_init。</p>
<p>经过使用windbg测试，发现Exe或Dll使用静态链接CRT库那么就会在CRTStartup入口函数中静态链接_CRTDLL_INIT中调用的<code>_heap_init</code>函数（里面调用CreateHeap），但是所有使用动态链接CRT库的模块的就不会在CRTStartup中再调用了，整个应用程序装载的时候之后，确定有模块动态链接CRT库，那么就调用<code>MSVCR71D!_CRTDLL_INIT</code>，这时就设置了CRT库的全局变量堆句柄<code>_crtheap</code>，所有动态链接CRT的模块就用到它了。<br>
<strong>总结一句，就是这个进程中，所有动态链接CRT库的模块公用CRT模块的heap，而所有静态链接CRT库的模块（包括进程本身）使用自身创建的heap。</strong></p>
<h2 id="动态链接"><a class="header-anchor" href="#动态链接"></a>动态链接</h2>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">。。。</span><br><span class="line">call_dlld!mainCRTStartup+<span class="number">0x142</span></span><br><span class="line">kernel32!BaseProcessStart+<span class="number">0x23</span></span><br><span class="line">。。。。</span><br><span class="line">ntdll!RtlCreateHeap (FPO: [Non-Fpo])</span><br><span class="line">kernel32!HeapCreate+<span class="number">0x55</span> (FPO: [<span class="number">3</span>,<span class="number">0</span>,<span class="number">4</span>])</span><br><span class="line">MSVCR71D!_heap_init+<span class="number">0x1a</span> (FPO: [Non-Fpo]) (CONV: cdecl) [f:\vs70builds\<span class="number">3077</span>\vc\crtbld\crt\src\heapinit.c @ <span class="number">173</span>]</span><br><span class="line">MSVCR71D!_CRTDLL_INIT+<span class="number">0xab</span> (FPO: [Non-Fpo]) (CONV: stdcall) [f:\vs70builds\<span class="number">3077</span>\vc\crtbld\crt\src\crtlib.c @ <span class="number">212</span>]</span><br><span class="line">ntdll!LdrpCallInitRoutine+<span class="number">0x14</span></span><br><span class="line">ntdll!LdrpRunInitializeRoutines+<span class="number">0x344</span> (FPO: [Non-Fpo])</span><br><span class="line">ntdll!LdrpInitializeProcess+<span class="number">0x1131</span> (FPO: [<span class="number">5</span>,<span class="number">89</span>,<span class="number">4</span>])</span><br><span class="line">ntdll!_LdrpInitialize+<span class="number">0x183</span> (FPO: [Non-Fpo])</span><br><span class="line">ntdll!KiUserApcDispatcher+<span class="number">0x7</span></span><br></pre></td></tr></table></figure>
<h2 id="静态链接"><a class="header-anchor" href="#静态链接"></a>静态链接</h2>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">kernel32!HeapCreate+<span class="number">0x55</span> (FPO: [<span class="number">3</span>,<span class="number">0</span>,<span class="number">4</span>])</span><br><span class="line">call_dlld!_heap_init+<span class="number">0x1a</span></span><br><span class="line">call_dlld!mainCRTStartup+<span class="number">0xc1</span></span><br><span class="line">kernel32!BaseProcessStart+<span class="number">0x23</span> (FPO: [Non-Fpo])</span><br></pre></td></tr></table></figure>
<p>就是这样了！</p>
<p>当Dll（分配内存）和Exe（释放内存）都使用静态链接CRT库，那么悲剧发生了：Dll分配使用的是Dll的_crtheap全局句柄分配堆，Exe释放使用Exe的_crtheap全局句柄分配堆。</p>
<p>在Debug模式下会有检查释放内存是否在自身的堆内存block链表中，但在Release模式下却是不可预知的崩溃了。</p>
<p>但是当二者都是使用动态链接CRT DLL，那么malloc和free对应使用的堆句柄就是CRT DLL中的_crtheap了。这依赖于各个模块的编译选项设置（都设置为动态链接CRT库）</p>
<p><strong>所以最根本的错误在于：不同的模块使用了不同的堆。<br>
所以必须保证使用同一个堆。<br>
所以最根本的做法还是，哪个模块分配的，由那个模块来释放。</strong></p>
<p>可选的方法有：<br>
1。在DLL中输出一个函数给EXE调用，专门用来释放由DLL分配的内存；<br>
2。用GlobalAlloc()代替new，用GlobalFree()代替delete；<br>
3。使用单一的堆，分配内存使用HeapAlloc(GetProcessHeap(),0,size)，释放内存使用HeapFree(GetProcessHeap(),0,p)；<br>
4。把dll和exe的Settings的C/C++选项卡的Code Generation的Use Run-time liberary改成Debug Multithreaded DLL，在Release版本中改成Multithreaded DLL；这样使用一个CRT了——MSVCRT.DLL。</p>
<hr>
<p><strong>（编者注：在不同版本的vc runtime之间也不能混用new和delete，即使用的都是CRT DLL。）</strong></p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/release-memory-allocated-by-another-module/">http://xnerv.wang/release-memory-allocated-by-another-module/</a></strong><br>
转载自：<a href="http://guaniuzhijia.blog.163.com/blog/static/16547206920105792946352/">一个模块分配的内存由另外一个模块释放~引发的血案</a></p>
]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Windows</tag>
        <tag>Heap</tag>
        <tag>DLL</tag>
        <tag>DLL Hell</tag>
      </tags>
  </entry>
  <entry>
    <title>(Stack Overflow) SAVE TRANSACTION vs BEGIN TRANSACTION (SQL Server) how to nest transactions nicely</title>
    <url>/save-transaction-vs-begin-transaction-sql-server-how-to-nest-transactions-nicely/</url>
    <content><![CDATA[<h2 id="Question"><a class="header-anchor" href="#Question"></a>Question</h2>
<p>I have a stored procedure that needs to set a save point so that it can, under certain circumstances, undo everything it did and return an error code to the caller, or accept/commit it and return success to the caller. But I need it to work whether the caller has already started a transaction or not. The doc is extremely confusing on this subject. Here is what I think will work, but I’m not certain of all the ramifications.</p>
<p>The thing is - this <code>Stored Procedure (SP)</code> is called by others. So I don’t know if they’ve started a transaction or not… Even if I require users to start a transaction to use my SP, I still have questions about the proper use of <code>Save Points</code> …</p>
<p>My SP will test if a transaction is in progress, and if not, start one with <code>BEGIN TRANSACTION</code>. If a transaction is already in progress, it will instead create a save point with <code>SAVE TRANSACTION MySavePointName</code>, and save the fact this is what I did.</p>
<span id="more"></span>
<p>Then if I have to roll back my changes, if I did a <code>BEGIN TRANSACTION</code> earlier, then I will <code>ROLLBACK TRANSACTION</code>. If I did the save point, then I will <code>ROLLBACK TRANSACTION MySavePointName</code>. This scenario seems to work great.</p>
<p>Here is where I get a little confused - if I want to keep the work I’ve done, if I started a transaction I will execute <code>COMMIT TRANSACTION</code>. But if I created a save point? I tried <code>COMMIT TRANSACTION MySavePointName</code>, but then the caller tries to commit its transaction and gets an error:</p>
<blockquote>
<p>The COMMIT TRANSACTION request has no corresponding BEGIN TRANSACTION.</p>
</blockquote>
<p>So I’m wondering then - a save point can be rolled back (that works: <code>ROLLBACK TRANSACTION MySavePointName</code> will NOT roll back the caller’s transaction). But perhaps one never needs to “commit” it? It just stays there, in case you need to roll back to it, but goes away once the original transaction is committed (or rolled back)?</p>
<p>If there is a “better” way to “nest” a transaction, please shed some light as well. I haven’t figured out how to nest with <code>BEGIN TRANSACTION</code> but only rollback or commit my internal transaction. Seems <code>ROLLBACK</code> will always roll back to the top transaction, while <code>COMMIT</code> simply decrements <code>@@trancount</code>.</p>
<h2 id="Answer-by-Brian-B"><a class="header-anchor" href="#Answer-by-Brian-B"></a>Answer by Brian B</h2>
<p>I believe I’ve figured this all out now, so I will answer my own question…</p>
<p>I’ve even blogged my findings if you want more details at <a href="http://geekswithblogs.net/bbiales/archive/2012/03/15/how-to-nest-transactions-nicely---quotbegin-transactionquot-vs-quotsave.aspx">http://geekswithblogs.net/bbiales/archive/2012/03/15/how-to-nest-transactions-nicely—quotbegin-transactionquot-vs-quotsave.aspx</a></p>
<p>So my SP starts with something like this, to start a new transaction if there is none, but use a Save Point if one is already in progress:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">DECLARE</span> <span class="variable">@startingTranCount</span> <span class="type">int</span></span><br><span class="line"><span class="keyword">SET</span> <span class="variable">@startingTranCount</span> <span class="operator">=</span> @<span class="variable">@TRANCOUNT</span></span><br><span class="line"></span><br><span class="line">IF <span class="variable">@startingTranCount</span> <span class="operator">&gt;</span> <span class="number">0</span></span><br><span class="line">    SAVE TRANSACTION mySavePointName</span><br><span class="line"><span class="keyword">ELSE</span></span><br><span class="line">    <span class="keyword">BEGIN</span> TRANSACTION</span><br><span class="line"><span class="comment">-- …</span></span><br></pre></td></tr></table></figure>
<p>Then, when ready to commit the changes, you only need to commit if we started the transaction ourselves:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">IF <span class="variable">@startingTranCount</span> <span class="operator">=</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">COMMIT</span> TRANSACTION</span><br></pre></td></tr></table></figure>
<p>And finally, to roll back just your changes so far:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- Roll back changes...</span></span><br><span class="line">IF <span class="variable">@startingTranCount</span> <span class="operator">&gt;</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">ROLLBACK</span> TRANSACTION MySavePointName</span><br><span class="line"><span class="keyword">ELSE</span></span><br><span class="line">    <span class="keyword">ROLLBACK</span> TRANSACTION</span><br></pre></td></tr></table></figure>
<hr>
<p><strong>Article link: <a href="http://xnerv.wang/save-transaction-vs-begin-transaction-sql-server-how-to-nest-transactions-nicely/">http://xnerv.wang/save-transaction-vs-begin-transaction-sql-server-how-to-nest-transactions-nicely/</a></strong><br>
Reprinted from: <a href="https://stackoverflow.com/q/9713350">(StackOverflow) SAVE TRANSACTION vs BEGIN TRANSACTION (SQL Server) how to nest transactions nicely</a></p>
]]></content>
      <categories>
        <category>DBMS</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>DBMS</tag>
        <tag>SQL Server</tag>
        <tag>Transaction</tag>
        <tag>Savepoint</tag>
      </tags>
  </entry>
  <entry>
    <title>(Stack Overflow) Signal handling with multiple threads in Linux</title>
    <url>/signal-handling-with-multiple-threads-in-linux/</url>
    <content><![CDATA[<h2 id="Question"><a class="header-anchor" href="#Question"></a>Question</h2>
<p>In Linux, what happens when a program (that possibly has multiple threads) receives a signal, like SIGTERM or SIGHUP?</p>
<p>Which thread intercepts the signal? Can multiple threads get the same signal? Is there a special thread dedicated entirely to handling signals? If not, what happens inside the thread that is to handle the signal? How does the execution resume after the signal handler routine finishes?</p>
<span id="more"></span>
<h2 id="Answer-by-Alan"><a class="header-anchor" href="#Answer-by-Alan"></a>Answer by Alan</h2>
<p>This is slightly nuanced, based on which version of the Linux kernel you are using.</p>
<p>Assuming 2.6 posix threads, and if you are talking about the OS sending SIGTERM or SIGHUP, the signal is sent to process, which is received by and handled by root thread. Using POSIX threads, you can also sent SIGTERM to individual threads as well, but I suspect you are asking about what happens when the OS sends the signal to the process.</p>
<p>In 2.6, SIGTERM will cause child threads to exit “cleanly”, where as 2.4, child threads were left in an indeterminate state.</p>
<h2 id="Answer-by-sarnold"><a class="header-anchor" href="#Answer-by-sarnold"></a>Answer by sarnold</h2>
<p><code>pthreads(7)</code> describes that POSIX.1 requires all threads in a process share attributes, including:</p>
<ul>
<li>signal dispositions</li>
</ul>
<p>POSIX.1 also requires some attributes to be <em>distinct</em> for each thread, including:</p>
<ul>
<li>signal mask (<code>pthread_sigmask(3)</code>)</li>
<li>alternate signal stack (<code>sigaltstack(2)</code>)</li>
</ul>
<p>The Linux kernel’s <code>complete_signal()</code> routine has the following code block – the comments are quite useful:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Now find a thread we can wake up to take the signal off the queue.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * If the main thread wants the signal, it gets first crack.</span></span><br><span class="line"><span class="comment"> * Probably the least surprising to the average bear.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">if</span> (wants_signal(sig, p))</span><br><span class="line">        t = p;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (!group || thread_group_empty(p))</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * There is just one thread and it does not need to be woken.</span></span><br><span class="line"><span class="comment">         * It will dequeue unblocked signals before it runs again.</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line"><span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * Otherwise try to find a suitable thread.</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        t = signal-&gt;curr_target;</span><br><span class="line">        <span class="keyword">while</span> (!wants_signal(sig, t)) &#123;</span><br><span class="line">                t = next_thread(t);</span><br><span class="line">                <span class="keyword">if</span> (t == signal-&gt;curr_target)</span><br><span class="line">                        <span class="comment">/*</span></span><br><span class="line"><span class="comment">                         * No thread needs to be woken.</span></span><br><span class="line"><span class="comment">                         * Any eligible threads will see</span></span><br><span class="line"><span class="comment">                         * the signal in the queue soon.</span></span><br><span class="line"><span class="comment">                         */</span></span><br><span class="line">                        <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        signal-&gt;curr_target = t;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Found a killable thread.  If the signal will be fatal,</span></span><br><span class="line"><span class="comment"> * then start taking the whole group down immediately.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">if</span> (sig_fatal(p, sig) &amp;&amp;</span><br><span class="line">    !(signal-&gt;flags &amp; (SIGNAL_UNKILLABLE | SIGNAL_GROUP_EXIT)) &amp;&amp;</span><br><span class="line">    !sigismember(&amp;t-&gt;real_blocked, sig) &amp;&amp;</span><br><span class="line">    (sig == SIGKILL || !t-&gt;ptrace)) &#123;</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * This signal will be fatal to the whole group.</span></span><br><span class="line"><span class="comment">         */</span></span><br></pre></td></tr></table></figure>
<p>So, you see that <em>you</em> are in charge of where signals are delivered:</p>
<p>If your process has set a signal’s disposition to <code>SIG_IGN</code> or <code>SIG_DFL</code>, then the signal is ignored (or default – kill, core, or ignore) for all threads.</p>
<p>If your process has set a signal’s disposition to a specific handler routine, then you can control which thread will receive the signals by manipulating specific thread signal masks using <code>pthread_sigmask(3)</code>. You can nominate one thread to manage them all, or create one thread per signal, or any mixture of these options for specific signals, or you rely on the Linux kernel’s current default behavior of delivering the signal to the main thread.</p>
<p>Some signals, however, are special:</p>
<figure class="highlight txt"><table><tr><td class="code"><pre><span class="line">A signal may be generated (and thus pending) for a process as</span><br><span class="line">a whole (e.g., when sent using kill(2)) or for a specific</span><br><span class="line">thread (e.g., certain signals, such as SIGSEGV and SIGFPE,</span><br><span class="line">generated as a consequence of executing a specific machine-</span><br><span class="line">language instruction are thread directed, as are signals</span><br><span class="line">targeted at a specific thread using pthread_kill(3)).  A</span><br><span class="line">process-directed signal may be delivered to any one of the</span><br><span class="line">threads that does not currently have the signal blocked.  If</span><br><span class="line">more than one of the threads has the signal unblocked, then</span><br><span class="line">the kernel chooses an arbitrary thread to which to deliver</span><br><span class="line">the signal.</span><br></pre></td></tr></table></figure>
<hr>
<p><strong>Article link: <a href="http://xnerv.wang/signal-handling-with-multiple-threads-in-linux/">http://xnerv.wang/signal-handling-with-multiple-threads-in-linux/</a></strong><br>
Reprinted from: <a href="https://stackoverflow.com/q/11679568">(StackOverflow) Signal handling with multiple threads in Linux</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Linux</tag>
        <tag>Stack Overflow</tag>
        <tag>yield</tag>
      </tags>
  </entry>
  <entry>
    <title>Snapshot Isolation Level in SQL Server - What, Why and How - Part 1（转载）</title>
    <url>/snapshot-isolation-level-in-sql-server-what-why-and-how-part-1/</url>
    <content><![CDATA[<h2 id="Introduction"><a class="header-anchor" href="#Introduction"></a>Introduction</h2>
<p><a href="http://msdn.microsoft.com/en-us/library/tcbchxcb(v=vs.80).aspx">Snapshot Isolation</a> level was introduced in SQL Server 2005 and has been available ever since. Snapshot isolation levels improve performance but there are some things to take into consideration when using this feature. Some people use it frequently as it minimizes blocking and improves performance/concurrency without knowing its impact on maintaining versions in tempdb, whereas some people stay away from it because of this extra overhead. Some people get confused about the two variants of snapshot isolation level (Read Committed Snapshot Isolation (RCSI) and Snapshot Isolation (SI)) and use one where the other is needed or vice versa.</p>
<p>In this article series, I am going to discuss what snapshot isolation levels are, their variants, why and when we should use them and how we should start using this feature with examples.</p>
<span id="more"></span>
<h2 id="Understanding-Snapshot-Isolation-Level"><a class="header-anchor" href="#Understanding-Snapshot-Isolation-Level"></a>Understanding Snapshot Isolation Level</h2>
<p>Isolation level controls how two or more transactions running simultaneously should be isolated from each other in terms of locking and blocking resources. Isolation level determines the level of concurrency and data consistency. Prior to SQL Server we had four isolation levels as briefly discussed below:</p>
<ul>
<li><strong>Read Uncommitted</strong> – The transaction that uses this isolation level neither acquires shared locks to prevent others from modifying the data nor is blocked by conflicting locks acquired by other transactions. As this transaction can see the data that has been changed by other transactions but has not been committed, there is a possibility of dirty reads. This isolation level assures higher concurrency at the cost of data consistency.</li>
<li><strong>Read Committed</strong> – This is the default transaction isolation level in SQL Server and prevents dirty reads by not allowing reading of modified but not yet committed data by other transactions in the current transaction. A transaction with this isolation level acquires shared locks to prevent other transactions from modifying the data during read operation by that transaction. As a shared lock can be acquired only if there is no exclusive lock (needed for data modification) by other transactions, it ensures it reads only committed data.</li>
<li><strong>Repeatable Read</strong> – A transaction with Read Committed isolation level might face a problem of repeatable read, which means in a single transaction two data reads might see different sets of data if the data is changed between these two data reads. This happens as shared lock is acquired only while data is processed and released immediately after it. In other words, after the first data read the shared lock will be released and if the other transaction modifies the data (as other transactions can acquire exclusive locks) before a subsequent data read, the subsequent data read will see a different set of data than the previous data read.<br>
To avoid a repeatable read issue, you can use Repeatable Read isolation level with your transaction. The difference between Read Committed and Repeatable Read is, in the Read Committed isolation level the shared lock is released once the data gets processed without waiting for transaction completion whereas in Repeatable Read isolation levels the shared lock is held until the transaction completes either by committing or roll backing. Of course holding the shared lock till the end of the transaction improves the data consistency but reduces concurrency as well.</li>
<li><strong>Serializable</strong> – Even though Repeatable Read isolation level provides consistency in repeatable reads, there is still the possibility of phantom read ( Phantom read means two reads from a single transaction return a different number of records even though they use exactly same predicates).<br>
Serializable isolation level provides the highest level of data consistency but at the cost of greatly reduced concurrency. To avoid phantom, it uses range locks in the range of key values that match predicates of each statement executed in the current transaction. This way this isolation level blocks other transactions from inserting or updating any rows, which qualify the predicates used in the current transaction and hence the current transaction will keep on getting exactly the same records in the current transaction for the query. Please note the range locks are acquired and held till the completion of the transaction and hence this isolation is most restrictive and should be used only when absolutely necessary.</li>
</ul>
<p>If you notice, in all of the above isolation levels (except in the case of Read Uncommitted where there is a possibility of dirty reads anyway), the data writers (exclusive lock) block data readers (shared lock) and data readers block data writers. SQL Server 2005 introduced two new snapshot based isolation levels. The idea behind these isolation levels is to not let data writers block data readers and vice versa. These new snapshot isolation levels use a row versioning concept where they maintain the version of previously committed data in version store (tempdb) and hence it allows data readers to continue reading the older committed/consistent version of data before the current transaction/statement began, even though current version is locked and being changed by other data writers.</p>
<h2 id="Why-When-and-Where-Should-We-Use-Snapshot-Isolation-Levels"><a class="header-anchor" href="#Why-When-and-Where-Should-We-Use-Snapshot-Isolation-Levels"></a>Why, When and Where Should We Use Snapshot Isolation Levels?</h2>
<p>When using snapshot isolation levels, when the same data is modified by many data writers, SQL Server might need to maintain multiple versions of the old data and hence proper envisioning and planning needs to be done for the tempdb database size and storage before utilizing this feature. SQL Server needs to maintain versions in version store as long as they might be needed by currently running operations and if they are not needed they are removed from the version store by the SQL Server.</p>
<p>When you use snapshot (how to use is discussed in the next section) isolation levels, any update (please note many updates to the same data in a single transaction does not create multiple versions but rather many updates from multiple transactions do) will be marked with a timestamp and will create a version with old committed data in version store and a pointer (14 bytes needed for pointer and additional overhead) is stored with the changed/new data. This storage of pointers will also add to the cost of using snapshot isolation level. If changes are very frequent, successive prior versions are stored in tempdb using a linked list structure and the newest committed value is always stored in a page in the database.</p>
<p>There are two variants of using snapshot isolation levels as discussed below:</p>
<ul>
<li><strong>Read Committed Snapshot Isolation (RCSI)</strong> – This is also frequently referred to as statement level snapshot isolation level. This is, you can say, an extension of Read Committed isolation level but with increased concurrency. In this data readers don’t get blocked by data writers but rather once enabled at database level, SQL Server starts maintaining a version of data being changed by data writers and data readers get data (last committed version before the statement starts, irrespective of the timing of transaction start) from versions stored in version store. As I said, to use it you just have to enable at database level and no code changes are required as it applies to all the transactions by default.</li>
<li><strong>Snapshot Isolation (SI)</strong> – This is also frequently referred to as transaction level snapshot isolation level. This increases concurrency along with data consistency at transaction level. Like RCSI, data readers aren’t blocked by data writers but rather once enabled at database level and specified to be used in the code, SQL Server start maintaining a version of the data being changed by data writers and data readers get data (last committed version before the transaction start, in other words it provides transaction level consistent view of data) from versions stored in version store.</li>
</ul>
<p>This requires code changes to use the SET command to with the transaction with which you want to use it.</p>
<p>Using either of the snapshot isolation levels requires enabling it at database level first though another important difference between RCSI and SI is, SI requires you to explicitly change the isolation level to SNAPSHOT for each transaction that you want to execute at the transaction level with SI and usage of this in legacy system requires code changes, whereas RCSI becomes the default for all the transaction without doing any code changes.</p>
<p>Now at the end, just to summarize the benefit of using snapshot isolation, data readers can get consistent data without being blocked by data writers running at the same time as the versions get stored in version store in the tempdb database before data is changed, whereas the cost of using snapshot isolation is more overheard on SQL Server in creating and maintaining versions and the increased size of tempdb for storage for version data and the increased size of each row for pointers. The overhead even becomes more when you use SI or transaction level snapshot, in which case versions are maintained till the end of the transaction as opposed to completion of the statement, as in case of RCSI.</p>
<h2 id="Conclusion"><a class="header-anchor" href="#Conclusion"></a>Conclusion</h2>
<p>SQL Server 2005 and later versions have 6 different isolation levels. I briefly talked about the earlier four, which have been in SQL Server for a long time and talked in detail about two new snapshot based isolation levels. To learn more about how to use this great feature and how they differ from each other with an example, please refer to the next article on the series.</p>
<p>In closing, I would like to reiterate, these new snapshot based isolation levels are great as they provide better concurrency but come at a cost. Please ensure you do a thorough study before using this feature and consider the size and load on tempdb. especially in the case of SI.</p>
<h3 id="Resources"><a class="header-anchor" href="#Resources"></a>Resources</h3>
<p><a href="http://msdn.microsoft.com/en-us/library/ms173763(v=sql.105).aspx">SET TRANSACTION ISOLATION LEVEL (Transact-SQL)</a></p>
<p><a href="http://msdn.microsoft.com/en-us/library/ms189122(v=sql.105).aspx">Isolation Levels in the Database Engine</a></p>
<p><a href="http://www.databasejournal.com/article.php/3880181/Arshad-Ali.htm"><strong>See all articles by Arshad Ali</strong></a></p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/snapshot-isolation-level-in-sql-server-what-why-and-how-part-1/">http://xnerv.wang/snapshot-isolation-level-in-sql-server-what-why-and-how-part-1/</a></strong><br>
转载自：<a href="https://www.databasejournal.com/features/mssql/snapshot-isolation-level-in-sql-server-what-why-and-how-part-1.html">Snapshot Isolation Level in SQL Server - What, Why and How - Part 1</a></p>
]]></content>
      <categories>
        <category>DBMS</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>DBMS</tag>
        <tag>SQL Server</tag>
        <tag>Transaction</tag>
        <tag>Isolation Level</tag>
      </tags>
  </entry>
  <entry>
    <title>Snapshot isolation transaction aborted due to update conflict.（转载）</title>
    <url>/snapshot-isolation-transaction-aborted-due-to-update-conflict/</url>
    <content><![CDATA[<h2 id="Question"><a class="header-anchor" href="#Question"></a>Question</h2>
<p>To avoid deadlocks, we switched from ReadCommittedSnapshot isolation to SnapShot isolation for a SQL Server database at the database level and transaction level in the client code. Now, when two users perform concurrent operations on the database through the client, one of the clients get this error:</p>
<p>“Snapshot isolation transaction aborted due to update conflict. You cannot use snapshot isolation to access table ‘dbo.cust_table’ directly or indirectly in database ‘cust_database’ to update, delete, or insert the row that has been modified or deleted by another transaction. Retry the transaction or change the isolation level for the update/delete statement.”</p>
<p>What can we do to avoid deadlocks and update conflicts at the same time?</p>
<p>(The same code with Oracle database and Oracle client works without any issues with the default Read Committed Snapshot isolation level)</p>
<p>- SusmithaP</p>
<span id="more"></span>
<h2 id="All-replies"><a class="header-anchor" href="#All-replies"></a>All replies</h2>
<p>Hello</p>
<p>Ok, you might be confused: READ_COMMITED_SNAPSHOT and the transaction isolation level SNAPSHOT are different.</p>
<p>When you set a database to READ_COMMITED_SNAPSHOT your database will add 16 bytes to each row in the table for version storing.  So whenever modifications to the data happen the readers are able to access a version of the row.  This is statement level meaning the phantom rows and repeatable reads within the default transaction level (now READ_COMMITTED_SNAPSHOT) are possible.</p>
<p>SET TRANSACTION ISOLATION SNAPSHOT is different.  There is no version store initially, it is on request.  So modifications will create the versioning so readers will not be blocked.  This transaction level (similar to SERIALIZABLE without the blocking) phantom rows and non-repeatable reads are not possible.  SNAPSHOT isolation is transaction level.  With this transaction level you can run into problems when you have two (or more) writers, when the first transaction one creates a row version the next transaction comes along it also uses the version store.  When the first transaction tries to commit it’s fine as the its version is up to date but as the second user/transaction goes to commit its transaction details (from the version it read) are now out of date.  The second transaction won’t commit as it’s not consistent.</p>
<p>So what your problem is you are using both methods but when you are setting the transaction isolation level (from your clients) to SNAPSHOT the READ_COMMITED_SNAPSHOT is ignored.  You need to ask whether your procedures require the snapshot equivalent of COMMITED or SERIALIZABLE?</p>
<p>Hope this helps</p>
<p>- Rob</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/snapshot-isolation-transaction-aborted-due-to-update-conflict/">http://xnerv.wang/snapshot-isolation-transaction-aborted-due-to-update-conflict/</a></strong><br>
转载自：<a href="https://social.msdn.microsoft.com/Forums/sqlserver/en-US/834b7c8f-58d8-4491-a4c4-b24593076cab/snapshot-isolation-transaction-aborted-due-to-update-conflict?forum=sqldatabaseengine">Snapshot isolation transaction aborted due to update conflict.</a></p>
]]></content>
      <categories>
        <category>DBMS</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>DBMS</tag>
        <tag>SQL Server</tag>
        <tag>Transaction</tag>
        <tag>Isolation Level</tag>
      </tags>
  </entry>
  <entry>
    <title>一些大学常用算法及知识点的回顾</title>
    <url>/some-knowledge-points-learned-in-university/</url>
    <content><![CDATA[<p>本文是关于大学时一些常见的数据结构、算法和知识点的总结。其实与其说工作中会用到，不如说面试时被面到的可能性更大一些。不过其中一些特定领域的算法，像银行家算法，BAT的面试中我也还没有遇到过。适当地回顾大学时学到的一些知识点，也许能给自己带来一些快乐吧，一种仅存在于回忆中的快乐。</p>
<span id="more"></span>
<h2 id="排序算法"><a class="header-anchor" href="#排序算法"></a>排序算法</h2>
<h3 id="冒泡排序"><a class="header-anchor" href="#冒泡排序"></a>冒泡排序</h3>
<p>通过相邻元素的两两比较和swap，每次都将当前子序列中的最大/最小元素交换到当前子序列的最后面。</p>
<h3 id="快速排序"><a class="header-anchor" href="#快速排序"></a>快速排序</h3>
<p>选定第一个元素作为中轴，然后当i &lt; j的前提下，指针j从右至左寻找一个比中轴小的元素，指针i从左至右寻找一个比中轴大的元素，然后swap两者。最终i=j，则将i所在元素和中轴再swap。<br>
这里的重点是j必须先走。举个例子：3、1、2、5、4这个序列，如果i先移动，则最终的结构是5、1、2、3、4，显然是错误的。原因是：中轴选的是左边第一个元素（3），如果左边的指针先移动，极端案例下会使得左边指针停留在一个比中轴大的元素上（这里的5），而右边指针无法在i &lt; j的情况下找到一个比中轴小的元素，导致最终5和3交换而错误。<br>
的确无法很好地进行证明，只能举个反例来说明。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> a[<span class="number">101</span>],n;<span class="comment">//定义全局变量，这两个变量需要在子函数中使用</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">quicksort</span><span class="params">(<span class="type">int</span> left,<span class="type">int</span> right)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> i,j,t,temp;</span><br><span class="line">    <span class="keyword">if</span>(left&gt;right)</span><br><span class="line">       <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    temp=a[left]; <span class="comment">//temp中存的就是基准数</span></span><br><span class="line">    i=left;</span><br><span class="line">    j=right;</span><br><span class="line">    <span class="keyword">while</span>(i!=j)</span><br><span class="line">    &#123;</span><br><span class="line">                   <span class="comment">//顺序很重要，要先从右边开始找</span></span><br><span class="line">                   <span class="keyword">while</span>(a[j]&gt;=temp &amp;&amp; i&lt;j)</span><br><span class="line">                            j--;</span><br><span class="line">                   <span class="comment">//再找右边的</span></span><br><span class="line">                   <span class="keyword">while</span>(a[i]&lt;=temp &amp;&amp; i&lt;j)</span><br><span class="line">                            i++;</span><br><span class="line">                   <span class="comment">//交换两个数在数组中的位置</span></span><br><span class="line">                   <span class="keyword">if</span>(i&lt;j)</span><br><span class="line">                   &#123;</span><br><span class="line">                            t=a[i];</span><br><span class="line">                            a[i]=a[j];</span><br><span class="line">                            a[j]=t;</span><br><span class="line">                   &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//最终将基准数归位</span></span><br><span class="line">    a[left]=a[i];</span><br><span class="line">    a[i]=temp;</span><br><span class="line"></span><br><span class="line">    quicksort(left,i<span class="number">-1</span>);<span class="comment">//继续处理左边的，这里是一个递归的过程</span></span><br><span class="line">    quicksort(i+<span class="number">1</span>,right);<span class="comment">//继续处理右边的 ，这里是一个递归的过程</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="归并排序"><a class="header-anchor" href="#归并排序"></a>归并排序</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//将有二个有序数列a[first...mid]和a[mid...last]合并。</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">mergearray</span><span class="params">(<span class="type">int</span> a[], <span class="type">int</span> first, <span class="type">int</span> mid, <span class="type">int</span> last, <span class="type">int</span> temp[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> i = first, j = mid + <span class="number">1</span>;</span><br><span class="line">    <span class="type">int</span> m = mid,   n = last;</span><br><span class="line">    <span class="type">int</span> k = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (i &lt;= m &amp;&amp; j &lt;= n)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (a[i] &lt;= a[j])</span><br><span class="line">            temp[k++] = a[i++];</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            temp[k++] = a[j++];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (i &lt;= m)</span><br><span class="line">        temp[k++] = a[i++];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (j &lt;= n)</span><br><span class="line">        temp[k++] = a[j++];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; k; i++)</span><br><span class="line">        a[first + i] = temp[i];</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">mergesort</span><span class="params">(<span class="type">int</span> a[], <span class="type">int</span> first, <span class="type">int</span> last, <span class="type">int</span> temp[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (first &lt; last)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> mid = (first + last) / <span class="number">2</span>;</span><br><span class="line">        <span class="built_in">mergesort</span>(a, first, mid, temp);    <span class="comment">//左边有序</span></span><br><span class="line">        <span class="built_in">mergesort</span>(a, mid + <span class="number">1</span>, last, temp); <span class="comment">//右边有序</span></span><br><span class="line">        <span class="built_in">mergearray</span>(a, first, mid, last, temp); <span class="comment">//再将二个有序数列合并</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">MergeSort</span><span class="params">(<span class="type">int</span> a[], <span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> *p = <span class="keyword">new</span> <span class="type">int</span>[n];</span><br><span class="line">    <span class="keyword">if</span> (p == <span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    <span class="built_in">mergesort</span>(a, <span class="number">0</span>, n - <span class="number">1</span>, p);</span><br><span class="line">    <span class="keyword">delete</span>[] p;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注：有的书上是在mergearray()合并有序数列时分配临时数组，但是过多的new操作会非常费时。因此作了下小小的变化。只在MergeSort()中new一个临时数组。后面的操作都共用这一个临时数组。</p>
<h3 id="鸡尾酒排序"><a class="header-anchor" href="#鸡尾酒排序"></a><a href="https://zh.wikipedia.org/wiki/%E9%B8%A1%E5%B0%BE%E9%85%92%E6%8E%92%E5%BA%8F">鸡尾酒排序</a></h3>
<p>冒泡排序的变种，也被称作定向冒泡排序，鸡尾酒搅拌排序，搅拌排序（也可以视作选择排序的一种变形），涟漪排序，来回排序或快乐小时排序。<br>
先找到最小的数字，把他放到第一位，然后找到最大的数字放到最后一位。然后再找到第二小的数字放到第二位，再找到第二大的数字放到倒数第二位。以此类推，直到完成排序。</p>
<h2 id="二分查找"><a class="header-anchor" href="#二分查找"></a>二分查找</h2>
<p>递归版本：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">BSearch</span><span class="params">(elemtype a[],elemtype x,<span class="type">int</span> low,<span class="type">int</span> high)</span></span><br><span class="line"><span class="comment">/*在下届为low，上界为high的数组a中折半查找数据元素x*/</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> mid;</span><br><span class="line">    <span class="keyword">if</span>(low &gt; high)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    mid=(low + high) / <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">if</span>(x == a[mid])</span><br><span class="line">        <span class="keyword">return</span> mid;</span><br><span class="line">    <span class="keyword">if</span>(x &lt; a[mid])</span><br><span class="line">        <span class="keyword">return</span>(BSearch(a, x, low, mid<span class="number">-1</span>));</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">return</span>(BSearch(a, x, mid+<span class="number">1</span>, high));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>非递归版本</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int binary_search(int* a, int len, int goal)</span><br><span class="line">&#123;</span><br><span class="line">    int low = 0;</span><br><span class="line">    int high = len - 1;</span><br><span class="line">    while(low &lt;= high)</span><br><span class="line">    &#123;</span><br><span class="line">        int middle = (low + high)/2;</span><br><span class="line">        if(a[middle] == goal)</span><br><span class="line">            return middle;</span><br><span class="line">        //在左半边</span><br><span class="line">        else if(a[middle] &gt; goal)</span><br><span class="line">            high = middle - 1;</span><br><span class="line">        //在右半边</span><br><span class="line">        else</span><br><span class="line">            low = middle + 1;</span><br><span class="line">    &#125;</span><br><span class="line">    //没找到</span><br><span class="line">    return -1;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="图的遍历"><a class="header-anchor" href="#图的遍历"></a>图的遍历</h2>
<h3 id="DFS深度遍历（邻接图）"><a class="header-anchor" href="#DFS深度遍历（邻接图）"></a>DFS深度遍历（邻接图）</h3>
<p>首先申请一个visted[n]数组，标记每个节点是否已经访问。<br>
循环这个数组，如果一个节点没有被访问。就对其进行DFS遍历。<br>
DFS遍历：标记当前节点为已访问。然后从邻接图中获取该节点的第一个未访问的可连通邻居，递归对该邻居进行DFS。然后再获取第二个未访问的可连通邻居，重复这个循环直到所有可连通邻居都处理完。</p>
<h3 id="BFS广度遍历（邻接图）"><a class="header-anchor" href="#BFS广度遍历（邻接图）"></a>BFS广度遍历（邻接图）</h3>
<p>首先申请一个visted[n]数组，标记每个节点是否已经访问。<br>
循环这个数组，如果一个节点没有被访问。就对其进行BFS遍历。<br>
BFS遍历：标记当前节点为已访问。然后创建一个queue，将当前节点放入queue。然后类似于二叉树的层次遍历，以queue中的当前节点作为种子，在while循环中，每次弹出queue中的一个节点，获取其所有未访问的邻居节点加入到queue中。直到最后queue为空。</p>
<h2 id="最短路径"><a class="header-anchor" href="#最短路径"></a>最短路径</h2>
<h3 id="Dijkstra最短路径算法（单源最短路径）"><a class="header-anchor" href="#Dijkstra最短路径算法（单源最短路径）"></a><a href="http://blog.csdn.net/todd911/article/details/9347053">Dijkstra最短路径算法（单源最短路径）</a></h3>
<p>这个算法既可以被划入到贪心法的范畴，也可以划入到动态规划的范畴。（排序的操作涉及贪心法，而之后的推进过程可看作是动态规划）<br>
首先算出V0到各点的直连路径，然后从小到大排列，例如是V1、V2、V3……<br>
建立一个大小为n的数组distances（下标从1开始），表示V0分别到这个n个点的最短距离，初始值就是直连距离。<br>
首先V0到V1的最短路径一定就是V0到V1的直连路径，因为V1是距离V0最近的点，因此不可能有一条经过第三个点的绕路可以比V0到V1的直连路径更短。<br>
然后V2则是比较V0-V1和V0-V1-V2，选取最短的那条。更新distances[2]。<br>
而对于V3，则考察V0-V3直连距离，以及经过V1或V2到达V3的间接距离，选取最短的那条。更新distances[3]。<br>
……<br>
这里有个问题，为什么V0到V3的最短距离，一定是从已知点集合U中选择路径，而不是从未知点集合V中选择，例如V0-V4-V3这样的路径?<br>
这就是一开始对n个直连路径进行排序的原因，V0-V4一定 &gt;= V0-V3，因此V0-V4-V3一定 &gt;= V0-V3。<br>
另外本算法不能处理负权重边，用上面的例子说明，如果V0-V4是负权重，则有可能V0-V4-V3一定 &lt; V0-V3，因此这种算法就不再使用。（此时有没有其它好的方法？除了各边都加上同一个偏移量，将负权重都转正。）</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/***************************************</span></span><br><span class="line"><span class="comment">* About:    有向图的Dijkstra算法实现</span></span><br><span class="line"><span class="comment">* Author:   Tanky Woo</span></span><br><span class="line"><span class="comment">* Blog:     www.WuTianQi.com</span></span><br><span class="line"><span class="comment">***************************************/</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> maxnum = <span class="number">100</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> maxint = <span class="number">999999</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Dijkstra</span><span class="params">(<span class="type">int</span> n, <span class="type">int</span> v, <span class="type">int</span> *dist, <span class="type">int</span> *prev, <span class="type">int</span> c[maxnum][maxnum])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">bool</span> s[maxnum];    <span class="comment">// 判断是否已存入该点到S集合中</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>; i&lt;=n; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        dist[i] = c[v][i];</span><br><span class="line">        s[i] = <span class="number">0</span>;     <span class="comment">// 初始都未用过该点</span></span><br><span class="line">        <span class="keyword">if</span>(dist[i] == maxint)</span><br><span class="line">            prev[i] = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            prev[i] = v;</span><br><span class="line">    &#125;</span><br><span class="line">    dist[v] = <span class="number">0</span>;</span><br><span class="line">    s[v] = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 依次将未放入S集合的结点中，取dist[]最小值的结点，放入结合S中</span></span><br><span class="line">    <span class="comment">// 一旦S包含了所有V中顶点，dist就记录了从源点到所有其他顶点之间的最短路径长度</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">2</span>; i&lt;=n; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> tmp = maxint;</span><br><span class="line">        <span class="type">int</span> u = v;</span><br><span class="line">        <span class="comment">// 找出当前未使用的点j的dist[j]最小值</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">1</span>; j&lt;=n; ++j)</span><br><span class="line">            <span class="keyword">if</span>((!s[j]) &amp;&amp; dist[j]&lt;tmp)</span><br><span class="line">            &#123;</span><br><span class="line">                u = j;              <span class="comment">// u保存当前邻接点中距离最小的点的号码</span></span><br><span class="line">                tmp = dist[j];</span><br><span class="line">            &#125;</span><br><span class="line">        s[u] = <span class="number">1</span>;    <span class="comment">// 表示u点已存入S集合中</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 更新dist</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">1</span>; j&lt;=n; ++j)</span><br><span class="line">            <span class="keyword">if</span>((!s[j]) &amp;&amp; c[u][j]&lt;maxint)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="type">int</span> newdist = dist[u] + c[u][j];</span><br><span class="line">                <span class="keyword">if</span>(newdist &lt; dist[j])</span><br><span class="line">                &#123;</span><br><span class="line">                    dist[j] = newdist;</span><br><span class="line">                    prev[j] = u;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">searchPath</span><span class="params">(<span class="type">int</span> *prev,<span class="type">int</span> v, <span class="type">int</span> u)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> que[maxnum];</span><br><span class="line">    <span class="type">int</span> tot = <span class="number">1</span>;</span><br><span class="line">    que[tot] = u;</span><br><span class="line">    tot++;</span><br><span class="line">    <span class="type">int</span> tmp = prev[u];</span><br><span class="line">    <span class="keyword">while</span>(tmp != v)</span><br><span class="line">    &#123;</span><br><span class="line">        que[tot] = tmp;</span><br><span class="line">        tot++;</span><br><span class="line">        tmp = prev[tmp];</span><br><span class="line">    &#125;</span><br><span class="line">    que[tot] = v;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=tot; i&gt;=<span class="number">1</span>; --i)</span><br><span class="line">        <span class="keyword">if</span>(i != <span class="number">1</span>)</span><br><span class="line">            cout &lt;&lt; que[i] &lt;&lt; <span class="string">&quot; -&gt; &quot;</span>;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            cout &lt;&lt; que[i] &lt;&lt; endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">freopen</span>(<span class="string">&quot;input.txt&quot;</span>, <span class="string">&quot;r&quot;</span>, stdin);</span><br><span class="line">    <span class="comment">// 各数组都从下标1开始</span></span><br><span class="line">    <span class="type">int</span> dist[maxnum];     <span class="comment">// 表示当前点到源点的最短路径长度</span></span><br><span class="line">    <span class="type">int</span> prev[maxnum];     <span class="comment">// 记录当前点的前一个结点</span></span><br><span class="line">    <span class="type">int</span> c[maxnum][maxnum];   <span class="comment">// 记录图的两点间路径长度</span></span><br><span class="line">    <span class="type">int</span> n, line;             <span class="comment">// 图的结点数和路径数</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 输入结点数</span></span><br><span class="line">    cin &gt;&gt; n;</span><br><span class="line">    <span class="comment">// 输入路径数</span></span><br><span class="line">    cin &gt;&gt; line;</span><br><span class="line">    <span class="type">int</span> p, q, len;          <span class="comment">// 输入p, q两点及其路径长度</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 初始化c[][]为maxint</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>; i&lt;=n; ++i)</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">1</span>; j&lt;=n; ++j)</span><br><span class="line">            c[i][j] = maxint;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>; i&lt;=line; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        cin &gt;&gt; p &gt;&gt; q &gt;&gt; len;</span><br><span class="line">        <span class="keyword">if</span>(len &lt; c[p][q])       <span class="comment">// 有重边</span></span><br><span class="line">        &#123;</span><br><span class="line">            c[p][q] = len;      <span class="comment">// p指向q</span></span><br><span class="line">            c[q][p] = len;      <span class="comment">// q指向p，这样表示无向图</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>; i&lt;=n; ++i)</span><br><span class="line">        dist[i] = maxint;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>; i&lt;=n; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">1</span>; j&lt;=n; ++j)</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;%8d&quot;</span>, c[i][j]);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">Dijkstra</span>(n, <span class="number">1</span>, dist, prev, c);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 最短路径长度</span></span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;源点到最后一个顶点的最短路径长度: &quot;</span> &lt;&lt; dist[n] &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 路径</span></span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;源点到最后一个顶点的路径为: &quot;</span>;</span><br><span class="line">    <span class="built_in">searchPath</span>(prev, <span class="number">1</span>, n);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Floyd最短路径算法（多源最短路径）"><a class="header-anchor" href="#Floyd最短路径算法（多源最短路径）"></a>Floyd最短路径算法（多源最短路径）</h3>
<p>Dijkstra算法是用于计算单点到其它点的最短距离，复杂度是O(n<sup>2</sup>)，则计算完n个点的数据的复杂度就是O(n<sup>3</sup>)。而Floyd的算法复杂度也是O(n<sup>3</sup>).<br>
虽然两者的算法复杂度一样，但是如果依次对某个顶点运用Dijkstra算法,则与Floyd算法相比,很多路径和结果计算是重复的,虽然复杂度相同,但是运算量差了很多。<br>
此外，Dijkstra算法使用的前提是图中路径长度必须大于等于0，但是Floyd算法则仅仅要求没有总和小于0的环路就可以了。因此Floyd 算法应用范围比Dijkstra算法要广。</p>
<p>Floyd算法的思路：首先求出各点之间的直连距离矩阵，然后逐步引入1号点、2号点。。。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 经过1号顶点</span></span><br><span class="line"><span class="keyword">for</span>(i=<span class="number">1</span>;i&lt;=n;i++)</span><br><span class="line">    <span class="keyword">for</span>(j=<span class="number">1</span>;j&lt;=n;j++)</span><br><span class="line">        <span class="keyword">if</span> (e[i][j] &gt; e[i][<span class="number">1</span>]+e[<span class="number">1</span>][j])  e[i][j]=e[i][<span class="number">1</span>]+e[<span class="number">1</span>][j];</span><br><span class="line"><span class="comment">// 经过2号顶点</span></span><br><span class="line"><span class="keyword">for</span>(i=<span class="number">1</span>;i&lt;=n;i++)</span><br><span class="line">    <span class="keyword">for</span>(j=<span class="number">1</span>;j&lt;=n;j++)</span><br><span class="line">        <span class="keyword">if</span> (e[i][j] &gt; e[i][<span class="number">2</span>]+e[<span class="number">2</span>][j])  e[i][j]=e[i][<span class="number">2</span>]+e[<span class="number">2</span>][j];</span><br></pre></td></tr></table></figure>
<p>从而推导出一个三重循环</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span>(k=<span class="number">1</span>;k&lt;=n;k++)</span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">1</span>;i&lt;=n;i++)</span><br><span class="line">        <span class="keyword">for</span>(j=<span class="number">1</span>;j&lt;=n;j++)</span><br><span class="line">            <span class="keyword">if</span>(e[i][j]&gt;e[i][k]+e[k][j])</span><br><span class="line">                e[i][j]=e[i][k]+e[k][j];</span><br></pre></td></tr></table></figure>
<p>Floyd算法另一种理解DP，为理论爱好者准备的，上面这个形式的算法其实是Floyd算法的精简版，而真正的Floyd算法是一种基于DP(Dynamic Programming)的最短路径算法。设图G中n 个顶点的编号为1到n。令c [i, j, k]表示从i 到j 的最短路径的长度，其中k 表示该路径中的最大顶点，也就是说c[i,j,k]这条最短路径所通过的中间顶点最大不超过k。因此，如果G中包含边&lt; i, j &gt;，则c[i, j, 0] =边&lt; i, j &gt; 的长度；若i= j ，则c[i,j,0]=0；如果G中不包含边&lt; i, j &gt;，则c (i, j, 0)= +∞。c[i, j, n] 则是从i 到j 的最短路径的长度。对于任意的k&gt;0，通过分析可以得到：中间顶点不超过k 的i到j的最短路径有两种可能：该路径含或不含中间顶点k。若不含，则该路径长度应为c[i, j, k-1]，否则长度为 c[i, k, k-1] +c [k, j, k-1]。c[i, j, k]可取两者中的最小值。状态转移方程：c[i, j, k]=min{c[i, j, k-1], c [i, k, k-1]+c [k, j, k-1]}，k＞0。这样，问题便具有了<em><strong>最优子结构性质</strong></em>，可以用动态规划方法来求解。</p>
<h2 id="最小生成树：Prim算法和Kruskal算法"><a class="header-anchor" href="#最小生成树：Prim算法和Kruskal算法"></a><a href="http://www.cnblogs.com/biyeymyhjob/archive/2012/07/30/2615542.html">最小生成树：Prim算法和Kruskal算法</a></h2>
<p>网上的Prim实现方法的时间复杂度是O(N<sup>2</sup>)，但实际上先用快速排序对各边进行排序，然后用两个hashset，U和V记录两种点。然后遍历一次边的有序列表进行了，时间复杂度O(logN)。<br>
Kruskal算法的实现思想是：也是先对所有边排序，然后一开始时将每条边当作一个连通分量。然后循环地遍历边的有序列表，如果边的两个顶点不在同一个连通分量中，就将这两个连通分量合并为同一个（新的连通分量标识选择两者中较小的那个）。<br>
<span style="color:red">（描述不太清楚，还是不知道两个算法的区别）</span></p>
<h2 id="KMP算法"><a class="header-anchor" href="#KMP算法"></a><strong>KMP算法</strong></h2>
<p><em>（待补完）</em></p>
<h2 id="汉诺塔"><a class="header-anchor" href="#汉诺塔"></a>汉诺塔</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.i = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">move</span>(<span class="params">self, n, src, dst</span>):</span><br><span class="line">        self.i += <span class="number">1</span></span><br><span class="line">        <span class="built_in">print</span> <span class="string">&quot;the %d step: move dish %d %s to %s.&quot;</span> % (self.i, n, src, dst)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">hanoi</span>(<span class="params">self, n, src, dst, dep</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="number">1</span> == n:</span><br><span class="line">            self.move(<span class="number">1</span>, src, dst)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.hanoi(n - <span class="number">1</span>, src, dep, dst)</span><br><span class="line">            self.move(n, src, dst)</span><br><span class="line">            self.hanoi(n - <span class="number">1</span>, dep, dst, src)</span><br></pre></td></tr></table></figure>
<h2 id="Bloom-Filter"><a class="header-anchor" href="#Bloom-Filter"></a><a href="https://zh.wikipedia.org/zh-sg/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8">Bloom Filter</a></h2>
<p>Bloom Filter的这种高效是有一定代价的：在判断一个元素是否属于某个集合时，有可能会把不属于这个集合的元素误认为属于这个集合（false positive）。因此，Bloom Filter不适合那些“零错误”的应用场合。而在能容忍低错误率的应用场合下，Bloom Filter通过极少的错误换取了存储空间的极大节省。</p>
<p>无法从Bloom Filter集合中删除一个元素。因为该元素对应的位会牵动到其他的元素。所以一个简单的改进就是 counting Bloom filter，用一个counter数组代替位数组，就可以支持删除了。 此外，Bloom Filter的hash函数选择会影响算法的效果。</p>
<h2 id="银行家算法"><a class="header-anchor" href="#银行家算法"></a>银行家算法</h2>
<p>银行家算法：每个资源申请者要预先填写最大申请额度，然后以后每次能提出额度内的申请，银行家评估如果通过这次申请，那剩余的资源是否能构成安全序列。这里有一个假设是，每一名资源申请者只有在获取到最大额度的申请时，才会释放掉手中的资源。因此关键在于如何判断是否能够构成安全序列。<br>
安全序列的判定：检查所有申请者，看当前剩余资源能够使得其中至少一个申请者可以满足最大额度申请而释放掉其资源。因为这是一个使得可用资源增长的过程，因此检查的顺序是不会影响最终判定结果的。</p>
<h2 id="CA工作原理"><a class="header-anchor" href="#CA工作原理"></a><a href="http://my.oschina.net/0757/blog/207487">CA工作原理</a></h2>
<p>SSL(Secure Socket Layer) 是一种加密技术，可以提供对称加密和非对称加密。由于它在协议层里正好是在传输层与应用层之间，这就决定了上层应用必须经过它，这就是它广泛流行和易于实现的原因。<br>
对称加密有md5，sha1。由于md5已被学者证明可以计算出加密冲突，即它有一定的不安全性，所以建议用sha1加密。<br>
非对称性加密有RSA，即密码有一对，一个私钥，一个公钥，公钥可以让所有人知道，私钥只有自己知道。<br>
这样理解，服务器产生一对密钥，公钥给别人即客户端，客户端用它来加密，加密后发给服务端，服务端用自己的私钥解密后得到数据。<br>
数字签名就和上面的过程相反，即数据由服务端用私钥加密，客户端用服务端的公钥解密，解得出来就说明这数据包的确是出服务端发过来的。<br>
数字签名是由服务端自己签的，但没人去验证这个服务端是不是你所要访问的真实的，所以需要第三方来帮忙检验，就和支付宝处于第三方来协调的位置一样。这个第三方就叫CA。<br>
所以服务器产生的公钥就交给CA，CA用CA自己的私钥加密，即数字签名，加密生会生成证书，证书还是要交给服务端，放在服务端那边。当客户端访问服务端时，服务端就会把这个证书安装到客户端上。<br>
客户端就会用CA提供的CA自己的公钥来解密这个证书，（当然这个CA是浏览器预装时嵌入的可信的CA，如果不是预装时嵌入的CA，此时就没有CA的公钥，就解不了，就会弹出告警。）解得开就说明这个证书是某个CA认证过了的，是可信的，解开后就会得到数据，而这个数据就是服务端的公钥，此时用这个公钥与服务端进行数据传输。<br>
数据传输过程中，由于RSA方式加解密速度非常慢，所以会把对称与非对称两者结合起来用，即用RSA把对称加密的密码进行加密传输，再用对称密码进行加解密，这样就可以提高效率，且是安全的。</p>
<h2 id="B树"><a class="header-anchor" href="#B树"></a>B树</h2>
<p>B树：分支节点和叶节点均保存记录的关键码和记录的指针<br>
B+树：分支节点只保存记录关键码的复制，无记录指针。<br>
所有记录都集中在叶节点一层，并且叶节点可以构成一维线性表，便于连续访问和范围查询。<br>
两者的插入、删除基本一致。<br>
对于同样阶的B树和B+树，B+树的树高和平均检索长度均大于B树（因为B+树必须检索到叶节点一层）<br>
但实际上检索过程中，最耗时间的是…………IO，也就是访盘次数越少越好。<br>
B+树的分支节点无记录指针，同样一个盘块可以存放的关键码数就更多，所以虽然平均检索长度大，但访盘次数反而少，速度也就比B树快。</p>
<h2 id="deque、stack、queue、priority-queue，heap"><a class="header-anchor" href="#deque、stack、queue、priority-queue，heap"></a>deque、stack、queue、priority_queue，heap</h2>
<p>deque和list/vector一样是基本的容器类型。但stack/queue/priority_queue/heap则是抽象容器类型，必须基于一种基本容器类型。<br>
stack和queue默认是使用deque，而priority_queue默认是使用vector。<br>
queue是一种单向队列，push类似push_back，pop类似pop_front，其实就是用adapter模式将基本容器类型的接口变化了一下，所以目前看来实际应用的不多。stack也类似。<br>
priority_queue/heap则是基于基本容器类型，实现了一种高层的抽象数据结构。</p>
<h2 id="堆算法"><a class="header-anchor" href="#堆算法"></a>堆算法</h2>
<p>堆中每一个节点的父节点的下标是(i-1)/2, i!=0。<br>
第一个非叶子结点是size/2。</p>
<h3 id="堆的建立"><a class="header-anchor" href="#堆的建立"></a>堆的建立</h3>
<p>从最后一个非叶子结点开始，从后向前推，每次都比较一个非叶子结点和其两个子节点，将最大者交换到该非叶子结点的位置。时间复杂度是O(N)。</p>
<h3 id="堆的插入"><a class="header-anchor" href="#堆的插入"></a>堆的插入</h3>
<p>将元素放到最后面，然后逐步与父节点进行调整。<br>
父节点的下标是(i-1)/2,i!=0，对于大顶堆，如果当前节点比其父节点大，则swap，然后重复这个过程。<br>
时间复杂度是o(logN)。</p>
<h3 id="堆的删除"><a class="header-anchor" href="#堆的删除"></a>堆的删除</h3>
<p>将堆顶元素弹出，然后将最后一个元素填充到堆顶，然后逐步与子节点进行调整。<br>
子节点的下标是2i+1和2i+2，比较这两个节点与当前节点，将（可能的）最大者与当前节点进行swap，重复这个过程。<br>
时间复杂度是o(logN)。</p>
<h3 id="堆排序"><a class="header-anchor" href="#堆排序"></a>堆排序</h3>
<p>首先需要建立堆。<br>
然后每次将堆顶的元素与当前子序列中的最后一个元素交换，这样就同时完成了一个元素的直接选择排序，又完成了堆删除中的一步：将最后一个元素填充到堆顶。重复这个过程。<br>
时间复杂度是O(N)+N<em>log(N)=N</em>log(N)<br>
另外堆排序是不稳定的排序。（有没有可能规定相等元素在比较、替换等时的一套规则，使得堆排序能够稳定？）</p>
<h2 id="路由协议"><a class="header-anchor" href="#路由协议"></a>路由协议</h2>
<h3 id="LS-DV"><a class="header-anchor" href="#LS-DV"></a>LS/DV</h3>
<p>路由协议分成链路状态协议（LS）、和距离矢量协议（DV）两大类。</p>
<p>链路状态协议：例如OSPF协议。使用链路状态路由协议时，每台路由创建自己的LSA（链路状态通告），并在路由更新中泛洪（将网络的所有细节通告给其他的所有路由器）LSA给其他的所有路由器。泛洪LSA就是路由器将LSA发给邻居，邻居再将它转发给他的邻居，知道所有的路由器都收到这个LSA，路由器相连的子网也会创建并泛洪链路LSA，最后每台路由器都有所有路由器的LSA和所有链路LSA。</p>
<p>距离矢量协议：例如RIP协议。它们发送的全部的周期性（默认每隔30秒）的路由更新。更新中只包括子网和各自的距离（即到达目的子网的度量值）。除了邻居路由之外，路由器不了解网络拓扑的细节（因为它之和邻居路由交换数据）。如果到相同的子网有多条路由时，路由器选择最低度量值的路由，如果度量值相同时，就都选择（如rip协议中，有时有2个最佳路由）。</p>
<h3 id="自治系统AS"><a class="header-anchor" href="#自治系统AS"></a>自治系统AS</h3>
<p>自治系统AS：每一个AS分配一个16位的ASN号码，中国貌似至少有几十个ASN号码，上海电信、广东电信啥的都有自己独立的ASN号码。<br>
在互联网中，一个自治系统(AS)是一个有权自主地决定在本系统中应采用何种路由协议的小型单位。这个网络单位可以是一个简单的网络也可以是一个由一个或多个普通的网络管理员来控制的网络群体，它是一个单独的可管理的网络单元（例如一所大学，一个企业或者一个公司个体）。一个自治系统有时也被称为是一个路由选择域（routing domain）。一个自治系统将会分配一个全局的唯一的16位号码，有时我们把这个号码叫做自治系统号（ASN）。</p>
<h3 id="IGP-EGP"><a class="header-anchor" href="#IGP-EGP"></a>IGP/EGP</h3>
<p>IGP是内部网关协议，是一类协议的统称，其本身并不是协议。例如OSPF、RIP就属于IGP协议。<br>
EGP同样，是外部网关协议的统称。而BGP是EGP中一个具体的协议。</p>
<h3 id="RIP协议"><a class="header-anchor" href="#RIP协议"></a>RIP协议</h3>
<p>RIP协议被设计用于使用同种技术的中型网络，因此适应于大多数的校园网和使用速率变化不是很大的连续线的地区性网络。对于更复杂的环境，一般不使用RIP协议。<br>
RIP作为一个系统长驻进程（daemon）而存在于路由器中，负责从网络系统的其它路由器接收路由信息，从而对本地IP层路由表作动态的维护，保证IP层发送报文时选择正确的路由。同时负责广播本路由器的路由信息，通知相邻路由器作相应的修改。RIP协议处于UDP协议的上层，RIP所接收的路由信息都封装在UDP协议的数据报中，RIP在520号UDP端口上接收来自远程路由器的路由修改信息，并对本地的路由表做相应的修改，同时通知其它路由器。<br>
RIP路由协议用“更新（UNPDATES）”和“请求（REQUESTS）”这两种分组来传输信息的。每个具有RIP协议功能的路由器每隔30秒用UDP520端口给与之直接相连的机器广播更新信息。更新信息反映了该路由器所有的路由选择信息数据库。路由选择信息数据库的每个条目由“局域网上能达到的IP地址”和“与该网络的距离”两部分组成。请求信息用于寻找网络上能发出RIP报文的其他设备。</p>
<p>由于RIP的路由条目中并不保存完整路径，因此一旦网络波动，以及通讯延迟，可能会产生技术到无穷的问题。RIP设置最大条数15跳，也是为了避免这个问题。</p>
<ul>
<li>水平分割：记录每条最佳路由是从哪个邻居的哪个端口收到的，将不会再通过该端口向该邻居广播这条最佳路由。但是局限是只能在两个路由器时有效，三个及更多的路由器，仍有可能形成环。</li>
<li>毒化逆转：与水平分割不同，还是会通过该端口向该邻居广播这条路由，但是会设置成距离16：不可达。有可能立刻解决路由选择环路。否则，不正确的路径将在路由表中驻留到超时为止。破坏逆转的缺点是它增加了路由更新的的数据大小，且还是有可能形成环。</li>
<li>保持定时器法：当一条路由被删除后，一定时间内（如180s）不会再更新该路由。</li>
<li>触发更新法：毒化逆转将任何两个路由器构成的环路打破，但三个或更多个路由器构成的环路仍会发生，直到无穷（16）时为止。触发式更新法可加速收敛时间，它的工作原理是当某个路径的跳数改变了，路由器立即发出更新信息，不管路由器是否到达常规信息更新时间都发出更新信息。</li>
</ul>
<h3 id="OSPF算法"><a class="header-anchor" href="#OSPF算法"></a>OSPF算法</h3>
<p><em>OSPF算法真的不会成环么？例如A和B，两者交替地到目的IP的延时较短，那packet不就有可能在这两台路由器之间循环么？</em></p>
<h2 id="海明码"><a class="header-anchor" href="#海明码"></a><a href="http://blog.csdn.net/lycb_gz/article/details/8214961">海明码</a></h2>
<p><em>（待补完）</em></p>
<h2 id="欧拉回路-哈密顿回路"><a class="header-anchor" href="#欧拉回路-哈密顿回路"></a>欧拉回路/哈密顿回路</h2>
<p><strong>欧拉回路</strong>是经过所有边一次然后回到原点，<strong>哈密顿回路</strong>是经过所有节点一次然后回到原点，TSP旅行商问题就是哈密顿回路。<br>
可见欧拉回路是有可能重复经过一个点的，但哈密顿回路不能重复经过一条边。</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/some-knowledge-points-learned-in-university/">http://xnerv.wang/some-knowledge-points-learned-in-university/</a></strong></p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>数据结构与算法</tag>
        <tag>排序算法</tag>
        <tag>查找算法</tag>
        <tag>路由协议</tag>
      </tags>
  </entry>
  <entry>
    <title>静态库那些事儿/MT /MD（转载）</title>
    <url>/something-about-static-library-mt-md/</url>
    <content><![CDATA[<p>单例模式是一种很简单常用的设计模式,常见的做法可能是这样:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">Renderer&amp; <span class="title">getInstance</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">static</span> Renderer renderer;</span><br><span class="line">    <span class="keyword">return</span> renderer;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当然,这个代码在不支持static local variable thread-safe init的编译器上,是没有办法保证线程安全的,c++11标准已经规定static local variable只会被初始化一次了,然而vs2013还没有实现,vs2015里才支持了这条标准.不过这条代码在我们的程序里只有一个线程访问,所以也就不存在线程安全的问题.</p>
<span id="more"></span>
<p>然后有一天,写了点代码,程序崩溃了:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">Renderer::<span class="built_in">getInstance</span>().<span class="built_in">xxxx</span>();</span><br></pre></td></tr></table></figure>
<p>分析发现是Renderer里的一个成员变量<code>m_pMap == NULL</code>了,而在项目的其他地方,也有用这个xxxx()函数的地方,竟然没有问题.</p>
<p>那就在xxxx()里下个断点,然后看下this指针的值吧,第一次命中时this的值是0x0456adc4, 第二次命中的时候是0x074324ad(这个地址是我随便写的,反正就是这两次命中断点this的值不一样).这是怎么回事呢?为什么出现了两个Renderer的实例呢?</p>
<p>细心的我发现这两个this指向的Renderer实例并没有在同一个模块内,一个在a.dll里,一个在main.exe里!造成这种现象的原因,是因为开篇的那个getInstance()方法所在工程是一个静态库,然后main.exe工程和a.dll工程均链接了这个静态库,导致main.exe里和a.dll里都存在一个renderer实例.而我们这个renderer实例在使用前,要这样:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">Renderer::<span class="built_in">getInstance</span>().<span class="built_in">Create</span>();</span><br></pre></td></tr></table></figure>
<p>然后才可以初始化m_pMap, 崩溃在main.exe里那行代码之前,并没有调用Create(),所以导致m_pMap == NULL崩溃了.</p>
<p>问题到这里已经水落石出了,想办法弄成在两个模块里共用一个实例就可以了!问题解决.</p>
<p>当然,如果文章就这样结束了,未免太没劲儿了吧,顺便说说另一个大家经常忽略的事情.</p>
<p>在开发dll的过程中,总会有意无意的写出一些跨模块分配释放内存的代码,比如在A模块malloc了一块内存,在B模块free,然后导致崩溃.然后将编译器选项由/MT改为/MD就可以解决问题.为什么会出现这种问题呢?我们来看看malloc的实现(vs2013 crt):</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">__forceinline <span class="type">void</span> * __cdecl _heap_alloc (<span class="type">size_t</span> size)</span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (_crtheap == <span class="number">0</span>) &#123;</span><br><span class="line"><span class="meta">#<span class="keyword">if</span> !defined (_CRT_APP) || defined (_DEBUG)</span></span><br><span class="line">        _FF_MSGBANNER();    <span class="comment">/* write run-time error banner */</span></span><br><span class="line">        _NMSG_WRITE(_RT_CRT_NOTINIT);  <span class="comment">/* write message */</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span>  <span class="comment">/* !defined (_CRT_APP) || defined (_DEBUG) */</span></span></span><br><span class="line">        __crtExitProcess(<span class="number">255</span>);  <span class="comment">/* normally _exit(255) */</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">HeapAlloc</span>(_crtheap, <span class="number">0</span>, size ? size : <span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>malloc最后会调用HeapAlloc来分配内存,msdn看看HeapAlloc的说明,</p>
<blockquote>
<p>HeapAlloc Function</p>
<p>Allocates a block of memory from a heap. The allocated memory is not movable.</p>
<p>Syntax</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">LPVOID WINAPI <span class="title function_">HeapAlloc</span><span class="params">(</span></span><br><span class="line"><span class="params">  __in  HANDLE hHeap,</span></span><br><span class="line"><span class="params">  __in  DWORD dwFlags,</span></span><br><span class="line"><span class="params">  __in  SIZE_T dwBytes</span></span><br><span class="line"><span class="params">)</span>;</span><br></pre></td></tr></table></figure>
<p>Parameters</p>
<p>hHeap A handle to the heap from which the memory will be allocated. This handle is returned by the <a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366597.aspx">HeapCreate</a> or <a href="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366569.aspx">GetProcessHeap</a> function.</p>
</blockquote>
<p>对着msdn的说明可以知道,malloc用的heap handle是 _crtheap,这个_crtheap是个全局变量,那我们看看是什么时候给_crtheap赋值的吧.</p>
<p><img src="/assets/something-about-static-library-mt-md/1.jpg" alt=""></p>
<p>跟着红色箭头从上往下分析,首先在BaseThreadInitThunk上下个断点,然后F5执行,断点命中之后执行</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">x *!*_crtheap*</span><br></pre></td></tr></table></figure>
<p>找到crtheap的地址,结果显示在0f7ec190这里,这里的值目前也是0x00000000,证明还没有被赋值,那就在这个地址上打个写断点,</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ba w4 0f7ec190</span><br></pre></td></tr></table></figure>
<p>F5执行,断点命中,输入kb显示调用栈,结果发现是在_heap_init里对_crtheap赋值的,看看heap_init的代码吧:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> __cdecl _heap_init (<span class="type">void</span>)</span><br><span class="line">&#123;</span><br><span class="line">        <span class="comment">//  Initialize the &quot;big-block&quot; heap first.</span></span><br><span class="line">        <span class="keyword">if</span> ( (_crtheap = GetProcessHeap()) == <span class="literal">NULL</span> )</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>只是调用GetProcessHeap而已,那还得看看GetProcessHeap的实现:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">KERNELBASE!GetProcessHeap:</span><br><span class="line">75415620 64a118000000    mov     eax,dword ptr fs:[00000018h]</span><br><span class="line">75415626 8b4030          mov     eax,dword ptr [eax+30h]</span><br><span class="line">75415629 8b4018          mov     eax,dword ptr [eax+18h]</span><br><span class="line">7541562c c3              ret</span><br></pre></td></tr></table></figure>
<p><img src="/assets/something-about-static-library-mt-md/2.jpg" alt=""></p>
<p>分析汇编可知,首先去TEB + 0x18里取值赋值给eax,根据上图可知,0x18为Self指针,其实就是TEB自己的地址,然后去TEB+0x30里取值赋值给eax,由图可知,0x30为ProcessEnvironmentBlock,即PEB, 然后去PEB+0x18里取值作为返回值,也就是ProcessHeap(见下图),那我们看看PEB+0x18是多少,</p>
<p><img src="/assets/something-about-static-library-mt-md/3.jpg" alt=""></p>
<p><img src="/assets/something-about-static-library-mt-md/4.jpg" alt=""></p>
<p>由图可知GetProcessHeap会返回005d0000,然后赋值给_crtheap.那和/MT /MD有什么关系呢?</p>
<p>/MT:</p>
<blockquote>
<p>Causes your application to use the multithread, static version of the run-time library.</p>
</blockquote>
<p>/MD:</p>
<blockquote>
<p>Causes your application to use the multithread- and DLL-specific version of the run-time library.</p>
</blockquote>
<p>如果使用/MT,会使用静态版本的运行时库,每个模块里都会有一个_crtheap全局变量,_heap_init就会在每个模块里都被调用一次,而使用/MD则使用动态库版本的运行时库,整个进程里只有运行时库里才有一份_crtheap全局变量,在crt的dll加载的时候调用一次_heap_init.但是分析_heap_init的实现可知,就算调用多次,返回的依然是PEB里的那个堆句柄啊,也不会导致不同模块里的_crtheap有不同的值,那HeapFree和HeapAlloc使用的handle就是同一个,也不应该引起崩溃啊.事实的确如此,我也是在今天写这篇专栏用windbg分析的时候才发现这个问题.是我之前记错了还是crt的实现有变化呢?于是我查看了下vs2003的crt的_heap_init的实现:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> __cdecl _heap_init (</span><br><span class="line">        <span class="type">int</span> mtflag</span><br><span class="line">        )</span><br><span class="line">&#123;</span><br><span class="line">        <span class="comment">//  Initialize the &quot;big-block&quot; heap first.</span></span><br><span class="line">        <span class="keyword">if</span> ( (_crtheap = HeapCreate( mtflag ? <span class="number">0</span> : HEAP_NO_SERIALIZE,</span><br><span class="line">                                     BYTES_PER_PAGE, <span class="number">0</span> )) == <span class="literal">NULL</span> )</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifndef</span> _WIN64</span></span><br><span class="line">        <span class="comment">// Pick a heap, any heap</span></span><br><span class="line">        __active_heap = __heap_select();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> ( __active_heap == __V6_HEAP )</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">//  Initialize the small-block heap</span></span><br><span class="line">            <span class="keyword">if</span> (__sbh_heap_init(MAX_ALLOC_DATA_SIZE) == <span class="number">0</span>)</span><br><span class="line">            &#123;</span><br><span class="line">                HeapDestroy(_crtheap);</span><br><span class="line">                <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CRTDLL</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> ( __active_heap == __V5_HEAP )</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span> ( __old_sbh_new_region() == <span class="literal">NULL</span> )</span><br><span class="line">            &#123;</span><br><span class="line">                HeapDestroy( _crtheap );</span><br><span class="line">                <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span>  <span class="comment">/* CRTDLL */</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span>  <span class="comment">/* _WIN64 */</span></span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这就明了了,如果在vs2003里开发dll,然后编译dll的时候选择/MT,那这个dll内部就会有一份_crtheap,那在加载这个dll的时候,会调用一次_heap_init,然后调用HeapCreate来初始化_crtheap.这也就意味着其他模块使用/MT选项也会如此,导致每个模块里的_crtheap值是不同的.这样跨模块执行free,就会导致在handle A上分配的内存去handle B上释放导致了崩溃.如果所有模块均使用/MD选项,则只有crt的dll里有一份_crtheap,在crt的dll被加载的时候执行一次HeapCreate并赋值给_crtheap,然后HeapAlloc与 HeapFree使用的HANDLE都是同一个_crtheap,就不会崩溃了.</p>
<p>问题到这里就分析完毕了。</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/something-about-static-library-mt-md/">http://xnerv.wang/something-about-static-library-mt-md/</a></strong><br>
转载自：<a href="https://zhuanlan.zhihu.com/p/20628410">静态库那些事儿/MT /MD</a></p>
]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Windows</tag>
        <tag>Heap</tag>
        <tag>DLL</tag>
        <tag>DLL Hell</tag>
      </tags>
  </entry>
  <entry>
    <title>Special features of Linux memory management mechanism（转载）</title>
    <url>/special-features-of-linux-memory-management-mechanism/</url>
    <content><![CDATA[<p>In this article, I am going to describe some general features and some specific ones of the memory management in Linux. It will be mainly on dynamic memory allocation and release, as well as the management of the free memory. The article concerns the Linux kernel versions 2.6.X.</p>
<span id="more"></span>
<h2 id="Structure-of-the-Linux-memory-management"><a class="header-anchor" href="#Structure-of-the-Linux-memory-management"></a>Structure of the Linux memory management</h2>
<p>The term “memory management” refers to the mechanisms implemented by an operating system to provide applications with memory-related services. These services include usage of virtual memory (utilizing of a hard disk or other non-RAM storage media to provide additional program memory), protected memory (exclusive access to a region of memory by a process), and shared memory (cooperative access to a region of memory by multiple processes).</p>
<p>Memory management services in the Linux are built on a programming foundation that includes a peripheral device called <strong>Memory Management Unit (MMU)</strong>. MMU translates physical memory addresses to linear addresses used by the operating system, and requests a page fault interrupt, when the CPU tries to access memory that it is not entitled to.</p>
<p>Not all processors have MMUs. Therefore, the <a href="http://www.uclinux.org/index.html">uClinux distribution</a> (Linux for microcontrollers) supports a single address space of operation. This architecture lacks the protection provided by MMU but makes it possible for Linux to run on another class of processors.</p>
<p>For further understanding of structure of the MM services, we need to know that a basic unit of memory under Linux is <strong>page</strong>, a non-overlapping region of contiguous memory. All available physical memory is organized into pages towards the end of the kernel’s boot process. Size of page depends on processor architecture. Processor designs often allow to have two or more, sometimes simultaneously, page sizes.</p>
<p>Traditional page size used by Linux is 4096 bytes.</p>
<p>But using memory pages “as is” is not very convenient. Often we need to allocate less than one memory page. There are such possibilities in Linux:</p>
<ul>
<li><strong>in the kernel</strong>, you can allocate one of the small kernel objects using slab allocator;</li>
<li>you can allocate a memory block by kmalloc, but it will allocate only a block of the nearest bigger size that it has;</li>
<li><strong>in the user mode</strong>, you can allocate any amount of memory using heap management functions implemented in Standard C Library;</li>
<li>you can create your own heap manager on top of the Linux kernel system calls.</li>
</ul>
<p>To provide a simple interface for interaction with Memory Management Unit and perform such interaction in a portable way, in Linux, subsystem of allocating and releasing memory is split into three layers.  These layers are:</p>
<ul>
<li>The Slab Allocator</li>
<li>The Zone Allocator</li>
<li>The Buddy Allocator</li>
</ul>
<p>General scheme of all these layers interaction with user mode code and hardware looks as follows:</p>
<p><img src="/assets/special-features-of-linux-memory-management-mechanism/MemoryMS.png" alt="MemoryMS"></p>
<p>Figure 1. General scheme of the memory management in Linux</p>
<p>Note that in Linux, most of programs directly or indirectly use heap manager of the GCC Standard C Library called glibc, but you still can write your own heap manager on top of the kernel system calls.</p>
<p>As we can see on the Figure 1, user space allocation always leads to kernel allocation. Kernel allocates memory using the chain of three kernel allocators and maps allocated pages to the address space of the process, which has requested the allocation.</p>
<h2 id="Kernel-mode-memory-management-services"><a class="header-anchor" href="#Kernel-mode-memory-management-services"></a>Kernel mode memory management services</h2>
<p><strong>The Buddy Allocator</strong> is responsible for the management of the page allocations in the entire system. This code manages lists of physically contiguous pages and maps them into the MMU page tables to provide other kernel subsystems with the valid physical address ranges, when the kernel requests them (Physical to Virtual Address mapping is handled by a higher layer of the VM).</p>
<p>The Buddy Allocator splits memory into pairs of 2n pages where n is in range from 0 to MAX_ORDER constant (defined in the header file &lt;linux/mmzone.h&gt;), and stores information about the free blocks of pages in the array of lists as follows:</p>
<p><img src="/assets/special-features-of-linux-memory-management-mechanism/Buddy_all.png" alt="Buddy_all"></p>
<p>Figure 2: Array of lists of memory pages in the Buddy Allocator</p>
<p>Each list consists of free physically contiguous blocks of 2i memory pages, where <em>i</em> is a list number. Each of such blocks, except the block that consists of 1 page, can be split into two halves and used as 2 blocks of a half size.</p>
<p>So if no entries exist in the requested list, an entry from the next upper list is broken into two separate clusters and one is returned to the caller while the other one is added to the next lower list.</p>
<p>On the other hand, every two blocks of memory of the same size, which have common border (arranged in memory sequentially, from the standpoint of physical addresses), may be united into the single block of the bigger size. Such neighboring blocks are called <strong>Buddies</strong>.</p>
<p>When allocation is returned to the Buddy Allocator, it checks if buddy of the allocation is free, and if it is so, Buddy Allocator unites them into the bigger block. This operation is repeated until no more block buddies are found.</p>
<p>Also we should note that the Buddy Allocator can allocate only blocks of the size in pages that is equal to 2 raised to some power.</p>
<p>The Buddy Allocator also interacts with the kernel threads kswapd and bdflush, which are responsible for the maintaining with the swap.</p>
<p>Different ranges of physical pages may have different properties, for the purposes of the kernel. For example, Direct Memory Access can work only in specific range of physical addresses in the x86 architecture.  On the other hand PPC does not have this constraint.</p>
<p>For handling such situation in a hardware, independent way <strong>the Zone Allocator</strong> was created.</p>
<p>The Zone Allocator is used to allocate pages in the specified zone. Today Linux kernel is supporting three memory zones:</p>
<ul>
<li>DMA — This zone consists of memory accessible for direct memory operations of the legacy devices</li>
<li>NORMAL — This zone includes memory addresses used by the kernel for internal data structures as well as other system and user space allocations.</li>
<li>HIGHMEM — This zone includes all memory used exclusively for system allocations (file system buffers, user space allocations, etc).</li>
</ul>
<p>Note that the Zone Allocator also can manipulate only with memory pages.</p>
<p>Since we often need to allocate objects that have size less than the size of a page, we need something to deal with the pages and allocate lesser chunks of memory for us.</p>
<p>We know the sizes of the most objects that are often allocated in the kernel space, so we can create allocator that will receive pages of memory from the Zone Allocator and allocate small objects in these memory pages.  This subsystem is named <strong>the Slab Allocator (An Object-Caching Kernel Memory Allocator)</strong>.</p>
<p>The Slab Allocator organizes memory in caches, one cache for each object type, e.g. inode_cache, dentry_cache, buffer_head, vm_area_struct.  Each cache consists of many slabs (usually one page long), and each slab contains multiple initialized objects.</p>
<p>This means that the constructor of the objects is used only for newly allocated slabs and you should initialize object before release it to the Slab Allocator.</p>
<p>Also the Slab Allocator makes it possible to allocate buffers of memory of one of the specially defined sizes. Such buffers can be got using kernel function kmalloc. You specify the size of allocation, and kmalloc will allocate block of the greater size, the nearest to the one you requested. Sizes of memory blocks, which can be allocated by kmalloc, are available in the header file <code>&lt;linux/kmalloc_sizes.h&gt;</code>.</p>
<p>Also the kernel can allocate virtually contiguous memory (memory with contiguous virtual addresses, but not with contiguous physical addresses) using vmalloc function.</p>
<h2 id="Special-aspects-of-the-linux-kernel-mechanisms-of-the-memory-management"><a class="header-anchor" href="#Special-aspects-of-the-linux-kernel-mechanisms-of-the-memory-management"></a>Special aspects of the linux kernel mechanisms of the memory management</h2>
<h3 id="Why-Linux-developers-rarely-check-results-of-memory-allocation"><a class="header-anchor" href="#Why-Linux-developers-rarely-check-results-of-memory-allocation"></a>Why Linux developers rarely check results of memory allocation.</h3>
<p>The short answer is: “Because of overcommit”.</p>
<p>Under the default memory management strategy, malloc (and kmalloc, and vmalloc) always succeeds, even if the system has not enough memory to satisfy the request. The Linux kernel assumes that you’re not going to use all of the memory you asked for. Real allocation occurs only when you get access to the allocated memory, and if the system does not have enough free memory then it will run Out-of-memory (OOM) killer.  OOM killer will try to free some memory for you, killing other processes and releasing their memory or it will kill your process if it deems the task you are performing to have a lower priority.</p>
<p>This approach leads to some performance gains for applications, which allocate a lot of memory but use only some part of it, since allocation of the swap pages will not be performed before the swap pages is used.</p>
<p>But sometimes such approach is not good because of the chance to be killed by OOM killer at any moment. Fortunately, Linux allows to change default approach of the memory allocation and behavior of the system when the OOM event occurs.</p>
<p>The overcommit policy is set via the sysctl <code>vm.overcommit_memory</code>.</p>
<p>The Linux kernel supports the following overcommit handling modes associated with the values of the kernel parameter <code>vm.overcommit_memory</code>:</p>
<ol start="0">
<li>
<p>Heuristic overcommit handling. Obvious overcommits of address space are refused. This type of handling is used for a typical system. It ensures a seriously wild allocation fails while allowing overcommit to reduce swap usage. Root is allowed to allocate a bit more memory in this mode. This type is set by default.</p>
</li>
<li>
<p>Always overcommit. Appropriate for some scientific applications, which use a lot of memory.</p>
</li>
<li>
<p>Don’t overcommit. The total address space commit for the system is not permitted to exceed swap + a configurable percentage (50% by default) of physical RAM. Depending on the percentage you use, in most situations, this means that a process will not be killed while accessing pages but will receive errors on memory allocation as appropriate.</p>
</li>
</ol>
<p>The overcommit percentage is set via the sysctrl <code>vm.overcommit_ratio</code>.</p>
<p>The current overcommit limit and amount committed can be viewed in /proc/meminfo as <code>CommitLimit</code> and <code>Committed_AS</code> respectively.</p>
<h3 id="How-Out-of-memory-killer-mechanism-works"><a class="header-anchor" href="#How-Out-of-memory-killer-mechanism-works"></a>How Out-of-memory killer mechanism works</h3>
<p>There are three strategies to handle Out-of-memory situation:</p>
<ul>
<li>Kill allocating process</li>
<li>Kill some other process or processes to allow allocating process get the memory</li>
<li>Stop the system and show message about kernel panic.</li>
</ul>
<p>The first and the third strategies are fairly simple unlike the second strategy. Let’s consider it in more detail.</p>
<p>According to the second strategy, Linux will try to choose appropriate process to kill when it runs out of memory. “Appropriate” in this context means that:</p>
<ul>
<li>User will lose the minimum amount of work done</li>
<li>System will recover a large amount of memory</li>
<li>OOM killer don’t kill process that has not allocated a lot of memory</li>
<li>OOM killer intends to kill the minimum number of processes (to kill just one process would be the best)</li>
<li>OOM killer will kill the process the user expects it to kill</li>
</ul>
<p>In order to choose a process to kill, OOM killer calculates the value named <strong>Badness</strong>. Then it selects the process with the maximum Badness to be killed.  If the allocating process was chosen, OOM terminates its work. If some other process was chosen, OOM killer can be called more than once in case of previous run of the OOM killer did not free enough memory.</p>
<p>Badness is calculated according to the next rules:</p>
<ul>
<li>Initial badness of the process A is the size of the virtual memory allocated for it plus a half of size of the virtual memory allocated to the child processes of the process A;</li>
<li>Initial badness is divided by the square root of the CPU time consumed by the process A measured in tens of seconds;</li>
<li>Result is divided by the root with index 4 of the run time of the process A measured in thousands of seconds.</li>
<li>If the process A has “nice” greater than zero (priority is lower than normal), badness of the process A is multiplied by 2;</li>
<li>If the process A was started with the root privileges, badness of the process A is divided by 4;</li>
<li>If the process A performs raw IO, badness of the process A is divided by 4;</li>
<li>If memory usage of the process A might not impact the memory available to the process, which has initiated OOM procedure, then badness of process A is divided by 8;</li>
</ul>
<p>We can write badness of the process A as the equation:</p>
<p><img src="/assets/special-features-of-linux-memory-management-mechanism/formula1.png" alt="formula1"><br>
<img src="/assets/special-features-of-linux-memory-management-mechanism/formula2.png" alt="formula2"></p>
<p>Where:</p>
<p><em>if_nice</em> can be either 1 or 2 according to the nice of the process (2 if nice &gt; 2 or 1 otherwise)<br>
<em>if_root</em> can be 1 or 4 ( 4 if the process A  has root privileges or 1 otherwise  )<br>
<em>if_raw_io</em> can be 1 or 4 ( 4 if process has capability to perform raw IO or 1 otherwise )<br>
<em>if_memory_does_not_overlap</em> can be 1 or 8 ( 8 if the process A has no memory that can be allocated to the process, which has initiated OOM procedure).</p>
<p>You can see the mechanism of the out-of-memory handler in the source file “/mm/oom_kill.c”  in the Linux kernel sources tree.</p>
<p>You can tune OOM handling mechanism by setting values to such kernel parameters:</p>
<p><code>vm.oom_dump_tasks</code></p>
<p>This parameter enables a system-wide task dump (excluding kernel threads) to be produced when the kernel performs an OOM-killing and includes such information as pid, uid, tgid, vm size, rss, cpu, oom_adj score, and name.  It is helpful to determine why the OOM killer was invoked and to identify the process that caused it.</p>
<p>If it is set to zero, this information is suppressed.</p>
<p>If it is set to non-zero, this information is shown whenever the OOM killer actually kills a memory-hogging task.</p>
<p>By default <code>vm.oom_dump_tasks</code> is set to 1;</p>
<p><code>vm.oom_kill_allocating_task</code></p>
<p>This parameter enables or disables killing the OOM-triggered task in out-of-memory situations.</p>
<p>If this parameter is set to non-zero, the OOM killer simply kills the task that triggered the out-of-memory condition. It helps to avoid the resource-expensive tasklist scan and makes OOM killer very predictable.</p>
<p>If it is set to zero, the OOM killer will scan through the entire tasklist and select a task on the basis of the badness calculation.</p>
<p>By default <code>vm.oom_kill_allocating_task</code> is set to 0;</p>
<p><code>vm.panic_on_oom</code></p>
<p>If this kernel parameter is set to 1 the kernel panics occurs at out-of-memory situation. But, if a process is limited by nodes by mempolicy/cpusets, and those nodes get memory exhaustion status, one process may be killed by OOM killer. No kernel panic occurs in this case, because other memory nodes can be free.</p>
<p>If this parameter is set to 2, the kernel panic is forced even in the above-mentioned situation. Even if OOM happens under the memory <code>cgroup</code>, the whole system panics.</p>
<p>If this parameter is set to 0, the kernel will kill some processes when OOM happens.</p>
<p>By default <code>vm.panic_on_oom</code> is set to 0;</p>
<p>Note that <code>panic_on_oom</code> has higher priority than <code>oom_kill_allocating_task</code>.</p>
<h2 id="Additional-links-and-literature"><a class="header-anchor" href="#Additional-links-and-literature"></a>Additional links and literature:</h2>
<ul>
<li>Anatomy of the Linux slab allocator <a href="http://www.ibm.com/developerworks/linux/library/l-linux-slab-allocator/">http://www.ibm.com/developerworks/linux/library/l-linux-slab-allocator/</a></li>
<li>Understanding Virtual Memory <a href="http://www.redhat.com/magazine/001nov04/features/vm/">http://www.redhat.com/magazine/001nov04/features/vm/</a></li>
<li>When Linux Runs Out of Memory  <a href="http://linuxdevcenter.com/pub/a/linux/2006/11/30/linux-out-of-memory.html">http://linuxdevcenter.com/pub/a/linux/2006/11/30/linux-out-of-memory.html</a></li>
<li>Andries Brouwer, The Linux kernel <a href="http://www.win.tue.nl/~aeb/linux/lk/lk-9.html">http://www.win.tue.nl/~aeb/linux/lk/lk-9.html</a></li>
<li>Ops monkey blog entry “Linux memory overcommit” <a href="http://opsmonkey.blogspot.com/2007/01/linux-memory-overcommit.html">http://opsmonkey.blogspot.com/2007/01/linux-memory-overcommit.html</a></li>
<li>Outline of the Linux Memory Management System <a href="http://www.thehackademy.net/madchat/ebooks/Mem_virtuelle/linux-mm/vmoutline.html">http://www.thehackademy.net/madchat/ebooks/Mem_virtuelle/linux-mm/vmoutline.html</a></li>
<li>Linux kernel documentation: sysctl/vm.txt and vm/overcommit-accounting</li>
<li>Daniel P. Bovet Marco Cesati “Understanding the Linux Kernel”,  O’Reilly ISBN: 0-596-00002-2, 702 pages</li>
</ul>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/special-features-of-linux-memory-management-mechanism/">http://xnerv.wang/special-features-of-linux-memory-management-mechanism/</a></strong><br>
转载自：<a href="https://www.apriorit.com/dev-blog/209-linux-memory-management">Special features of Linux memory management mechanism</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Heap</tag>
        <tag>Linux</tag>
        <tag>Memory Management</tag>
        <tag>Buddy System</tag>
        <tag>Slab Allocator</tag>
      </tags>
  </entry>
  <entry>
    <title>Spin Lock in C++（转载）</title>
    <url>/spin-lock-in-cpp/</url>
    <content><![CDATA[<ul>
<li><a href="/codes/LockFree.zip">Download source code - 8.28 KB</a></li>
</ul>
<h2 id="Introduction"><a class="header-anchor" href="#Introduction"></a>Introduction</h2>
<p>If we use common synchronization primitives like mutexes and critical sections, then the following sequence of events occur between two threads that are looking to acquire a lock:</p>
<ol>
<li>Thread 1 acquires lock L and executes.</li>
<li>T2 tries to acquire lock L, but it’s already held and therefore blocks incurring a context switch.</li>
<li>T1 releases the lock L. This signals T2 and at lower level, this involves some sort of kernel transition.</li>
<li>T2 wakes up and acquires the lock L incurring another context switch.</li>
</ol>
<p>So there are always at least two context switches when primitive synchronization objects are used. A spin lock can get away with expensive context switches and kernel transition.</p>
<p>Most modern hardware supports atomic instructions and one of them is called ‘compare and swap’ (CAS). On Win32 systems, they are called interlocked operations. Using these interlocked functions, an application can compare and store a value in an atomic uninterruptible operation. With interlocked functions, it is possible to achieve lock freedom to save expensive context switches and kernel transitions which can be a bottleneck in a low latency application. On a multiprocessor machine, a spin lock (a kind of busy waiting) can avoid both of the above issues to save thousands of CPU cycles in context switches. However, the downside of using spin locks is that they become wasteful if held for a longer period of time, in which case they can prevent other threads from acquiring the lock and progressing. The implementation shown in this article is an effort to develop a general purpose spin lock.</p>
<h2 id="Algorithm"><a class="header-anchor" href="#Algorithm"></a>Algorithm</h2>
<p>A typical (or basic) spin lock acquire and release function would look something like below:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// acquire the lock</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Lock</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">volatile</span> <span class="type">int</span> dest = <span class="number">0</span>;</span><br><span class="line">    <span class="type">int</span> exchange = <span class="number">100</span>;</span><br><span class="line">    <span class="type">int</span> compare = <span class="number">0</span>;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">acquire</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="built_in">While</span>(<span class="literal">true</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span>(<span class="built_in">interlockedCompareExchange</span>(&amp;dest, exchange, compare) == <span class="number">0</span>)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="comment">// lock acquired</span></span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// release the lock</span></span><br><span class="line">    <span class="function">Void <span class="title">release</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="comment">// lock released</span></span><br><span class="line">       dest = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">.......</span><br></pre></td></tr></table></figure>
<p>Here, thread T1 acquires the lock by calling the function <code>acquire()</code>. In this case, the value of <code>dest</code> would become 100. When thread T2 tries to acquire the lock, it will loop continuously (a.k.a. busy waiting) as the values of <code>dest</code> and <code>compare</code> are different and therefore the function <code>InterlockedCompareExchange</code> will fail. When T1 calls <code>release()</code>, it sets the value of <code>dest</code> to 0 and therefore allows T2 to acquire the lock. Because only those threads that <code>acquire()</code> will call <code>release()</code>, mutual exclusion is guaranteed.</p>
<p>Above is a simple implementation of a spin lock. However, this implementation alone is not production fit because spinning consumes CPU cycles without doing any useful work, meaning that the thread spinning will still be scheduled on the processor until it is pre-empted. Another downside of spinning is that it will continuously access memory to re-evaluate the value of <code>dest</code> in the function <code>Interlockedxxx</code> and this also puts the pressure on bus communication.</p>
<p>On a single processor machine, spin wait would be a total waste of CPU as another thread T2 wouldn’t even get scheduled until the spinning thread is switched by the kernel.</p>
<p>So far this implementation isn’t good enough. A general purpose spin lock requires a bit more work in terms of falling back to true waiting in a worst case scenario when it spins for a longer period. Here are some of the points which must be considered:</p>
<h4 id="Yield-Processor"><a class="header-anchor" href="#Yield-Processor"></a>Yield Processor</h4>
<p>The Win32 function <code>YieldProcessor()</code> emits a ‘no operation’ instruction on processors. This makes the processor aware that the code is currently performing spin waits and will make the processor available to other logical processors in a hyper threading enabled processor so that the other logical processors can make progress.</p>
<h4 id="Switch-to-Another-Thread"><a class="header-anchor" href="#Switch-to-Another-Thread"></a>Switch to Another Thread</h4>
<p>Sometimes it is useful to force a context switch when a spinning thread has already consumed enough time spinning equivalent to its thread time slice allocated by the kernel. Here, it makes good sense to allow another thread to do useful work instead. The function <code>SwitchToThread()</code> relinquishes the calling thread’s time slice and runs another thread in the ready state. It returns <code>true</code> when a switch occurs, otherwise <code>false</code>.</p>
<h4 id="Sleeping"><a class="header-anchor" href="#Sleeping"></a>Sleeping</h4>
<p><code>SwitchToThread()</code> may not consider all threads on the system for execution, therefore it may be wise to sometimes call <code>Sleep()</code> or <code>Sleepex()</code>. Calling <code>Sleep()</code> with an argument of 0 is a good approach as it does not result in a context switch if there are no threads of equal priority in the ready state. <code>Sleep(0)</code> will result in a context switch if a higher priority thread is in ready state.</p>
<h2 id="Other-Considerations"><a class="header-anchor" href="#Other-Considerations"></a>Other Considerations</h2>
<p>A pure spin lock is only good enough when the lock is held for a very short period of time. Here the critical region may have not more than 10 instructions and practically even simple memory allocation or virtual calls or file I/O can take more than 10 instructions.</p>
<p>Secondly, as mentioned above, it would wasteful to use spin locks when an application runs on a single processor.</p>
<h2 id="Sample-Project-and-Implementation"><a class="header-anchor" href="#Sample-Project-and-Implementation"></a>Sample Project and Implementation</h2>
<p>The sample project in C++ consists of a spin lock implementation considering the points stated above. It also has an implementation of Stack, Queue, and a thin Producer-Consumer class. I’ll only focus on then Spin Lock implementation here as the rest of it is easy to follow.</p>
<p>The file <em>SpinLock.h</em> defines these constants:</p>
<ul>
<li><code>YIELD_ITERATION</code> set to 30 - What this means is that the thread spinning will spin for 30 iterations waiting for the lock to acquire before it calls <code>sleep(0)</code> to give an opportunity to other threads to progress.</li>
<li><code>MAX_SLEEP_ITERATION</code> set to 40 - This means when the total iteration (or spin) count reaches 40, then it would force a context switch using the function <code>SwitchToThread()</code> in case another thread is in ready state.</li>
</ul>
<p>The struct <code>tSpinLock</code> acts as a lock object which is declared in the class whose objects are being synchronized. This object is then passed in the constructor to the object of <code>tScopedLock</code> which initializes (references) the lock object passed to it. The <code>tScopedLock()</code> constructor locks the object using the member function of the class <code>tSpinWait</code>. The destructor <code>~tScopedLock()</code> releases the lock.</p>
<p>The <code>Lock()</code> function in the class <code>tSpinWait</code> has got a nested <code>while</code> loop. This is done on purpose. So if a thread is spinning to acquire the lock, it wouldn’t call <code>interlockedxxx()</code> with every iteration, rather it would be looping in the inner <code>while</code> loop. This hack avoids the system memory bus being overly busy due to continuous calls to the <code>interlockedxx</code> function.</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// spin wait to acquire</span></span><br><span class="line"><span class="keyword">while</span>(LockObj.dest != LockObj.compare) &#123;</span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">HasThreasholdReached</span>())</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>(m_iterations + YIELD_ITERATION &gt;= MAX_SLEEP_ITERATION)</span><br><span class="line">           <span class="built_in">Sleep</span>(<span class="number">0</span>);</span><br><span class="line">        <span class="keyword">if</span>(m_iterations &gt;= YIELD_ITERATION &amp;&amp; m_iterations &lt; MAX_SLEEP_ITERATION)</span><br><span class="line">           <span class="built_in">SwitchToThread</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// Yield processor on multi-processor but if on single processor</span></span><br><span class="line">    <span class="comment">// then give other thread the CPU</span></span><br><span class="line">    m_iterations++;    <span class="keyword">if</span>(Helper::<span class="built_in">GetNumberOfProcessors</span>() &gt; <span class="number">1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">       <span class="built_in">YieldProcessor</span>(<span class="comment">/*no op*/</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123; <span class="built_in">SwitchToThread</span>(); &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>The inner <code>while</code> loop just compares the value of <code>dest</code> and <code>compare</code> and if they are not equal, then it tries to acquire them using <code>interlockedxxx</code>. Depending on the iteration count, the thread is either put to sleep or switched. When the application is running on a single CPU, then it always forces a context switch.</p>
<h2 id="Test-Results"><a class="header-anchor" href="#Test-Results"></a>Test Results</h2>
<p>I tested the performance of this Spin Lock implementation by inserting 10000 integers into a queue from multiple threads (each thread inserting 10000 integers into the queue). I then replaced <code>SpinLock</code> with a Critical Section synchronization primitive in the code and ran the same tests. I ran all the tests on an Intel Core DUO CPU T9600 @ 2.80 GHz.</p>
<p><img src="https://www.codeproject.com/KB/threads/Spin_Lock/Results.jpg" alt="Results.jpg"></p>
<p>The <strong>x-axis</strong> is the number of threads and <strong>y-axis</strong> is the time taken in milliseconds. Both synchronization methods (spinlock and CS) showed close performance when the number of threads were 2 and 4. As the number of threads increased, critical section locking took more than double the time as compared to spin locks. Spin lock seemed to have scaled a lot better when contention increased due to the high number of threads. The time taken is calculated using <code>QueryPerformanceCounter</code> Win32 methods. However, I would suggest performing your own testing on the platform you intend to use.</p>
<p>Here is the table with the results:</p>
<colgroup><col width="64"><col width="149"><col width="177"></colgroup>
| No. of Threads | Time taken (Spin lock) | Time taken (Critical Section) |
| --- | --- | --- |
| 2 |  | 6.6 | 7.14 |
| 4 |  | 12.81 | 14.09 |
| 6 |  | 16.01 | 46.37 |
| 8 |  | 23.32 | 54.34 |
| 10 |  | 26.21 | 74.76 |
| 15 |  | 41.17 | 89.05 |
| 20 |  | 47.63 | 116.82 |
| 25 |  | 62.25 | 147.68 |
| 30 |  | 64.37 | 169.17 |
| 35 |  | 88.02 | 210.07 |
| 40 |  | 93.99 | 296.32 |
<h2 id="Future-Work"><a class="header-anchor" href="#Future-Work"></a>Future Work</h2>
<ul>
<li>Profiling the code on different platforms.</li>
<li>Adding a couple more data structures to the project like associated arrays and hashtable.</li>
</ul>
<h2 id="Conclusion"><a class="header-anchor" href="#Conclusion"></a>Conclusion</h2>
<p>This was an effort to develop a general purpose spin lock implementation. Pure spin locking isn’t a good option in all scenarios and therefore there is a need for an implementation which allows the spinning thread to be suspended by the kernel.</p>
<h2 id="History"><a class="header-anchor" href="#History"></a>History</h2>
<ul>
<li>First draft.</li>
<li>Revision 1 - Fixed a couple of typos.</li>
<li>Revision 2 - Code is now re-entrant safe.</li>
<li>Revision 3 - Lock release now uses <code>interlockedexchange</code>.</li>
<li>Revision 4 - Added test results.</li>
</ul>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/spin-lock-in-cpp/">http://xnerv.wang/spin-lock-in-cpp/</a></strong><br>
转载自：<a href="https://www.codeproject.com/Articles/184046/Spin-Lock-in-C">Spin Lock in C++</a></p>
]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>C++</tag>
        <tag>Programing</tag>
        <tag>spinlock</tag>
      </tags>
  </entry>
  <entry>
    <title>SPV、SPV节点和SPV钱包 (初稿）（转载）</title>
    <url>/spv-spv-nodes-spv-purses/</url>
    <content><![CDATA[<h2 id="一、什么是SPV"><a class="header-anchor" href="#一、什么是SPV"></a>一、什么是SPV</h2>
<p>SPV是 <strong>“Simplified Payment Verification”（简单支付验证）</strong> 的缩写。中本聪论文简要地提及了这一概念，指出：不运行完全节点也可验证支付，用户只需要保存所有的block header就可以了。用户虽然不能自己验证交易，但如果能够从区块链的某处找到相符的交易，他就可以知道网络已经认可了这笔交易，而且得到了网络的多少个确认。</p>
<p>按照中本聪的原文，这里有个细节需要注意，SPV指的是“支付验证“，而不是“交易验证”。这两种验证有很大区别。<br>
&quot;交易验证”非常复杂，涉及到验证是否有足够余额可供支出、是否存在双花、脚本能否通过等等，通常由运行完全节点的矿工来完成。<br>
“支付验证”则比较简单，只判断用于“支付”的那笔交易是否已经被验证过，并得到了多少的算力保护（多少确认数）。</p>
<p>考虑这样一种情况，A收到来自B的一个通知，B声称他已经从某某账户中汇款一定数额的钱给了A。去中心方式下，没有任何人能证明B的可靠。接到这一通知，A如何能判断B所说的是真的呢？<br>
在比特币系统中，这一通知是以一个固定格式的“交易&quot;来实现的，该交易中包含B的汇款账户、B的签名、汇给A的金额以及A的地址。<br>
如果A想本人亲自验证这笔交易，首先，A要遍历区块链账本，定位到B的账户上，这样才能查看B所给的账户上是否曾经有足够的金额；接下来，A要遍历后续的所有账本，看B是否已经支出了这个账户上的钱给别人(是否存在双花欺骗）；然后还要验证脚本来判断B是否拥有该账户的支配权。这一过程要求A必须得到完整的区块链才行。</p>
<p>但是，如果A只想知道这笔支付是否已经得到了验证（如果验证了就发货），他可以依赖比特币系统来快速验证。即，检查发生此项支付的那笔交易是否已经收录于区块链中，并得到了多少个确认。</p>
<span id="more"></span>
<p><strong>原理</strong>：block header中有三个关键字段，一是prev_block_hash(前一区块的hash值，确保了区块链所记录的交易次序）；二是bits（当前区块的计算难度）, 三是merkle_root_hash（借助merkle tree算法，确保收录与区块中所有交易的真实性）。</p>
<p>验证某个交易是否真实存在时，理论上，用户可以通过以下方式进行验证：<br>
0. 从网络上获取并保存最长链的所有block header至本地；</p>
<ol>
<li>计算该交易的hash值tx_hash；</li>
<li>定位到包含该tx_hash所在的区块，验证block header是否包含在已知的最长链中；</li>
<li>从区块中获取构建merkle tree所需的hash值；</li>
<li>根据这些hash值计算merkle_root_hash；</li>
<li>若计算结果与block header中的merkle_root_hash相等，则交易真实存在。</li>
<li>根据该block header所处的位置，确定该交易已经得到多少个确认。</li>
</ol>
<p><strong>优点</strong>：极大地节省存储空间。减轻终端用户的负担。无论未来的交易量有多大，block header的大小始终不变，只有80字节。按照每小时6个的出块速度，每年产出52560个区块。当只保存block header时，每年新增的存储需求约为4兆字节，100年后累计的存储需求仅为400兆，即使用户使用的是最低端的设备，正常情况下也完全能够负载。</p>
<p><strong>问题</strong>：如何才能通过tx_hash定位到该交易所在的区块? 以往的比特币协议中缺少对此的支持。</p>
<h2 id="二、比特币钱包"><a class="header-anchor" href="#二、比特币钱包"></a>二、比特币钱包</h2>
<p>在进一步讨论SPV的实现之前，先要说明一下比特币的钱存放的是什么，钱包和私钥之间是什么关系？</p>
<h3 id="比特币钱包"><a class="header-anchor" href="#比特币钱包"></a>比特币钱包</h3>
<p>既然用到“钱包”一词，那么应该与我们日常生活中使用的钱包有一定的相似之处。为了更直观说明，我们与日常生活中所使用的钱包做一下对比。<br>
日常生活中里面存放的可能是纸币、支票、印鉴等等(为了简化说明，我们把银行卡排除在外，使用银行卡涉及到很多中间环节，增加表述上的复杂度)。<br>
用纸币购物时，</p>
<ol>
<li>从钱包中凑足若干张不同面值的纸币，计算总面值是否大于所需金额以及应找回多少零钱；</li>
<li>将这些纸币直接交给卖方；</li>
<li>卖方验证这些纸币的真伪；</li>
<li>卖方计算这些纸币的面值是否大于或等于商品价格，并找回相应的零钱。</li>
<li>将收到的零钱放回钱包。</li>
</ol>
<p>比特币的钱包里存放的相当于是一张张标有面值的“一次性支票”和对应的“印鉴”。支付时，</p>
<ol>
<li>用户从钱包中取出若干张“一次性支票”，自己计算总面值是否大于所需金额以及应找回多少零钱，注意要扣除比特币系统所收取的手续费;</li>
<li>给卖方开一张支票，注明卖方地址和支付金额；如果需要找零，给自己开一张找零支票（写上自己的地址和找零金额）；</li>
<li>在每张从钱包中取出的支票上加盖对应的印鉴，确认支付权；</li>
<li>将这些票据提交给比特币系统，比特币系统验证支票的真伪和支付是否有效。</li>
<li>若比特币系统验证通过，收款方将收到的支票放入钱包。用户则将自己钱包中的已支付的支票丢弃（这些支票已经被比特币系统视为无效了，无法继续使用），</li>
</ol>
<p>即使是刚接触比特币的人，估计也能猜出“印鉴”指的是“私钥”。但“一次性支票”是什么？<br>
比特币系统中，这种“一次性支票”的术语是UTXO，全称是Unspent Transaction Outputs(未花费的交易输出）。区块链是一个收录所有历史交易（Transaction)的总帐，每个区块（block)中包含若干笔交易记录。<br>
每个交易记录由两部分构成：资金来源（可以有多个来源）和资金去向（可以有多个去向），术语为Tx_in(交易输入）和Tx_out（交易输出）。也就是说，每笔交易TX包含有若干个Tx_in和若干个Tx_out。</p>
<p>除创世区块中的交易（genesis block）外，每笔交易必须要有资金来源。资金来源有两种，一种是挖矿奖励（依照固定算法实现的货币发行），出现在每个block的第一笔交易中；另一种是先前的交易中未曾使用的某个Tx_out(交易输出），即UTXO。支出方要出示证据来证明自己对该Tx_out拥有所有权，而比特币系统则要验证该Tx_out是否真的未被花费（是否是UTXO）以及支出方是否有权将其花费。</p>
<p>资金去向（TX_out)包含两个部分，一是传递的金额，二是支配权(谁可以动用）。取款权通过比特币的脚本系统来实现。若收款方地址是以1开头的普通地址，则脚本中会包含地址所对应公钥的hash值（hash160)，动用款项时一般需要用对应的私钥进行签名；若收款方地址是以3开头的多重签名地址，则脚本中会包含某个特定脚本的hash值（hash160)，动用款项时，一般需要依照特定的脚本，用多个私钥来签名。</p>
<p>用户钱包中的比特币实际上是用户拥有支配权的、且尚未花费的Tx_out中记录的金额总和，即用户可支配的所有UTXO金额之和。</p>
<p>完整的钱包中应存有若干个UTXO和支配每个UTXO时所对应的私钥。当然，有时从安全角度出发，可能会把钱包划分为两个部分，在线钱包中只有UTXO，而离线钱包只存私钥。</p>
<p>但是，用户怎么才能把自己的所有UTXO都放到钱包中呢？</p>
<h2 id="三、用户如何收录自己的UTXO"><a class="header-anchor" href="#三、用户如何收录自己的UTXO"></a>三、用户如何收录自己的UTXO</h2>
<h3 id="（一）去中心化方式："><a class="header-anchor" href="#（一）去中心化方式："></a>（一）去中心化方式：</h3>
<p><strong>实现方法</strong>：</p>
<ol>
<li>在本地建立一个用于存储UTXO的数据库；</li>
<li>设置区块扫描起始点（区块链上的扫描起始高度)，从该点开始，依次下载该点之后所有区块（block)的完整数据。</li>
<li>解析每个block的所有TX数据，依次读取每个Tx_in的prev_Tx_out(［tx hash］ + ［tx_out的序号］），检索UTXO数据库中是否存在这个Tx_out，如果有，则从UTXO数据库中删除（或标记删除）。</li>
<li>依次解析每个Tx_out的脚本，若与用户相关，则将[tx hash] + ［Tx_out的序号］以及整个tx_out的内容记录到UTXO数据库；</li>
</ol>
<p><strong>备注</strong>：如果钱包中只有新创建的私钥，可以从最新的区块开始扫描（由于私钥发生碰撞的可能性可以视为0，在你告知他人比特币地址之前，该私钥对应的地址上不会有任何收入）</p>
<p><strong>优点</strong>：不依赖于信任；数据准确。<br>
<strong>缺点</strong>：速度慢，需要从比特币网络下载大量数据，对网络造成的压力大。</p>
<h3 id="（二）中心化方式："><a class="header-anchor" href="#（二）中心化方式："></a>（二）中心化方式：</h3>
<ol>
<li>某个中心化机构（或个人）运行完整的比特币节点，建立一个收录所有UTXO的数据库。</li>
<li>用户用中心化机构提供的api来请求与自己有关的UTXO数据。</li>
</ol>
<p><strong>优点</strong>：速度快，不拖累比特币网络；<br>
<strong>缺点</strong>：依赖于信任；数据不一定准确（有可能中心化服务器出现故障，或是与中心服务器的会话被劫持，数据遭篡改）</p>
<h2 id="四、瘦客户端、SPV轻钱包和SPV节点是什么？"><a class="header-anchor" href="#四、瘦客户端、SPV轻钱包和SPV节点是什么？"></a>四、瘦客户端、SPV轻钱包和SPV节点是什么？</h2>
<p><strong>瘦客户端</strong>：参考了SPV的机制，在监听收款地址时，客户端在本地只需保存与用户可支配交易相关的数据。因为本地没有完整的区块链，缺少发送方的相关数据，客户端无法亲自验证交易是否合法，只能判断交易是否是被收录，并且得到了几个确认。这与SPV有很多相似之处，因而很多场合下这种瘦客户端也常被成为是“SPV客户端”，不过，与SPV的区别是，在去中心化方式下，这些客户端仍需下载每个新区块的全部数据并进行解析，只是无需在本地保存全部数据而已。</p>
<p><strong>“轻钱包”</strong> 是用瘦客户端模式实现的钱包，因为不存储完整区块链，就涉及到如何获取UTXO的问题。不同的开发者可能有各自的实现方法，但从效率上考虑，往往多用中心化的方式来实现。</p>
<p><strong>SPV节点</strong>：支持使用布隆过滤器（Bloom filter)在快速检索并返回相关数据的节点。这样的节点可以为去中心化方式SPV查询提供必要的支持。<br>
SPV在实现上涉及到一个问题，如何才能通过tx_hash来定位到该支付交易所在的区块?用中心化方式来实现很好解决，但用去中心化就不那么简单了，因为以往的比特币系统协议中缺少对SPV的支持。原有协议中，可以通过getheaders命令来获取block headers，可以通过getdata命令支持获取指定的block, 但不支持通过tx_hash反向查找所在的block。为了定位block，客户端往往不得不下载整个区块链。Bloom filter解决了客户端检索的问题，原理是Bloom filter可以快速判断出某检索值一定不存在于某个指定的集合，从而可以过滤掉大量无关数据，减少客户端不必要的下载量。</p>
<p>前文提到，SPV的用途是验证某个支付是否确实存在，并得到多少个确认。而钱包的用途则是用于管理自己的资产以及进行支付。简言之，SPV的应用场合往往是为发货做准备（知道钱到帐了），“轻钱包”的应用场合往往是数钱或花钱。虽然“轻钱包”中部分借鉴了SPV的机制，但和SPV是完全不用的应用方向，直接把这两个词连起略显牵强。这种钱包要么采用中心化的方式——提高了效率，但引入了信任的风险；要么采用去中心化方式——无需信任，但效率低，且增加网络的负担。</p>
<p>SPV节点的出现使以去中心化方式来实现高效、低负荷的“轻钱包”成为了可能。笔者认为将基于SPV节点来实现的&quot;轻钱包&quot;简称为“SPV轻钱包”可能会更为合适些。</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/spv-spv-nodes-spv-purses/">http://xnerv.wang/spv-spv-nodes-spv-purses/</a></strong><br>
转载自：<a href="http://8btc.com/thread-15128-1-1.html">SPV、SPV节点和SPV钱包 (初稿）</a></p>
]]></content>
      <categories>
        <category>区块链与比特币</category>
      </categories>
      <tags>
        <tag>区块链与比特币</tag>
        <tag>区块链</tag>
        <tag>比特币</tag>
        <tag>SPV</tag>
      </tags>
  </entry>
  <entry>
    <title>SQL Server - Buffer Management - Reading Pages（转载）</title>
    <url>/sql-server-buffer-management-reading-pages/</url>
    <content><![CDATA[<p>The I/O from an instance of the SQL Server Database Engine includes logical and physical reads. A logical read occurs every time the Database Engine requests a page from the <a href="https://technet.microsoft.com/en-us/library/aa337525.aspx">buffer cache</a>. If the page is not currently in the buffer cache, a physical read first copies the page from disk into the cache.</p>
<p>The read requests generated by an instance of the Database Engine are controlled by the relational engine and optimized by the storage engine. The relational engine determines the most effective access method (such as a table scan, an index scan, or a keyed read); the access methods and buffer manager components of the storage engine determine the general pattern of reads to perform, and optimize the reads required to implement the access method. The thread executing the batch schedules the reads.</p>
<span id="more"></span>
<h2 id="Read-Ahead"><a class="header-anchor" href="#Read-Ahead"></a>Read-Ahead</h2>
<p>The Database Engine supports a performance optimization mechanism called read-ahead. Read-ahead anticipates the data and index pages needed to fulfill a query execution plan and brings the pages into the buffer cache before they are actually used by the query. This allows computation and I/O to overlap, taking full advantage of both the CPU and the disk.</p>
<p>The read-ahead mechanism allows the Database Engine to read up to 64 contiguous pages (512KB) from one file. The read is performed as a single scatter-gather read to the appropriate number of (probably non-contiguous) buffers in the buffer cache. If any of the pages in the range are already present in the buffer cache, the corresponding page from the read will be discarded when the read completes. The range of pages may also be “trimmed” from either end if the corresponding pages are already present in the cache.</p>
<p>There are two kinds of read-ahead: one for data pages and one for index pages.</p>
<h3 id="Reading-Data-Pages"><a class="header-anchor" href="#Reading-Data-Pages"></a>Reading Data Pages</h3>
<p>Table scans used to read data pages are very efficient in the Database Engine. The index allocation map (IAM) pages in a SQL Server database list the extents used by a table or index. The storage engine can read the IAM to build a sorted list of the disk addresses that must be read. This allows the storage engine to optimize its I/Os as large sequential reads that are performed in sequence, based on their location on the disk. For more information about IAM pages, see <a href="https://technet.microsoft.com/en-us/library/ms187501.aspx">Managing Space Used by Objects</a>.</p>
<h3 id="Reading-Index-Pages"><a class="header-anchor" href="#Reading-Index-Pages"></a>Reading Index Pages</h3>
<p>The storage engine reads index pages serially in key order. For example, this illustration shows a simplified representation of a set of leaf pages that contains a set of keys and the intermediate index node mapping the leaf pages. For more information about the structure of pages in an index, see <a href="https://technet.microsoft.com/en-us/library/ms177443.aspx">Clustered Index Structures</a>.</p>
<p><img src="https://i-technet.sec.s-msft.com/dynimg/IC70389.gif" alt="Intermediate index node maps to leaf pages by key" title="Intermediate index node maps to leaf pages by key"></p>
<p>The storage engine uses the information in the intermediate index page above the leaf level to schedule serial read-aheads for the pages that contain the keys. If a request is made for all the keys from ABC to DEF, the storage engine first reads the index page above the leaf page. However, it does not just read each data page in sequence from page 504 to page 556 (the last page with keys in the specified range). Instead, the storage engine scans the intermediate index page and builds a list of the leaf pages that must be read. The storage engine then schedules all the reads in key order. The storage engine also recognizes that pages 504/505 and 527/528 are contiguous and performs a single scatter read to retrieve the adjacent pages in a single operation. When there are many pages to be retrieved in a serial operation, the storage engine schedules a block of reads at a time. When a subset of these reads is completed, the storage engine schedules an equal number of new reads until all the required reads have been scheduled.</p>
<p>The storage engine uses prefetching to speed base table lookups from nonclustered indexes. The leaf rows of a nonclustered index contain pointers to the data rows that contain each specific key value. As the storage engine reads through the leaf pages of the nonclustered index, it also starts scheduling asynchronous reads for the data rows whose pointers have already been retrieved. This allows the storage engine to retrieve data rows from the underlying table before it has completed the scan of the nonclustered index. Prefetching is used regardless of whether the table has a clustered index. SQL Server Enterprise uses more prefetching than other editions of SQL Server, allowing more pages to be read ahead. The level of prefetching is not configurable in any edition. For more information about nonclustered indexes, see <a href="https://technet.microsoft.com/en-us/library/ms177484.aspx">Nonclustered Index Structures</a>.</p>
<h2 id="Advanced-Scanning"><a class="header-anchor" href="#Advanced-Scanning"></a>Advanced Scanning</h2>
<p>In SQL Server Enterprise, the advanced scan feature allows multiple tasks to share full table scans. If the execution plan of a Transact-SQL statement requires a scan of the data pages in a table and the Database Engine detects that the table is already being scanned for another execution plan, the Database Engine joins the second scan to the first, at the current location of the second scan. The Database Engine reads each page one time and passes the rows from each page to both execution plans. This continues until the end of the table is reached.</p>
<p>At that point, the first execution plan has the complete results of a scan, but the second execution plan must still retrieve the data pages that were read before it joined the in-progress scan. The scan for the second execution plan then wraps back to the first data page of the table and scans forward to where it joined the first scan. Any number of scans can be combined like this. The Database Engine will keep looping through the data pages until it has completed all the scans. This mechanism is also called “merry-go-round scanning” and demonstrates why the order of the results returned from a SELECT statement cannot be guaranteed without an ORDER BY clause.</p>
<p>For example, assume that you have a table with 500,000 pages. UserA executes a Transact-SQL statement that requires a scan of the table. When that scan has processed 100,000 pages, UserB executes another Transact-SQL statement that scans the same table. The Database Engine schedules one set of read requests for pages after 100,001, and passes the rows from each page back to both scans. When the scan reaches the 200,000th page, UserC executes another Transact-SQL statement that scans the same table. Starting with page 200,001, the Database Engine passes the rows from each page it reads back to all three scans. After it reads the 500,000th row, the scan for UserA is complete, and the scans for UserB and UserC wrap back and start to read the pages starting with page 1. When the Database Engine gets to page 100,000, the scan for UserB is completed. The scan for UserC then keeps going alone until it reads page 200,000. At this point, all the scans have been completed.</p>
<p>Without advanced scanning, each user would have to compete for buffer space and cause disk arm contention. The same pages would then be read once for each user, instead of read one time and shared by multiple users, slowing down performance and taxing resources.</p>
<h2 id="See-Also"><a class="header-anchor" href="#See-Also"></a>See Also</h2>
<p><strong>Concepts</strong><br>
<a href="https://technet.microsoft.com/en-us/library/ms177443.aspx">Clustered Index Structures</a><br>
<a href="https://technet.microsoft.com/en-us/library/ms177484.aspx">Nonclustered Index Structures</a><br>
<a href="https://technet.microsoft.com/en-us/library/ms188270.aspx">Heap Structures</a><br>
<a href="https://technet.microsoft.com/en-us/library/aa337560.aspx">Writing Pages</a></p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/sql-server-buffer-management-reading-pages/">http://xnerv.wang/sql-server-buffer-management-reading-pages/</a></strong><br>
转载自：<a href="https://technet.microsoft.com/en-us/library/ms191475.aspx">Reading Pages</a></p>
]]></content>
      <categories>
        <category>DBMS</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>DBMS</tag>
        <tag>SQL Server</tag>
        <tag>Buffer Pool</tag>
        <tag>Read Ahead</tag>
      </tags>
  </entry>
  <entry>
    <title>SQL Server - Buffer Management - Writing Pages（转载）</title>
    <url>/sql-server-buffer-management-writing-pages/</url>
    <content><![CDATA[<p>The I/O from an instance of the Database Engine includes logical and physical writes. A logical write occurs when data is modified in a page in the <a href="https://technet.microsoft.com/en-us/library/aa337525.aspx">buffer cache</a>. A physical write occurs when the page is written from the buffer cache to disk.</p>
<p>When a page is modified in the buffer cache, it is not immediately written back to disk; instead, the page is marked as <em>dirty</em>. This means that a page can have more than one logical write made before it is physically written to disk. For each logical write, a transaction log record is inserted in the log cache that records the modification. The log records must be written to disk before the associated dirty page is removed from the buffer cache and written to disk. SQL Server uses a technique known as <em>write-ahead logging</em> that prevents writing a dirty page before the associated log record is written to disk. This is essential to the correct working of the recovery manager. For more information, see <a href="https://technet.microsoft.com/en-us/library/ms186259.aspx">Write-Ahead Transaction Log</a>.</p>
<span id="more"></span>
<p>The following illustration shows the process for writing a modified data page.</p>
<p><img src="https://i-technet.sec.s-msft.com/dynimg/IC89338.gif" alt="Writing a modified data page." title="Writing a modified data page."></p>
<p>When the buffer manager writes a page, it searches for adjacent dirty pages that can be included in a single gather-write operation. Adjacent pages have consecutive page IDs and are from the same file; the pages do not have to be contiguous in memory. The search continues both forward and backward until one of the following events occurs:</p>
<ul>
<li>
<p>A clean page is found.</p>
</li>
<li>
<p>32 pages have been found.</p>
</li>
<li>
<p>A dirty page is found whose log sequence number (LSN) has not yet been flushed in the log.</p>
</li>
<li>
<p>A page is found that cannot be immediately latched.</p>
</li>
</ul>
<p>In this way, the entire set of pages can be written to disk with a single gather-write operation.</p>
<p>Just before a page is written, the form of page protection specified in the database is added to the page. If torn page protection is added, the page must be latched EX(clusively) for the I/O. This is because the torn page protection modifies the page, making it unsuitable for any other thread to read. If checksum page protection is added, or the database uses no page protection, the page is latched with an UP(date) latch for the I/O. This latch prevents anyone else from modifying the page during the write, but still allows readers to use it. For more information about disk I/O page protection options, see <a href="https://technet.microsoft.com/en-us/library/aa337525.aspx">Buffer Management</a>.</p>
<p>A dirty page is written to disk in one of three ways.</p>
<ul>
<li>
<p>Lazy writing</p>
<p>The lazy writer is a system process that keeps free buffers available by removing infrequently used pages from the buffer cache. Dirty pages are first written to disk.</p>
</li>
<li>
<p>Eager writing</p>
<p>The eager write process writes dirty data pages associated with nonlogged operations such as bulk insert and select into. This process allows creating and writing new pages to take place in parallel. That is, the calling operation does not have to wait until the entire operation finishes before writing the pages to disk.</p>
</li>
<li>
<p>Checkpoint</p>
<p>The checkpoint process periodically scans the buffer cache for buffers with pages from a specified database and writes all dirty pages to disk. Checkpoints save time during a later recovery by creating a point at which all dirty pages are guaranteed to have been written to disk. The user may request a checkpoint operation by using the CHECKPOINT command, or the Database Engine may generate automatic checkpoints based on the amount of log space used and time elapsed since the last checkpoint. In addition, a checkpoint is generated when certain activities occur. For example, when a data or log file is added or removed from a database, or when the instance of SQL Server is stopped. For more information, see <a href="https://technet.microsoft.com/en-us/library/ms189573.aspx">Checkpoints and the Active Portion of the Log</a>.</p>
<p>The lazy writing, eager writing, and checkpoint processes do not wait for the I/O operation to complete. They always use asynchronous (or overlapped) I/O and continue with other work, checking for I/O success later. This allows SQL Server to maximize both CPU and I/O resources for the appropriate tasks.</p>
</li>
</ul>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/sql-server-buffer-management-writing-pages/">http://xnerv.wang/sql-server-buffer-management-writing-pages/</a></strong><br>
转载自：<a href="https://technet.microsoft.com/en-us/library/aa337560.aspx">Writing Pages</a></p>
]]></content>
      <categories>
        <category>DBMS</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>DBMS</tag>
        <tag>SQL Server</tag>
        <tag>Buffer Pool</tag>
        <tag>Lazy Writing</tag>
        <tag>Eager Writing</tag>
        <tag>Checkpoint</tag>
      </tags>
  </entry>
  <entry>
    <title>SQL TRANSACTION ISOLATION LEVELS EXPLAINED（转载）</title>
    <url>/sql-transaction-isolation-levels-explained/</url>
    <content><![CDATA[<p>This article is part of a series. You do not have to read them in order but I will be referring to topics and explanations in previous articles:</p>
<ol>
<li><a href="/implementing-your-own-transactions-with-mvcc">Implementing Your Own Transactions with MVCC</a></li>
<li><strong>SQL Transaction Isolation Levels Explained</strong></li>
<li><a href="/implementing-repeatable-read-and-serializable-transaction-isolation">Implementing Repeatable Read and Serializable Transaction Isolation</a></li>
</ol>
<span id="more"></span>
<hr>
<p><img src="http://postachio-images.s3.amazonaws.com/aa0e0e8e-5932-48c5-bbd5-bb782bc5caef/10b13ce3-f899-409d-8004-b28197b473c7/a3b0f2ca-fc22-4418-a86e-57a6d410a66b.png" alt=""></p>
<h2 id="The-Bad-Stuff"><a class="header-anchor" href="#The-Bad-Stuff"></a>The Bad Stuff</h2>
<p>Before I can explain what’s different about the isolation levels we have to understand what it is that can go wrong with concurrent transactions (more than one client viewing or modifying the data at the same time).</p>
<p>Let’s say we have a table <code>users</code>:</p>
<table>
<thead>
<tr>
<th>id</th>
<th>name</th>
<th>age</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Joe</td>
<td>20</td>
</tr>
<tr>
<td>2</td>
<td>Jill</td>
<td>25</td>
</tr>
</tbody>
</table>
<h3 id="Dirty-Reads"><a class="header-anchor" href="#Dirty-Reads"></a>Dirty Reads</h3>
<p>A <em>dirty read</em> is when the current transaction reads a row written by another uncommitted transaction that’s currently in-flight. For example:</p>
<table>
<thead>
<tr>
<th>Transaction 1</th>
<th>Transaction 2</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>BEGIN;</code></td>
<td><code>BEGIN;</code></td>
</tr>
<tr>
<td><code>SELECT age FROM users WHERE id = 1; /* will read 20 */</code></td>
<td></td>
</tr>
<tr>
<td></td>
<td><code>UPDATE users SET age = 21 WHERE id = 1; /* No commit here */</code></td>
</tr>
<tr>
<td></td>
<td><code>SELECT age FROM users WHERE id = 1; /* will read 21 */</code></td>
</tr>
</tbody>
</table>
<p>Basically, if the database is not able to keep track of who is changing the data (by keeping multiple versions of the same row with different visibilities) then rows be read even through they should not yet be visible to that other transaction.</p>
<h3 id="Non-repeatable-Reads"><a class="header-anchor" href="#Non-repeatable-Reads"></a>Non-repeatable Reads</h3>
<p>A <em>non-repeatable read</em> occurs when the current transaction reads the same data but this time it is different. It is different because another transaction has been committed during the life of the current transaction:</p>
<table>
<thead>
<tr>
<th>Transaction 1</th>
<th>Transaction 2</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>BEGIN;</code></td>
<td><code>BEGIN;</code></td>
</tr>
<tr>
<td><code>SELECT * FROM users WHERE id = 1;</code></td>
<td></td>
</tr>
<tr>
<td></td>
<td><code>UPDATE users SET age = 21 WHERE id = 1;</code></td>
</tr>
<tr>
<td></td>
<td><code>COMMIT;</code></td>
</tr>
<tr>
<td><code>SELECT * FROM users WHERE id = 1; /* will read 21 */</code></td>
<td></td>
</tr>
</tbody>
</table>
<p>Basically, the database does not maintain what the transaction has <em>already seen</em> so each time the data is read (such as multiple <code>SELECT</code> statements in the same transaction) the same visibility check is done on those rows but some rows may have changed in the mean time.</p>
<h3 id="Phantom-Reads"><a class="header-anchor" href="#Phantom-Reads"></a>Phantom Reads</h3>
<p>A <em>phantom read</em> happens when the current transaction re-executes a query returning a set of rows that satisfy a search condition and finds that the set of rows satisfying the condition has changed due to another recently-committed transaction.</p>
<table>
<thead>
<tr>
<th>Transaction 1</th>
<th>Transaction 2</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>BEGIN;</code></td>
<td><code>BEGIN;</code></td>
</tr>
<tr>
<td><code>SELECT COUNT(*) FROM users WHERE age BETWEEN 10 AND 30; /* will return 5 */</code></td>
<td></td>
</tr>
<tr>
<td></td>
<td><code>INSERT INTO users(id,name,age) VALUES ( 3, 'Bob', 27 );</code></td>
</tr>
<tr>
<td></td>
<td><code>COMMIT;</code></td>
</tr>
<tr>
<td><code>SELECT COUNT(*) FROM users WHERE age BETWEEN 10 AND 30; /* will return 6 */</code></td>
<td></td>
</tr>
</tbody>
</table>
<p>This can be thought of as a special type of non-repeatable read, but it is important to distinguish it as a different case because the possibility of it occurring depends on the isolation levels explained next.</p>
<p>The distinction is that that the original rows are re-read correctly (even if they had been changed) but a new row (or rows) have been inserted into the <em>range</em> it previously selected. So it hasn’t broken the re-read rule, but the data returned is still different.</p>
<h2 id="The-SQL-Standard"><a class="header-anchor" href="#The-SQL-Standard"></a>The SQL Standard</h2>
<p>The SQL Standard defines four isolation levels which are described by what type of errors they are allowed to permit. It does not specify how the implementations themselves work.</p>
<p>In most databases MVCC is used. Sometimes with some complex rules to handle higher isolation levels built on top. However, there are other mechanisms; SQLite3 use a separate journal, for example.</p>
<ul>
<li><strong>Read uncommitted</strong> permits dirty reads, non repeatable reads and phantom reads.</li>
<li><strong>Read committed</strong> permits non repeatable reads and phantom reads.</li>
<li><strong>Repeatable read</strong> permits only phantom reads.</li>
<li><strong>Serializable</strong> does not permit any read errors.</li>
</ul>
<h3 id="Read-Uncommitted"><a class="header-anchor" href="#Read-Uncommitted"></a>Read Uncommitted</h3>
<p>“Read uncommitted&quot; is the most loose transaction isolation and is in fact not even implemented in some databases because it is too loose to be useful. A transaction in this mode is susceptible to all types of read errors mentioned above since it is not required to even check if a row is committed or not.</p>
<p>If the database itself was not able to keep multiple version of a row but you still wanted the virtual container of a transaction to be able to perform a <code>ROLLBACK</code> this might be your only choice.</p>
<h3 id="Read-Committed"><a class="header-anchor" href="#Read-Committed"></a>Read Committed</h3>
<p>“Read committed&quot; is the most common transaction isolation and usually is the default as it has the best balance between locking and performance. It will never read versions of rows that are currently uncommitted, however it is still susceptible to other transactions changing data between statements.</p>
<h3 id="Repeatable-Read"><a class="header-anchor" href="#Repeatable-Read"></a>Repeatable Read</h3>
<p>“Repeatable read&quot; ensures rows that have been read (rather than modified) will still be read, even if they are changed by other transactions. This provides an almost true snapshot of the data however it does incur overhead with locking and/or causing other transactions to be rolled back more commonly.</p>
<h3 id="Serializable"><a class="header-anchor" href="#Serializable"></a>Serializable</h3>
<p>In a perfect world (at least for a database) we would like only one client to be connected to the database at a any given time. This would guarantee there are no side effects between concurrent clients, since there are none.</p>
<p>This is “Serializable&quot;, the most strict mode and works exactly like this - client perform transactions in serial.</p>
<p>In practicality a database could not serve just one person at a time so some fancy internal algorithms are used to make sure that clients are not overlapping in anyway. This is tricky but means clients can concurrently work with the database but have the same guarantees as if the transactions were formed one after another.</p>
<p>Depending on the database system it may rollback a transaction at the time of, or at the end of the transaction if it thinks the transaction isolation has been compromised. Applications that need this level of isolation should be built carefully so that they can always retry the transaction on failure.</p>
<h2 id="Database-Vendors"><a class="header-anchor" href="#Database-Vendors"></a>Database Vendors</h2>
<p>Here are some of the common database vendors and what levels of isolation they support.</p>
<h3 id="DB2"><a class="header-anchor" href="#DB2"></a>DB2</h3>
<p>DB2 supports all four database isolation levels, but has different names for each of the levels:</p>
<ul>
<li>Uncommitted read (UR) -&gt; Read uncommitted.</li>
<li>Cursor stability (CS) -&gt; Read committed (default).</li>
<li>Read stability (RS) -&gt; Repeatable read.</li>
<li>Repeatable read (RR) -&gt; Serializable.</li>
</ul>
<p>Links:</p>
<ul>
<li><a href="http://www.ibm.com/support/knowledgecenter/SSEPGG_9.7.0/com.ibm.db2.luw.admin.perf.doc/doc/c0004121.html">IBM Knowledge Center</a></li>
</ul>
<h3 id="Derby"><a class="header-anchor" href="#Derby"></a>Derby</h3>
<p>Derby supports all four levels of isolation, with read committed being the default.</p>
<p>Links:</p>
<ul>
<li><a href="https://db.apache.org/derby/docs/10.3/devguide/cdevconcepts15366.html">Isolation levels and concurrency</a></li>
</ul>
<h3 id="H2"><a class="header-anchor" href="#H2"></a>H2</h3>
<p>H2 supports only three isolation levels; read uncommitted, read committed and serializable which can only be set at the connection level (not per transaction). The default is read committed.</p>
<p>Links:</p>
<ul>
<li><a href="http://www.h2database.com/html/advanced.html#transaction_isolation">H2 - Advanced</a></li>
</ul>
<h3 id="MySQL-and-MariaDB"><a class="header-anchor" href="#MySQL-and-MariaDB"></a>MySQL and MariaDB</h3>
<p>When MySQL and MariaDB are using InnoDB they support all four transaction isolation levels with repeatable read as the default. Even though MySQL and MariaDB allow other pluggable engines, InnoDB is the most common when transactions are required and is usually the default engine on modern versions of either.</p>
<p>The original engine, MyISAM does not support transactions but it still used and available. Transaction commands will be ignored rather than result in an error. This is effectively running a database in read uncommitted mode.</p>
<p>Links:</p>
<ol>
<li><a href="https://dev.mysql.com/doc/refman/5.7/en/innodb-transaction-isolation-levels.html">MySQL :: MySQL 5.7 Reference Manual :: 15.5.2.1 Transaction Isolation Levels</a></li>
<li><a href="https://mariadb.com/kb/en/mariadb/set-transaction/">SET TRANSACTION - MariaDB Knowledge Base</a></li>
</ol>
<h3 id="Oracle"><a class="header-anchor" href="#Oracle"></a>Oracle</h3>
<p>Oracle only supports read committed (default) and serializable.</p>
<p>Links:</p>
<ul>
<li><a href="http://www.oracle.com/technetwork/issue-archive/2005/05-nov/o65asktom-082389.html">Ask Tom: On Transaction Isolation Levels</a></li>
</ul>
<h3 id="PostgreSQL"><a class="header-anchor" href="#PostgreSQL"></a>PostgreSQL</h3>
<p>PostgreSQL supports three levels; read committed, repeatable read and serializable. The syntax allows you to choose read read uncommitted but it will function as read committed.</p>
<p>Read committed is the default.</p>
<p>Links:</p>
<ul>
<li><a href="https://www.postgresql.org/docs/9.1/static/transaction-iso.html">PostgreSQL: Documentation: 9.1: Transaction Isolation</a></li>
</ul>
<h3 id="Redshift"><a class="header-anchor" href="#Redshift"></a>Redshift</h3>
<p><a href="http://docs.aws.amazon.com/redshift/latest/mgmt/welcome.html">Redshift</a> is a modified version of PostgreSQL that can only be used on <a href="https://aws.amazon.com">Amazon Web Services (AWS)</a>. Redshift only supports serializable. Selecting a different isolation level will have no effect.</p>
<p>Links:</p>
<ul>
<li><a href="http://docs.aws.amazon.com/redshift/latest/dg/r_BEGIN.html">BEGIN - Amazon Redshift</a></li>
</ul>
<h3 id="SQL-Server"><a class="header-anchor" href="#SQL-Server"></a>SQL Server</h3>
<p>Microsoft SQL Server (which is also commonly used as a backend for Microsoft Access instead of the in-built engine) supports all four transaction isolation levels with the default being read committed.</p>
<p>SQL Server also has a fifth option called “snapshot&quot; which allows transactions to see a consistent read state. It is unclear if this is an alias of another isolation level or has a specific implementation.</p>
<p>Links:</p>
<ul>
<li><a href="https://msdn.microsoft.com/en-AU/library/ms173763.aspx">SET TRANSACTION ISOLATION LEVEL (Transact-SQL)</a></li>
</ul>
<h3 id="SQLite3"><a class="header-anchor" href="#SQLite3"></a>SQLite3</h3>
<p>The default implementation of SQLite3 (since you can compile it from source with lots of different options) only works in Serialized mode.</p>
<p>Anyone that has dealt with SQLite3 a lot will understand that this can cause a lot of locking issues but it also the most safe safe considering all the mission-critical systems that SQLite3 is deployed in.</p>
<p>Since v3.7.0 write-ahead logging (WAL) has been introduced to make concurrent environments work more like other database vendors.</p>
<p>Links:</p>
<ul>
<li><a href="https://www.sqlite.org/isolation.html">Isolation In SQLite</a></li>
<li><a href="https://www.sqlite.org/wal.html">Write-Ahead Logging</a></li>
</ul>
<hr>
<p>If your favourite database vendor is not listed, please let me know.</p>
<h2 id="Other-Resources"><a class="header-anchor" href="#Other-Resources"></a>Other Resources</h2>
<ul>
<li><a href="https://github.com/ept/hermitage">GitHub - ept/hermitage</a>: What are the differences between the transaction isolation levels in databases? This is a suite of test cases which differentiate isolation levels.</li>
</ul>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/sql-transaction-isolation-levels-explained/">http://xnerv.wang/sql-transaction-isolation-levels-explained/</a></strong><br>
转载自：<a href="http://elliot.land/post/sql-transaction-isolation-levels-explained">SQL TRANSACTION ISOLATION LEVELS EXPLAINED</a></p>
]]></content>
      <categories>
        <category>DBMS</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>DBMS</tag>
        <tag>SQL Server</tag>
        <tag>Transaction</tag>
        <tag>Isolation Level</tag>
      </tags>
  </entry>
  <entry>
    <title>每天进步一点点——五分钟理解一致性哈希算法(consistent hashing)（转载）</title>
    <url>/study-consistent-hashing-in-5min/</url>
    <content><![CDATA[<p>一致性哈希算法在1997年由麻省理工学院提出的一种分布式哈希（DHT）实现算法，设计目标是为了解决因特网中的热点(Hot spot)问题，初衷和CARP十分类似。一致性哈希修正了CARP使用的简 单哈希算法带来的问题，使得分布式哈希（DHT）可以在P2P环境中真正得到应用。</p>
<span id="more"></span>
<p>一致性hash算法提出了在动态变化的Cache环境中，判定哈希算法好坏的四个定义：</p>
<ol>
<li><font color="red">平衡性(Balance)</font>：平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。</li>
<li><font color="red">单调性(Monotonicity)</font>：单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。哈希的结果应能够保证原有已分配的内容可以被映射到原有的或者新的缓冲中去，而不会被映射到旧的缓冲集合中的其他缓冲区。</li>
<li><font color="red">分散性(Spread)</font>：在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性。</li>
<li><font color="red">负载(Load)</font>：负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同 的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷。</li>
</ol>
<p>在分布式集群中，对机器的添加删除，或者机器故障后自动脱离集群这些操作是分布式集群管理最基本的功能。如果采用常用的hash(object)%N算法，那么在有机器添加或者删除后，很多原有的数据就无法找到了，这样严重的违反了单调性原则。接下来主要讲解一下一致性哈希算法是如何设计的：</p>
<h2 id="环形Hash空间"><a class="header-anchor" href="#环形Hash空间"></a>环形Hash空间</h2>
<p>按照常用的hash算法来将对应的key哈希到一个具有2<sup>32次方个桶的空间中，即0~(2</sup>32)-1的数字空间中。现在我们可以将这些数字头尾相连，想象成一个闭合的环形。如下图</p>
<center>
<img src="/assets/study-consistent-hashing-in-5min/1.jpg"/>
</center>
<h3 id="把数据通过一定的hash算法处理后映射到环上"><a class="header-anchor" href="#把数据通过一定的hash算法处理后映射到环上"></a>把数据通过一定的hash算法处理后映射到环上</h3>
<p>现在我们将object1、object2、object3、object4四个对象通过特定的Hash函数计算出对应的key值，然后散列到Hash环上。如下图：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">Hash(object1) = key1；</span><br><span class="line">Hash(object2) = key2；</span><br><span class="line">Hash(object3) = key3；</span><br><span class="line">Hash(object4) = key4；</span><br></pre></td></tr></table></figure>
<center>
<img src="/assets/study-consistent-hashing-in-5min/2.jpg"/>
</center>
<h3 id="将机器通过hash算法映射到环上"><a class="header-anchor" href="#将机器通过hash算法映射到环上"></a>将机器通过hash算法映射到环上</h3>
<p>在采用一致性哈希算法的分布式集群中将新的机器加入，其原理是通过使用与对象存储一样的Hash算法将机器也映射到环中（一般情况下对机器的hash计算是采用机器的IP或者机器唯一的别名作为输入值），然后以顺时针的方向计算，将所有对象存储到离自己最近的机器中。<br>
假设现在有NODE1，NODE2，NODE3三台机器，通过Hash算法得到对应的KEY值，映射到环中，其示意图如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">Hash(NODE1) = KEY1;</span><br><span class="line">Hash(NODE2) = KEY2;</span><br><span class="line">Hash(NODE3) = KEY3;</span><br></pre></td></tr></table></figure>
<center>
<img src="/assets/study-consistent-hashing-in-5min/3.jpg"/>
</center>
<p>通过上图可以看出对象与机器处于同一哈希空间中，这样按顺时针转动object1存储到了NODE1中，object3存储到了NODE2中，object2、object4存储到了NODE3中。在这样的部署环境中，hash环是不会变更的，因此，通过算出对象的hash值就能快速的定位到对应的机器中，这样就能找到对象真正的存储位置了。</p>
<h2 id="机器的删除与添加"><a class="header-anchor" href="#机器的删除与添加"></a>机器的删除与添加</h2>
<p>普通hash求余算法最为不妥的地方就是在有机器的添加或者删除之后会照成大量的对象存储位置失效，这样就大大的不满足单调性了。下面来分析一下一致性哈希算法是如何处理的。</p>
<ol>
<li>
<p>节点（机器）的删除<br>
以上面的分布为例，如果NODE2出现故障被删除了，那么按照顺时针迁移的方法，object3将会被迁移到NODE3中，这样仅仅是object3的映射位置发生了变化，其它的对象没有任何的改动。如下图：</p>
<center>
<img src="/assets/study-consistent-hashing-in-5min/4.jpg"/>
</center>
</li>
<li>
<p>节点（机器）的添加<br>
如果往集群中添加一个新的节点NODE4，通过对应的哈希算法得到KEY4，并映射到环中，如下图：</p>
<center>
<img src="/assets/study-consistent-hashing-in-5min/5.jpg"/>
</center>
<p>通过按顺时针迁移的规则，那么object2被迁移到了NODE4中，其它对象还保持这原有的存储位置。通过对节点的添加和删除的分析，一致性哈希算法在保持了单调性的同时，还是数据的迁移达到了最小，这样的算法对分布式集群来说是非常合适的，避免了大量数据迁移，减小了服务器的的压力。</p>
</li>
</ol>
<h2 id="平衡性"><a class="header-anchor" href="#平衡性"></a>平衡性</h2>
<p>根据上面的图解分析，一致性哈希算法满足了单调性和负载均衡的特性以及一般hash算法的分散性，但这还并不能当做其被广泛应用的原由，因为还缺少了平衡性。下面将分析一致性哈希算法是如何满足平衡性的。hash算法是不保证平衡的，如上面只部署了NODE1和NODE3的情况（NODE2被删除的图），object1存储到了NODE1中，而object2、object3、object4都存储到了NODE3中，这样就照成了非常不平衡的状态。在一致性哈希算法中，为了尽可能的满足平衡性，其引入了虚拟节点。<br>
——<font color="red">“虚拟节点”（ virtual node ）是实际节点（机器）在 hash 空间的复制品（ replica ），一实际个节点（机器）对应了若干个“虚拟节点”，这个对应个数也成为“复制个数”，“虚拟节点”在 hash 空间中以hash值排列。</font><br>
以上面只部署了NODE1和NODE3的情况（NODE2被删除的图）为例，之前的对象在机器上的分布很不均衡，现在我们以2个副本（复制个数）为例，这样整个hash环中就存在了4个虚拟节点，最后对象映射的关系图如下：</p>
<center>
<img src="/assets/study-consistent-hashing-in-5min/6.png"/>
</center>
<p>根据上图可知对象的映射关系：object1-&gt;NODE1-1，object2-&gt;NODE1-2，object3-&gt;NODE3-2，object4-&gt;NODE3-1。通过虚拟节点的引入，对象的分布就比较均衡了。那么在实际操作中，正真的对象查询是如何工作的呢？对象从hash到虚拟节点到实际节点的转换如下图：</p>
<center>
<img src="/assets/study-consistent-hashing-in-5min/7.png"/>
</center>
<p>“虚拟节点”的hash计算可以采用对应节点的IP地址加数字后缀的方式。例如假设NODE1的IP地址为192.168.1.100。引入“虚拟节点”前，计算 cache A 的 hash 值：<br>
Hash(“192.168.1.100”);<br>
引入“虚拟节点”后，计算“虚拟节”点NODE1-1和NODE1-2的hash值：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">Hash(“<span class="number">192.168</span><span class="number">.1</span><span class="number">.100</span>#<span class="number">1</span>”); <span class="comment">// NODE1-1</span></span><br><span class="line">Hash(“<span class="number">192.168</span><span class="number">.1</span><span class="number">.100</span>#<span class="number">2</span>”); <span class="comment">// NODE1-2</span></span><br></pre></td></tr></table></figure>
<p>参考：<br>
[1] <a href="http://blog.huanghao.me/?p=14">http://blog.huanghao.me/?p=14</a></p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/study-consistent-hashing-in-5min/">http://xnerv.wang/study-consistent-hashing-in-5min/</a></strong><br>
转载自：<a href="http://blog.csdn.net/cywosp/article/details/23397179/">每天进步一点点——五分钟理解一致性哈希算法(consistent hashing)</a></p>
]]></content>
      <categories>
        <category>分布式及存储</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>分布式及存储</tag>
        <tag>Consistent Hashing</tag>
        <tag>一致性哈希</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式理论及架构的一些整理</title>
    <url>/summary-of-distributed-theory-and-architecture/</url>
    <content><![CDATA[<h2 id="CAP理论及BASE理论"><a class="header-anchor" href="#CAP理论及BASE理论"></a>CAP理论及BASE理论</h2>
<p><img src="http://www.hollischuang.com/wp-content/uploads/2015/12/cap.jpg" alt="分布式系统的CAP理论"></p>
<h3 id="分布式系统的CAP理论"><a class="header-anchor" href="#分布式系统的CAP理论"></a><a href="http://www.hollischuang.com/archives/666">分布式系统的CAP理论</a></h3>
<blockquote>
<p>一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项。<br>
<a href="http://www.glassbeam.com/sites/all/themes/glassbeam/images/blog/10.1.1.67.6951.pdf">麻省理工学院的Seth Gilbert和Nancy Lynch从理论上证明了CAP</a></p>
</blockquote>
<span id="more"></span>
<h3 id="分布式系统的BASE理论"><a class="header-anchor" href="#分布式系统的BASE理论"></a><a href="http://www.hollischuang.com/archives/672">分布式系统的BASE理论</a></h3>
<blockquote>
<p>eBay的架构师Dan Pritchett源于对大规模分布式系统的实践总结，在ACM上发表文章提出BASE理论，BASE理论是对CAP理论的延伸，核心思想是即使无法做到强一致性（Strong Consistency，CAP的一致性就是强一致性），但应用可以采用适合的方式达到最终一致性（Eventual Consitency）。</p>
<blockquote>
<p>BASE是指基本可用（Basically Available）、软状态（ Soft State）、最终一致性（ Eventual Consistency）。</p>
<ul>
<li>基本可用（Basically Available）<br>
基本可用是指分布式系统在出现故障的时候，允许损失部分可用性，即保证核心可用。<br>
电商大促时，为了应对访问量激增，部分用户可能会被引导到降级页面，服务层也可能只提供降级服务。这就是损失部分可用性的体现。</li>
<li>软状态（ Soft State）<br>
软状态是指允许系统存在中间状态，而该中间状态不会影响系统整体可用性。分布式存储中一般一份数据至少会有三个副本，允许不同节点间副本同步的延时就是软状态的体现。mysql replication的异步复制也是一种体现。</li>
<li>最终一致性（ Eventual Consistency）<br>
最终一致性是指系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。弱一致性和强一致性相反，最终一致性是弱一致性的一种特殊情况。</li>
</ul>
</blockquote>
</blockquote>
<p>两阶段提交主要保证了分布式事务的原子性：即所有结点要么全做要么全不做。<br>
一个协调者，多个参与者。协调者收集参与者的投票，全通过就commit，否则abort。<br>
将提交分成两阶段进行的目的很明确，就是尽可能晚地提交事务，让事务在提交前尽可能地完成所有能完成的工作，这样，最后的提交阶段将是一个耗时极短的微小操作，这种操作在一个分布式系统中失败的概率是非常小的，也就是所谓的“网络通讯危险期”非常的短暂，这是两阶段提交确保分布式事务原子性的关键所在。（唯一理论上两阶段提交出现问题的情况是当协调者发出提交指令后当机并出现磁盘故障等永久性错误，导致事务不可追踪和恢复）。<br>
（注意，二阶段提交相对的就是一阶段提交，就是普通的本地事务模式）</p>
<h3 id="关于分布式事务、两阶段提交协议、三阶提交协议"><a class="header-anchor" href="#关于分布式事务、两阶段提交协议、三阶提交协议"></a><a href="http://www.hollischuang.com/archives/681">关于分布式事务、两阶段提交协议、三阶提交协议</a></h3>
<blockquote>
<p>无论是二阶段提交还是三阶段提交都无法彻底解决分布式的一致性问题。Google Chubby的作者Mike Burrows说过， there is only one consensus protocol, and that’s Paxos” – all other approaches are just broken versions of Paxos. 意即世上只有一种一致性算法，那就是Paxos，所有其他一致性算法都是Paxos算法的不完整版。<br>
3PC在2PC的基础上，加上了第一个CanCommit阶段。在第三个doCommit阶段，如果超时会自动commit，其它阶段超时会自动rollback。</p>
</blockquote>
<h4 id="深入理解分布式系统的2PC和3PC"><a class="header-anchor" href="#深入理解分布式系统的2PC和3PC"></a><a href="http://www.hollischuang.com/archives/1580">深入理解分布式系统的2PC和3PC</a></h4>
<blockquote>
<p>2PC协议中，如果出现协调者和参与者都挂了的情况，有可能导致数据不一致。（这个应该指的是一个参加者节点在一段很短的时间内处于数据不一致状态，这也是不允许的，即使之后能够逐步恢复）<br>
简单概括一下就是，如果挂掉的那台机器已经执行了commit，那么协调者可以从所有未挂掉的参与者的状态中分析出来，并执行commit。如果挂掉的那个参与者执行了rollback，那么协调者和其他的参与者执行的肯定也是rollback操作。<br>
所以，再多引入一个阶段之后，3PC解决了2PC中存在的那种由于协调者和参与者同时挂掉有可能导致的数据一致性问题。<br>
3PC存在的问题<br>
在doCommit阶段，如果参与者无法及时接收到来自协调者的doCommit或者rebort请求时，会在等待超时之后，会继续进行事务的提交。<br>
所以，由于网络原因，协调者发送的abort响应没有及时被参与者接收到，那么参与者在等待超时之后执行了commit操作。这样就和其他接到abort命令并执行回滚的参与者之间存在数据不一致的情况。</p>
</blockquote>
<h4 id="XA事务"><a class="header-anchor" href="#XA事务"></a>XA事务</h4>
<p>MySQL的XA事务，估计就是对XA事务的支持。这样如果有一个XA事务管理器，就可以在MySQL和其它支持XA事务的数据库如SQL Server之间，进行分布式事务处理了。</p>
<blockquote>
<p>X/Open 组织（即现在的 Open Group ）定义了分布式事务处理模型。 X/Open DTP 模型（ 1994 ）包括应用程序（ AP ）、事务管理器（ TM ）、资源管理器（ RM ）、通信资源管理器（ CRM ）四部分。一般，常见的事务管理器（ TM ）是交易中间件，常见的资源管理器（ RM ）是数据库，常见的通信资源管理器（ CRM ）是消息中间件。    通常把一个数据库内部的事务处理，如对多个表的操作，作为本地事务看待。数据库的事务处理对象是本地事务，而分布式事务处理的对象是全局事务。<br>
XA 就是 X/Open DTP 定义的交易中间件与数据库之间的接口规范（即接口函数），交易中间件用它来通知数据库事务的开始、结束以及提交、回滚等。 XA 接口函数由数据库厂商提供。</p>
</blockquote>
<h2 id="拜占庭将军问题"><a class="header-anchor" href="#拜占庭将军问题"></a><a href="https://zh.wikipedia.org/wiki/%E6%8B%9C%E5%8D%A0%E5%BA%AD%E5%B0%86%E5%86%9B%E9%97%AE%E9%A2%98">拜占庭将军问题</a></h2>
<p>拜占庭将军问题（Byzantine Generals Problem），是由莱斯利兰伯特提出的点对点通信中的基本问题。 在分布式计算上，不同的计算机透过讯息交换，尝试达成共识；但有时候，系统上协调计算机（Coordinator / Commander）或成员计算机 （Member / Lieutanent）可能因系统错误并交换错的讯息，导致影响最终的系统一致性。拜占庭将军问题就根据错误计算机的数量，寻找可能的解决办法 ，这无法找到一个绝对的答案，但只可以用来验证一个机制的有效程度）。</p>
<h2 id="开源分布式系统"><a class="header-anchor" href="#开源分布式系统"></a>开源分布式系统</h2>
<h3 id="HBase"><a class="header-anchor" href="#HBase"></a><img src="http://img.blog.csdn.net/20130508221106201" alt="HBase"></h3>
<p>HBase可以看作对应Google BigTable的开源实现。HBase不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库。另一个不同的是HBase基于列的而不是基于行的模式。</p>
<h3 id="解析全球级分布式数据库Google-Spanner"><a class="header-anchor" href="#解析全球级分布式数据库Google-Spanner"></a><a href="http://www.csdn.net/article/2012-09-19/2810132-google-spanner-next-database-datacenter">解析全球级分布式数据库Google Spanner</a></h3>
<h3 id="OceanBase"><a class="header-anchor" href="#OceanBase"></a><a href="http://blog.csdn.net/expleeve/article/details/8484213">OceanBase</a></h3>
<p><img src="http://img.my.csdn.net/uploads/201301/09/1357697101_4690.jpg" alt="OceanBase"></p>
<p>一个高性能的分布式表格系统，提供类似BigTable的性能和扩展性，但表格中保存的是强类型的数据，比如integer, string， datetime等。 它使用C++编写，运行于64位Linux环境下。生产环境下需要使用多台机器搭建OceanBase集群以提供高可用和高性能，但是你也完全可以使用一台机器运行OceanBase。</p>
<h3 id="TFS（Taobao-FileSystem）"><a class="header-anchor" href="#TFS（Taobao-FileSystem）"></a><a href="http://code.taobao.org/p/tfs/wiki/intro/">TFS（Taobao !FileSystem）</a></h3>
<p>淘宝针对海量非结构化数据存储设计的分布式系统，构筑在普通的Linux机器集群上，可为外部提供高可靠和高并发的存储访问。高可扩展、高可用、高性能、面向互联网服务。</p>
<h3 id="Tair"><a class="header-anchor" href="#Tair"></a><a href="http://tair.taobao.org/">Tair</a></h3>
<blockquote>
<p>Tair是一个高性能，分布式，可扩展，高可靠的key/value结构存储系统。</p>
</blockquote>
<h4 id="tair的总体结构"><a class="header-anchor" href="#tair的总体结构"></a>tair的总体结构</h4>
<blockquote>
<p><img src="https://www.lvtao.net/content/uploadfile/201312/3bdf79391dc2ddf5c52a67d08d87ad3720131225075456.jpg" alt="tair的总体结构"></p>
</blockquote>
<h4 id="tair的负载均衡算法"><a class="header-anchor" href="#tair的负载均衡算法"></a>tair的负载均衡算法</h4>
<p><img src="https://www.lvtao.net/content/uploadfile/201312/2a4ba3d47c43013ec31257aee3be666d20131225075456.jpg" alt="tair的负载均衡算法"></p>
<blockquote>
<p>tair的分布采用的是一致性哈希算法，对于所有的key，分到Q个桶中，桶是负载均衡和数据迁移的基本单位。config server 根据一定的策略把每个桶指派到不同的data server上。因为数据按照key做hash算法，所以可以认为每个桶中的数据基本是平衡的。保证了桶分布的均衡性，就保证了数据分布的均衡性。</p>
</blockquote>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/summary-of-distributed-theory-and-architecture/">http://xnerv.wang/summary-of-distributed-theory-and-architecture/</a></strong></p>
]]></content>
      <categories>
        <category>分布式及存储</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>分布式及存储</tag>
        <tag>2PC</tag>
        <tag>3PC</tag>
      </tags>
  </entry>
  <entry>
    <title>孤儿进程与僵尸进程[总结]（转载）</title>
    <url>/summary-of-orphan-process-and-zombie-process/</url>
    <content><![CDATA[<h2 id="1、前言"><a class="header-anchor" href="#1、前言"></a>1、前言</h2>
<p>之前在看《unix环境高级编程》第八章进程时候，提到孤儿进程和僵尸进程，一直对这两个概念比较模糊。今天被人问到什么是孤儿进程和僵尸进程，会带来什么问题，怎么解决，我只停留在概念上面，没有深入，倍感惭愧。晚上回来google了一下，再次参考APUE，认真总结一下，加深理解。</p>
<h2 id="2、基本概念"><a class="header-anchor" href="#2、基本概念"></a>2、基本概念</h2>
<p>我们知道在unix/linux中，正常情况下，子进程是通过父进程创建的，子进程在创建新的进程。子进程的结束和父进程的运行是一个异步过程,即父进程永远无法预测子进程 到底什么时候结束。 当一个 进程完成它的工作终止之后，它的父进程需要调用wait()或者waitpid()系统调用取得子进程的终止状态。</p>
<p><strong>孤儿进程：一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。</strong></p>
<p><strong>僵尸进程：一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵死进程。</strong></p>
<span id="more"></span>
<h2 id="3、问题及危害"><a class="header-anchor" href="#3、问题及危害"></a>3、问题及危害</h2>
<p>unix提供了一种机制可以保证只要父进程想知道子进程结束时的状态信息， 就可以得到。这种机制就是: 在每个进程退出的时候,内核释放该进程所有的资源,包括打开的文件,占用的内存等。 但是仍然为其保留一定的信息(包括进程号the process ID,退出状态the termination status of the process,运行时间the amount of CPU time taken by the process等)。直到父进程通过wait / waitpid来取时才释放。 但这样就导致了问题，如果进程不调用wait / waitpid的话， 那么保留的那段信息就不会释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程. 此即为僵尸进程的危害，应当避免。</p>
<p>孤儿进程是没有父进程的进程，孤儿进程这个重任就落到了init进程身上，init进程就好像是一个民政局，专门负责处理孤儿进程的善后工作。每当出现一个孤儿进程的时候，内核就把孤 儿进程的父进程设置为init，而init进程会循环地wait()它的已经退出的子进程。这样，当一个孤儿进程凄凉地结束了其生命周期的时候，init进程就会代表党和政府出面处理它的一切善后工作。因此孤儿进程并不会有什么危害。</p>
<p>任何一个子进程(init除外)在exit()之后，并非马上就消失掉，而是留下一个称为僵尸进程(Zombie)的数据结构，等待父进程处理。这是每个 子进程在结束时都要经过的阶段。如果子进程在exit()之后，父进程没有来得及处理，这时用ps命令就能看到子进程的状态是“Z”。如果父进程能及时 处理，可能用ps命令就来不及看到子进程的僵尸状态，但这并不等于子进程不经过僵尸状态。  如果父进程在子进程结束之前退出，则子进程将由init接管。init将会以父进程的身份对僵尸状态的子进程进行处理。</p>
<p>僵尸进程危害场景：</p>
<p>例如有个进程，它定期的产 生一个子进程，这个子进程需要做的事情很少，做完它该做的事情之后就退出了，因此这个子进程的生命周期很短，但是，父进程只管生成新的子进程，至于子进程 退出之后的事情，则一概不闻不问，这样，系统运行上一段时间之后，系统中就会存在很多的僵死进程，倘若用ps命令查看的话，就会看到很多状态为Z的进程。 严格地来说，僵死进程并不是问题的根源，罪魁祸首是产生出大量僵死进程的那个父进程。因此，当我们寻求如何消灭系统中大量的僵死进程时，答案就是把产生大 量僵死进程的那个元凶枪毙掉（也就是通过kill发送SIGTERM或者SIGKILL信号啦）。枪毙了元凶进程之后，它产生的僵死进程就变成了孤儿进 程，这些孤儿进程会被init进程接管，init进程会wait()这些孤儿进程，释放它们占用的系统进程表中的资源，这样，这些已经僵死的孤儿进程 就能瞑目而去了。</p>
<h2 id="3、孤儿进程和僵尸进程测试"><a class="header-anchor" href="#3、孤儿进程和僵尸进程测试"></a>3、孤儿进程和僵尸进程测试</h2>
<p>孤儿进程测试程序如下所示：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;errno.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">pid_t</span> pid;</span><br><span class="line">    <span class="comment">//创建一个进程</span></span><br><span class="line">    pid = fork();</span><br><span class="line">    <span class="comment">//创建失败</span></span><br><span class="line">    <span class="keyword">if</span> (pid &lt; <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        perror(<span class="string">&quot;fork error:&quot;</span>);</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//子进程</span></span><br><span class="line">    <span class="keyword">if</span> (pid == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;I am the child process.\n&quot;</span>);</span><br><span class="line">        <span class="comment">//输出进程ID和父进程ID</span></span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;pid: %d\tppid:%d\n&quot;</span>,getpid(),getppid());</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;I will sleep five seconds.\n&quot;</span>);</span><br><span class="line">        <span class="comment">//睡眠5s，保证父进程先退出</span></span><br><span class="line">        sleep(<span class="number">5</span>);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;pid: %d\tppid:%d\n&quot;</span>,getpid(),getppid());</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;child process is exited.\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//父进程</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;I am father process.\n&quot;</span>);</span><br><span class="line">        <span class="comment">//父进程睡眠1s，保证子进程输出进程id</span></span><br><span class="line">        sleep(<span class="number">1</span>);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;father process is  exited.\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>测试结果如下：<br>
<img src="/assets/summary-of-orphan-process-and-zombie-process/1.jpg" alt=""></p>
<p>僵尸进程测试程序如下所示：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;errno.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">pid_t</span> pid;</span><br><span class="line">    pid = fork();</span><br><span class="line">    <span class="keyword">if</span> (pid &lt; <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        perror(<span class="string">&quot;fork error:&quot;</span>);</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (pid == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;I am child process.I am exiting.\n&quot;</span>);</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;I am father process.I will sleep two seconds\n&quot;</span>);</span><br><span class="line">    <span class="comment">//等待子进程先退出</span></span><br><span class="line">    sleep(<span class="number">2</span>);</span><br><span class="line">    <span class="comment">//输出进程信息</span></span><br><span class="line">    system(<span class="string">&quot;ps -o pid,ppid,state,tty,command&quot;</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;father process is exiting.\n&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>测试结果如下所示：<br>
<img src="/assets/summary-of-orphan-process-and-zombie-process/2.jpg" alt=""></p>
<p>僵尸进程测试2：父进程循环创建子进程，子进程退出，造成多个僵尸进程，程序如下所示：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;errno.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">pid_t</span>  pid;</span><br><span class="line">    <span class="comment">//循环创建子进程</span></span><br><span class="line">    <span class="keyword">while</span>(<span class="number">1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        pid = fork();</span><br><span class="line">        <span class="keyword">if</span> (pid &lt; <span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            perror(<span class="string">&quot;fork error:&quot;</span>);</span><br><span class="line">            <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (pid == <span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;I am a child process.\nI am exiting.\n&quot;</span>);</span><br><span class="line">            <span class="comment">//子进程退出，成为僵尸进程</span></span><br><span class="line">            <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">//父进程休眠20s继续创建子进程</span></span><br><span class="line">            sleep(<span class="number">20</span>);</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>程序测试结果如下所示：<br>
<img src="/assets/summary-of-orphan-process-and-zombie-process/3.jpg" alt=""></p>
<h2 id="4、僵尸进程解决办法"><a class="header-anchor" href="#4、僵尸进程解决办法"></a>4、僵尸进程解决办法</h2>
<h3 id="（1）通过信号机制"><a class="header-anchor" href="#（1）通过信号机制"></a>（1）通过信号机制</h3>
<p>子进程退出时向父进程发送SIGCHILD信号，父进程处理SIGCHILD信号。在信号处理函数中调用wait进行处理僵尸进程。测试程序如下所示：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;errno.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;signal.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="type">void</span> <span class="title function_">sig_child</span><span class="params">(<span class="type">int</span> signo)</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">pid_t</span> pid;</span><br><span class="line">    <span class="comment">//创建捕捉子进程退出信号</span></span><br><span class="line">    signal(SIGCHLD,sig_child);</span><br><span class="line">    pid = fork();</span><br><span class="line">    <span class="keyword">if</span> (pid &lt; <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        perror(<span class="string">&quot;fork error:&quot;</span>);</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (pid == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;I am child process,pid id %d.I am exiting.\n&quot;</span>,getpid());</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;I am father process.I will sleep two seconds\n&quot;</span>);</span><br><span class="line">    <span class="comment">//等待子进程先退出</span></span><br><span class="line">    sleep(<span class="number">2</span>);</span><br><span class="line">    <span class="comment">//输出进程信息</span></span><br><span class="line">    system(<span class="string">&quot;ps -o pid,ppid,state,tty,command&quot;</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;father process is exiting.\n&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="type">void</span> <span class="title function_">sig_child</span><span class="params">(<span class="type">int</span> signo)</span></span><br><span class="line">&#123;</span><br><span class="line">     <span class="type">pid_t</span>        pid;</span><br><span class="line">     <span class="type">int</span>        stat;</span><br><span class="line">     <span class="comment">//处理僵尸进程</span></span><br><span class="line">     <span class="keyword">while</span> ((pid = waitpid(<span class="number">-1</span>, &amp;stat, WNOHANG)) &gt;<span class="number">0</span>)</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;child %d terminated.\n&quot;</span>, pid);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>测试结果如下所示：<br>
程序测试结果如下所示：<br>
<img src="/assets/summary-of-orphan-process-and-zombie-process/4.jpg" alt=""></p>
<h3 id="（2）fork两次"><a class="header-anchor" href="#（2）fork两次"></a>（2）fork两次</h3>
<p>《Unix 环境高级编程》8.6节说的非常详细。原理是将子进程成为孤儿进程，从而其的父进程变为init进程，通过init进程可以处理僵尸进程。测试程序如下所示：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;errno.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">pid_t</span>  pid;</span><br><span class="line">    <span class="comment">//创建第一个子进程</span></span><br><span class="line">    pid = fork();</span><br><span class="line">    <span class="keyword">if</span> (pid &lt; <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        perror(<span class="string">&quot;fork error:&quot;</span>);</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//第一个子进程</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (pid == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">//子进程再创建子进程</span></span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;I am the first child process.pid:%d\tppid:%d\n&quot;</span>,getpid(),getppid());</span><br><span class="line">        pid = fork();</span><br><span class="line">        <span class="keyword">if</span> (pid &lt; <span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            perror(<span class="string">&quot;fork error:&quot;</span>);</span><br><span class="line">            <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//第一个子进程退出</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (pid &gt;<span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;first procee is exited.\n&quot;</span>);</span><br><span class="line">            <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//第二个子进程</span></span><br><span class="line">        <span class="comment">//睡眠3s保证第一个子进程退出，这样第二个子进程的父亲就是init进程里</span></span><br><span class="line">        sleep(<span class="number">3</span>);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;I am the second child process.pid: %d\tppid:%d\n&quot;</span>,getpid(),getppid());</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//父进程处理第一个子进程退出</span></span><br><span class="line">    <span class="keyword">if</span> (waitpid(pid, <span class="literal">NULL</span>, <span class="number">0</span>) != pid)</span><br><span class="line">    &#123;</span><br><span class="line">        perror(<span class="string">&quot;waitepid error:&quot;</span>);</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>测试结果如下图所示：<br>
<img src="/assets/summary-of-orphan-process-and-zombie-process/5.jpg" alt=""></p>
<h2 id="5、参考资料"><a class="header-anchor" href="#5、参考资料"></a>5、参考资料</h2>
<ul>
<li>《unix环境高级编程》第八章</li>
<li><a href="http://www.rosoo.net/a/201109/15071.html">http://www.rosoo.net/a/201109/15071.html</a></li>
<li><a href="http://blog.chinaunix.net/uid-1829236-id-3166986.html">http://blog.chinaunix.net/uid-1829236-id-3166986.html</a></li>
<li><a href="http://forkhope.diandian.com/post/2012-10-01/40040574200">http://forkhope.diandian.com/post/2012-10-01/40040574200</a></li>
<li><a href="http://blog.csdn.net/metasearch/article/details/2498853">http://blog.csdn.net/metasearch/article/details/2498853</a></li>
<li><a href="http://blog.csdn.net/yuwenliang/article/details/6770750">http://blog.csdn.net/yuwenliang/article/details/6770750</a></li>
</ul>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/summary-of-orphan-process-and-zombie-process/">http://xnerv.wang/summary-of-orphan-process-and-zombie-process/</a></strong><br>
转载自：<a href="http://www.cnblogs.com/Anker/p/3271773.html">孤儿进程与僵尸进程[总结]</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Linux</tag>
        <tag>进程管理</tag>
        <tag>孤儿进程</tag>
        <tag>僵尸进程</tag>
      </tags>
  </entry>
  <entry>
    <title>TCP模型知识点总结</title>
    <url>/tcp-model-knowledge-summary/</url>
    <content><![CDATA[<h2 id="协议格式"><a class="header-anchor" href="#协议格式"></a>协议格式</h2>
<h3 id="IPv4"><a class="header-anchor" href="#IPv4"></a><a href="http://blog.csdn.net/ce123_zhouwei/article/details/17453033">IPv4</a></h3>
<p><img src="/assets/tcp-model-knowledge-summary/ipv4.jpg" alt="IPv4头"><br>
IP首部中的校验和只覆盖IP的首部，不覆盖IP数据报中的任何数据。<br>
IP层会丢弃传输中损坏的数据报，但是不产生错误消息，由上层去检测和重传。但是如果发生了分片，IP层应该能保证原子性。<br>
在IP层下面的每一种数据链路层都有自己的帧格式，其中包括帧格式中的数据字段的最大长度，即最大传送单元 MTU (Maximum Transfer Unit)。当一个数据报封装成链路层的帧时，此数据报的总长度（即首部加上数据部分）最好不能超过下面的数据链路层的MTU值，否则要分片。<br>
增加首部的可变部分是为了增加IP数据报的功能，但这同时也使得IP数据报的首部长度成为可变的。这就增加了每一个路由器处理数据报的开销，实际上这些选项很少被使用。新的IP版本IPv6就将IP数据报的首部长度做成固定的。<br>
IP包中只有首部检验和，由TCP和UDP报文各自包含自身的数据校验和。</p>
<span id="more"></span>
<h3 id="IPv6"><a class="header-anchor" href="#IPv6"></a>IPv6</h3>
<p><img src="/assets/tcp-model-knowledge-summary/ipv6.png" alt="IPv6头"></p>
<h4 id="IPv6的区别"><a class="header-anchor" href="#IPv6的区别"></a>IPv6的区别</h4>
<ul>
<li>
<p>首部长度<br>
首部长度可变，IPv4首部的选项字段允许IP首部被扩展，由此导致数据报首部长度可变，故不能预先确定数据字段从何开始，同时也使路由器处理一个IP数据报所需时间差异很大(有的要处理选项，有的不需要)。基于此，IPv6采用固定40字节长度的报头长度(称基本报头)。IPv6如何实现IPv4选项字段类似的功能，答案是扩展报头，并由IPv6基本报头的下一个首部指向扩展报头(如果有的话)。路由器不处理扩展报头，提升了路由器处理效率。</p>
</li>
<li>
<p>分片/重组<br>
IPv6，分片与重组只能在源与目的地上执行，不允许在中间路由器进行。分片与重组是个耗时的操作，将该功能从路由器转移到端系统，大大加快了网络中的IP转发速率。那，如果路由器收到IPv6数据报太大而不能转发到出链路上怎么办？该路由器丢弃该包，并向发送发发回一个&quot;分组太大&quot;的ICMP差错报文，于是发送发使用较小长度的IP数据报重发数据。</p>
</li>
<li>
<p>首部检查和<br>
IPv4中由于TTL的递减，所以每经过一个路由器都需要重新计算校验和，导致路由器处理速度的低下。加之，传输层和链路层协议执行了检验操作，网络传输可靠性提升，所以IPv6不进行首部检查和，从而更快速处理IP分组。（但在网络传输的过程中，链路层packet是可能损坏的，考虑到厂商设备的多样性和高负载。所以TCP校验应该是关键，如果发现checksum不对，TCP可以要求对方重传丢失的内容。）</p>
</li>
</ul>
<h3 id="TCP头"><a class="header-anchor" href="#TCP头"></a>TCP头</h3>
<p><img src="/assets/tcp-model-knowledge-summary/tcp.jpg" alt="TCP头"><br>
校验和是针对header和data计算出来的。TCP和UDP计算校验和时，都要加上一个12字节的伪首部。伪首部共有12字节，包含如下信息：源IP地址、目的IP地址、保留字节(置0)、传输层协议号(TCP是6)、TCP报文长度(报头+数据)。伪首部是为了增加TCP校验和的检错能力：如检查TCP报文是否收错了(目的IP地址)、传输层协议是否选对了(传输层协议号)等。<br>
TCP和UDP的报文都没有一个字段可以表明自身长度，这个长度是由IP包中的总长度来记录的。</p>
<p><a href="http://blog.csdn.net/wilsonpeng3/article/details/12869233">TCP报文段首部格式详解</a></p>
<blockquote>
<ul>
<li>TCP首部长度：由于TCP首部包含一个长度可变的选项部分，所以需要这么一个值来指定这个TCP报文段到底有多长。或者可以这么理解：就是表示TCP报文段中数据部分在整个TCP报文段中的位置。该字段的单位是32位字，即：4个字节。</li>
<li>选项部分：其最大长度可根据TCP首部长度进行推算。TCP首部长度用4位表示，那么选项部分最长为：(2^4-1)*4-20=40字节（但要全零填充为4字节的整数倍）。</li>
<li>选项部分的应用：
<ol>
<li>MSS最大报文段长度(Maxium Segment Size)：指明数据字段的最大长度，数据字段的长度加上TCP首部的长度才等于整个TCP报文段的长度。MSS值指示自己期望对方发送TCP报文段时那个数据字段的长度。通信双方可以有不同的MSS值。如果未填写，默认采用536字节。MSS只出现在SYN报文中。即：MSS出现在SYN=1的报文段中。</li>
<li>窗口扩大选项(Windows Scaling)：由于TCP首部的窗口大小字段长度是16位，所以其表示的最大数是65535。但是随着时延和带宽比较大的通信产生（如卫星通信），需要更大的窗口来满足性能和吞吐率，所以产生了这个窗口扩大选项。</li>
<li>SACK选择确认项(Selective Acknowledgements)：用来确保只重传缺少的报文段，而不是重传所有报文段。比如主机A发送报文段1、2、3，而主机B仅收到报文段1、3。那么此时就需要使用SACK选项来告诉发送方只发送丢失的数据。那么又如何指明丢失了哪些报文段呢？使用SACK需要两个功能字节。一个表示要使用SACK选项，另一个指明这个选项占用多少字节。描述丢失的报文段2，是通过描述它的左右边界报文段1、3来完成的。而这个1、3实际上是表示序列号，所以描述一个丢失的报文段需要64位即8个字节的空间。那么可以推算整个选项字段最多描述(40-2)/8=4个丢失的报文段。</li>
<li>时间戳选项（Timestamps）：可以用来计算RTT(往返时间)，发送方发送TCP报文时，把当前的时间值放入时间戳字段，接收方收到后发送确认报文时，把这个时间戳字段的值复制到确认报文中，当发送方收到确认报文后即可计算出RTT。也可以用来防止回绕序号PAWS，也可以说可以用来区分相同序列号的不同报文。因为序列号用32为表示，每2^32个序列号就会产生回绕，那么使用时间戳字段就很容易区分相同序列号的不同报文。</li>
<li>NOP(NO-Operation)：它要求选项部分中的每种选项长度必须是4字节的倍数，不足的则用NOP填充。同时也可以用来分割不同的选项字段。如窗口扩大选项和SACK之间用NOP隔开。</li>
</ol>
</li>
</ul>
</blockquote>
<h3 id="UDP"><a class="header-anchor" href="#UDP"></a>UDP</h3>
<p><a href="http://blog.csdn.net/wypblog/article/details/7494458">linux网络编程之：UDP数据包格式</a><br>
<img src="/assets/tcp-model-knowledge-summary/udp.jpg" alt="UCP头"></p>
<blockquote>
<p>UDP数据报格式有首部和数据两个部分。首部很简单，共8字节。包括：</p>
<ul>
<li>源端口（Source Port）：2字节，源端口号。</li>
<li>目的端口（Destination Port ）：2字节，目的端口号。</li>
<li>长度（Length）：2字节，UDP用户数据报的总长度，以字节为单位。</li>
<li>检验和（Checksum）：2字节，用于校验UDP数据报的数字段和包含UDP数据报首部的“伪首部”。其校验方法同IP分组首部中的首部校验和。</li>
</ul>
<p>伪首部，又称为伪包头（Pseudo Header）：是指在TCP的分段或UDP的数据报格式中，在数据报首部前面增加源IP地址、目的IP地址、IP分组的协议字段、TCP或UDP数据报的总长度等共12字节，所构成的扩展首部结构。此伪首部是一个临时的结构，它既不向上也不向下传递，仅仅只是为了保证可以校验套接字的正确性。</p>
</blockquote>
<p>UDP的校验和是可选的，如果校验码为 0 ,意味着发送者末产生校验码。这表示对于数据段不使用校验,因为 IP 只是对 IP 首部进行校验。</p>
<h4 id="RST"><a class="header-anchor" href="#RST"></a>RST</h4>
<p>产生复位的一种常见情况是当连接请求到达时，目的端口没有进程正在监听。对于UDP，当一个数据报到达目的端口时，该端口没在使用，它将产生一个ICMP端口不可达的信息。而TCP则使用复位/重置连接。<br>
RST报文段不会导致另一端产生任何响应，另一端根本不进行确认。收到RST的一方将终止该连接，并通知应用层连接复位。</p>
<h4 id="带外数据SO-OOBINLINE"><a class="header-anchor" href="#带外数据SO-OOBINLINE"></a><a href="http://blog.csdn.net/ordeder/article/details/43243425">带外数据SO_OOBINLINE</a></h4>
<p>其实就是一个指针指向正常数据中的一个字节的后一个字节位置。<br>
<a href="http://blog.chinaunix.net/uid-1728743-id-4945690.html">别用TCP的紧急数据</a>提到带外数据已经不建议使用。同时提到带外数据可以用于控制意图，这样就不用像FTP一样得单独开一个控制连接了。<br>
TCP的紧急指针，一般都不建议使用，而且不同的TCP/IP实现，也不同，一般说如果你有紧急数据宁愿再建立一个新的TCP/IP连接发送数据，让对方紧急处理。但是，虽然sendUrgentData的参数data是int类型，但只有这个int类型的低字节被发送，其它的三个字节被忽略。<br>
接收端如何处理这个数据存在一些模糊。有的平台和API把它和平常数据分开处理，然后大多数解决方案是把它放到普通数据队列，让应用自己去从队列中获取处理。</p>
<h2 id="一些TCP参数"><a class="header-anchor" href="#一些TCP参数"></a>一些TCP参数</h2>
<h3 id="tcp-max-syn-backlog"><a class="header-anchor" href="#tcp-max-syn-backlog"></a>tcp_max_syn_backlog</h3>
<p><a href="https://yq.aliyun.com/articles/4252?&amp;utm_campaign=sys&amp;utm_medium=market&amp;utm_source=edm_email&amp;msctype=email&amp;mscmsgid=111616021800142609">Linux TCP队列相关参数的总结</a></p>
<blockquote>
<p>建立连接涉及两个队列：<br>
半连接队列，保存SYN_RECV状态的连接。队列长度由net.ipv4.tcp_max_syn_backlog设置。<br>
accept队列，保存ESTABLISHED状态的连接。队列长度为min(net.core.somaxconn, backlog)。其中backlog是我们创建ServerSocket(intport, int backlog)时指定的参数，最终会传递给listen方法。</p>
</blockquote>
<p><a href="http://www.cnxct.com/something-about-phpfpm-s-backlog/">TCP SOCKET中backlog参数的用途是什么？</a><br>
在linux 2.2以前，backlog大小包括了半连接状态和全连接状态两种队列大小。linux 2.2以后，分离为两个backlog来分别限制半连接SYN_RCVD状态的未完成连接队列大小跟全连接ESTABLISHED状态的已完成连接队列大小。互联网上常见的TCP SYN FLOOD恶意DOS攻击方式就是用/proc/sys/net/ipv4/tcp_max_syn_backlog来控制的。<br>
在使用listen函数时，内核会根据传入参数的backlog跟系统配置参数/proc/sys/net/core/somaxconn中，二者取最小值，作为“ESTABLISHED状态之后，完成TCP连接，等待服务程序ACCEPT”的队列大小。在kernel 2.4.25之前，是写死在代码常量SOMAXCONN，默认值是128。在kernel 2.4.25之后，在配置文件/proc/sys/net/core/somaxconn (即 /etc/sysctl.conf 之类 )中可以修改。<br>
<img src="http://img2.cnxct.com/2015/06/tcp-sync-queue-and-accept-queue-small-1024x747.jpg" alt="tcp-sync-queue-and-accept-queue"></p>
<p><a href="http://veithen.github.io/2014/01/01/how-tcp-backlog-works-in-linux.html">How TCP backlog works in Linux</a><br>
backlog为0 时在linux上表明允许不受限制的连接数，这是一个缺陷，因为它可能会导致SYN Flooding(拒绝服务型攻击。</p>
<h3 id="tcp-tw-recycle-：BOOLEAN"><a class="header-anchor" href="#tcp-tw-recycle-：BOOLEAN"></a>tcp_tw_recycle ：BOOLEAN</h3>
<p>默认值是0。<br>
打开快速 TIME-WAIT sockets 回收。除非得到技术专家的建议或要求﹐请不要随意修改这个值。(做NAT的时候，建议打开它)。</p>
<h3 id="tcp-tw-reuse：BOOLEAN"><a class="header-anchor" href="#tcp-tw-reuse：BOOLEAN"></a>tcp_tw_reuse：BOOLEAN</h3>
<p>默认值是0。<br>
该文件表示是否允许重新应用处于TIME-WAIT状态的socket用于新的TCP连接(这个对快速重启动某些服务,而启动后提示端口已经被使用的情形非常有帮助)。</p>
<h3 id="tcp-max-orphans-：INTEGER"><a class="header-anchor" href="#tcp-max-orphans-：INTEGER"></a>tcp_max_orphans ：INTEGER</h3>
<p>缺省值是8192。<br>
系统所能处理不属于任何进程的TCP sockets最大数量。假如超过这个数量﹐那么不属于任何进程的连接会被立即reset，并同时显示警告信息。之所以要设定这个限制﹐纯粹为了抵御那些简单的 DoS 攻击﹐千万不要依赖这个或是人为的降低这个限制(这个值Redhat AS版本中设置为32768，但是很多防火墙修改的时候,，议该值修改为2000)。</p>
<h3 id="tcp-abort-on-overflow-：BOOLEAN"><a class="header-anchor" href="#tcp-abort-on-overflow-：BOOLEAN"></a>tcp_abort_on_overflow ：BOOLEAN</h3>
<p>缺省值是0。<br>
当守护进程太忙而不能接受新的连接，就向对方发送reset消息，默认值是false。这意味着当溢出的原因是因为一个偶然的猝发，那么连接将恢复状态。只有在你确信守护进程真的不能完成连接请求时才打开该选项，该选项会影响客户的使用。(对待已经满载的sendmail，apache这类服务的时候，这个可以很快让客户端终止连接，可以给予服务程序处理已有连接的缓冲机会,所以很多防火墙上推荐打开它)。</p>
<h3 id="TCP-NODELAY"><a class="header-anchor" href="#TCP-NODELAY"></a>TCP_NODELAY</h3>
<p><a href="https://www.cnblogs.com/god-of-death/p/7154481.html">神秘的40毫秒延迟与TCP_NODELAY</a></p>
<blockquote>
<p>Nagle’s Algorithm 是为了提高带宽利用率设计的算法，其做法是合并小的TCP 包为一个，避免了过多的小报文的 TCP 头所浪费的带宽。如果开启了这个算法 （默认），则协议栈会累积数据直到以下两个条件之一满足的时候才真正发送出 去：</p>
<ul>
<li>积累的数据量到达最大的 TCP Segment Size。</li>
<li>收到了一个 Ack。<br>
TCP Delayed Acknoledgement 也是为了类似的目的被设计出来的，它的作用就是延迟 Ack 包的发送，使得协议栈有机会合并多个 Ack，提高网络性能。<br>
如果一个 TCP 连接的一端启用了 Nagle‘s Algorithm，而另一端启用了 TCP Delayed Ack，而发送的数据包又比较小，则可能会出现这样的情况：发送端在等待接收端对上一个packet 的 Ack 才发送当前的 packet，而接收端则正好延迟了 此 Ack 的发送，那么这个正要被发送的 packet 就会同样被延迟。当然 Delayed Ack 是有个超时机制的，而默认的超时正好就是 40ms。<br>
现代的 TCP/IP 协议栈实现，默认几乎都启用了这两个功能，你可能会想，按我上面的说法，当协议报文很小的时候，岂不每次都会触发这个延迟问题？事实不是那样的。仅当协议的交互是发送端连续发送两个 packet，然后立刻 read 的时候才会出现问题。</li>
</ul>
</blockquote>
<p>Nagle算法主要是避免发送小的数据包，要求TCP连接上最多只能有一个未被确认的小分组，在该分组的确认到达之前不能发送其他的小分组。相反，TCP收集这些少量的小分组，并在确认到来时以一个分组的方式发出去。</p>
<h3 id="SO-LINGER"><a class="header-anchor" href="#SO-LINGER"></a>SO_LINGER</h3>
<p>设置函数close()关闭TCP连接时的行为。缺省close()的行为是，如果有数据残留在socket发送缓冲区中则系统将继续发送这些数据给对方，等待被确认，然后返回。SO_LINGER选项用来改变此缺省设置。使用如下结构：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">struct linger &#123;</span><br><span class="line">     int l_onoff; /* 0 = off, nozero = on */</span><br><span class="line">     int l_linger; /* linger time */</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>l_onoff</th>
<th>l_linger</th>
<th>closesocket行为</th>
<th>发送队列</th>
<th>底层行为</th>
</tr>
</thead>
<tbody>
<tr>
<td>零</td>
<td>忽略</td>
<td>立即返回。</td>
<td>保持直至发送完成。</td>
<td>系统接管套接字并保证将数据发送至对端。</td>
</tr>
<tr>
<td>非零</td>
<td>零</td>
<td>立即返回。</td>
<td>立即放弃。</td>
<td>直接发送RST包，自身立即复位，不用经过2MSL状态。对端收到复位错误号。</td>
</tr>
<tr>
<td>非零</td>
<td>非零</td>
<td>阻塞直到l_linger时间超时或数据发送完成。(套接字必须设置为阻塞)</td>
<td>在超时时间段内保持尝试发送，若超时则立即放弃。</td>
<td>超时则同第二种情况，若发送完成则皆大欢喜。</td>
</tr>
</tbody>
</table>
<p>第二种设置主要是为了避免主动断开连接方进入TIME_WAIT状态。丢失缓冲区中未丢失数据只是一种副作用。</p>
<h3 id="SO-REUSEADDR-SO-REUSEPORT"><a class="header-anchor" href="#SO-REUSEADDR-SO-REUSEPORT"></a>SO_REUSEADDR / SO_REUSEPORT</h3>
<p><a href="http://blog.csdn.net/yaokai_assultmaster/article/details/68951150">浅析套接字中SO_REUSEPORT和SO_REUSEADDR的区别</a></p>
<h3 id="SO-KEEPALIVE"><a class="header-anchor" href="#SO-KEEPALIVE"></a><a href="http://tldp.org/HOWTO/TCP-Keepalive-HOWTO/overview.html">SO_KEEPALIVE</a></h3>
<p>貌似是由发起连接方（客户端）主动发给服务端的，就是一个data size为0的packet，服务器收到这个packet也会回复一个同样data size为0的packet表明连接仍存活。</p>
<p><strong>SO_KEEPALIVE和心跳线程</strong><br>
SO_KEEPALIVE是系统底层的机制，用于系统维护每一个tcp连接的。<br>
心跳线程属于应用层，主要用于终端和服务器连接的检查。<br>
即使SO_KEEPALIVE检测到连接正常，但并不能保证终端和服务器连接的正常。有一种情况，服务器进程死了，但它和客户端的tcp连接还连着（该连接由系统维护的）。<br>
这就是SO_KEEPALIVE不能取代心跳线程的原因吧。</p>
<h2 id="TCP协议"><a class="header-anchor" href="#TCP协议"></a>TCP协议</h2>
<p><img src="http://coolshell.cn//wp-content/uploads/2009/09/tcp1.jpg" alt="TCP状态转换图"></p>
<h3 id="四次挥手"><a class="header-anchor" href="#四次挥手"></a>四次挥手</h3>
<p><img src="http://dl.iteye.com/upload/attachment/0077/3159/734c7efd-3d62-3946-a234-acdddff3b507.jpg" alt="四次挥手状态转换图"><br>
其实也可以看成两次过程，任何一方发送FIN表明自己不会再发送数据。</p>
<h4 id="TIME-WAIT（涉及主动断开连接一方）"><a class="header-anchor" href="#TIME-WAIT（涉及主动断开连接一方）"></a>TIME_WAIT（涉及主动断开连接一方）</h4>
<p>TCP协议在关闭连接的四次握手过程中，<strong>最终的ACK</strong> 是由 <strong>主动关闭连接</strong> 的一端（后面统称A端）发出的，如果这个ACK丢失，对方（后面统称B端）将重发出最终的FIN，因此A端必须维护状态信息（TIME_WAIT）允许它重发最终的ACK。如果A端不维持TIME_WAIT状态，而是处于CLOSED 状态，那么A端将响应RST分节，B端收到后将此分节解释成一个错误（在java中会抛出connection reset的SocketException)。<br>
因而，要实现TCP全双工连接的正常终止，必须处理终止过程中四个分节任何一个分节的丢失情况，主动关闭连接的A端必须维持TIME_WAIT状态。<br>
主动关闭的一方要负责处于TIME_WAIT状态中。MSL就是maximum segment lifetime(最大分节生命期），这是一个IP数据包能在互联网上生存的最长时间，超过这个时间IP数据包将在网络中消失 。MSL在RFC 1122上建议是2分钟，而源自berkeley的TCP实现传统上使用30秒。Windows使用的是2分钟，而Linux则是30秒。</p>
<h4 id="CLOSE-WAIT（涉及被动断开连接一方）"><a class="header-anchor" href="#CLOSE-WAIT（涉及被动断开连接一方）"></a>CLOSE_WAIT（涉及被动断开连接一方）</h4>
<p>在被动关闭连接情况下，在已经接收到FIN，但是还没有发送自己的FIN的时刻，连接处于CLOSE_WAIT状态。<br>
出现大量CLOSE_WAIT的现象，主要原因是某种情况下对方关闭socket链接，但是我方忙与读或者写，没有关闭连接。代码需要判断socket，一旦读到0，断开连接，read返回负，检查一下errno，如果不是AGAIN，就断开连接。</p>
<p><a href="http://blog.csdn.net/shootyou/article/details/6622226">服务器TIME_WAIT和CLOSE_WAIT详解和解决办法</a></p>
<h3 id="拥塞控制"><a class="header-anchor" href="#拥塞控制"></a>拥塞控制</h3>
<p><img src="http://img.blog.csdn.net/20130801220438375?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc2ljb2ZpZWxk/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="拥塞避免算法"></p>
<p>当cwnd&lt;ssthresh时，使用慢开始算法。<br>
当cwnd&gt;ssthresh时，改用拥塞避免算法。<br>
当cwnd=ssthresh时，慢开始与拥塞避免算法任意。</p>
<h3 id="快重传和快恢复"><a class="header-anchor" href="#快重传和快恢复"></a>快重传和快恢复</h3>
<p>快重传要求接收方在收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时捎带确认。快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。</p>
<p>快重传配合使用的还有快恢复算法，有以下两个要点:</p>
<ol>
<li>当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把ssthresh门限减半。但是接下去并不执行慢开始算法。</li>
<li>考虑到如果网络出现拥塞的话就不会收到好几个重复的确认，所以发送方现在认为网络可能没有出现拥塞。所以此时不执行慢开始算法，而是将cwnd设置为ssthresh的大小，然后执行拥塞避免算法。如下图：</li>
</ol>
<p><img src="http://img.blog.csdn.net/20130801220556750?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc2ljb2ZpZWxk/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="快重传的示意图"></p>
<h3 id="随机早期检测RED"><a class="header-anchor" href="#随机早期检测RED"></a><a href="http://blog.csdn.net/sicofield/article/details/9708383">随机早期检测RED</a></h3>
<p>若发生路由器的尾部丢弃，可能影响到很多条TCP连接，结果就是这许多的TCP连接在同一时间进入慢开始状态。这在术语中称为全局同步。全局同步会使得网络的通信量突然下降很多，而在网络恢复正常之后，其通信量又突然增大很多。<br>
为避免发生网路中的全局同步现象，路由器采用随机早期检测(RED:randomearly detection)。</p>
<h3 id="msl、ttl及rtt的区别"><a class="header-anchor" href="#msl、ttl及rtt的区别"></a>msl、ttl及rtt的区别</h3>
<ol>
<li>MSL 是Maximum Segment Lifetime英文的缩写，中文可以译为“报文最大生存时间”，他是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。例如RIP协议用经过的最大路由节点数作为MSL。</li>
<li>IP头中有一个TTL域，TTL是 time to live的缩写，中文可以译为“生存时间”，这个生存时间是由源主机设置初始值但不是存的具体时间，而是存储了一个ip数据报可以经过的最大路由数，每经 过一个处理他的路由器此值就减1，当此值为0则数据报将被丢弃，同时发送ICMP报文通知源主机。RFC 793中规定MSL为2分钟，实际应用中常用的是30秒，1分钟和2分钟等。<br>
TTL与MSL是有关系的但不是简单的相等的关系，MSL要大于等于TTL。</li>
<li>RTT是客户到服务器往返所花时间（round-trip time，简称RTT），TCP含有动态估算RTT的算法。TCP还持续估算一个给定连接的RTT，这是因为RTT受网络传输拥塞程序的变化而变化。</li>
</ol>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/tcp-model-knowledge-summary/">http://xnerv.wang/tcp-model-knowledge-summary/</a></strong></p>
]]></content>
      <categories>
        <category>网络协议</category>
      </categories>
      <tags>
        <tag>网络协议</tag>
        <tag>原创</tag>
        <tag>TCP</tag>
        <tag>IP</tag>
        <tag>UDP</tag>
      </tags>
  </entry>
  <entry>
    <title>RSYNC的核心算法（转载）</title>
    <url>/the-core-algorithm-of-rsync/</url>
    <content><![CDATA[<p><a href="http://en.wikipedia.org/wiki/Rsync">rsync</a>是unix/linux下同步文件的一个高效算法，它能同步更新两处计算机的文件与目录，并适当利用查找文件中的不同块以减少数据传输。rsync中一项与其他大部分类似程序或协定中所未见的重要特性是镜像是只对有变更的部分进行传送。rsync可拷贝／显示目录属性，以及拷贝文件，并可选择性的压缩以及递归拷贝。rsync利用由<a href="http://en.wikipedia.org/wiki/Andrew_Tridgell">Andrew Tridgell</a>发明的算法。这里不介绍其使用方法，只介绍其核心算法。我们可以看到，Unix下的东西，一个命令，一个工具都有很多很精妙的东西，怎么学也学不完，这就是<a href="https://coolshell.cn/articles/2322.html" title="Unix传奇(上篇)">Unix的文化</a>啊。</p>
<p>本来不想写这篇文章的，因为原先发现有很多中文blog都说了这个算法，但是看了一下，发现这些中文blog要么翻译国外文章翻译地非常烂，要么就是介绍这个算法介绍得很乱让人看不懂，还有错误，误人不浅，所以让我觉得有必要写篇rsync算法介绍的文章。（当然，我成文比较仓促，可能会有一些错误，请指正）</p>
<span id="more"></span>
<h2 id="问题"><a class="header-anchor" href="#问题"></a>问题</h2>
<p>首先， 我们先来想一下rsync要解决的问题，如果我们要同步的文件只想传不同的部分，我们就需要对两边的文件做diff，但是这两个问题在两台不同的机器上，无法做diff。如果我们做diff，就要把一个文件传到另一台机器上做diff，但这样一来，我们就传了整个文件，这与我们只想传输不同部的初衷相背。</p>
<p>于是我们就要想一个办法，让这两边的文件见不到面，但还能知道它们间有什么不同。这就出现了rsync的算法。</p>
<h2 id="算法"><a class="header-anchor" href="#算法"></a>算法</h2>
<p>rsync的算法如下：（<strong>假设我们同步源文件名为fileSrc，同步目的文件叫fileDst</strong>）</p>
<p>1）<strong>分块Checksum算法</strong>。首先，我们会把fileDst的文件平均切分成若干个小块，比如每块512个字节（最后一块会小于这个数），然后对每块计算两个checksum，</p>
<ul>
<li>一个叫<a href="http://en.wikipedia.org/wiki/Rolling_hash">rolling checksum</a>，是弱checksum，32位的checksum，其使用的是Mark Adler发明的<a href="http://en.wikipedia.org/wiki/Adler-32" title="Adler-32">adler-32</a>算法，</li>
<li>另一个是强checksum，128位的，以前用md4，现在用md5 hash算法。</li>
</ul>
<p>为什么要这样？因为若干年前的硬件上跑md4的算法太慢了，所以，我们需要一个快算法来鉴别文件块的不同，但是弱的adler32算法碰撞概率太高了，所以我们还要引入强的checksum算法以保证两文件块是相同的。<strong>也就是说，弱的checksum是用来区别不同，而强的是用来确认相同</strong>。（checksum的具体公式可以参看<a href="http://rsync.samba.org/tech_report/node3.html">这篇文章</a>）</p>
<p>2）**传输算法。**同步目标端会把fileDst的一个checksum列表传给同步源，这个列表里包括了三个东西，<strong>rolling checksum(32bits)</strong>，<strong>md5 checksume(128bits)</strong>，<strong>文件块编号</strong>。</p>
<p>我估计你猜到了同步源机器拿到了这个列表后，会对fileSrc做同样的checksum，然后和fileDst的checksum做对比，这样就知道哪些文件块改变了。</p>
<p>但是，聪明的你一定会有以下两个疑问：</p>
<ul>
<li>
<p>如果我fileSrc这边在文件中间加了一个字符，这样后面的文件块都会位移一个字符，这样就完全和fileDst这边的不一样了，但理论上来说，我应该只需要传一个字符就好了。这个怎么解决？</p>
</li>
<li>
<p>如果这个checksum列表特别长，而我的两边的相同的文件块可能并不是一样的顺序，那就需要查找，线性的查找起来应该特别慢吧。这个怎么解决？</p>
</li>
</ul>
<p>很好，让我们来看一下同步源端的算法。</p>
<p>3）<strong>checksum查找算法</strong>。同步源端拿到fileDst的checksum数组后，会把这个数据存到一个hash table中，用rolling checksum做hash，以便获得O(1)时间复杂度的查找性能。这个hash table是16bits的，所以，hash table的尺寸是2的16次方，对rolling checksum的hash会被散列到0 到 2^16 – 1中的某个整数值。（对于hash table，如果你不清楚，建议回去看大学时的数据结构教科书）</p>
<p>顺便说一下，我在网上看到很多文章说，“要对rolling checksum做排序”（比如<a href="http://www.yejun.cn/?p=472">这篇</a>和<a href="http://blog.csdn.net/tobeandnottobe/article/details/6719848">这篇</a>），这两篇文章都引用并翻译了<a href="http://rsync.samba.org/tech_report/node4.html">原作者的这篇文章</a>，但是他们都理解错了，不是排序，就只是把fileDst的checksum数据，按rolling checksum做存到2^16的hash table中，当然会发生碰撞，把碰撞的做成一个链表就好了。这就是<a href="http://rsync.samba.org/tech_report/node4.html">原文</a>中所说的第二步——搜索有碰撞的情况。</p>
<p>4）<strong>比对算法</strong>。这是最关键的算法，细节如下：</p>
<p>4.1）取fileSrc的第一个文件块（我们假设的是512个长度），也就是从fileSrc的第1个字节到第512个字节，取出来后做rolling checksum计算。计算好的值到hash表中查。</p>
<p>4.2）如果查到了，说明发现在fileDst中有潜在相同的文件块，于是就再比较md5的checksum，因为rolling checksume太弱了，可能发生碰撞。于是还要算md5的128bits的checksum，这样一来，我们就有 2^-(32+128) = 2^-160的概率发生碰撞，这太小了可以忽略。<strong>如果rolling checksum和md5 checksum都相同，这说明在fileDst中有相同的块，我们需要记下这一块在fileDst下的文件编号</strong>。</p>
<p>4.3）如果fileSrc的rolling checksum 没有在hash table中找到，那就不用算md5 checksum了。表示这一块中有不同的信息。总之，只要rolling checksum 或 md5 checksum 其中有一个在fileDst的checksum hash表中找不到匹配项，那么就会触发算法对fileSrc的rolling动作。于是，<strong>算法会住后step 1个字节，取fileSrc中字节2-513的文件块要做checksum，go to (4.1)</strong> – 现在你明白什么叫rolling checksum了吧。</p>
<p>4.4）这样，我们就可以找出fileSrc相邻两次匹配中的那些文本字符，这些就是我们要往同步目标端传的文件内容了。</p>
<h2 id="图示"><a class="header-anchor" href="#图示"></a>图示</h2>
<p>怎么，你没看懂？ 好吧，我送佛送上西，画个示意图给你看看（对图中的东西我就不再解释了）。</p>
<p><img src="https://coolshell.cn/wp-content/uploads/2012/05/rsync-algorithm.jpg" alt="" title="rsync algorithm"></p>
<p>这样，最终，在同步源这端，我们的rsync算法可能会得到下面这个样子的一个数据数组，图中，红色块表示在目标端已匹配上，不用传输（注：我专门在其中显示了两块chunk #5，相信你会懂的），而白色的地方就是需要传输的内容（注意：这些白色的块是不定长的），这样，同步源这端把这个数组（白色的就是实际内容，红色的就放一个标号）压缩传到目的端，在目的端的rsync会根据这个表重新生成文件，这样，同步完成。</p>
<p><img src="https://coolshell.cn/wp-content/uploads/2012/05/rsync-algorithm-result.jpg" alt="" title="rsync algorithm result"></p>
<p>最后想说一下，对于某些压缩文件使用rsync传输可能会传得更多，因为被压缩后的文件可能会非常的不同。对此，对于gzip和bzip2这样的命令，记得开启 “rsyncalbe” 模式。</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/the-core-algorithm-of-rsync/">http://xnerv.wang/the-core-algorithm-of-rsync/</a></strong><br>
转载自：<a href="https://coolshell.cn/articles/7425.html">RSYNC 的核心算法</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Linux</tag>
        <tag>rsync</tag>
      </tags>
  </entry>
  <entry>
    <title>在美国第一次购买和使用树莓派时遇到的一些问题</title>
    <url>/the-first-time-to-buy-and-use-raspberry-in-usa/</url>
    <content><![CDATA[<p>新买了一个Raspberry Pi 4 Model B，第一次使用树莓派，遇到一些问题，记录下来希望对自己和他人所有帮助。</p>
<h2 id="买什么套装"><a class="header-anchor" href="#买什么套装"></a>买什么套装</h2>
<p>虽然在我买的时候2GB款的树莓派4B税前价格是35刀，但是亚马逊上是不直接卖板子的，一些要捆绑一些配件像Micro SD卡、电源、散热片、Micro HDMI线啥的。众所周知美国这边的各种线卖的巨贵无比，国内淘宝9块9包邮的线，在这边可能就是20刀不包税。而像CanaKit等可以直接卖板子的网站，则一般需要6到7刀左右的邮费。最后我还是在亚马逊上买了一个包括电源和三块散热片的套装，税前45刀左右。</p>
<p>树莓派4B的电源线是5V3A Type-C接口，我看了一下现在手机的充电线大多是5V2A这个样子，据说只要别接太多额外负载，手机充电线也是可以的。散热片不确定是否是必须的，我在不接散热片的情况下尽跑翻墙代理程序的时候在45摄氏度左右，但西雅图这边气温比较低，夏天最高温度也就32到34摄氏度左右。如果是在国内温度比较高的地区，建议还是贴散热片比较保险。</p>
<p>盒子的话淘宝20块就能买个很好的了，美国这边差不多20刀不包税。估计盒子会对散热造成一定负面影响，因此还是建议至少贴散热片。另外我一直在找有没有能装下一个2.5英寸或者3.5英寸硬盘的树莓派盒子，但是淘宝和亚马逊上都没有找到，移动硬盘只能单独放盒子外面，通过USB和树莓派连接在一起了。</p>
<p>如果是把树莓派作为翻墙代理等服务器用途的话，Micro HDMI不是必须的，我下面会讲到怎么远程初始化树莓派。</p>
<span id="more"></span>
<h2 id="没有Micro-HDMI线"><a class="header-anchor" href="#没有Micro-HDMI线"></a>没有Micro HDMI线</h2>
<p>第一次知道有Micro HDMI接口，所以很显然我没有这种线。电脑大多使用的都是普通大小的HDMI线。在美国买线相当划不来，一个这样的线得一、二十刀。所以我通过网线将树莓派接在路由器上，然后通过远程SSH的方式连接到树莓派上进行配置。</p>
<p>但是需要注意的是，虽然安装树莓派系统有两种方式（<a href="https://zhuanlan.zhihu.com/p/59027897">如何给树莓派安装操作系统</a>）：<br>
方式一：将NOOBS写入Micro SD卡<br>
方式二：直接将操作系统镜像写入Micro SD卡</p>
<p>但方式一应该是需要将树莓派连接显示器才能操作安装程序的，所以我用的第二种方式，直接将操作系统Raspbian镜像写入Micro SD卡。树莓派上有一个Micro SD卡读卡器，需要将安装了Raspbian的Micro SD卡插入这里。</p>
<p>此外，树莓派4B的SSH默认是关闭的，在写入镜像完成后，还需要通过电脑在Micro SD里创建一个文件名为SSH的空文件。然后将Micro SD卡插入树莓派卡槽，通电后SSH Server才会启动，这样才能通过SSH Client连接上去。</p>
<p>然后问题来了，SSH连接的时候如何得知树莓派的IP？如果是自己家，你有路由器的管理密码的话，登录进去找找看所有连接上来的设备，看有没有类似Raspberry名字的设备连接上来。如果没有路由器的管理密码或者想偷懒的话，可以参考<a href="https://blog.wangpengpeng.site/2020/02/28/%E5%A6%82%E4%BD%95%E8%BF%99%E6%B2%A1%E6%9C%89%E6%98%BE%E7%A4%BA%E5%99%A8%E7%9A%84%E6%83%85%E5%86%B5%E4%B8%8B%E8%8E%B7%E5%8F%96%E6%A0%91%E8%8E%93%E6%B4%BEIP%EF%BC%9F/#%E6%9C%80%E5%AE%9E%E9%99%85%E9%83%BD%E5%8A%9E%E6%B3%95">如何这没有显示器的情况下获取树莓派IP？</a>这篇文章，或者用ipscan等局域网内IP扫描工具直接扫描所有IP。</p>
<h2 id="启用WIFI"><a class="header-anchor" href="#启用WIFI"></a>启用WIFI</h2>
<p>按照从网上找到的一些教程（例如<a href="https://www.cirmall.com/articles/27944">树莓派4B，3B+和3B，如何配置WiFi和蓝牙</a>），我在执行<code>sudo iwlist wlan0 scan</code>的时候遇到了类似<code>interface doesnt support scanning</code>的错误信息。在执行<code>sudo ifconfig wlan0 up</code>的时候，则遇到了<code>SIOCSIFFLAGS: Operation not possible due to RF-kill</code>的错误信息。据查rfkill是管理WIFI和蓝牙功能的一个软开关，跟控制耗电相关。根据<a href="https://blog.csdn.net/fickyou/article/details/50885824">SIOCSIFFLAGS: Operation not possible due to RF-kill</a>关闭了相关的设置后解决问题。</p>
<h2 id="通过蓝牙SSH"><a class="header-anchor" href="#通过蓝牙SSH"></a>通过蓝牙SSH</h2>
<p>参考了一下文章但目前暂时未能解决这个问题，主要的问题是我的笔记本检测不到树莓派的蓝牙信号，虽然我的手机能够检测到树莓派的蓝牙。通过蓝牙SSH并不是刚需，等以后如果我能解决这个问题的时候再补完这一部分。</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/the-first-time-to-buy-and-use-raspberry-in-usa/">http://xnerv.wang/the-first-time-to-buy-and-use-raspberry-in-usa/</a></strong></p>
]]></content>
      <categories>
        <category>树莓派</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>树莓派</tag>
        <tag>Raspberry</tag>
      </tags>
  </entry>
  <entry>
    <title>The Google File System——论文详解（转载）</title>
    <url>/the-google-file-system-paper-analysis/</url>
    <content><![CDATA[<p>“Google文件存储系统（GFS）是构建在廉价服务器之上的大型分布式系统。它将服务器故障视为正常现象，通过软件方式自动容错，在保证系统可用性和可靠性同时，大大降低系统成本。</p>
<p>GFS是Google整个分布式系统的基石，其他存储系统如Google BigTable、GoogleMegastore等系统均直接或间接构建在GFS之上。另外，Google的大规模批处理系统MapReduce也是利用GFS系统作为海量数据的输入输出。”</p>
<p>以下内容为在研读Google_File_System论文时，对其中一些关键技术的理解。要想更加深入的理解GFS，还需进一步研究GFS源码以及论文等。</p>
<h2 id="一、单一Master节点："><a class="header-anchor" href="#一、单一Master节点："></a>一、单一Master节点：</h2>
<p>如何避免单一的Msaster节点成为系统性能瓶颈：</p>
<ol>
<li>客户端只向Master请求元数据信息，并不通过Master节点进行chunk数据读写，具体的数据读写操作由ChunkServer直接负责。</li>
<li>客户端在向Master请求某chunk元数据时,Master会一次返回包括该chunk紧接之后的几个chunk信息，有效减少客户端的请求次数。</li>
</ol>
<p>客户端读取数据流程如下：<br>
<img src="/assets/the-google-file-system-paper-analysis/1.png" alt=""></p>
<span id="more"></span>
<h2 id="二、Chunk尺寸："><a class="header-anchor" href="#二、Chunk尺寸："></a>二、Chunk尺寸：</h2>
<p>选择64MB作为chunk的大小，该尺寸远大于一般系统的Block size。这是由具体的业务特性决定的：即通常操作的是大文件。</p>
<p><img src="/assets/the-google-file-system-paper-analysis/2.png" alt=""></p>
<h2 id="三、Master元数据："><a class="header-anchor" href="#三、Master元数据："></a>三、Master元数据：</h2>
<p>Master以心跳信息来监控chunkserver的状态。 其中，chunk的副本位置信息，采取启动master时轮询（心跳信息）chunkserver，然后定期轮询来获取chunk的副本位置信息，而不是直接在master中持久化该信息。 这样简化了Master与chunkserver之间的的数据同步问题。</p>
<h3 id="操作日志："><a class="header-anchor" href="#操作日志："></a>操作日志：</h3>
<p>强同步：即只有当操作日志被写入到本地磁盘以及远程机器（备master）磁盘后，才会响应客户端的操作请求。同时master会收集多个日志后，批量写入磁盘。</p>
<p>checkpoint:  在灾难恢复时通过回放操作日志来将系统恢复到最近状态。为了减低回放时间，使用checkpoint方式来使得回放的日志尽量短，即在恢复时只需要回放checkpoint之后的日志文件即可。之前的旧日志文件及checkpoint文件可定期删除。“操作日志相当于一盘录像带，而checkpoint可以在该录像带上间隔性的插上一些标记点（将内存缓冲的数据写入磁盘，完成后，相应的在操作日志带上插入最新的一个标记点）。最新一个标记点之前的所有日志记录的操作都已经持久化保存了，而该点之后的操作保存在内存中。当内存中数据丢失时，只需回放该点之后的部分日志即可恢复。而checkpoint文件就是记录了这些点的位置等信息。”</p>
<p><img src="/assets/the-google-file-system-paper-analysis/3.png" alt=""></p>
<h2 id="四、系统交互："><a class="header-anchor" href="#四、系统交互："></a>四、系统交互：</h2>
<p>Master以带超时的租约来授权主chunkserver来执行具体的操作任务，从而减小Master的管理负担。Master与chunkserver之间通过定期的心跳信息来交互信息：master获取chunkserver’的状态信息，chunkserver申请延长租约时间等。</p>
<p>以下为客户端写数据的操作流程：<br>
<img src="/assets/the-google-file-system-paper-analysis/4.png" alt=""></p>
<h2 id="五、负载均衡："><a class="header-anchor" href="#五、负载均衡："></a>五、负载均衡：</h2>
<p><img src="/assets/the-google-file-system-paper-analysis/5.png" alt=""></p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/the-google-file-system-paper-analysis/">http://xnerv.wang/the-google-file-system-paper-analysis/</a></strong><br>
转载自：<a href="http://blog.csdn.net/yuyixinye/article/details/43483139">The Google File System——论文详解</a></p>
]]></content>
      <categories>
        <category>分布式及存储</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>分布式及存储</tag>
        <tag>Google</tag>
        <tag>GFS</tag>
      </tags>
  </entry>
  <entry>
    <title>The Tale of Two Evaluators: Understanding MASM and C++ Expression Evaluators in WinDbg（转载）</title>
    <url>/the-tale-of-two-evaluators-understanding-masm-and-cpp-expression-evaluators-in-windbg/</url>
    <content><![CDATA[<p>Much like any powerful tool with a command line interface, the WinDBG expression syntax can sometimes seem quite cryptic. In the interest of trying to unlock the power of the command line interface, in this article we’re going to cover a fundamental WinDBG concept that is key to understanding those long, strange commands: the expression evaluators.</p>
<p>As it turns out, there are two built in expression evaluators in WinDBG, the MASM evaluator and the C++ evaluator. In order to better understand the differences, we’ll first discuss the MASM evaluator in detail and then move on to the C++ evaluator.</p>
<p>Please note that this article is not going to attempt to be definitive and list every possible operator or feature of the expression evaluators. We’re simply going to focus on what we find to be the most useful in the hopes of getting you started. However, once you’ve gotten your feet wet full details are available in the WinDBG documentation.</p>
<span id="more"></span>
<h2 id="MASM-Expression-Evaluator"><a class="header-anchor" href="#MASM-Expression-Evaluator"></a>MASM Expression Evaluator</h2>
<p>The MASM expression evaluator is the expression evaluator enabled by default. The main thing that you have to remember when dealing with the MASM expression evaluator is that every expression you type results in nothing but an address. So, for example, MASM has no idea what data type your variable is, it just knows the address of your local variable. In addition, in the case of symbols the address returned is the <em>address of</em> <em>the symbol</em> and <em>not</em> the contents of the address.</p>
<p>We can see exactly what this means if we give the <em>evaluate expression</em> command (?) the name of a local:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1: kd&gt; ?irpSp</span><br><span class="line"></span><br><span class="line">Evaluate expression: -109664056 = f976a8c8</span><br></pre></td></tr></table></figure>
<p>If we then cross reference that with the <em>dv</em> output, we see that the value returned here is indeed the address of the variable and not the pointer contents:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1: kd&gt; dv /v /t irpSp</span><br><span class="line"></span><br><span class="line">f976a8c8 struct _IO_STACK_LOCATION * irpSp = 0x825c6fdc</span><br></pre></td></tr></table></figure>
<p>There are a couple of other interesting features of the MASM expression evaluator. The first is that the default radix used by the evaluator is hex, thus all values passed to the expression evaluator are first assumed to be hex values:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1: kd&gt; n</span><br><span class="line"></span><br><span class="line">base is 16</span><br><span class="line"></span><br><span class="line">1: kd&gt; ?1234</span><br><span class="line"></span><br><span class="line">Evaluate expression: 4660 = 00001234</span><br><span class="line"></span><br><span class="line">1: kd&gt; n 10</span><br><span class="line"></span><br><span class="line">base is 10</span><br><span class="line"></span><br><span class="line">1: kd&gt; ?1234</span><br><span class="line"></span><br><span class="line">Evaluate expression: 1234 = 000004d2</span><br></pre></td></tr></table></figure>
<p>You can change the default radix for the MASM evaluator with the <em>n</em> command, or you can override the radix for individual values. This is done by using one of the following prefixes:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">0x for hexadecimal</span><br><span class="line"></span><br><span class="line">0t for octal</span><br><span class="line"></span><br><span class="line">0y binary</span><br><span class="line"></span><br><span class="line">0n for decimnal (the &#x27;n&#x27; is silent)</span><br></pre></td></tr></table></figure>
<p>There’s also another override which might come in handy, <strong>!</strong>. By prefixing a value with <strong>!</strong> you’re telling the MASM evaluator that the following value is a symbol name and not a hexadecimal number. This can be helpful if you have an ambiguous local variable name, such as <em>fcb</em>:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1: kd&gt; ? fcb</span><br><span class="line"></span><br><span class="line">Evaluate expression: 4043 = 00000fcb</span><br><span class="line"></span><br><span class="line">1: kd&gt; ? !fcb</span><br><span class="line"></span><br><span class="line">Evaluate expression: -109664276 = f976a7ec</span><br></pre></td></tr></table></figure>
<p>Lastly, there’s the <em>poi</em> operator in MASM that you’ll likely find useful. As mentioned, MASM gives you the address of a symbol but not the contents. In most cases, you’ll find yourself more interested in the contents of the address. Take for example a local NTSTATUS value, if you give the name of the variable to the expression evaluator command you will get the local variable address:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1: kd&gt; ?status</span><br><span class="line"></span><br><span class="line">Evaluate expression: -138300352 = f7c1b440</span><br></pre></td></tr></table></figure>
<p>In order to see the NTSTATUS value you will need to dereference that address, which is exactly what <em>poi</em> does:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1: kd&gt; ?poi(status)</span><br><span class="line"></span><br><span class="line">Evaluate expression: -1073741823 = c0000001</span><br></pre></td></tr></table></figure>
<h2 id="C-Expression-Evaluator"><a class="header-anchor" href="#C-Expression-Evaluator"></a>C++ Expression Evaluator</h2>
<p>The C++ expression evaluator provides lots of added features over the MASM expression evaluator. The most important feature is that the evaluator is type aware. This means that you are able to access your variables in the same way as you are in your C/C++ code. In addition, in contrast to the MASM evaluator, symbol expressions result not in the address of the symbol but the <em>contents</em> of the address, thus there is no need for the <em>poi</em> operator.</p>
<p>In order to begin playing with the C++ evaluator, we’ll need to switch the current evaluator from MASM to C++:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1: kd&gt; .expr /s c++</span><br><span class="line"></span><br><span class="line">Current expression evaluator: C++ - C++ source expressions</span><br></pre></td></tr></table></figure>
<p>Now we can try looking at our status variable again:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1: kd&gt; ?status</span><br><span class="line"></span><br><span class="line">Evaluate expression: -1073741823 = c0000001</span><br></pre></td></tr></table></figure>
<p>And we can immediately start to see the differences; for example, instead of the address of the local variable we’re given the contents.</p>
<p>What’s also particularly important to know about the C++ evaluator is that all numeric values default to decimal, regardless of what your default radix is. There is no way to change this, which means that any hex value must have an explicit <em>0x</em> prefix:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1: kd&gt; n</span><br><span class="line"></span><br><span class="line">base is 16</span><br><span class="line"></span><br><span class="line">1: kd&gt; ?1234</span><br><span class="line"></span><br><span class="line">Evaluate expression: 1234 = 000004d2</span><br><span class="line"></span><br><span class="line">1: kd&gt; ?0x1234</span><br><span class="line"></span><br><span class="line">Evaluate expression: 4660 = 00001234</span><br></pre></td></tr></table></figure>
<p>As mentioned, the C++ evaluator also allows for you to treat your variables the way you would in your C/C++ code. For example, I have a local PFILE_OBJECT variable and I can easily dereference fields of that structure:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1: kd&gt; ? fileObject-&gt;DeviceObject</span><br><span class="line"></span><br><span class="line">Evaluate expression: -2117322120 = 81cc3a78</span><br><span class="line"></span><br><span class="line">1: kd&gt; ? fileObject-&gt;FileName.Buffer</span><br><span class="line"></span><br><span class="line">Evaluate expression: -505429944 = e1dfc048</span><br></pre></td></tr></table></figure>
<p>This idea also extends out to pointer arithmetic, since the evaluator is aware of the types of your pointers. Let’s see what happens if we add one to the <em>PWCHAR</em> <em>Buffer</em> field of our UNICODE_STRING above:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1: kd&gt; ?fileObject-&gt;FileName.Buffer+1</span><br><span class="line"></span><br><span class="line">Evaluate expression: -505429942 = e1dfc04a</span><br></pre></td></tr></table></figure>
<p>The last nice feature that we’ll discuss is the ability to cast virtual addresses into structure types and then dereference fields of the structure. Here we take an address, cast it as an ETHREAD, then view a field:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1: kd&gt; ? ((nt!_ethread *)0x81d11020)-&gt;Win32StartAddress</span><br><span class="line"></span><br><span class="line">Evaluate expression: 1979339677 = 75fa539d</span><br></pre></td></tr></table></figure>
<h2 id="Switching-Evaluators"><a class="header-anchor" href="#Switching-Evaluators"></a>Switching Evaluators</h2>
<p>As you can see, there are probably reasons to use the MASM evaluator in some cases and the C++ evaluator in others. Due to the MASM evaluator’s symbol evaluation and respect of the default radix, it’s likely to be the evaluator that you want to use on a daily basis. In fact, the WinDBG documentation recommends sticking to the MASM evaluator for day to day use. However, the C++ evaluator can be handy and lead to much more powerful WinDBG scripting.</p>
<p>Thus, the question becomes how to incorporate both evaluators into your normal usage? We’ve already seen the first choice in switching between evaluators, which is to use the <em>.expr</em> command to change the default evaluator:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1: kd&gt; .expr /q</span><br><span class="line"></span><br><span class="line">Available expression evaluators:</span><br><span class="line"></span><br><span class="line">MASM - Microsoft Assembler expressions</span><br><span class="line"></span><br><span class="line">C++ - C++ source expressions</span><br><span class="line"></span><br><span class="line">Current expression evaluator: MASM - Microsoft Assembler expressions</span><br><span class="line"></span><br><span class="line">1: kd&gt; .expr /s c++</span><br><span class="line"></span><br><span class="line">Current expression evaluator: C++ - C++ source expressions</span><br><span class="line"></span><br><span class="line">1: kd&gt; .expr /s masm</span><br><span class="line"></span><br><span class="line">Current expression evaluator: MASM - Microsoft Assembler expressions</span><br></pre></td></tr></table></figure>
<p>That’s cumbersome though and you need to remember to switch back. The more convenient option is to leave MASM as the default evaluator but perform an evaluator override when you want to evaluate an express with C++. This is done with the <code>_@@_</code> prefix, which has three forms:</p>
<ul>
<li>
<p>@@c++(<em>expression</em>) - Evaluate expression with the C++ evaluator</p>
</li>
<li>
<p>@@masm() - Evaluate expression with the MASM evaluator</div></p>
</li>
<li>
<p>@@() - Evaluate the expression with <em>the</em> <em>opposite of the evaluator that should be used</em></p>
</li>
</ul>
<p>The third option is a bit tricky and less clear than the first two options. It simply looks to see what evaluator <em>should</em> be used for the current expression and uses the opposite. It basically just saves you some typing if you know what expression evaluator would be used and you want the opposite.</p>
<p>We can see this in action in a goofy example. Let’s see what we’d get if we added four to the length of the file name in the file object. We’re currently in the MASM expression evaluator, so we’ll need to perform an override to get the name length out of the file object:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1: kd&gt; .expr</span><br><span class="line"></span><br><span class="line">Current expression evaluator: MASM - Microsoft Assembler expressions</span><br><span class="line"></span><br><span class="line">1: kd&gt; ? 4 + @@c++(fileObject-&gt;FileName.Length)</span><br><span class="line"></span><br><span class="line">Evaluate expression: 6 = 00000006</span><br></pre></td></tr></table></figure>
<p>Because we already knew that we were in the MASM evaluator, we could have omitted the <em>c++</em> from the @@ prefix:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1: kd&gt; ? 4 + @@(fileObject-&gt;FileName.Length)</span><br><span class="line"></span><br><span class="line">Evaluate expression: 6 = 00000006</span><br></pre></td></tr></table></figure>
<h2 id="When-the-Default-Isn’t-the-Default"><a class="header-anchor" href="#When-the-Default-Isn’t-the-Default"></a>When the Default Isn’t the Default</h2>
<p>While most of the time we’re working with whatever the default expression evaluator is, there are three circumstances in which you will <em>always</em> get the C++ evaluator by default.</p>
<p>The first is when using the <em>??</em> command, which is used specifically for evaluating C++ expressions. This command is nice because it goes beyond showing just the value of the expression and shows typed information. So, instead of seeing the file name buffer address in our earlier examples we can dump out the full Unicode string structure:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1: kd&gt; .expr</span><br><span class="line"></span><br><span class="line">Current expression evaluator: MASM - Microsoft Assembler expressions</span><br><span class="line"></span><br><span class="line">1: kd&gt; ?? fileObject-&gt;FileName</span><br><span class="line"></span><br><span class="line">struct _UNICODE_STRING</span><br><span class="line"></span><br><span class="line">&quot;\&quot;</span><br><span class="line"></span><br><span class="line">+0x000 Length : 2</span><br><span class="line"></span><br><span class="line">+0x002 MaximumLength : 0x38</span><br><span class="line"></span><br><span class="line">+0x004 Buffer : 0xe1dfc048 &quot;\&quot;</span><br></pre></td></tr></table></figure>
<p>You are allowed to specify MASM expressions to this command, you just need to wrap them in a @@masm() or @@() prefix. Confusingly enough, @@() works here because that simply chooses the opposite evaluator from what <em>would</em> be used, which in this case is C++:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1: kd&gt; ?? status</span><br><span class="line"></span><br><span class="line">long 0xc0000001</span><br><span class="line"></span><br><span class="line">1: kd&gt; ?? @@masm(status)</span><br><span class="line"></span><br><span class="line">unsigned int64 0xffffffff`f7c1b440</span><br><span class="line"></span><br><span class="line">1: kd&gt; ?? @@(status)</span><br><span class="line"></span><br><span class="line">unsigned int64 0xffffffff`f7c1b440</span><br></pre></td></tr></table></figure>
<p>The other two places where you get the C++ expression evaluator are the Watch and Locals windows. This is what allows you to type addresses as structures and browse them via the GUI in those windows.</p>
<h2 id="Hopefully-A-Little-Less-Cryptic"><a class="header-anchor" href="#Hopefully-A-Little-Less-Cryptic"></a>Hopefully A Little Less Cryptic</h2>
<p>The debugger syntax is indeed rich and full of nuances, which can make diving in a bit of a challenge at first. Hopefully this intro to the expression evaluators provides a good starting point for some experimentation of your own.</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/the-tale-of-two-evaluators-understanding-masm-and-cpp-expression-evaluators-in-windbg/">http://xnerv.wang/the-tale-of-two-evaluators-understanding-masm-and-cpp-expression-evaluators-in-windbg/</a></strong><br>
转载自：<a href="http://www.osronline.com/article.cfm?article=540">The Tale of Two Evaluators: Understanding MASM and C++ Expression Evaluators in WinDbg</a></p>
]]></content>
      <categories>
        <category>WinDbg</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Windows</tag>
        <tag>WinDbg</tag>
      </tags>
  </entry>
  <entry>
    <title>线程同步与原子操作</title>
    <url>/thread-synchronization-and-atomic-operation/</url>
    <content><![CDATA[<h2 id="volatile"><a class="header-anchor" href="#volatile"></a>volatile</h2>
<ul>
<li>volatile使得代码每次在读写volatile变量时都需要从内存读写，而不能使用寄存器中缓存的值。并且也禁止编译器对volatible做编译优化。volatile本身并不是用于线程同步，也不保证原子读写（例如volatile a++这种需要几个指令才能完成的操作）。volatile主要用于access to memory mapped devices和variables in signal handlers and between setjmp and longjmp。C++标准禁止编译器reorder同一个线程内的volatile变量的读写，但不同线程则没有限制。non-volatile变量则有可能发生reorder（<a href="https://sites.google.com/site/kjellhedstrom2/stay-away-from-volatile-in-threaded-code">Stay away from Volatile in threaded code?</a>）。</li>
<li>而根据<a href="https://blog.csdn.net/dm_vincent/article/details/79604716">为什么volatile++不是原子性的？</a>中的说法，volatile的读操作后会插入LoadLoad和LoadStore屏障，避免volatile读操作与后面的普通读写发生reorder。而volatile的写操作前会插入StoreLoad和StoreStore屏障，避免volatile写操作与后面的普通读写发生reorder（我不太确定这种说法的正确性，毕竟在wikipedia<a href="https://en.wikipedia.org/wiki/Volatile_(computer_programming)">volatile (computer programming)</a>中并没有提到volatile会插入内存屏障，或者只有Java等语言才会这样做？）。</li>
<li><a href="https://zh.wikipedia.org/wiki/%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C">内存屏障</a>中有提到
<blockquote>
<p>C与C++语言中，volatile关键字意图允许内存映射的I/O操作。这要求编译器对此的数据读写按照程序中的先后顺序执行，不能对volatile内存的读写重排序。因此关键字volatile并不保证是一个内存屏障。[4]<br>
对于Visual Studio 2003，编译器保证对volatile的操作是有序的，但是不能保证处理器的乱序执行。因此，可以使用InterlockedCompareExchange或InterlockedExchange函数。<br>
对于Visual Studio 2005及以后版本，编译器对volatile变量的读操作使用acquire semantics，对写操作使用release semantics。</p>
</blockquote>
</li>
</ul>
<span id="more"></span>
<ul>
<li>volatile跟const一样属于变量修饰符，因此也和const一样必须弄清楚修饰的是指针还是变量自身（或者甚至是第几级指针）。例如<code>uchar * volatile reg;</code>说明指针reg本身是volatile的，而<code>volatile uchar *reg;</code>说明*reg（也就是reg指向的变量）是volatile的。而且volatile也可以和const同时使用。</li>
<li><a href="https://blog.csdn.net/hanchaoman/article/details/41116251">volatile陷阱</a>一文中有提到几种volatile的陷阱和误用。</li>
<li><a href="https://mcuoneclipse.com/2013/08/14/volatile-can-be-harmful/">“Volatile” can be harmful…</a>中提到可以将函数参数标记为volatile避免编译器优化，从而便于debug。</li>
</ul>
<h2 id="临界区块（Critical-section）"><a class="header-anchor" href="#临界区块（Critical-section）"></a>临界区块（Critical section）</h2>
<ul>
<li>Windows的<a href="https://zh.wikipedia.org/wiki/%E8%87%A8%E7%95%8C%E5%8D%80%E6%AE%B5">CRITICAL_SECTION</a>首先会在用户态自旋尝试几次获取锁，如果最终还是失败的话就会内核模式等待。</li>
</ul>
<h2 id="内存屏障（Memory-barrier）"><a class="header-anchor" href="#内存屏障（Memory-barrier）"></a>内存屏障（Memory barrier）</h2>
<ul>
<li>首先要明白的一点，reorder不仅可以发生在编译时，也可以发生在运行时。CPU流水线也可以重排某些指令顺序。所以即使是同一段编译好的程序，不同的CPU内核也可能执行不同的指令顺序。（<a href="http://jpbempel.blogspot.com/2013/05/volatile-and-memory-barriers.html">Volatile and memory barriers</a>）</li>
<li>根据<a href="https://en.wikipedia.org/wiki/Memory_barrier">Memory barrier</a>，如果只有单个CPU，即使发生reorder也不会有什么问题，问题都是发生在多个线程之间。而且内存屏障只在运行时生效？？？而编译时需要用volatile？并且这篇wiki也提到volatile并不能阻止volatile变量和non-volatile变量的reorder。本质上，C/C++标准中volatile是通过控制编译器而实现的（虽然编译器实现有可能引入内存屏障来实现volatile），而内存屏障是通过特殊CPU指令实现的）。</li>
<li><a href="https://stackoverflow.com/questions/1787450/how-do-i-understand-read-memory-barriers-and-volatile">How do I Understand Read Memory Barriers and Volatile</a>中将对内存的操作比喻成有一个queue（因为CPU比内存快），所以Acquire操作就是flush all read requests in the queue（实际上并不是flush，而只是加一个标记，所以叫做内存屏障），而Release操作就是flush all write requests in the queue。因此在Acquire(lfence)之前的read requests一定会完成在Acquire之前，而Release(sfence)之前的write requests一定会完成在Release之后。类似于“半透膜”的效果。（那也就是说Acquire是LoadLoad屏障，而Release是WriteWrite屏障？）而full barrier (or full fence, mfence)就是禁止在此之前的所有read/write操作被reorder到本操作之后。</li>
<li>而C++11中的Acquire和Release定义则与上面的回答不同。C++11中的Acquire是LoadLoad+StoreLoad，Release是LoadStore+StoreStore。结合<a href="https://twistoy.com/post/cpp11-memory-model">C++11内存模型</a>，<a href="https://www.jianshu.com/p/a26763dd9b0e">内存屏障与内存模型</a>，<a href="http://lday.me/2017/12/02/0018_cpp_atomic_summary/">C++内存屏障（内存顺序）总结</a>，<a href="https://en.cppreference.com/w/cpp/atomic/memory_order#Release-Acquire_ordering">std::memory_order</a>等文章，6中内存屏障级别的区别是：
<blockquote>
<p>（建议仔细再阅读最后一篇文章。不太明白的是，当论及other thread acquire/release the same atomic时，是指代码上有acquire/release操作的线程，还是指在某一个时刻瞬间进行了acquire/release的线程？就目前看来前者的可能性更大一些）</p>
</blockquote>
</li>
</ul>
<h2 id="条件变量（Condition-Variable）"><a class="header-anchor" href="#条件变量（Condition-Variable）"></a>条件变量（Condition Variable）</h2>
<ul>
<li>C++11的条件变量跟win32的Event有一个区别，就是必须在wait之后signal，否则就必须结合预测条件（从而检查是否在wait之前已经signal）。<a href="https://www.modernescpp.com/index.php/c-core-guidelines-be-aware-of-the-traps-of-condition-variables">C++ Core Guidelines: Be Aware of the Traps of Condition Variables</a></li>
</ul>
<h2 id="Atomic"><a class="header-anchor" href="#Atomic"></a>Atomic</h2>
<ul>
<li><a href="https://stackoverflow.com/questions/19900524/does-the-c-11-standard-guarantees-that-stdatomic-is-implemented-as-a-lock">Does the C++ 11 standard guarantees that std::atomic&lt;&gt; is implemented as a lock-free operation?</a>，C++11不保证std::atomic<T>是lock-free的，而是由数据类型长度等因素决定的，可以用std::atomic<T>::is_lock_free()来判断该类型是否lock-free。</li>
<li><a href="https://stackoverflow.com/questions/25740388/what-is-the-difference-between-explicit-atomic-load-store-and-usual-operator-an">What is the difference between explicit atomic load/store and usual operator= and operator T?</a>，两者是相等的，后者使用默认的memory_order_seq_cst级别内存屏障。</li>
</ul>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/thread-synchronization-and-atomic-operation/">http://xnerv.wang/thread-synchronization-and-atomic-operation/</a></strong></p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>操作系统</tag>
        <tag>线程同步</tag>
        <tag>原子操作</tag>
        <tag>volatile</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL - 利用gdb跟踪MDL加锁过程（转载）</title>
    <url>/trace-metadata-lock-procedure-using-gdb/</url>
    <content><![CDATA[<h2 id="MDL-Meta-Data-LocK-的作用"><a class="header-anchor" href="#MDL-Meta-Data-LocK-的作用"></a>MDL(Meta Data LocK)的作用</h2>
<p>在MySQL5.1及之前的版本中，如果有未提交的事务trx，当执行DROP/RENAME/ALTER TABLE RENAME操作时，不会被其他事务阻塞住。这会导致如下问题(MySQL bug#989)</p>
<p>master： 未提交的事务，但SQL已经完成(binlog也准备好了)，表schema发生更改，在commit的时候不会被察觉到.</p>
<p>slave： 在binlog里是以事务提交顺序记录的，DDL隐式提交，因此在备库先执行DDL，后执行事务trx，由于trx作用的表已经发生了改变，因此trx会执行失败。 在DDL时的主库DML压力越大，这个问题触发的可能性就越高</p>
<p>在5.5引入了MDL（meta data lock）锁来解决在这个问题</p>
<span id="more"></span>
<h2 id="MDL锁的类型"><a class="header-anchor" href="#MDL锁的类型"></a>MDL锁的类型</h2>
<p>metadata lock也是一种锁。每个metadata lock都会定义锁住的对象，锁的持有时间和锁的类型</p>
<table>
<thead>
<tr>
<th>属性</th>
<th>范围</th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr>
<td>GLOBAL</td>
<td>全局锁</td>
<td>主要作用是防止DDL和写操作的过程中执行 set golbal_read_only =on 或flush tables with read lock;</td>
</tr>
<tr>
<td>commit</td>
<td>提交保护锁</td>
<td>主要作用是执行flush tables with read lock后，防止已经开始在执行的写事务提交</td>
</tr>
<tr>
<td>SCHEMA</td>
<td>库锁</td>
<td>对象</td>
</tr>
<tr>
<td>TABLE</td>
<td>表锁</td>
<td>对象</td>
</tr>
<tr>
<td>FUNCTION</td>
<td>函数锁</td>
<td>对象</td>
</tr>
<tr>
<td>PROCEDURE</td>
<td>存储过程锁</td>
<td>对象</td>
</tr>
<tr>
<td>TRIGGER</td>
<td>触发器锁</td>
<td>对象</td>
</tr>
<tr>
<td>EVENT</td>
<td>事件锁</td>
<td>对象</td>
</tr>
</tbody>
</table>
<p>这些锁具有以下层级关系<br>
<img src="http://ata2-img.cn-hangzhou.img-pub.aliyun-inc.com/9fef60e1111bdbc1e883646a85adeb67.png" alt="MDL_SCOPE.png"></p>
<h2 id="MDL锁的简单示例"><a class="header-anchor" href="#MDL锁的简单示例"></a>MDL锁的简单示例</h2>
<p>在实际工作中，最常见的MDL冲突就DDL的操作被没用提交的事务所阻塞。 我们下面通过一个具体的实例来演示DDL加MDL锁的过程。在这个实例中，利用gdb来跟踪DDL申请MDL锁的过程。</p>
<p>会话1:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">create</span> <span class="keyword">table</span> ti(id <span class="type">int</span> <span class="keyword">primary</span> key, c1 <span class="type">int</span>, key(c1)) engine<span class="operator">=</span>InnoDB</span><br><span class="line">stats_auto_recalc<span class="operator">=</span><span class="keyword">default</span>;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.03</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">insert</span> <span class="keyword">into</span> ti <span class="keyword">values</span> (<span class="number">1</span>,<span class="number">1</span>), (<span class="number">2</span>,<span class="number">2</span>);</span><br><span class="line">Query OK, <span class="number">2</span> <span class="keyword">rows</span> affected (<span class="number">0.03</span> sec)</span><br><span class="line">Records: <span class="number">2</span>  Duplicates: <span class="number">0</span>  Warnings: <span class="number">0</span></span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">start</span> transaction;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> ti;</span><br><span class="line"><span class="operator">+</span><span class="comment">----+------+</span></span><br><span class="line"><span class="operator">|</span> id <span class="operator">|</span> c1   <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----+------+</span></span><br><span class="line"><span class="operator">|</span>  <span class="number">1</span> <span class="operator">|</span>    <span class="number">1</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>  <span class="number">2</span> <span class="operator">|</span>    <span class="number">2</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----+------+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>
<p>再开启第二个会话,利用gdb来跟踪mysql加MDL的过程 会话2：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost mysql]# ps -ef|grep mysql</span><br><span class="line">root      3336  2390  0 06:33 pts/2    00:00:01 /u02/mysql/bin/mysqld --basedir=/u02/mysql/ --datadir=/u02/mysql/data</span><br><span class="line">--plugin-dir=/u02/mysql//lib/plugin --user=root</span><br><span class="line">--log-error=/u02/mysql/tmp/error1.log --open-files-limit=10240</span><br><span class="line">--pid-file=/u02/mysql/tmp/mysql.pid</span><br><span class="line">--socket=/u02/mysql/tmp/mysql.sock --port=3306</span><br><span class="line"></span><br><span class="line">[root@localhost mysql]# gdb -p 3336</span><br><span class="line">----在GDB设置以下断点</span><br><span class="line">(gdb) b MDL_context::acquire_lock</span><br><span class="line">Breakpoint 1 at 0x730cab: file /u02/mysql-server-5.6/sql/mdl.cc, line 2187.</span><br><span class="line">(gdb) b lock_rec_lock</span><br><span class="line">Breakpoint 2 at 0xb5ef50: file /u02/mysql-server-5.6/storage/innobase/lock/lock0lock.cc, line 2296.</span><br><span class="line"></span><br><span class="line">(gdb) c</span><br><span class="line">Continuing.....</span><br></pre></td></tr></table></figure>
<p>开启第三个会话</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">alter</span> <span class="keyword">table</span> ti stats_auto_recalc<span class="operator">=</span><span class="number">1</span>;</span><br><span class="line">这个操作被hang住</span><br></pre></td></tr></table></figure>
<p>在会话2中执行下面的操作</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(gdb) p mdl_request</span><br><span class="line">$1 = (MDL_request *) 0x7f697d1c3bd0</span><br><span class="line">(gdb) p *mdl_request</span><br><span class="line">$2 = &#123;</span><br><span class="line">type = MDL_INTENTION_EXCLUSIVE, duration = MDL_STATEMENT, next_in_list = 0x7f697002a560, prev_in_list = 0x7f697d1c3df8, ticket = 0x0, key = &#123;m_length = 3, m_db_name_length = 0,</span><br><span class="line">    m_ptr = &#x27;\000&#x27; &lt;repeats 20 times&gt;, &quot;0|\002p\000\000\001\000\060&lt;\034&#125;i\177\000\000&gt;\240\344\000\000\000\000\000\000\t\000pi\177\000\000\000\t\000pi\177\000\000`&gt;\034&#125;i\177\000\000V\312\344\000\000\000\000\000\240&gt;\034&#125;i\177\000\000\333\361\254\000b\001\000\000\a?\000\001&quot;, &#x27;\000&#x27; &lt;repeats 20 times&gt;, &quot;0|\002p\000\000\001\000\220&lt;\034&#125;i\177\000\000&gt;\240\344\000\000\000\000\000\340\236\002pi\177\000\000\333\361\254\000\000\000\000\000\a?\000\001&quot;, &#x27;\000&#x27; &lt;repeats 12 times&gt;&quot;\340, &gt;\034&#125;i\177\000\000\060|\002p\000\000\001\000\350\062\220\003\000\000\000\000\333\361\254\000\000\000\000\000$\226\363&quot;, &#x27;\000&#x27; &lt;repeats 14 times&gt;,</span><br><span class="line">&quot;?\034&#125;i\177\000\000\060|\002p\000\000\001\000\000=\034&#125;i\177\000\000&gt;\240\344\000\000\000\000\000\000&quot;...,</span><br><span class="line">static m_namespace_to_wait_state_name = &#123;</span><br><span class="line">&#123;m_key = 101,</span><br><span class="line">        m_name = 0xf125a2 &quot;Waiting for global read lock&quot;, m_flags = 0&#125;,</span><br><span class="line">&#123;m_key = 102,</span><br><span class="line">	m_name = 0xf125c0 &quot;Waiting for schema metadata lock&quot;, m_flags = 0&#125;,</span><br><span class="line">&#123;m_key = 103,</span><br><span class="line">        m_name = 0xf125e8 &quot;Waiting for table metadata lock&quot;, m_flags = 0&#125;,</span><br><span class="line">&#123;m_key = 104,</span><br><span class="line">	m_name = 0xf12608 &quot;Waiting for stored function metadata lock&quot;, m_flags = 0&#125;,</span><br><span class="line">&#123;m_key = 105,</span><br><span class="line">        m_name = 0xf12638 &quot;Waiting for stored procedure metadata lock&quot;, m_flags = 0&#125;,</span><br><span class="line">&#123;m_key = 106,</span><br><span class="line">	m_name = 0xf12668 &quot;Waiting for trigger metadata lock&quot;, m_flags = 0&#125;,</span><br><span class="line">&#123;m_key = 107,</span><br><span class="line">        m_name = 0xf12690 &quot;Waiting for event metadata lock&quot;, m_flags = 0&#125;,</span><br><span class="line">&#123;m_key = 108,</span><br><span class="line">	m_name = 0xf126b0 &quot;Waiting for commit lock&quot;, m_flags = 0&#125;&#125;&#125;&#125;</span><br><span class="line">(gdb)</span><br></pre></td></tr></table></figure>
<p>从上面的输出中，我只能看到申请了一个语句级别的MDL_INTENTION_EXCLUSIVE。并没有看到什么其他有意义的信息。我们继续gdb跟踪</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(gdb) p *(mdl_request-&gt;next_in_list)</span><br><span class="line">$3 = &#123;type = MDL_INTENTION_EXCLUSIVE, duration = MDL_TRANSACTION, next_in_list = 0x7f697002a388, prev_in_list = 0x7f697d1c3bd8, ticket = 0x0, key = &#123;m_length = 7, m_db_name_length = 4,</span><br><span class="line">    m_ptr = &quot;\001test\000\000\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217\217&quot;,</span><br><span class="line">static m_namespace_to_wait_state_name = &#123;</span><br><span class="line">&#123;m_key = 101,</span><br><span class="line">        m_name = 0xf125a2 &quot;Waiting for global read lock&quot;, m_flags = 0&#125;,</span><br><span class="line">&#123;m_key = 102,</span><br><span class="line">	m_name = 0xf125c0 &quot;Waiting for schema metadata lock&quot;, m_flags = 0&#125;,</span><br><span class="line">&#123;m_key = 103,</span><br><span class="line">        m_name = 0xf125e8 &quot;Waiting for table metadata lock&quot;, m_flags = 0&#125;,</span><br><span class="line">&#123;m_key = 104,</span><br><span class="line">	m_name = 0xf12608 &quot;Waiting for stored function metadata lock&quot;, m_flags = 0&#125;,</span><br><span class="line">&#123;m_key = 105,</span><br><span class="line">        m_name = 0xf12638 &quot;Waiting for stored procedure metadata lock&quot;, m_flags = 0&#125;,</span><br><span class="line">&#123;m_key = 106,</span><br><span class="line">	m_name = 0xf12668 &quot;Waiting for trigger metadata lock&quot;, m_flags = 0&#125;,</span><br><span class="line">&#123;m_key = 107,</span><br><span class="line">        m_name = 0xf12690 &quot;Waiting for event metadata lock&quot;, m_flags = 0&#125;,</span><br><span class="line">&#123;m_key = 108,</span><br><span class="line">	m_name = 0xf126b0 &quot;Waiting for commit lock&quot;, m_flags = 0&#125;&#125;&#125;&#125;</span><br></pre></td></tr></table></figure>
<p>从上面的输出中，我们看到了需要在test（见输出中的 m_ptr = “\001test）数据库上加一把事务级的MDL_INTENTION_EXCLUSIVE锁。它并没有告诉我们最终的MDL会落在哪个对象上。我们继续跟踪</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$4 = &#123;type = MDL_SHARED_UPGRADABLE, duration = MDL_TRANSACTION, next_in_list = 0x0, prev_in_list = 0x7f697002a568, ticket = 0x0, key = &#123;m_length = 9, m_db_name_length = 4,</span><br><span class="line">    m_ptr = &quot;\002test\000ti&quot;, &#x27;\000&#x27; &lt;repeats 378 times&gt;,</span><br><span class="line">static m_namespace_to_wait_state_name = &#123;</span><br><span class="line">&#123;m_key = 101,</span><br><span class="line">	m_name = 0xf125a2 &quot;Waiting for global read lock&quot;, m_flags = 0&#125;,</span><br><span class="line">&#123;m_key = 102,</span><br><span class="line">	m_name = 0xf125c0 &quot;Waiting for schema metadata lock&quot;, m_flags = 0&#125;,</span><br><span class="line">&#123;m_key = 103,</span><br><span class="line">	m_name = 0xf125e8 &quot;Waiting for table metadata lock&quot;, m_flags = 0&#125;,</span><br><span class="line">&#123;m_key = 104,</span><br><span class="line">        m_name = 0xf12608 &quot;Waiting for stored function metadata lock&quot;, m_flags = 0&#125;,</span><br><span class="line">&#123;m_key = 105,</span><br><span class="line">	m_name = 0xf12638 &quot;Waiting for stored procedure metadata lock&quot;, m_flags = 0&#125;,</span><br><span class="line">&#123;m_key = 106,</span><br><span class="line">        m_name = 0xf12668 &quot;Waiting for trigger metadata lock&quot;, m_flags = 0&#125;,</span><br><span class="line">&#123;m_key = 107,</span><br><span class="line">	m_name = 0xf12690 &quot;Waiting for event metadata lock&quot;, m_flags = 0&#125;,</span><br><span class="line">&#123;m_key = 108,</span><br><span class="line">        m_name = 0xf126b0 &quot;Waiting for commit lock&quot;, m_flags = 0&#125;&#125;&#125;&#125;</span><br></pre></td></tr></table></figure>
<p>从上面的输出中，我们可以看出最终是要在test数据库的ti对象上加一把MDL_SHARED_UPGRADABLE锁。在做DDL时会先加MDL_SHARED_UPGRADABLE锁，然后升级到MDL_EXCLUSIVE锁</p>
<p>我来执行下面的过程 会话1</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql&gt; commit;</span><br><span class="line">Query OK, 0 rows affected (5.51 sec)</span><br></pre></td></tr></table></figure>
<p>会话2</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(gdb) p *mdl_request</span><br><span class="line">$5 = &#123;type = MDL_EXCLUSIVE, duration = MDL_TRANSACTION, next_in_list = 0x20302000000, prev_in_list = 0x200000001, ticket = 0x0, key = &#123;m_length = 9, m_db_name_length = 4,</span><br><span class="line">    m_ptr = &quot;\002test\000ti\000\000\000\000@\031\220\003\000\000\000\000\333\361\254\000\000\000\000\000\260&lt;\034&#125;i\177\000\000\302\362\254\000\000\000\000\000\300&lt;\034&#125;i\177\000\000\060|\002pi\177\000\000\320&lt;\034&#125;i\177\000\000\360\236\344\000\000\000\000\000\000\t\000pi\177\000\000(&#125;\002pi\177\000\000\360&lt;\034&#125;i\177\000\000\234\312\344\000\000\000\000\000H\245\002pi\177\000\000\333\361\254\000\000\000\000\000\023\360\000\001&quot;, &#x27;\000&#x27; &lt;repeats 12 times&gt;, &quot;`S\005pi\177\000\000\060|\002p\000\000\001\000\060=\034&#125;i\177\000\000&gt;\240\344\000\000\000\000\000\000\t\000pi\177\000\000\000\t\000pi\177\000\000\200=\034&#125;i\177\000\000\231\310\344\000\000\000\000\000\240=\034&#125;i\177\000\000l-d0t\b\000\000H\344\000\001\000\000\000\000\023\360\000\001\000\000\000\000\226&quot;...,</span><br><span class="line">static m_namespace_to_wait_state_name = &#123;</span><br><span class="line">&#123;m_key = 101,</span><br><span class="line">	m_name = 0xf125a2 &quot;Waiting for global read lock&quot;, m_flags = 0&#125;,</span><br><span class="line">&#123;m_key = 102,</span><br><span class="line">	m_name = 0xf125c0 &quot;Waiting for schema metadata lock&quot;, m_flags = 0&#125;,</span><br><span class="line">&#123;m_key = 103,</span><br><span class="line">        m_name = 0xf125e8 &quot;Waiting for table metadata lock&quot;, m_flags = 0&#125;,</span><br><span class="line">&#123;m_key = 104,</span><br><span class="line">	m_name = 0xf12608 &quot;Waiting for stored function metadata lock&quot;, m_flags = 0&#125;,</span><br><span class="line">&#123;m_key = 105,</span><br><span class="line">        m_name = 0xf12638 &quot;Waiting for stored procedure metadata lock&quot;, m_flags = 0&#125;,</span><br><span class="line">&#123;m_key = 106,</span><br><span class="line">	m_name = 0xf12668 &quot;Waiting for trigger metadata lock&quot;, m_flags = 0&#125;,</span><br><span class="line">&#123;m_key = 107,</span><br><span class="line">        m_name = 0xf12690 &quot;Waiting for event metadata lock&quot;, m_flags = 0&#125;,</span><br><span class="line">&#123;m_key = 108,</span><br><span class="line">	m_name = 0xf126b0 &quot;Waiting for commit lock&quot;, m_flags = 0&#125;&#125;&#125;&#125;</span><br></pre></td></tr></table></figure>
<p>从上面的输出中，我们看到了最终是在test.ti上申请了事务级别的MDL_EXCLUSIVE锁。</p>
<p>会话3</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">alter</span> <span class="keyword">table</span> ti stats_auto_recalc<span class="operator">=</span><span class="number">1</span>;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">22</span> min <span class="number">58.99</span> sec)</span><br><span class="line">Records: <span class="number">0</span>  Duplicates: <span class="number">0</span>  Warnings: <span class="number">0</span></span><br></pre></td></tr></table></figure>
<h2 id="小结"><a class="header-anchor" href="#小结"></a>小结</h2>
<p>本例只是简单的演示了，在同一个事务的不同时期加的不同的MDL的锁。MYSQL中DDL的操作不属于事务操作的范围。这就给mysql主备基于语句级别同步带来了困难。mysql主备在同步的过程中，为了保证主备结构一致性，而引入了MDL机制。为了尽可能的降低MDL带来的影响。请在业务低谷的时候，执行DDL操作。</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/trace-metadata-lock-procedure-using-gdb/">http://xnerv.wang/trace-metadata-lock-procedure-using-gdb/</a></strong><br>
转载自：<a href="http://mysql.taobao.org/monthly/2017/09/06/">利用gdb跟踪MDL加锁过程</a></p>
]]></content>
      <categories>
        <category>DBMS</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>DBMS</tag>
        <tag>MySQL</tag>
        <tag>MDL</tag>
        <tag>gdb</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL - 跟踪Metadata lock（转载）</title>
    <url>/trace-metadata-lock/</url>
    <content><![CDATA[<h2 id="背景"><a class="header-anchor" href="#背景"></a>背景</h2>
<p>MySQL 从5.5.3版本，对Metadata lock进行了调整，主要是MDL锁持有的周期从语句变成了事务， 其原因主要是解决两个问题：</p>
<p><strong>问题1: 破坏事务隔离级别</strong> 在repeatable read的隔离级别下，多次的select语句执行过程中，会因为其它session的DDL语句，而导致select语句执行的结果不相同，破坏了RR的隔离级别。</p>
<p><strong>问题2: 破坏binlog的顺序</strong> 在对表的DML过程中，会因为其它session的DDL语句，导致binlog里的event顺序在备库执行的结果和主库不一致。</p>
<p>从MySQL 5.5.3开始，MDL锁的持有周期变成了事务，解决了上面提到的两个问题，但在autocommit=off的情况下，也大大增加了阻塞的可能性。DBA对于阻塞的case，处理起来又比较麻烦，原因就是MDL锁的阻塞情况没有暴露明确的信息。</p>
<p>从MySQL 5.7.6开始，可以通过performance schema来查询MDL锁的持有情况。</p>
<p>在开始介绍5.7的跟踪Metadata lock之前， 小编还想讨论一下前面提到的这两个问题，在Oracle数据库中是如何处理的。</p>
<span id="more"></span>
<h2 id="Oracle的处理方式"><a class="header-anchor" href="#Oracle的处理方式"></a>Oracle的处理方式</h2>
<p>首先，Oracle只实现了两种隔离级别，即read committed和serializable，我们来看下serializable级别下，怎么来处理问题1:</p>
<p>先看如下的case:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">session <span class="number">1</span>:                                                 session <span class="number">2</span>:</span><br><span class="line"><span class="comment">--                                                         create table t1(id number);</span></span><br><span class="line"><span class="comment">--                                                         insert into t1 values(1);</span></span><br><span class="line"><span class="comment">--                                                         commit;</span></span><br><span class="line"><span class="keyword">SET</span> TRANSACTION ISOLATION LEVEL SERIALIZABLE;              <span class="comment">--</span></span><br><span class="line">TEST<span class="operator">/</span>TEST<span class="variable">@ORCL</span><span class="operator">&gt;</span><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t1;                           <span class="comment">--</span></span><br><span class="line">        ID</span><br><span class="line"><span class="comment">----------</span></span><br><span class="line">         <span class="number">1</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> selected.</span><br><span class="line"><span class="comment">--                                                         alter table t1 add col number;</span></span><br><span class="line">TEST<span class="operator">/</span>TEST<span class="variable">@ORCL</span><span class="operator">&gt;</span><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t1;                           <span class="comment">--</span></span><br><span class="line"></span><br><span class="line">        ID        COL</span><br><span class="line"><span class="comment">---------- ----------</span></span><br><span class="line">         <span class="number">1</span></span><br><span class="line"><span class="comment">--                                                         alter table t1 add col1 number default 10;</span></span><br><span class="line">TEST<span class="operator">/</span>TEST<span class="variable">@ORCL</span><span class="operator">&gt;</span><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t1;                           <span class="comment">--</span></span><br><span class="line">        ID        COL       COL1</span><br><span class="line"><span class="comment">---------- ---------- ----------</span></span><br><span class="line">         <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>可以看到，虽然session是serializable隔离级别，但并没有产生阻塞的情况，Oracle保证了session1的多次select查询的返回结果是一样的， 但t1表数据字典的变化是马上可见的，这个也是符合serializable的要求的，因为隔离级别只定义了数据的可见性，而没有定义数据字典的可见性。</p>
<p>那MySQL能否不要MDL锁，来达到这样的效果？</p>
<p>答案是否定的，因为Oracle是堆表，alter的操作只更改了数据字典，数据记录没有发生变化，纵使加了default值，也是在原记录上进行的update，完全可以使用scn号来构建一致性读版本，这样就不会产生阻塞。 而MySQL是IOT表，alter的过程进行了表重建，无法完成read view的构建。</p>
<p>那我们再来看问题2，Oracle的处理方式:</p>
<p>对于redo日志，Oracle的处理方式和InnoDB的处理方式一致，也就是当使用redo的时候，日志的写入并不和事务的提交与否有必然的关系，也不用和提交的顺序保持一致。这一点就和binlog区别开来，也就是物理日志是可以避免使用逻辑日志(binlog)带来的问题。</p>
<p>MySQL如果要避免这两个问题，而不引入Metadata lock，可以有以下两个思路：</p>
<ol>
<li>DDL只更改数据字典，行记录的变更在原记录上进行，这样能够实现多版本，也就是我们常说的在线加字段；</li>
<li>使用物理redo日志，避免使用binlog。</li>
</ol>
<p>这两种都会对现有的MySQL架构带来调整，仅供参考。</p>
<p>下面我们回来看下对5.7 MDL的tracing。</p>
<h2 id="MySQL-5-7"><a class="header-anchor" href="#MySQL-5-7"></a>MySQL 5.7</h2>
<p>首先，打开metadata locks的tracing功能。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">UPDATE</span> performance_schema.setup_consumers <span class="keyword">SET</span> ENABLED <span class="operator">=</span> <span class="string">&#x27;YES&#x27;</span> <span class="keyword">WHERE</span> NAME <span class="operator">=</span> <span class="string">&#x27;global_instrumentation&#x27;</span>;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"><span class="keyword">Rows</span> matched: <span class="number">1</span> Changed: <span class="number">0</span> Warnings: <span class="number">0</span></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">UPDATE</span> performance_schema.setup_instruments <span class="keyword">SET</span> ENABLED <span class="operator">=</span> <span class="string">&#x27;YES&#x27;</span> <span class="keyword">WHERE</span> NAME <span class="operator">=</span> <span class="string">&#x27;wait/lock/metadata/sql/mdl&#x27;</span>;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"><span class="keyword">Rows</span> matched: <span class="number">1</span> Changed: <span class="number">0</span> Warnings: <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>打开两个session，一个select，一个truncate。因为MDL锁的情况，select会阻塞truncate的操作。</p>
<p>session 1: 操作如下：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">set</span> session autocommit<span class="operator">=</span><span class="number">0</span>;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">select</span> @<span class="variable">@autocommit</span>, @<span class="variable">@tx_isolation</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">--------------+----------------+</span></span><br><span class="line"><span class="operator">|</span> @<span class="variable">@autocommit</span> <span class="operator">|</span> @<span class="variable">@tx_isolation</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">--------------+----------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">0</span> <span class="operator">|</span> READ<span class="operator">-</span>COMMITTED <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">--------------+----------------+</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t limit <span class="number">1</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">----+------+</span></span><br><span class="line"><span class="operator">|</span> id <span class="operator">|</span> val <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----+------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">1</span> <span class="operator">|</span> <span class="number">1</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----+------+</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>
<p>session 2: 操作如下：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">truncate</span> <span class="keyword">table</span> t;</span><br></pre></td></tr></table></figure>
<p>结果看到的就是session2被阻塞， 接下来check一下performance schema的信息：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> performance_schema.metadata_locks\G</span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">1</span>\. <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">OBJECT_TYPE: <span class="keyword">TABLE</span></span><br><span class="line">OBJECT_SCHEMA: test</span><br><span class="line">OBJECT_NAME: t</span><br><span class="line">OBJECT_INSTANCE_BEGIN: <span class="number">140450128308592</span></span><br><span class="line">LOCK_TYPE: SHARED_READ</span><br><span class="line">LOCK_DURATION: TRANSACTION</span><br><span class="line">LOCK_STATUS: GRANTED</span><br><span class="line">SOURCE: sql_parse.cc:<span class="number">5585</span></span><br><span class="line">OWNER_THREAD_ID: <span class="number">27</span></span><br><span class="line">OWNER_EVENT_ID: <span class="number">17</span></span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">2</span>\. <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">OBJECT_TYPE: <span class="keyword">GLOBAL</span></span><br><span class="line">OBJECT_SCHEMA: <span class="keyword">NULL</span></span><br><span class="line">OBJECT_NAME: <span class="keyword">NULL</span></span><br><span class="line">OBJECT_INSTANCE_BEGIN: <span class="number">140450195436144</span></span><br><span class="line">LOCK_TYPE: INTENTION_EXCLUSIVE</span><br><span class="line">LOCK_DURATION: STATEMENT</span><br><span class="line">LOCK_STATUS: GRANTED</span><br><span class="line">SOURCE: sql_base.cc:<span class="number">5224</span></span><br><span class="line">OWNER_THREAD_ID: <span class="number">30</span></span><br><span class="line">OWNER_EVENT_ID: <span class="number">8</span></span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">3</span>\. <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">OBJECT_TYPE: SCHEMA</span><br><span class="line">OBJECT_SCHEMA: test</span><br><span class="line">OBJECT_NAME: <span class="keyword">NULL</span></span><br><span class="line">OBJECT_INSTANCE_BEGIN: <span class="number">140450195434272</span></span><br><span class="line">LOCK_TYPE: INTENTION_EXCLUSIVE</span><br><span class="line">LOCK_DURATION: TRANSACTION</span><br><span class="line">LOCK_STATUS: GRANTED</span><br><span class="line">SOURCE: sql_base.cc:<span class="number">5209</span></span><br><span class="line">OWNER_THREAD_ID: <span class="number">30</span></span><br><span class="line">OWNER_EVENT_ID: <span class="number">8</span></span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">4</span>\. <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">OBJECT_TYPE: <span class="keyword">TABLE</span></span><br><span class="line">OBJECT_SCHEMA: test</span><br><span class="line">OBJECT_NAME: t</span><br><span class="line">OBJECT_INSTANCE_BEGIN: <span class="number">140450195434368</span></span><br><span class="line">LOCK_TYPE: EXCLUSIVE</span><br><span class="line">LOCK_DURATION: TRANSACTION</span><br><span class="line">LOCK_STATUS: PENDING</span><br><span class="line">SOURCE: sql_parse.cc:<span class="number">5585</span></span><br><span class="line">OWNER_THREAD_ID: <span class="number">30</span></span><br><span class="line">OWNER_EVENT_ID: <span class="number">8</span></span><br><span class="line"><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span> <span class="number">5</span>\. <span class="type">row</span> <span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span><span class="operator">*</span></span><br><span class="line">OBJECT_TYPE: <span class="keyword">TABLE</span></span><br><span class="line">OBJECT_SCHEMA: performance_schema</span><br><span class="line">OBJECT_NAME: metadata_locks</span><br><span class="line">OBJECT_INSTANCE_BEGIN: <span class="number">140450128262384</span></span><br><span class="line">LOCK_TYPE: SHARED_READ</span><br><span class="line">LOCK_DURATION: TRANSACTION</span><br><span class="line">LOCK_STATUS: GRANTED</span><br><span class="line">SOURCE: sql_parse.cc:<span class="number">5585</span></span><br><span class="line">OWNER_THREAD_ID: <span class="number">27</span></span><br><span class="line">OWNER_EVENT_ID: <span class="number">18</span></span><br><span class="line"><span class="number">5</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>
<p>如上所示，在t表上，持有一个SHARE_READ lock，而且还有一个EXCULSIVE lock请求是pending状态，也就是我们被阻塞的session 2。</p>
<p>在5.7之前，我们可以通过show processlist，来查看MDL阻塞的情况，但无法获取session 1的信息:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> OBJECT_TYPE, OBJECT_SCHEMA, OBJECT_NAME, LOCK_TYPE, LOCK_STATUS, THREAD_ID, PROCESSLIST_ID, PROCESSLIST_INFO <span class="keyword">FROM</span> performance_schema.metadata_locks <span class="keyword">INNER</span> <span class="keyword">JOIN</span> performance_schema.threads <span class="keyword">ON</span> THREAD_ID <span class="operator">=</span> OWNER_THREAD_ID <span class="keyword">WHERE</span> PROCESSLIST_ID <span class="operator">&lt;&gt;</span> CONNECTION_ID();</span><br><span class="line"><span class="operator">+</span><span class="comment">-------------+---------------+-------------+---------------------+-------------+-----------+----------------+------------------+</span></span><br><span class="line"><span class="operator">|</span> OBJECT_TYPE <span class="operator">|</span> OBJECT_SCHEMA <span class="operator">|</span> OBJECT_NAME <span class="operator">|</span> LOCK_TYPE <span class="operator">|</span> LOCK_STATUS <span class="operator">|</span> THREAD_ID <span class="operator">|</span> PROCESSLIST_ID <span class="operator">|</span> PROCESSLIST_INFO <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------+---------------+-------------+---------------------+-------------+-----------+----------------+------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">GLOBAL</span> <span class="operator">|</span> <span class="keyword">NULL</span> <span class="operator">|</span> <span class="keyword">NULL</span> <span class="operator">|</span> INTENTION_EXCLUSIVE <span class="operator">|</span> GRANTED <span class="operator">|</span> <span class="number">30</span> <span class="operator">|</span> <span class="number">8</span> <span class="operator">|</span> <span class="keyword">truncate</span> <span class="keyword">table</span> t <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> SCHEMA <span class="operator">|</span> test <span class="operator">|</span> <span class="keyword">NULL</span> <span class="operator">|</span> INTENTION_EXCLUSIVE <span class="operator">|</span> GRANTED <span class="operator">|</span> <span class="number">30</span> <span class="operator">|</span> <span class="number">8</span> <span class="operator">|</span> <span class="keyword">truncate</span> <span class="keyword">table</span> t <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">TABLE</span> <span class="operator">|</span> test <span class="operator">|</span> t <span class="operator">|</span> EXCLUSIVE <span class="operator">|</span> PENDING <span class="operator">|</span> <span class="number">30</span> <span class="operator">|</span> <span class="number">8</span> <span class="operator">|</span> <span class="keyword">truncate</span> <span class="keyword">table</span> t <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------+---------------+-------------+---------------------+-------------+-----------+----------------+------------------+</span></span><br><span class="line"><span class="number">3</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">show</span> processlist;</span><br><span class="line"><span class="operator">+</span><span class="comment">----+------+-----------+------+---------+------+---------------------------------+------------------+</span></span><br><span class="line"><span class="operator">|</span> Id <span class="operator">|</span> <span class="keyword">User</span> <span class="operator">|</span> Host <span class="operator">|</span> db <span class="operator">|</span> Command <span class="operator">|</span> <span class="type">Time</span> <span class="operator">|</span> State <span class="operator">|</span> Info <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----+------+-----------+------+---------+------+---------------------------------+------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">5</span> <span class="operator">|</span> root <span class="operator">|</span> localhost <span class="operator">|</span> test <span class="operator">|</span> Query <span class="operator">|</span> <span class="number">0</span> <span class="operator">|</span> starting <span class="operator">|</span> <span class="keyword">show</span> processlist <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">8</span> <span class="operator">|</span> root <span class="operator">|</span> localhost <span class="operator">|</span> test <span class="operator">|</span> Query <span class="operator">|</span> <span class="number">50</span> <span class="operator">|</span> Waiting <span class="keyword">for</span> <span class="keyword">table</span> metadata lock <span class="operator">|</span> <span class="keyword">truncate</span> <span class="keyword">table</span> t <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----+------+-----------+------+---------+------+---------------------------------+------------------+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>
<p>接下来当事务提交了后，释放MDL锁再查询，就看不到MDL锁的信息了。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">commit</span>;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> OBJECT_TYPE, OBJECT_SCHEMA, OBJECT_NAME, LOCK_TYPE, LOCK_STATUS, THREAD_ID, PROCESSLIST_ID, PROCESSLIST_INFO <span class="keyword">FROM</span> performance_schema.metadata_locks <span class="keyword">INNER</span> <span class="keyword">JOIN</span> performance_schema.threads <span class="keyword">ON</span> THREAD_ID <span class="operator">=</span> OWNER_THREAD_ID <span class="keyword">WHERE</span> PROCESSLIST_ID <span class="operator">&lt;&gt;</span> CONNECTION_ID();</span><br><span class="line"><span class="keyword">Empty</span> <span class="keyword">set</span> (<span class="number">0.01</span> sec)</span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t;</span><br><span class="line"><span class="keyword">Empty</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>
<p>MySQL 5.7可以通过performance schema来检索MDL锁阻塞情况，方便DBA来诊断问题。</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/trace-metadata-lock/">http://xnerv.wang/trace-metadata-lock/</a></strong><br>
转载自：<a href="http://mysql.taobao.org/monthly/2015/10/02/">跟踪Metadata lock</a></p>
]]></content>
      <categories>
        <category>DBMS</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>DBMS</tag>
        <tag>MySQL</tag>
        <tag>MDL</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式系统的事务处理（转载）</title>
    <url>/transaction-processing-of-distributed-system/</url>
    <content><![CDATA[<p><img src="https://coolshell.cn/wp-content/uploads/2014/01/trade-off.jpg" alt="">当我们在生产线上用一台服务器来提供数据服务的时候，我会遇到如下的两个问题：</p>
<p>1）一台服务器的性能不足以提供足够的能力服务于所有的网络请求。</p>
<p>2）我们总是害怕我们的这台服务器停机，造成服务不可用或是数据丢失。</p>
<p>于是我们不得不对我们的服务器进行扩展，加入更多的机器来分担性能上的问题，以及来解决单点故障问题。 通常，我们会通过两种手段来扩展我们的数据服务：</p>
<p>1）<strong>数据分区</strong>：就是把数据分块放在不同的服务器上（如：uid % 16，一致性哈希等）。</p>
<p>2）<strong>数据镜像</strong>：让所有的服务器都有相同的数据，提供相当的服务。</p>
<span id="more"></span>
<p>对于第一种情况，我们无法解决数据丢失的问题，单台服务器出问题时，会有部分数据丢失。所以，<strong>数据服务的高可用性只能通过第二种方法来完成——数据的冗余存储</strong>（一般工业界认为比较安全的备份数应该是3份，如：Hadoop和Dynamo）<strong>。 但是，加入更多的机器，会让我们的数据服务变得很复杂，尤其是跨服务器的事务处理，也就是跨服务器的数据一致性</strong>。这个是一个很难的问题。 让我们用最经典的Use Case：“A帐号向B帐号汇钱”来说明一下，熟悉RDBMS事务的都知道从帐号A到帐号B需要6个操作：</p>
<ol>
<li>从A帐号中把余额读出来。</li>
<li>对A帐号做减法操作。</li>
<li>把结果写回A帐号中。</li>
<li>从B帐号中把余额读出来。</li>
<li>对B帐号做加法操作。</li>
<li>把结果写回B帐号中。</li>
</ol>
<p>为了数据的一致性，这6件事，要么都成功做完，要么都不成功，而且这个操作的过程中，对A、B帐号的其它访问必需锁死，所谓锁死就是要排除其它的读写操作，不然会有脏数据的问题，这就是事务。那么，我们在加入了更多的机器后，这个事情会变得复杂起来：</p>
<p>1）<strong>在数据分区的方案中</strong>：如果A帐号和B帐号的数据不在同一台服务器上怎么办？我们需要一个跨机器的事务处理。也就是说，如果A的扣钱成功了，但B的加钱不成功，我们还要把A的操作给回滚回去。这在跨机器的情况下，就变得比较复杂了。</p>
<p>2）<strong>在数据镜像的方案中</strong>：A帐号和B帐号间的汇款是可以在一台机器上完成的，但是别忘了我们有多台机器存在A帐号和B帐号的副本。如果对A帐号的汇钱有两个并发操作（要汇给B和C），这两个操作发生在不同的两台服务器上怎么办？也就是说，在数据镜像中，在不同的服务器上对同一个数据的写操作怎么保证其一致性，保证数据不冲突？</p>
<p>同时，我们还要考虑性能的因素，如果不考虑性能的话，事务得到保证并不困难，系统慢一点就行了。除了考虑性能外，我们还要考虑可用性，也就是说，一台机器没了，数据不丢失，服务可由别的机器继续提供。 于是，我们需要重点考虑下面的这么几个情况：</p>
<p>1）<strong>容灾</strong>：数据不丢、结点的Failover</p>
<p>2）<strong>数据的一致性</strong>：事务处理</p>
<p>3）<strong>性能：吞吐量 、 响应时间</strong></p>
<p>前面说过，要解决数据不丢，只能通过数据冗余的方法，就算是数据分区，每个区也需要进行数据冗余处理。这就是数据副本：当出现某个节点的数据丢失时可以从副本读到，数据副本是分布式系统解决数据丢失异常的唯一手段。所以，在这篇文章中，简单起见，我们只讨论在数据冗余情况下考虑数据的一致性和性能的问题。简单说来：</p>
<p><strong>1）要想让数据有高可用性，就得写多份数据。</strong></p>
<p><strong>2）写多份的问题会导致数据一致性的问题。</strong></p>
<p><strong>3）数据一致性的问题又会引发性能问题</strong></p>
<p>这就是软件开发，按下了葫芦起了瓢。</p>
<h2 id="一致性模型"><a class="header-anchor" href="#一致性模型"></a>一致性模型</h2>
<p>说起数据一致性来说，简单说有三种类型（当然，如果细分的话，还有很多一致性模型，如：顺序一致性，FIFO一致性，会话一致性，单读一致性，单写一致性，但为了本文的简单易读，我只说下面三种）：</p>
<p>1）<strong>Weak 弱一致性</strong>：当你写入一个新值后，读操作在数据副本上可能读出来，也可能读不出来。比如：某些cache系统，网络游戏其它玩家的数据和你没什么关系，VOIP这样的系统，或是百度搜索引擎（呵呵）。</p>
<p>2）<strong>Eventually 最终一致性</strong>：当你写入一个新值后，有可能读不出来，但在某个时间窗口之后保证最终能读出来。比如：DNS，电子邮件、Amazon S3，Google搜索引擎这样的系统。</p>
<p>3）<strong>Strong 强一致性</strong>：新的数据一旦写入，在任意副本任意时刻都能读到新值。比如：文件系统，RDBMS，Azure Table都是强一致性的。</p>
<p>从这三种一致型的模型上来说，我们可以看到，Weak和Eventually一般来说是异步冗余的，而Strong一般来说是同步冗余的，异步的通常意味着更好的性能，但也意味着更复杂的状态控制。同步意味着简单，但也意味着性能下降。 好，让我们由浅入深，一步一步地来看有哪些技术：</p>
<h2 id="Master-Slave"><a class="header-anchor" href="#Master-Slave"></a>Master-Slave</h2>
<p>首先是Master-Slave结构，对于这种加构，Slave一般是Master的备份。在这样的系统中，一般是如下设计的：</p>
<p>1）读写请求都由Master负责。</p>
<p>2）写请求写到Master上后，由Master同步到Slave上。</p>
<p>从Master同步到Slave上，你可以使用异步，也可以使用同步，可以使用Master来push，也可以使用Slave来pull。 通常来说是Slave来周期性的pull，所以，是最终一致性。这个设计的问题是，如果Master在pull周期内垮掉了，那么会导致这个时间片内的数据丢失。如果你不想让数据丢掉，Slave只能成为Read-Only的方式等Master恢复。</p>
<p>当然，如果你可以容忍数据丢掉的话，你可以马上让Slave代替Master工作（对于只负责计算的结点来说，没有数据一致性和数据丢失的问题，Master-Slave的方式就可以解决单点问题了） 当然，Master Slave也可以是强一致性的， 比如：当我们写Master的时候，Master负责先写自己，等成功后，再写Slave，两者都成功后返回成功，整个过程是同步的，如果写Slave失败了，那么两种方法，一种是标记Slave不可用报错并继续服务（等Slave恢复后同步Master的数据，可以有多个Slave，这样少一个，还有备份，就像前面说的写三份那样），另一种是回滚自己并返回写失败。（注：一般不先写Slave，因为如果写Master自己失败后，还要回滚Slave，此时如果回滚Slave失败，就得手工订正数据了）你可以看到，如果Master-Slave需要做成强一致性有多复杂。</p>
<h2 id="Master-Master"><a class="header-anchor" href="#Master-Master"></a>Master-Master</h2>
<p>Master-Master，又叫<a href="http://en.wikipedia.org/wiki/Multi-master_replication">Multi-master</a>，是指一个系统存在两个或多个Master，每个Master都提供read-write服务。这个模型是Master-Slave的加强版，数据间同步一般是通过Master间的异步完成，所以是最终一致性。 Master-Master的好处是，一台Master挂了，别的Master可以正常做读写服务，他和Master-Slave一样，当数据没有被复制到别的Master上时，数据会丢失。很多数据库都支持Master-Master的Replication的机制。</p>
<p>另外，如果多个Master对同一个数据进行修改的时候，这个模型的恶梦就出现了——对数据间的冲突合并，这并不是一件容易的事情。看看Dynamo的Vector Clock的设计（记录数据的版本号和修改者）就知道这个事并不那么简单，而且Dynamo对数据冲突这个事是交给用户自己搞的。就像我们的SVN源码冲突一样，对于同一行代码的冲突，只能交给开发者自己来处理。（在本文后后面会讨论一下Dynamo的Vector Clock）</p>
<h2 id="Two-Three-Phase-Commit"><a class="header-anchor" href="#Two-Three-Phase-Commit"></a>Two/Three Phase Commit</h2>
<p>这个协议的缩写又叫2PC，中文叫两阶段提交。在分布式系统中，每个节点虽然可以知晓自己的操作时成功或者失败，却无法知道其他节点的操作的成功或失败。当一个事务跨越多个节点时，为了保持事务的ACID特性，需要引入一个作为<strong>协调者</strong>的组件来统一掌控所有节点(称作<strong>参与者</strong>)的操作结果并最终指示这些节点是否要把操作结果进行真正的提交(比如将更新后的数据写入磁盘等等)。 两阶段提交的算法如下：</p>
<p><strong>第一阶段</strong>：</p>
<ol>
<li>协调者会问所有的参与者结点，是否可以执行提交操作。</li>
<li>各个参与者开始事务执行的准备工作：如：为资源上锁，预留资源，写undo/redo log……</li>
<li>参与者响应协调者，如果事务的准备工作成功，则回应“可以提交”，否则回应“拒绝提交”。</li>
</ol>
<p><strong>第二阶段</strong>：</p>
<ul>
<li>
<p>如果所有的参与者都回应“可以提交”，那么，协调者向所有的参与者发送“正式提交”的命令。参与者完成正式提交，并释放所有资源，然后回应“完成”，协调者收集各结点的“完成”回应后结束这个Global Transaction。</p>
</li>
<li>
<p>如果有一个参与者回应“拒绝提交”，那么，协调者向所有的参与者发送“回滚操作”，并释放所有资源，然后回应“回滚完成”，协调者收集各结点的“回滚”回应后，取消这个Global Transaction。</p>
</li>
</ul>
<p><img src="https://coolshell.cn/wp-content/uploads/2014/01/Two-phase_commit.png" alt=""></p>
<p>我们可以看到，2PC说白了就是第一阶段做Vote，第二阶段做决定的一个算法，也可以看到2PC这个事是强一致性的算法。在前面我们讨论过Master-Slave的强一致性策略，和2PC有点相似，只不过2PC更为保守一些——先尝试再提交。 2PC用的是比较多的，在一些系统设计中，会串联一系列的调用，比如：A -&gt; B -&gt; C -&gt; D，每一步都会分配一些资源或改写一些数据。比如我们B2C网上购物的下单操作在后台会有一系列的流程需要做。如果我们一步一步地做，就会出现这样的问题，如果某一步做不下去了，那么前面每一次所分配的资源需要做反向操作把他们都回收掉，所以，操作起来比较复杂。现在很多处理流程（Workflow）都会借鉴2PC这个算法，使用 try -&gt; confirm的流程来确保整个流程的能够成功完成。 举个通俗的例子，西方教堂结婚的时候，都有这样的桥段：</p>
<p>1）牧师分别问新郎和新娘：你是否愿意……不管生老病死……（询问阶段）</p>
<p>2）当新郎和新娘都回答愿意后（锁定一生的资源），牧师就会说：我宣布你们……（事务提交）</p>
<p>这是多么经典的一个两阶段提交的事务处理。 另外，我们也可以看到其中的一些问题， A）其中一个是同步阻塞操作，这个事情必然会非常大地影响性能。 B）另一个主要的问题是在TimeOut上，比如，</p>
<p>1）如果第一阶段中，参与者没有收到询问请求，或是参与者的回应没有到达协调者。那么，需要协调者做超时处理，一旦超时，可以当作失败，也可以重试。</p>
<p>2）如果第二阶段中，正式提交发出后，如果有的参与者没有收到，或是参与者提交/回滚后的确认信息没有返回，一旦参与者的回应超时，要么重试，要么把那个参与者标记为问题结点剔除整个集群，这样可以保证服务结点都是数据一致性的。</p>
<p>3）糟糕的情况是，第二阶段中，如果参与者收不到协调者的commit/fallback指令，参与者将处于“状态未知”阶段，参与者完全不知道要怎么办，比如：如果所有的参与者完成第一阶段的回复后（可能全部yes，可能全部no，可能部分yes部分no），如果协调者在这个时候挂掉了。那么所有的结点完全不知道怎么办（问别的参与者都不行）。为了一致性，要么死等协调者，要么重发第一阶段的yes/no命令。</p>
<p>两段提交最大的问题就是第3）项，<strong>如果第一阶段完成后，参与者在第二阶没有收到决策，那么数据结点会进入“不知所措”的状态，这个状态会block住整个事务</strong>。也就是说，协调者Coordinator对于事务的完成非常重要，Coordinator的可用性是个关键。 因些，我们引入三段提交，三段提交在<a href="http://en.wikipedia.org/wiki/Three-phase_commit_protocol">Wikipedia</a>上的描述如下，他把二段提交的第一个段break成了两段：询问，然后再锁资源。最后真正提交。三段提交的示意图如下：</p>
<p><img src="https://coolshell.cn/wp-content/uploads/2014/01/Three-phase_commit_diagram.png" alt=""></p>
<p>三段提交的核心理念是：<strong>在询问的时候并不锁定资源，除非所有人都同意了，才开始锁资源</strong>。</p>
<p>理论上来说，如果第一阶段所有的结点返回成功，那么有理由相信成功提交的概率很大。这样一来，可以降低参与者Cohorts的状态未知的概率。也就是说，一旦参与者收到了PreCommit，意味他知道大家其实都同意修改了。这一点很重要。下面我们来看一下3PC的状态迁移图：（<strong>注意图中的虚线，那些F,T是Failuer或Timeout</strong>，其中的：状态含义是 q – Query，a – Abort，w – Wait，p – PreCommit，c – Commit）</p>
<p><img src="https://coolshell.cn/wp-content/uploads/2014/01/Three-phase_commit_status.png" alt=""></p>
<p>从上图的状态变化图我们可以从虚线（那些F,T是Failuer或Timeout）看到——<strong>如果结点处在P状态（PreCommit）的时候发生了F/T的问题，三段提交比两段提交的好处是，三段提交可以继续直接把状态变成C状态（Commit），而两段提交则不知所措</strong>。</p>
<p>其实，三段提交是一个很复杂的事情，实现起来相当难，而且也有一些问题。</p>
<p>看到这里，我相信你有很多很多的问题，你一定在思考2PC/3PC中各种各样的失败场景，<strong>你会发现Timeout是个非常难处理的事情，因为网络上的Timeout在很多时候让你无所事从，你也不知道对方是做了还是没有做。于是你好好的一个状态机就因为Timeout成了个摆设</strong>。</p>
<p><strong>一个网络服务会有三种状态：1）Success，2）Failure，3）Timeout，第三个绝对是恶梦，尤其在你需要维护状态的时候</strong>。</p>
<h2 id="Two-Generals-Problem（两将军问题）"><a class="header-anchor" href="#Two-Generals-Problem（两将军问题）"></a>Two Generals Problem（两将军问题）</h2>
<p><a href="http://en.wikipedia.org/wiki/Two_Generals'_Problem">Two Generals Problem</a> 两将军问题是这么一个思维性实验问题： 有两支军队，它们分别有一位将军领导，现在准备攻击一座修筑了防御工事的城市。这两支军队都驻扎在那座城市的附近，分占一座山头。一道山谷把两座山分隔开来，并且两位将军唯一的通信方式就是派各自的信使来往于山谷两边。不幸的是，这个山谷已经被那座城市的保卫者占领，并且存在一种可能，那就是任何被派出的信使通过山谷是会被捕。 请注意，虽然两位将军已经就攻击那座城市达成共识，但在他们各自占领山头阵地之前，并没有就进攻时间达成共识。两位将军必须让自己的军队同时进攻城市才能取得成功。因此，他们必须互相沟通，以确定一个时间来攻击，并同意就在那时攻击。如果只有一个将军进行攻击，那么这将是一个灾难性的失败。 这个思维实验就包括考虑他们如何去做这件事情。下面是我们的思考：</p>
<p>1）第一位将军先发送一段消息“让我们在上午9点开始进攻”。然而，一旦信使被派遣，他是否通过了山谷，第一位将军就不得而知了。任何一点的不确定性都会使得第一位将军攻击犹豫，因为如果第二位将军不能在同一时刻发动攻击，那座城市的驻军就会击退他的军队的进攻，导致他的军对被摧毁。</p>
<p>2）知道了这一点，第二位将军就需要发送一个确认回条：“我收到您的邮件，并会在9点的攻击。”但是，如果带着确认消息的信使被抓怎么办？所以第二位将军会犹豫自己的确认消息是否能到达。</p>
<p>3）于是，似乎我们还要让第一位将军再发送一条确认消息——“我收到了你的确认”。然而，如果这位信使被抓怎么办呢？</p>
<p>4）这样一来，是不是我们还要第二位将军发送一个“确认收到你的确认”的信息。</p>
<p>靠，于是你会发现，这事情很快就发展成为不管发送多少个确认消息，都没有办法来保证两位将军有足够的自信自己的信使没有被敌军捕获。</p>
<p><img src="https://coolshell.cn/wp-content/uploads/2014/01/two-generals-problems.jpg" alt=""></p>
<p><strong>这个问题是无解的</strong><span style="line-height: 1.5em;">。</span><span style="line-height: 1.5em;">两个将军问题和它的无解证明首先由E.A.Akkoyunlu,K.Ekanadham和R.V.Huber于1975年在《一些限制与折衷的网络通信设计》一文中发表，就在这篇文章的第73页中一段描述两个黑帮之间的通信中被阐明。 1978年，在Jim Gray的《数据库操作系统注意事项》一书中（从第465页开始）被命名为两个将军悖论。作为两个将军问题的定义和无解性的证明的来源，这一参考被广泛提及。</span></p>
<p>这个实验意在阐明：试图通过建立在一个不可靠的连接上的交流来协调一项行动的隐患和设计上的巨大挑战。</p>
<p>从工程上来说，一个解决两个将军问题的实际方法是使用一个能够承受通信信道不可靠性的方案，并不试图去消除这个不可靠性，但要将不可靠性削减到一个可以接受的程度。比如，第一位将军排出了100位信使并预计他们都被捕的可能性很小。在这种情况下，不管第二位将军是否会攻击或者受到任何消息，第一位将军都会进行攻击。另外，第一位将军可以发送一个消息流，而第二位将军可以对其中的每一条消息发送一个确认消息，这样如果每条消息都被接收到，两位将军会感觉更好。然而我们可以从证明中看出，他们俩都不能肯定这个攻击是可以协调的。他们没有算法可用（比如，收到4条以上的消息就攻击）能够确保防止仅有一方攻击。再者，第一位将军还可以为每条消息编号，说这是1号，2号……直到n号。这种方法能让第二位将军知道通信信道到底有多可靠，并且返回合适的数量的消息来确保最后一条消息被接收到。如果信道是可靠的话，只要一条消息就行了，其余的就帮不上什么忙了。最后一条和第一条消息丢失的概率是相等的。</p>
<p>两将军问题可以扩展成更变态的<strong>拜占庭将军问题 (Byzantine Generals Problem)</strong>，其故事背景是这样的：拜占庭位于现在土耳其的伊斯坦布尔，是东罗马帝国的首都。由于当时拜占庭罗马帝国国土辽阔，为了防御目的，因此每个军队都分隔很远，将军与将军之间只能靠信差传消息。 在战争的时候，拜占庭军队内所有将军必需达成一致的共识，决定是否有赢的机会才去攻打敌人的阵营。但是，军队可能有叛徒和敌军间谍，这些叛徒将军们会扰乱或左右决策的过程。这时候，在已知有成员谋反的情况下，其余忠诚的将军在不受叛徒的影响下如何达成一致的协议，这就是拜占庭将军问题。</p>
<h2 id="Paxos算法"><a class="header-anchor" href="#Paxos算法"></a>Paxos算法</h2>
<p><a href="http://en.wikipedia.org/wiki/Paxos_(computer_science)">Wikipedia上的各种Paxos算法</a>的描述非常详细，大家可以去围观一下。</p>
<p>Paxos 算法解决的问题是在一个可能发生上述异常的分布式系统中如何就某个值达成一致，保证不论发生以上任何异常，都不会破坏决议的一致性。一个典型的场景是，在一个分布式数据库系统中，如果各节点的初始状态一致，每个节点都执行相同的操作序列，那么他们最后能得到一个一致的状态。为保证每个节点执行相同的命令序列，需要在每一条指令上执行一个「一致性算法」以保证每个节点看到的指令一致。一个通用的一致性算法可以应用在许多场景中，是分布式计算中的重要问题。从20世纪80年代起对于一致性算法的研究就没有停止过。</p>
<p><strong>Notes</strong>：Paxos算法是莱斯利·兰伯特（Leslie Lamport，就是 LaTeX 中的”La”，此人现在在微软研究院）于1990年提出的一种基于消息传递的一致性算法。由于算法难以理解起初并没有引起人们的重视，使Lamport在八年后1998年重新发表到ACM Transactions on Computer Systems上（<a href="http://research.microsoft.com/users/lamport/pubs/lamport-paxos.pdf">The Part-Time Parliament</a>）。即便如此paxos算法还是没有得到重视，2001年Lamport 觉得同行无法接受他的幽默感，于是用容易接受的方法重新表述了一遍（<a href="http://research.microsoft.com/users/lamport/pubs/paxos-simple.pdf">Paxos Made Simple</a>）。可见Lamport对Paxos算法情有独钟。近几年Paxos算法的普遍使用也证明它在分布式一致性算法中的重要地位。2006年Google的三篇论文初现“云”的端倪，其中的Chubby Lock服务使用Paxos作为Chubby Cell中的一致性算法，Paxos的人气从此一路狂飙。（Lamport 本人在 <a href="http://research.microsoft.com/users/lamport/pubs/pubs.html#lamport-paxos">他的blog 中</a>描写了他用9年时间发表这个算法的前前后后）</p>
<p>注：Amazon的AWS中，所有的云服务都基于一个ALF（Async Lock Framework）的框架实现的，这个ALF用的就是Paxos算法。我在Amazon的时候，看内部的分享视频时，设计者在内部的Principle Talk里说他参考了ZooKeeper的方法，但他用了另一种比ZooKeeper更易读的方式实现了这个算法。</p>
<p>简单说来，Paxos的目的是让整个集群的结点对某个值的变更达成一致。Paxos算法基本上来说是个民主选举的算法——大多数的决定会成个整个集群的统一决定。任何一个点都可以提出要修改某个数据的提案，是否通过这个提案取决于这个集群中是否有超过半数的结点同意（所以Paxos算法需要集群中的结点是单数）。</p>
<p>这个算法有两个阶段（假设这个有三个结点：A，B，C）：</p>
<p><strong>第一阶段：Prepare阶段</strong></p>
<p>A把申请修改的请求Prepare Request发给所有的结点A，B，C。注意，Paxos算法会有一个Sequence Number（你可以认为是一个提案号，这个数不断递增，而且是唯一的，也就是说A和B不可能有相同的提案号），这个提案号会和修改请求一同发出，任何结点在“Prepare阶段”时都会拒绝其值小于当前提案号的请求。所以，结点A在向所有结点申请修改请求的时候，需要带一个提案号，越新的提案，这个提案号就越是是最大的。</p>
<p>如果接收结点收到的提案号n大于其它结点发过来的提案号，这个结点会回应Yes（本结点上最新的被批准提案号），并保证不接收其它<code>&lt;n</code>的提案。这样一来，结点上在Prepare阶段里总是会对最新的提案做承诺。</p>
<p>优化：在上述 prepare 过程中，如果任何一个结点发现存在一个更高编号的提案，则需要通知 提案人，提醒其中断这次提案。</p>
<p><strong>第二阶段：Accept阶段</strong></p>
<p>如果提案者A收到了超过半数的结点返回的Yes，然后他就会向所有的结点发布Accept Request（同样，需要带上提案号n），如果没有超过半数的话，那就返回失败。</p>
<p>当结点们收到了Accept Request后，如果对于接收的结点来说，n是最大的了，那么，它就会修改这个值，如果发现自己有一个更大的提案号，那么，结点就会拒绝修改。</p>
<p>我们可以看以，这似乎就是一个“两段提交”的优化。其实，<strong>2PC/3PC都是分布式一致性算法的残次版本，Google Chubby的作者Mike Burrows说过这个世界上只有一种一致性算法，那就是Paxos，其它的算法都是残次品。</strong></p>
<p>我们还可以看到：对于同一个值的在不同结点的修改提案就算是在接收方被乱序收到也是没有问题的。</p>
<p>关于一些实例，你可以看一下Wikipedia中文中的“<a href="http://zh.wikipedia.org/zh/Paxos%E7%AE%97%E6%B3%95#.E5.AE.9E.E4.BE.8B">Paxos样例</a>”一节，我在这里就不再多说了。对于Paxos算法中的一些异常示例，大家可以自己推导一下。你会发现基本上来说只要保证有半数以上的结点存活，就没有什么问题。</p>
<p>多说一下，自从Lamport在1998年发表Paxos算法后，对Paxos的各种改进工作就从未停止，其中动作最大的莫过于2005年发表的<a href="http://research.microsoft.com/apps/pubs/default.aspx?id=64624">Fast Paxos</a>。无论何种改进，其重点依然是在消息延迟与性能、吞吐量之间作出各种权衡。为了容易地从概念上区分二者，称前者Classic Paxos，改进后的后者为Fast Paxos。</p>
<h2 id="总结"><a class="header-anchor" href="#总结"></a>总结</h2>
<p>下图来自：Google App Engine的co-founder Ryan Barrett在2009年的google i/o上的演讲《<a href="http://snarfed.org/transactions_across_datacenters_io.html">Transaction Across DataCenter</a>》（视频： <a href="http://www.youtube.com/watch?v=srOgpXECblk" title="阿里旺旺无法确定该链接的安全性">http://www.youtube.com/watch?v=srOgpXECblk</a>）</p>
<p><img src="https://coolshell.cn/wp-content/uploads/2014/01/Transaction-Across-DataCenter.jpg" alt=""></p>
<p>前面，我们说过，要想让数据有高可用性，就需要冗余数据写多份。写多份的问题会带来一致性的问题，而一致性的问题又会带来性能问题。从上图我们可以看到，我们基本上来说不可以让所有的项都绿起来，这就是著名的CAP理论：一致性，可用性，分区容忍性，你只可能要其中的两个。</p>
<h2 id="NWR模型"><a class="header-anchor" href="#NWR模型"></a>NWR模型</h2>
<p><strong>最后我还想提一下Amazon Dynamo的NWR模型。这个NWR模型把CAP的选择权交给了用户，让用户自己的选择你的CAP中的哪两个</strong>。</p>
<p>所谓NWR模型。N代表N个备份，W代表要写入至少W份才认为成功，R表示至少读取R个备份。<strong>配置的时候要求W+R &gt; N</strong>。 因为W+R &gt; N， 所以 R &gt; N-W 这个是什么意思呢？就是读取的份数一定要比总备份数减去确保写成功的倍数的差值要大。</p>
<p>也就是说，每次读取，都至少读取到一个最新的版本。从而不会读到一份旧数据。当我们需要高可写的环境的时候，我们可以配置W = 1 如果N=3 那么R = 3。 这个时候只要写任何节点成功就认为成功，但是读的时候必须从所有的节点都读出数据。如果我们要求读的高效率，我们可以配置 W=N R=1。这个时候任何一个节点读成功就认为成功，但是写的时候必须写所有三个节点成功才认为成功。</p>
<p>NWR模型的一些设置会造成脏数据的问题，因为这很明显不是像Paxos一样是一个强一致的东西，所以，可能每次的读写操作都不在同一个结点上，于是会出现一些结点上的数据并不是最新版本，但却进行了最新的操作。</p>
<p>所以，Amazon Dynamo引了数据版本的设计。也就是说，如果你读出来数据的版本是v1，当你计算完成后要回填数据后，却发现数据的版本号已经被人更新成了v2，那么服务器就会拒绝你。版本这个事就像“乐观锁”一样。</p>
<p>但是，对于分布式和NWR模型来说，版本也会有恶梦的时候——就是版本冲的问题，比如：我们设置了N=3 W=1，如果A结点上接受了一个值，版本由v1 -&gt; v2，但还没有来得及同步到结点B上（异步的，应该W=1，写一份就算成功），B结点上还是v1版本，此时，B结点接到写请求，按道理来说，他需要拒绝掉，但是他一方面并不知道别的结点已经被更新到v2，另一方面他也无法拒绝，因为W=1，所以写一分就成功了。于是，出现了严重的版本冲突。</p>
<p>Amazon的Dynamo把版本冲突这个问题巧妙地回避掉了——版本冲这个事交给用户自己来处理。</p>
<p>于是，Dynamo引入了Vector Clock（矢量钟？!）这个设计。这个设计让每个结点各自记录自己的版本信息，也就是说，对于同一个数据，需要记录两个事：1）谁更新的我，2）我的版本号是什么。</p>
<p>下面，我们来看一个操作序列：</p>
<p>1）一个写请求，第一次被节点A处理了。节点A会增加一个版本信息(A，1)。我们把这个时候的数据记做D1(A，1)。 然后另外一个对同样key的请求还是被A处理了于是有D2(A，2)。这个时候，D2是可以覆盖D1的，不会有冲突产生。</p>
<p>2）现在我们假设D2传播到了所有节点(B和C)，B和C收到的数据不是从客户产生的，而是别人复制给他们的，所以他们不产生新的版本信息，所以现在B和C所持有的数据还是D2(A，2)。于是A，B，C上的数据及其版本号都是一样的。</p>
<p>3）如果我们有一个新的写请求到了B结点上，于是B结点生成数据D3(A,2; B,1)，意思是：数据D全局版本号为3，A升了两新，B升了一次。这不就是所谓的代码版本的log么？</p>
<p>4）如果D3没有传播到C的时候又一个请求被C处理了，于是，以C结点上的数据是D4(A,2; C,1)。</p>
<p>5）好，最精彩的事情来了：如果这个时候来了一个读请求，我们要记得，我们的W=1 那么R=N=3，所以R会从所有三个节点上读，此时，他会读到三个版本：</p>
<ul>
<li>A结点：D2(A,2)</li>
<li>B结点：D3(A,2;  B,1);</li>
<li>C结点：D4(A,2;  C,1)</li>
</ul>
<p>6）这个时候可以判断出，D2已经是旧版本（已经包含在D3/D4中），可以舍弃。</p>
<p>7）但是D3和D4是明显的版本冲突。于是，交给调用方自己去做版本冲突处理。就像源代码版本管理一样。</p>
<p>很明显，上述的Dynamo的配置用的是CAP里的A和P。</p>
<p>我非常推大家都去看看这篇论文：《<a href="http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/decandia07dynamo.pdf">Dynamo：Amazon’s Highly Available Key-Value Store</a>》，如果英文痛苦，你可以<a href="http://vdisk.weibo.com/s/AKRQZMLLc1ol">看看译文</a>（译者不详）。</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/transaction-processing-of-distributed-system/">http://xnerv.wang/transaction-processing-of-distributed-system/</a></strong><br>
转载自：<a href="https://coolshell.cn/articles/10910.html">分布式系统的事务处理</a></p>
]]></content>
      <categories>
        <category>分布式及存储</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>分布式及存储</tag>
        <tag>2PC</tag>
        <tag>分布式事务</tag>
        <tag>Paxos</tag>
      </tags>
  </entry>
  <entry>
    <title>进程分配内存的两种方式--brk() 和mmap()（不涉及共享内存）（转载）</title>
    <url>/two-ways-of-allocating-memory-brk-and-mmap/</url>
    <content><![CDATA[<h2 id="如何查看进程发生缺页中断的次数？"><a class="header-anchor" href="#如何查看进程发生缺页中断的次数？"></a>如何查看进程发生缺页中断的次数？</h2>
<p>用ps -o majflt,minflt -C program命令查看。<br>
majflt代表major fault，中文名叫大错误，minflt代表minor fault，中文名叫小错误。<br>
这两个数值表示一个进程自启动以来所发生的缺页中断的次数。</p>
<h2 id="发成缺页中断后，执行了那些操作？"><a class="header-anchor" href="#发成缺页中断后，执行了那些操作？"></a>发成缺页中断后，执行了那些操作？</h2>
<p>当一个进程发生缺页中断的时候，进程会陷入内核态，执行以下操作：</p>
<ol>
<li>检查要访问的虚拟地址是否合法</li>
<li>查找/分配一个物理页</li>
<li>填充物理页内容（读取磁盘，或者直接置0，或者啥也不干）</li>
<li><strong>建立映射关系（虚拟地址到物理地址）</strong></li>
</ol>
<p>重新执行发生缺页中断的那条指令<br>
如果第3步，需要读取磁盘，那么这次缺页中断就是majflt，否则就是minflt。</p>
<span id="more"></span>
<h2 id="内存分配的原理"><a class="header-anchor" href="#内存分配的原理"></a>内存分配的原理</h2>
<p>从操作系统角度来看，进程分配内存有两种方式，分别由两个系统调用完成：<strong>brk和mmap（不考虑共享内存）</strong>。</p>
<ol>
<li>brk是将数据段(.data)的最高地址指针_edata往高地址推；</li>
<li>mmap是在进程的虚拟地址空间中（堆和栈中间，称为文件映射区域的地方）找一块空闲的虚拟内存。</li>
</ol>
<p>这两种方式分配的都是虚拟内存，没有分配物理内存。在第一次访问已分配的虚拟地址空间的时候，发生缺页中断，操作系统负责分配物理内存，然后建立虚拟内存和物理内存之间的映射关系。</p>
<p>在标准C库中，提供了malloc/free函数分配释放内存，这两个函数底层是由brk，mmap，munmap这些系统调用实现的。</p>
<h3 id="下面以一个例子来说明内存分配的原理："><a class="header-anchor" href="#下面以一个例子来说明内存分配的原理："></a>下面以一个例子来说明内存分配的原理：</h3>
<p>情况一、malloc小于128k的内存，使用brk分配内存，将_edata往高地址推(只分配虚拟空间，不对应物理内存(因此没有初始化)，第一次读/写数据时，引起内核缺页中断，内核才分配对应的物理内存，然后虚拟地址空间建立映射关系)，如下图：</p>
<center>
<img src="/assets/two-ways-of-allocating-memory-brk-and-mmap/1.jpg" />
</center>
<ol>
<li>
<p>进程启动的时候，其（虚拟）内存空间的初始布局如图1所示。<br>
其中，<strong>mmap内存映射文件是在堆和栈的中间</strong>（<a href="http://xn--libc-2-9v9ii49d.2.93.so">例如libc-2.2.93.so</a>，其它数据文件等），为了简单起见，省略了内存映射文件。<br>
_edata指针（glibc里面定义）指向数据段的最高地址。</p>
</li>
<li>
<p>进程调用A=malloc(30K)以后，内存空间如图2：<br>
malloc函数会调用brk系统调用，将_edata指针往高地址推30K，就完成虚拟内存分配。<br>
你可能会问：只要把_edata+30K就完成内存分配了？<br>
事实是这样的，_edata+30K只是完成虚拟地址的分配，A这块内存现在还是没有物理页与之对应的，等到进程第一次读写A这块内存的时候，发生缺页中断，这个时候，内核才分配A这块内存对应的物理页。也就是说，如果用malloc分配了A这块内容，然后从来不访问它，那么，A对应的物理页是不会被分配的。</p>
</li>
<li>
<p>进程调用B=malloc(40K)以后，内存空间如图3。<br>
情况二、malloc大于128k的内存，使用mmap分配内存，在堆和栈之间找一块空闲内存分配(对应独立内存，而且初始化为0)，如下图：</p>
</li>
</ol>
<center>
<img src="/assets/two-ways-of-allocating-memory-brk-and-mmap/2.jpg" />
</center>
<ol start="4">
<li>
<p>进程调用C=malloc(200K)以后，内存空间如图4：<br>
默认情况下，malloc函数分配内存，如果请求内存大于128K（可由M_MMAP_THRESHOLD选项调节），那就不是去推_edata指针了，而是利用mmap系统调用，从堆和栈的中间分配一块虚拟内存。<br>
这样子做主要是因为::<br>
brk分配的内存需要等到高地址内存释放以后才能释放（例如，在B释放之前，A是不可能释放的，这就是内存碎片产生的原因，什么时候紧缩看下面），而mmap分配的内存可以单独释放。<br>
当然，还有其它的好处，也有坏处，再具体下去，有兴趣的同学可以去看glibc里面malloc的代码了。</p>
</li>
<li>
<p>进程调用D=malloc(100K)以后，内存空间如图5；</p>
</li>
</ol>
<center>
<img src="/assets/two-ways-of-allocating-memory-brk-and-mmap/3.jpg" />
</center>
<ol start="6">
<li>
<p>进程调用free©以后，C对应的虚拟内存和物理内存一起释放。</p>
</li>
<li>
<p>进程调用free(B)以后，如图7所示：<br>
B对应的虚拟内存和物理内存都没有释放，因为只有一个_edata指针，如果往回推，那么D这块内存怎么办呢？<br>
当然，B这块内存，是可以重用的，如果这个时候再来一个40K的请求，那么malloc很可能就把B这块内存返回回去了。</p>
</li>
</ol>
<p>8、进程调用free(D)以后，如图8所示：<br>
B和D连接起来，变成一块140K的空闲内存。</p>
<p>9、默认情况下：<br>
当最高地址空间的空闲内存超过128K（可由M_TRIM_THRESHOLD选项调节）时，执行内存紧缩操作（trim）。在上一个步骤free的时候，发现最高地址空闲内存超过128K，于是内存紧缩，变成图9所示。</p>
<h3 id="在了解了内存分配原理以后来看一个现象："><a class="header-anchor" href="#在了解了内存分配原理以后来看一个现象："></a>在了解了内存分配原理以后来看一个现象：</h3>
<h4 id="现象"><a class="header-anchor" href="#现象"></a>现象</h4>
<ol>
<li>
<p>压力测试过程中，发现被测对象性能不够理想，具体表现为：<br>
进程的系统态CPU消耗20，用户态CPU消耗10，系统idle大约70</p>
</li>
<li>
<p>用ps -o majflt,minflt -C program命令查看，发现majflt每秒增量为0，而minflt每秒增量大于10000。</p>
</li>
</ol>
<h4 id="初步分析"><a class="header-anchor" href="#初步分析"></a>初步分析</h4>
<p>majflt代表major fault，中文名叫大错误，minflt代表minor fault，中文名叫小错误。<br>
这两个数值表示一个进程自启动以来所发生的缺页中断的次数。<br>
当一个进程发生缺页中断的时候，进程会陷入内核态，执行以下操作：</p>
<ol>
<li>检查要访问的虚拟地址是否合法</li>
<li>查找/分配一个物理页</li>
<li>填充物理页内容(读取磁盘，或者直接置0，或者啥也不干)</li>
<li>建立映射关系(虚拟地址到物理地址)</li>
<li>重新执行发生缺页中断的那条指令</li>
</ol>
<p>如果第3步，需要读取磁盘，那么这次缺页中断就是majflt，否则就是minflt。<br>
此进程minflt如此之高，一秒10000多次，不得不怀疑它跟进程内核态cpu消耗大有很大关系。</p>
<h4 id="分析代码"><a class="header-anchor" href="#分析代码"></a>分析代码</h4>
<p>查看代码，发现是这么写的：一个请求来，用malloc分配2M内存，请求结束后free这块内存。看日志，发现分配内存语句耗时10us，平均一条请求处理耗时1000us 。 原因已找到！<br>
虽然分配内存语句的耗时在一条处理请求中耗时比重不大，但是这条语句严重影响了性能。要解释清楚原因，需要先了解一下内存分配的原理。</p>
<h4 id="真相大白"><a class="header-anchor" href="#真相大白"></a>真相大白</h4>
<p>说完内存分配的原理，那么被测模块在内核态cpu消耗高的原因就很清楚了：每次请求来都malloc一块2M的内存，默认情况下，malloc调用mmap分配内存，请求结束的时候，调用munmap释放内存。假设每个请求需要6个物理页，那么每个请求就会产生6个缺页中断，在2000的压力下，每秒就产生了10000多次缺页中断，这些缺页中断不需要读取磁盘解决，所以叫做minflt;缺页中断在内核态执行，因此进程的内核态cpu消耗很大。缺页中断分散在整个请求的处理过程中，所以表现为分配语句耗时(10us)相对于整条请求的处理时间(1000us)比重很小。</p>
<h4 id="解决办法"><a class="header-anchor" href="#解决办法"></a>解决办法</h4>
<ul>
<li>将动态内存改为静态分配，或者启动的时候，用malloc为每个线程分配，然后保存在threaddata里面。但是，由于这个模块的特殊性，静态分配，或者启动时候分配都不可行。另外，Linux下默认栈的大小限制是10M，如果在栈上分配几M的内存，有风险。</li>
<li>禁止malloc调用mmap分配内存，禁止内存紧缩。<br>
在进程启动时候，加入以下两行代码：</li>
</ul>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">mallopt(M_MMAP_MAX, <span class="number">0</span>); <span class="comment">// 禁止malloc调用mmap分配内存</span></span><br><span class="line">mallopt(M_TRIM_THRESHOLD, <span class="number">-1</span>); <span class="comment">// 禁止内存紧缩</span></span><br></pre></td></tr></table></figure>
<p>效果：加入这两行代码以后，用ps命令观察，压力稳定以后，majlt和minflt都为0。进程的系统态cpu从20降到10。</p>
<h2 id="小结"><a class="header-anchor" href="#小结"></a>小结</h2>
<p>可以用命令ps -o majflt minflt -C program来查看进程的majflt, minflt的值，这两个值都是累加值，从进程启动开始累加。在对高性能要求的程序做压力测试的时候，我们可以多关注一下这两个值。<br>
　　如果一个进程使用了mmap将很大的数据文件映射到进程的虚拟地址空间，我们需要重点关注majflt的值，因为相比minflt，majflt对于性能的损害是致命的，随机读一次磁盘的耗时数量级在几个毫秒，而minflt只有在大量的时候才会对性能产生影响。</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/two-ways-of-allocating-memory-brk-and-mmap/">http://xnerv.wang/two-ways-of-allocating-memory-brk-and-mmap/</a></strong><br>
转载自：<a href="http://blog.csdn.net/yusiguyuan/article/details/39496057">进程分配内存的两种方式–brk() 和mmap()（不涉及共享内存）</a></p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>操作系统</tag>
        <tag>内存管理</tag>
        <tag>进程</tag>
      </tags>
  </entry>
  <entry>
    <title>理解 Memory barrier（内存屏障）（转载）</title>
    <url>/understand-memory-barrier/</url>
    <content><![CDATA[<p>本文例子均在 Linux（g++）下验证通过，CPU 为 X86-64 处理器架构。所有罗列的 Linux 内核代码也均在（或只在）X86-64 下有效。</p>
<p>本文首先通过范例（以及内核代码）来解释 Memory barrier，然后介绍一个利用 Memory barrier 实现的无锁环形缓冲区。</p>
<span id="more"></span>
<h2 id="Memory-barrier-简介"><a class="header-anchor" href="#Memory-barrier-简介"></a>Memory barrier 简介</h2>
<p>程序在运行时内存实际的访问顺序和程序代码编写的访问顺序不一定一致，这就是内存乱序访问。内存乱序访问行为出现的理由是为了提升程序运行时的性能。内存乱序访问主要发生在两个阶段：</p>
<ol>
<li>编译时，编译器优化导致内存乱序访问（指令重排）</li>
<li>运行时，多 CPU 间交互引起内存乱序访问</li>
</ol>
<p>Memory barrier 能够让 CPU 或编译器在内存访问上有序。一个 Memory barrier 之前的内存访问操作必定先于其之后的完成。Memory barrier 包括两类：</p>
<ol>
<li>编译器 barrier</li>
<li>CPU Memory barrier</li>
</ol>
<p>很多时候，编译器和 CPU 引起内存乱序访问不会带来什么问题，但一些特殊情况下，程序逻辑的正确性依赖于内存访问顺序，这时候内存乱序访问会带来逻辑上的错误，例如：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// thread 1</span></span><br><span class="line"><span class="keyword">while</span> (!ok);</span><br><span class="line"><span class="built_in">do</span>(x);</span><br><span class="line"></span><br><span class="line"><span class="comment">// thread 2</span></span><br><span class="line">x = <span class="number">42</span>;</span><br><span class="line">ok = <span class="number">1</span>;</span><br><span class="line">ccc</span><br></pre></td></tr></table></figure>
<p>此段代码中，ok 初始化为 0，线程 1 等待 ok 被设置为 1 后执行 do 函数。假如说，线程 2 对内存的写操作乱序执行，也就是 x 赋值后于 ok 赋值完成，那么 do 函数接受的实参就很可能出乎程序员的意料，不为 42。</p>
<h2 id="编译时内存乱序访问"><a class="header-anchor" href="#编译时内存乱序访问"></a>编译时内存乱序访问</h2>
<p>在编译时，编译器对代码做出优化时可能改变实际执行指令的顺序（例如 gcc 下 O2 或 O3 都会改变实际执行指令的顺序）：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// test.cpp</span></span><br><span class="line"><span class="type">int</span> x, y, r;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">f</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    x = r;</span><br><span class="line">    y = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>编译器优化的结果可能导致 y = 1 在 x = r 之前执行完成。首先直接编译此源文件：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">g++ -S test.cpp</span><br></pre></td></tr></table></figure>
<p>得到相关的汇编代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">movl    r(%rip), %eax</span><br><span class="line">movl    %eax, x(%rip)</span><br><span class="line">movl    $1, y(%rip)</span><br></pre></td></tr></table></figure>
<p>这里我们看到，x = r 和 y = 1 并没有乱序。现使用优化选项 O2（或 O3）编译上面的代码（g++ -O2 -S test.cpp），生成汇编代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">movl    r(%rip), %eax</span><br><span class="line">movl    $1, y(%rip)</span><br><span class="line">movl    %eax, x(%rip)</span><br></pre></td></tr></table></figure>
<p>我们可以清楚的看到经过编译器优化之后 movl $1, y(%rip) 先于 movl %eax, x(%rip) 执行。避免编译时内存乱序访问的办法就是使用编译器 barrier（又叫优化 barrier）。Linux 内核提供函数 barrier() 用于让编译器保证其之前的内存访问先于其之后的完成。内核实现 barrier() 如下（X86-64 架构）：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> barrier() __asm__ __volatile__(<span class="string">&quot;&quot;</span> ::: <span class="string">&quot;memory&quot;</span>)</span></span><br></pre></td></tr></table></figure>
<p>现在把此编译器 barrier 加入代码中：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> x, y, r;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">f</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    x = r;</span><br><span class="line">    __asm__ __volatile__(<span class="string">&quot;&quot;</span> ::: <span class="string">&quot;memory&quot;</span>);</span><br><span class="line">    y = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这样就避免了编译器优化带来的内存乱序访问的问题了（如果有兴趣可以再看看编译之后的汇编代码）。本例中，我们还可以使用 volatile 这个关键字来避免编译时内存乱序访问（而无法避免后面要说的运行时内存乱序访问）。volatile 关键字能够让相关的变量之间在内存访问上避免乱序，这里可以修改 x 和 y 的定义来解决问题：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">volatile</span> <span class="type">int</span> x, y;</span><br><span class="line"><span class="type">int</span> r;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">f</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    x = r;</span><br><span class="line">    y = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>现加上了 volatile 关键字，这使得 x 相对于 y、y 相对于 x 在内存访问上有序。在 Linux 内核中，提供了一个宏 ACCESS_ONCE 来避免编译器对于连续的 ACCESS_ONCE 实例进行指令重排。其实 ACCESS_ONCE 实现源码如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> ACCESS_ONCE(x) (*(volatile typeof(x) *)&amp;(x))</span></span><br></pre></td></tr></table></figure>
<p>此代码只是将变量 x 转换为 volatile 的而已。现在我们就有了第三个修改方案：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> x, y, r;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">f</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">ACCESS_ONCE</span>(x) = r;</span><br><span class="line">    <span class="built_in">ACCESS_ONCE</span>(y) = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>到此基本上就阐述完了我们的编译时内存乱序访问的问题。下面开始介绍运行时内存乱序访问。</p>
<h2 id="运行时内存乱序访问"><a class="header-anchor" href="#运行时内存乱序访问"></a>运行时内存乱序访问</h2>
<p>在运行时，CPU 虽然会乱序执行指令，但是在单个 CPU 的上，硬件能够保证程序执行时所有的内存访问操作看起来像是按程序代码编写的顺序执行的，这时候 Memory barrier 没有必要使用（不考虑编译器优化的情况下）。这里我们了解一下 CPU 乱序执行的行为。在乱序执行时，一个处理器真正执行指令的顺序由可用的输入数据决定，而非程序员编写的顺序。</p>
<p>早期的处理器为有序处理器（In-order processors），有序处理器处理指令通常有以下几步：</p>
<ol>
<li>指令获取</li>
<li>如果指令的输入操作对象（input operands）可用（例如已经在寄存器中了），则将此指令分发到适当的功能单元中。如果一个或者多个操作对象不可用（通常是由于需要从内存中获取），则处理器会等待直到它们可用</li>
<li>指令被适当的功能单元执行</li>
<li>功能单元将结果写回寄存器堆（Register file，一个 CPU 中的一组寄存器）</li>
</ol>
<p>相比之下，乱序处理器（Out-of-order processors）处理指令通常有以下几步：</p>
<ol>
<li>指令获取</li>
<li>指令被分发到指令队列</li>
<li>指令在指令队列中等待，直到输入操作对象可用（一旦输入操作对象可用，指令就可以离开队列，即便更早的指令未被执行）</li>
<li>指令被分配到适当的功能单元并执行</li>
<li>执行结果被放入队列（而不立即写入寄存器堆）</li>
<li>只有所有更早请求执行的指令的执行结果被写入寄存器堆后，指令执行的结果才被写入寄存器堆（执行结果重排序，让执行看起来是有序的）</li>
</ol>
<p>从上面的执行过程可以看出，乱序执行相比有序执行能够避免等待不可用的操作对象（有序执行的第二步）从而提高了效率。现代的机器上，处理器运行的速度比内存快很多，有序处理器花在等待可用数据的时间里已经可以处理大量指令了。</p>
<p>现在思考一下乱序处理器处理指令的过程，我们能得到几个结论：</p>
<ol>
<li>对于单个 CPU 指令获取是有序的（通过队列实现）</li>
<li>对于单个 CPU 指令执行结果也是有序返回寄存器堆的（通过队列实现）</li>
</ol>
<p>由此可知，在单 CPU 上，不考虑编译器优化导致乱序的前提下，多线程执行不存在内存乱序访问的问题。我们从内核源码也可以得到类似的结论（代码不完全的摘录）：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_SMP</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> smp_mb() mb()</span></span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> smp_mb() barrier()</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure>
<p>这里可以看到，如果是 SMP 则使用 mb，mb 被定义为 CPU Memory barrier（后面会讲到），而非 SMP 时，直接使用编译器 barrier。</p>
<p>在多 CPU 的机器上，问题又不一样了。每个 CPU 都存在 cache（cache 主要是为了弥补 CPU 和内存之间较慢的访问速度），当一个特定数据第一次被特定一个 CPU 获取时，此数据显然不在 CPU 的 cache 中（这就是 cache miss）。此 cache miss 意味着 CPU 需要从内存中获取数据（这个过程需要 CPU 等待数百个周期），此数据将被加载到 CPU 的 cache 中，这样后续就能直接从 cache 上快速访问。当某个 CPU 进行写操作时，它必须确保其他的 CPU 已经将此数据从它们的 cache 中移除（以便保证一致性），只有在移除操作完成后此 CPU 才能安全的修改数据。显然，存在多个 cache 时，我们必须通过一个 cache 一致性协议来避免数据不一致的问题，而这个通讯的过程就可能导致乱序访问的出现，也就是这里说的运行时内存乱序访问。这里不再深入讨论整个细节，这是一个比较复杂的问题，有兴趣可以研究<a href="http://www.rdrop.com/users/paulmck/scalability/paper/whymb.2010.06.07c.pdf">http://www.rdrop.com/users/paulmck/scalability/paper/whymb.2010.06.07c.pdf</a>一文，其详细的分析了整个过程。</p>
<p>现在通过一个例子来说明多 CPU 下内存乱序访问：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// test2.cpp</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;assert.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// -------------------</span></span><br><span class="line"><span class="type">int</span> cpu_thread1 = <span class="number">0</span>;</span><br><span class="line"><span class="type">int</span> cpu_thread2 = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">volatile</span> <span class="type">int</span> x, y, r1, r2;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">start</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    x = y = r1 = r2 = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">end</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">assert</span>(!(r1 == <span class="number">0</span> &amp;&amp; r2 == <span class="number">0</span>));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">run1</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    x = <span class="number">1</span>;</span><br><span class="line">    r1 = y;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">run2</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    y = <span class="number">1</span>;</span><br><span class="line">    r2 = x;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// -------------------</span></span><br><span class="line"><span class="type">static</span> <span class="type">pthread_barrier_t</span> barrier_start;</span><br><span class="line"><span class="type">static</span> <span class="type">pthread_barrier_t</span> barrier_end;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">static</span> <span class="type">void</span>* <span class="title">thread1</span><span class="params">(<span class="type">void</span>*)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">        <span class="built_in">pthread_barrier_wait</span>(&amp;barrier_start);</span><br><span class="line">        <span class="built_in">run1</span>();</span><br><span class="line">        <span class="built_in">pthread_barrier_wait</span>(&amp;barrier_end);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">static</span> <span class="type">void</span>* <span class="title">thread2</span><span class="params">(<span class="type">void</span>*)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">        <span class="built_in">pthread_barrier_wait</span>(&amp;barrier_start);</span><br><span class="line">        <span class="built_in">run2</span>();</span><br><span class="line">        <span class="built_in">pthread_barrier_wait</span>(&amp;barrier_end);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">assert</span>(<span class="built_in">pthread_barrier_init</span>(&amp;barrier_start, <span class="literal">NULL</span>, <span class="number">3</span>) == <span class="number">0</span>);</span><br><span class="line">    <span class="built_in">assert</span>(<span class="built_in">pthread_barrier_init</span>(&amp;barrier_end, <span class="literal">NULL</span>, <span class="number">3</span>) == <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="type">pthread_t</span> t1;</span><br><span class="line">    <span class="type">pthread_t</span> t2;</span><br><span class="line">    <span class="built_in">assert</span>(<span class="built_in">pthread_create</span>(&amp;t1, <span class="literal">NULL</span>, thread1, <span class="literal">NULL</span>) == <span class="number">0</span>);</span><br><span class="line">    <span class="built_in">assert</span>(<span class="built_in">pthread_create</span>(&amp;t2, <span class="literal">NULL</span>, thread2, <span class="literal">NULL</span>) == <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="type">cpu_set_t</span> cs;</span><br><span class="line">    <span class="built_in">CPU_ZERO</span>(&amp;cs);</span><br><span class="line">    <span class="built_in">CPU_SET</span>(cpu_thread1, &amp;cs);</span><br><span class="line">    <span class="built_in">assert</span>(<span class="built_in">pthread_setaffinity_np</span>(t1, <span class="built_in">sizeof</span>(cs), &amp;cs) == <span class="number">0</span>);</span><br><span class="line">    <span class="built_in">CPU_ZERO</span>(&amp;cs);</span><br><span class="line">    <span class="built_in">CPU_SET</span>(cpu_thread2, &amp;cs);</span><br><span class="line">    <span class="built_in">assert</span>(<span class="built_in">pthread_setaffinity_np</span>(t2, <span class="built_in">sizeof</span>(cs), &amp;cs) == <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">        <span class="built_in">start</span>();</span><br><span class="line">        <span class="built_in">pthread_barrier_wait</span>(&amp;barrier_start);</span><br><span class="line">        <span class="built_in">pthread_barrier_wait</span>(&amp;barrier_end);</span><br><span class="line">        <span class="built_in">end</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里创建了两个线程来运行测试代码（需要测试的代码将放置在 run 函数中）。我使用了 pthread barrier（区别于本文讨论的 Memory barrier）主要为了让两个子线程能够同时运行它们的 run 函数。此段代码不停的尝试同时运行两个线程的 run 函数，以便得出我们期望的结果。在每次运行 run 函数前会调用一次 start 函数（进行数据初始化），run 运行后会调用一次 end 函数（进行结果检查）。run1 和 run2 两个函数运行在哪个 CPU 上则通过 cpu_thread1 和 cpu_thread2 两个变量控制。</p>
<p>先编译此程序：g++ -lpthread -o test2 test2.cpp（这里未优化，目的是为了避免编译器优化的干扰）。需要注意的是，两个线程运行在两个不同的 CPU 上（CPU 0 和 CPU 1）。只要内存不出现乱序访问，那么 r1 和 r2 不可能同时为 0，因此断言失败表示存在内存乱序访问。编译之后运行此程序，会发现存在一定概率导致断言失败。为了进一步说明问题，我们把 cpu_thread2 的值改为 0，换而言之就是让两个线程跑在同一个 CPU 下，再运行程序发现断言不再失败。</p>
<p>最后，我们使用 CPU Memory barrier 来解决内存乱序访问的问题（X86-64 架构下）：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> cpu_thread1 = <span class="number">0</span>;</span><br><span class="line"><span class="type">int</span> cpu_thread2 = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">run1</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    x = <span class="number">1</span>;</span><br><span class="line">    __asm__ __volatile__(<span class="string">&quot;mfence&quot;</span> ::: <span class="string">&quot;memory&quot;</span>);</span><br><span class="line">    r1 = y;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">run2</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    y = <span class="number">1</span>;</span><br><span class="line">    __asm__ __volatile__(<span class="string">&quot;mfence&quot;</span> ::: <span class="string">&quot;memory&quot;</span>);</span><br><span class="line">    r2 = x;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="准备使用-Memory-barrier"><a class="header-anchor" href="#准备使用-Memory-barrier"></a>准备使用 Memory barrier</h2>
<p>Memory barrier 常用场合包括：</p>
<ol>
<li>实现同步原语（synchronization primitives）</li>
<li>实现无锁数据结构（lock-free data structures）</li>
<li>驱动程序</li>
</ol>
<p>实际的应用程序开发中，开发者可能完全不知道 Memory barrier 就可以开发正确的多线程程序，这主要是因为各种同步机制中已经隐含了 Memory barrier（但和实际的 Memory barrier 有细微差别），这就使得不直接使用 Memory barrier 不会存在任何问题。但是如果你希望编写诸如无锁数据结构，那么 Memory barrier 还是很有用的。</p>
<p>通常来说，在单个 CPU 上，存在依赖的内存访问有序：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Q = P;</span><br><span class="line">D = *Q;</span><br></pre></td></tr></table></figure>
<p>这里内存操作有序。然而在 Alpha CPU 上，存在依赖的内存读取操作不一定有序，需要使用数据依赖 barrier（由于 Alpha 不常见，这里就不详细解释了）。</p>
<p>在 Linux 内核中，除了前面说到的编译器 barrier — barrier() 和 ACCESS_ONCE()，还有 CPU Memory barrier：</p>
<ol>
<li>通用 barrier，保证读写操作有序的，mb() 和 smp_mb()</li>
<li>写操作 barrier，仅保证写操作有序的，wmb() 和 smp_wmb()</li>
<li>读操作 barrier，仅保证读操作有序的，rmb() 和 smp_rmb()</li>
</ol>
<p>注意，所有的 CPU Memory barrier（除了数据依赖 barrier 之外）都隐含了编译器 barrier。这里的 smp 开头的 Memory barrier 会根据配置在单处理器上直接使用编译器 barrier，而在 SMP 上才使用 CPU Memory barrier（也就是 mb()、wmb()、rmb()，回忆上面相关内核代码）。</p>
<p>最后需要注意一点的是，CPU Memory barrier 中某些类型的 Memory barrier 需要成对使用，否则会出错，详细来说就是：一个写操作 barrier 需要和读操作（或数据依赖）barrier 一起使用（当然，通用 barrier 也是可以的），反之依然。</p>
<h2 id="Memory-barrier-的范例"><a class="header-anchor" href="#Memory-barrier-的范例"></a>Memory barrier 的范例</h2>
<p>读内核代码进一步学习 Memory barrier 的使用。</p>
<p>Linux 内核实现的无锁（只有一个读线程和一个写线程时）环形缓冲区 kfifo 就使用到了 Memory barrier，实现源码如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * A simple kernel FIFO implementation.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Copyright (C) 2004 Stelian Pop &lt;stelian@popies.net&gt;</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * This program is free software; you can redistribute it and/or modify</span></span><br><span class="line"><span class="comment"> * it under the terms of the GNU General Public License as published by</span></span><br><span class="line"><span class="comment"> * the Free Software Foundation; either version 2 of the License, or</span></span><br><span class="line"><span class="comment"> * (at your option) any later version.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * This program is distributed in the hope that it will be useful,</span></span><br><span class="line"><span class="comment"> * but WITHOUT ANY WARRANTY; without even the implied warranty of</span></span><br><span class="line"><span class="comment"> * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</span></span><br><span class="line"><span class="comment"> * GNU General Public License for more details.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * You should have received a copy of the GNU General Public License</span></span><br><span class="line"><span class="comment"> * along with this program; if not, write to the Free Software</span></span><br><span class="line"><span class="comment"> * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;linux/kernel.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;linux/module.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;linux/slab.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;linux/err.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;linux/kfifo.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;linux/log2.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * kfifo_init - allocates a new FIFO using a preallocated buffer</span></span><br><span class="line"><span class="comment"> * @buffer: the preallocated buffer to be used.</span></span><br><span class="line"><span class="comment"> * @size: the size of the internal buffer, this have to be a power of 2.</span></span><br><span class="line"><span class="comment"> * @gfp_mask: get_free_pages mask, passed to kmalloc()</span></span><br><span class="line"><span class="comment"> * @lock: the lock to be used to protect the fifo buffer</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Do NOT pass the kfifo to kfifo_free() after use! Simply free the</span></span><br><span class="line"><span class="comment"> * &amp;struct kfifo with kfree().</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">struct</span> kfifo *<span class="title function_">kfifo_init</span><span class="params">(<span class="type">unsigned</span> <span class="type">char</span> *buffer, <span class="type">unsigned</span> <span class="type">int</span> size,</span></span><br><span class="line"><span class="params">                         <span class="type">gfp_t</span> gfp_mask, <span class="type">spinlock_t</span> *lock)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">kfifo</span> *<span class="title">fifo</span>;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/* size must be a power of 2 */</span></span><br><span class="line">    BUG_ON(!is_power_of_2(size));</span><br><span class="line"></span><br><span class="line">    fifo = kmalloc(<span class="keyword">sizeof</span>(<span class="keyword">struct</span> kfifo), gfp_mask);</span><br><span class="line">    <span class="keyword">if</span> (!fifo)</span><br><span class="line">        <span class="keyword">return</span> ERR_PTR(-ENOMEM);</span><br><span class="line"></span><br><span class="line">    fifo-&gt;buffer = buffer;</span><br><span class="line">    fifo-&gt;size = size;</span><br><span class="line">    fifo-&gt;in = fifo-&gt;out = <span class="number">0</span>;</span><br><span class="line">    fifo-&gt;lock = lock;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> fifo;</span><br><span class="line">&#125;</span><br><span class="line">EXPORT_SYMBOL(kfifo_init);</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * kfifo_alloc - allocates a new FIFO and its internal buffer</span></span><br><span class="line"><span class="comment"> * @size: the size of the internal buffer to be allocated.</span></span><br><span class="line"><span class="comment"> * @gfp_mask: get_free_pages mask, passed to kmalloc()</span></span><br><span class="line"><span class="comment"> * @lock: the lock to be used to protect the fifo buffer</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * The size will be rounded-up to a power of 2.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">struct</span> kfifo *<span class="title function_">kfifo_alloc</span><span class="params">(<span class="type">unsigned</span> <span class="type">int</span> size, <span class="type">gfp_t</span> gfp_mask, <span class="type">spinlock_t</span> *lock)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">char</span> *buffer;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">kfifo</span> *<span class="title">ret</span>;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * round up to the next power of 2, since our &#x27;let the indices</span></span><br><span class="line"><span class="comment">     * wrap&#x27; technique works only in this case.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">if</span> (!is_power_of_2(size)) &#123;</span><br><span class="line">        BUG_ON(size &gt; <span class="number">0x80000000</span>);</span><br><span class="line">        size = roundup_pow_of_two(size);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    buffer = kmalloc(size, gfp_mask);</span><br><span class="line">    <span class="keyword">if</span> (!buffer)</span><br><span class="line">        <span class="keyword">return</span> ERR_PTR(-ENOMEM);</span><br><span class="line"></span><br><span class="line">    ret = kfifo_init(buffer, size, gfp_mask, lock);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (IS_ERR(ret))</span><br><span class="line">        kfree(buffer);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ret;</span><br><span class="line">&#125;</span><br><span class="line">EXPORT_SYMBOL(kfifo_alloc);</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * kfifo_free - frees the FIFO</span></span><br><span class="line"><span class="comment"> * @fifo: the fifo to be freed.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">kfifo_free</span><span class="params">(<span class="keyword">struct</span> kfifo *fifo)</span></span><br><span class="line">&#123;</span><br><span class="line">    kfree(fifo-&gt;buffer);</span><br><span class="line">    kfree(fifo);</span><br><span class="line">&#125;</span><br><span class="line">EXPORT_SYMBOL(kfifo_free);</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * __kfifo_put - puts some data into the FIFO, no locking version</span></span><br><span class="line"><span class="comment"> * @fifo: the fifo to be used.</span></span><br><span class="line"><span class="comment"> * @buffer: the data to be added.</span></span><br><span class="line"><span class="comment"> * @len: the length of the data to be added.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * This function copies at most @len bytes from the @buffer into</span></span><br><span class="line"><span class="comment"> * the FIFO depending on the free space, and returns the number of</span></span><br><span class="line"><span class="comment"> * bytes copied.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Note that with only one concurrent reader and one concurrent</span></span><br><span class="line"><span class="comment"> * writer, you don&#x27;t need extra locking to use these functions.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="type">unsigned</span> <span class="type">int</span> __kfifo_put(<span class="keyword">struct</span> kfifo *fifo,</span><br><span class="line">                         <span class="type">const</span> <span class="type">unsigned</span> <span class="type">char</span> *buffer, <span class="type">unsigned</span> <span class="type">int</span> len)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> l;</span><br><span class="line"></span><br><span class="line">    len = min(len, fifo-&gt;size - fifo-&gt;in + fifo-&gt;out);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * Ensure that we sample the fifo-&gt;out index -before- we</span></span><br><span class="line"><span class="comment">     * start putting bytes into the kfifo.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    smp_mb();</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* first put the data starting from fifo-&gt;in to buffer end */</span></span><br><span class="line">    l = min(len, fifo-&gt;size - (fifo-&gt;in &amp; (fifo-&gt;size - <span class="number">1</span>)));</span><br><span class="line">    <span class="built_in">memcpy</span>(fifo-&gt;buffer + (fifo-&gt;in &amp; (fifo-&gt;size - <span class="number">1</span>)), buffer, l);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* then put the rest (if any) at the beginning of the buffer */</span></span><br><span class="line">    <span class="built_in">memcpy</span>(fifo-&gt;buffer, buffer + l, len - l);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * Ensure that we add the bytes to the kfifo -before-</span></span><br><span class="line"><span class="comment">     * we update the fifo-&gt;in index.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    smp_wmb();</span><br><span class="line"></span><br><span class="line">    fifo-&gt;in += len;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> len;</span><br><span class="line">&#125;</span><br><span class="line">EXPORT_SYMBOL(__kfifo_put);</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * __kfifo_get - gets some data from the FIFO, no locking version</span></span><br><span class="line"><span class="comment"> * @fifo: the fifo to be used.</span></span><br><span class="line"><span class="comment"> * @buffer: where the data must be copied.</span></span><br><span class="line"><span class="comment"> * @len: the size of the destination buffer.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * This function copies at most @len bytes from the FIFO into the</span></span><br><span class="line"><span class="comment"> * @buffer and returns the number of copied bytes.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Note that with only one concurrent reader and one concurrent</span></span><br><span class="line"><span class="comment"> * writer, you don&#x27;t need extra locking to use these functions.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="type">unsigned</span> <span class="type">int</span> __kfifo_get(<span class="keyword">struct</span> kfifo *fifo,</span><br><span class="line">                         <span class="type">unsigned</span> <span class="type">char</span> *buffer, <span class="type">unsigned</span> <span class="type">int</span> len)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> l;</span><br><span class="line"></span><br><span class="line">    len = min(len, fifo-&gt;in - fifo-&gt;out);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * Ensure that we sample the fifo-&gt;in index -before- we</span></span><br><span class="line"><span class="comment">     * start removing bytes from the kfifo.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    smp_rmb();</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* first get the data from fifo-&gt;out until the end of the buffer */</span></span><br><span class="line">    l = min(len, fifo-&gt;size - (fifo-&gt;out &amp; (fifo-&gt;size - <span class="number">1</span>)));</span><br><span class="line">    <span class="built_in">memcpy</span>(buffer, fifo-&gt;buffer + (fifo-&gt;out &amp; (fifo-&gt;size - <span class="number">1</span>)), l);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* then get the rest (if any) from the beginning of the buffer */</span></span><br><span class="line">    <span class="built_in">memcpy</span>(buffer + l, fifo-&gt;buffer, len - l);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * Ensure that we remove the bytes from the kfifo -before-</span></span><br><span class="line"><span class="comment">     * we update the fifo-&gt;out index.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    smp_mb();</span><br><span class="line"></span><br><span class="line">    fifo-&gt;out += len;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> len;</span><br><span class="line">&#125;</span><br><span class="line">EXPORT_SYMBOL(__kfifo_get);</span><br></pre></td></tr></table></figure>
<p>为了更好的理解上面的源码，这里顺带说一下此实现使用到的一些和本文主题无关的技巧：</p>
<ol>
<li>使用与操作来求取环形缓冲区的下标，相比取余操作来求取下标的做法效率要高不少。使用与操作求取下标的前提是环形缓冲区的大小必须是 2 的 N 次方，换而言之就是说环形缓冲区的大小为一个仅有一个 1 的二进制数，那么 index &amp; (size – 1) 则为求取的下标（这不难理解）</li>
<li>使用了 in 和 out 两个索引且 in 和 out 是一直递增的（此做法比较巧妙），这样能够避免一些复杂的条件判断（某些实现下，in == out 时还无法区分缓冲区是空还是满）</li>
</ol>
<p>这里，索引 in 和 out 被两个线程访问。in 和 out 指明了缓冲区中实际数据的边界，也就是 in 和 out 同缓冲区数据存在访问上的顺序关系，由于未使用同步机制，那么保证顺序关系就需要使用到 Memory barrier 了。索引 in 和 out 都分别只被一个线程修改，而被两个线程读取。__kfifo_put 先通过 in 和 out 来确定可以向缓冲区中写入数据量的多少，这时，out 索引应该先被读取后才能真正的将用户 buffer 中的数据写入缓冲区，因此这里使用到了 smp_mb()，对应的，__kfifo_get 也使用 smp_mb() 来确保修改 out 索引之前缓冲区中数据已经被成功读取并写入用户 buffer 中了。对于 in 索引，在 __kfifo_put 中，通过 smp_wmb() 保证先向缓冲区写入数据后才修改 in 索引，由于这里只需要保证写入操作有序，故选用写操作 barrier，在 __kfifo_get 中，通过 smp_rmb() 保证先读取了 in 索引（这时候 in 索引用于确定缓冲区中实际存在多少可读数据）才开始读取缓冲区中数据（并写入用户 buffer 中），由于这里只需要保证读取操作有序，故选用读操作 barrier。</p>
<p>到这里，Memory barrier 就介绍完毕了。</p>
<h2 id="参考文献列表："><a class="header-anchor" href="#参考文献列表："></a>参考文献列表：</h2>
<p><a href="http://en.wikipedia.org/wiki/Memory_barrier">http://en.wikipedia.org/wiki/Memory_barrier</a><br>
<a href="http://en.wikipedia.org/wiki/Out-of-order_execution">http://en.wikipedia.org/wiki/Out-of-order_execution</a><br>
<a href="https://www.kernel.org/doc/Documentation/memory-barriers.txt">https://www.kernel.org/doc/Documentation/memory-barriers.txt</a></p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/understand-memory-barrier/">http://xnerv.wang/understand-memory-barrier/</a></strong><br>
转载自：<a href="http://name5566.com/4535.html">理解 Memory barrier（内存屏障）</a></p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>操作系统</tag>
        <tag>内存屏障</tag>
      </tags>
  </entry>
  <entry>
    <title>Understanding MySQL Isolation Levels: Repeatable-Read（转载）</title>
    <url>/understanding-mysql-isolation-levels-repeatable-read/</url>
    <content><![CDATA[<p>Isolation levels are a rare subject in MySQL literature. The documentation provides a terse description and focuses mainly on locking issues, but does not discuss the semantics of each isolation level. This is not only a problem that affects MySQL documentation but also the SQL standard itself.</p>
<p>Both the lack of documentation and the absence of a deeper description of the expected behavior in the SQL standard make <em>isolation levels</em> a topic that is more assumed than known by database administrators and developers. In this blog post, I aim to help you understand how the default isolation level in MySQL works and show you some surprising facts about it.</p>
<p>But first let’s see how isolation levels are described in the standard: “The transaction isolation level of a SQL-transaction defines the degree to which the operations on SQL-data, or schemas in that SQL-transaction are affected by the effects of and can affect operations on SQL-data or schemas in concurrent SQL-transactions”. To put it in plain words, isolation levels define how concurrent transactions interact while modifying data.</p>
<p>MySQL uses <strong>Repeatable-read</strong> as the default level. In the standard, this level forbids <em>dirty reads</em> (non committed data) and <em>non repeatable reads</em> (executing the same query twice should return the same values) and allows <em>phantom</em> reads (new rows are visible). But MySQL implements it in a different way. Let’s see how it is implemented with some examples.</p>
<span id="more"></span>
<h2 id="MySQL-Repeatable-Read-tests"><a class="header-anchor" href="#MySQL-Repeatable-Read-tests"></a>MySQL Repeatable-Read tests</h2>
<p>We create two connections against a MySQL server. We will call them <strong>Session Blue</strong> and <strong>Session Red</strong> (The fact that these are the colors of <a href="https://www.fcbarcelona.com">FC Barcelona</a> is purely coincidental). In Session Blue we will create the database <em>isolation</em> and the table <em>repeatable_read</em>, both will be required for this test.</p>
<p><img src="http://pythianblog.wpengine.com/wp-content/uploads/1_session_a.png" alt="Create database isolation and table repeatable_read"></p>
<h3 id="No-phantom-reads…-only-phantom-writes"><a class="header-anchor" href="#No-phantom-reads…-only-phantom-writes"></a>No phantom reads… only phantom writes!</h3>
<p>We start a transaction, verify current isolation level by checking the value of the variable <strong>tx_isolation</strong>, and retrieve the contents of <em>repeatable_read</em> table, this way we create a snapshot of that table for the whole transaction.</p>
<p><img src="http://pythianblog.wpengine.com/wp-content/uploads/2_session_a.png" alt="Start transaction, check tx_isolation value and retrieve table contents"></p>
<p>Now we move to Session Red and insert two rows into the table. We commit the transaction to make sure data is updated.</p>
<p><img src="http://pythianblog.wpengine.com/wp-content/uploads/3_session_b.png" alt="In a different session we insert two rows into the table"></p>
<p>Next we check what data is retrieved in Session Blue.</p>
<p><img src="http://pythianblog.wpengine.com/wp-content/uploads/4_session_a.png" alt="The first session, as expected, is not able to see the data inserted in the previous step."></p>
<p>As we can see, <em>repeatable-read</em> in MySQL avoids <em>Phantom Reads</em>, as rows are not retrieved. This is more restrictive than the standard description of the isolation level. But, what happens if we try to update the table contents? Our intuition is that we should not update any rows.</p>
<p><img src="http://pythianblog.wpengine.com/wp-content/uploads/5_session_a.png" alt="But I'm able to update the added rows."></p>
<p>Surprise! The update command tells us that one row matched and one row was changed. Let’s select table contents to view what is happening.</p>
<p><img src="http://pythianblog.wpengine.com/wp-content/uploads/6_session_a.png" alt="Now we see only the rows modified in the table."></p>
<p>We see just one row, the row that was modified by the update executed before. This is quite unexpected and counter-intuitive as the table never had one single row committed; we inserted and committed two rows. We are seeing a view of the table that never existed. As expected, when we commit, we see both rows, the one we modified and the other that was inserted before in Session Red.</p>
<p><img src="http://pythianblog.wpengine.com/wp-content/uploads/7_session_a.png" alt="When we commit, we can see all the data."></p>
<h3 id="More-phantom-writes"><a class="header-anchor" href="#More-phantom-writes"></a>More phantom writes!</h3>
<p>Now we will begin another transaction and retrieve table contents. We retrieve table contents to create a snapshot (probably we should call it a version) of the table.</p>
<p><img src="http://pythianblog.wpengine.com/wp-content/uploads/8_session_a.png" alt="We start a new transaction and retrieve table contents."></p>
<p>Back in Session Red, we will run a transaction to update the contents of the table. Note: <em>Phantom reads</em> only affect new rows, not the ones already existing.</p>
<p><img src="http://pythianblog.wpengine.com/wp-content/uploads/9_session_b.png" alt="We update one of the existing rows in another session."></p>
<p>Let’s find what Session Blue retrieves and what can update.</p>
<p><img src="http://pythianblog.wpengine.com/wp-content/uploads/10_session_a-1.png" alt="Updates do not honor the values retrieved, but the values modified in a different session."></p>
<p>Initially, we see the table unchanged. But no rows matched when we try to update the table using the data we retrieved in the select. We see one row with value “modified” for the <em>text</em> column, but the update finds no rows. When we update the table using a column value that was not modified by any transaction, in this case <em>id</em>, then we are able to proceed. Now we see the new value for the <em>text</em> column.</p>
<h3 id="WYSINWYW-What-you-see-is-NOT-what-you-write"><a class="header-anchor" href="#WYSINWYW-What-you-see-is-NOT-what-you-write"></a>WYSINWYW (What you see is NOT what you write)</h3>
<p>We will return our table to the original values and we will create an additional table required for the next test.</p>
<p><img src="http://pythianblog.wpengine.com/wp-content/uploads/11_session_a-1.png" alt="We rebuild the table with the original values and create one more table."></p>
<p>As usual we start a new transaction and we retrieve table contents to create the snapshot.</p>
<p><img src="http://pythianblog.wpengine.com/wp-content/uploads/12_session_a.png" alt="Once again we start a transaction and retrieve table contents."></p>
<p>Now we go back to Session Red to update the contents of the whole table.</p>
<p><img src="http://pythianblog.wpengine.com/wp-content/uploads/13_session_b.png" alt="In another session, we modify table data."></p>
<p>Returning to Session Blue, we “clone” the contents of the table <em>repeatable_read</em> to <em>repeatable_read_copy</em> table using an <em>insert into … select</em> statement. After that we retrieve the values of both tables using a select.</p>
<p><img src="http://pythianblog.wpengine.com/wp-content/uploads/14_session_a.png" alt="We do an insert as select to copy the table results and we find that rows are written with the modified values"></p>
<p>The values of rows inserted into the copy table using an <em>insert into … as select</em> is <strong>different</strong> than the values of rows retrieved using a regular <em>select</em> statement. Once we commit the transaction, as expected, we are able to see the modified data in the original table too.</p>
<p><img src="http://pythianblog.wpengine.com/wp-content/uploads/15_session_a.png" alt="Results now are as expected"></p>
<h2 id="Conclusions"><a class="header-anchor" href="#Conclusions"></a>Conclusions</h2>
<p>After these tests, we have found about MySQL implementation of <em>Repeatable-read</em> isolation level:</p>
<ul>
<li>When using just select statements is even more restrictive than SQL Standard, as <em>Phantom Reads</em> do not happen. Besides the snapshot is used for all tables and all rows, as we find while we use a <em>mysqldump with –single-transaction</em>.</li>
<li>When the transaction modifies data, the behavior is a mix of <em>Repeatable-read</em> (rows not modified are not visible) and <em>Read committed</em> (modified rows are visible). We cannot say that this is not the standard as these situations are not described in it and do not fit in the three concurrency phenomena: <em>Dirty Read, Non-repeatable Read and Phantom Read</em>.</li>
<li>When the transaction writes new data based on existing data, it uses the committed data, instead of the snapshot retrieved previously. This is valid both for modified and new rows, mimicking <em>Read committed</em> behavior.</li>
</ul>
<p>The way MySQL implements Repeatable Read is not intuitive and, although it is required to support statement replication, can lead to some problems while running data modification and transfer to other tables in concurrent transactions. If your application can face these issues, you will need to modify your queries using <em>select … for update</em> statements and thus increase the number of locks in the database.</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/understanding-mysql-isolation-levels-repeatable-read/">http://xnerv.wang/understanding-mysql-isolation-levels-repeatable-read/</a></strong><br>
转载自：<a href="https://blog.pythian.com/understanding-mysql-isolation-levels-repeatable-read/">Understanding MySQL Isolation Levels: Repeatable-Read</a></p>
]]></content>
      <categories>
        <category>DBMS</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>DBMS</tag>
        <tag>MySQL</tag>
        <tag>Transaction</tag>
        <tag>Isolation Level</tag>
      </tags>
  </entry>
  <entry>
    <title>(Stack Overflow) Understanding SIX lock in SQL Server</title>
    <url>/understanding-six-lock-in-sql-server/</url>
    <content><![CDATA[<h2 id="Question"><a class="header-anchor" href="#Question"></a>Question</h2>
<p>Can somebody explain me how a process can acquire <code>SIX</code> lock on a page? I my deadlock-graph xml file I see that a process running under <strong>RC isolation level</strong> (executing a <code>select</code> statement at the moment of deadlock) holds a <code>SIX</code> lock on a page.</p>
<p>What does this mean and how that lock could have been acquired? From what I got from <a href="http://msdn.microsoft.com/en-us/library/aa213039%28v=sql.80%29.aspx">http://msdn.microsoft.com/en-us/library/aa213039%28v=sql.80%29.aspx</a> <code>SIX</code> locks protects <code>S</code>-locks on all resources and <code>IX</code> locks on some resources lower in the hierarchy.</p>
<p>For my case that would be <code>IX</code>-locks on rows? Can <code>IX</code>-lock be placed on a row? (I guess no). I am confused.</p>
<p>Another thing is that I expect several <code>X</code>-locks on rows and no <code>S</code>-locks at all (since the <strong>IL</strong> is <strong>ReadCommited</strong>). Why do I have the whole page locked with <code>SIX</code> if I only inserted several records in previous statement?</p>
<p>up!</p>
<span id="more"></span>
<h2 id="Answer-by-Sebastian-Meine"><a class="header-anchor" href="#Answer-by-Sebastian-Meine"></a>Answer by Sebastian Meine</h2>
<p>To answer that I have to take a little detour, so bear with me. If two sessions take a lock on the same resource SQL Server checks the lock compatibility map and if the second request is not “compatible” with the first, the second session has to wait. There are three lock types &quot;S&quot;hared, &quot;U&quot;pdate and e&quot;X&quot;clusive. S locks are taken to read from a resource and X locks are taken to write to a resource. S locks are compatible with each other, X locks are not compatible with anything else. U locks are a hybrid that is used in some cases for deadlock prevention.</p>
<p>Now, SQL Server can take locks on several levels:Table, Partition, Page and Row. So if session one takes a table lock and session two takes a non-compatible lock on one row of the table, those two locks are not on the same resource and SQL Server won’t detect the collision. To protect against that, SQL Server always starts to take a lock on the table level and works its way down the hierarchy. Now the point of page and row locks is higher concurrency, so if one session wants to write to one row and another session wants to write to another row, they should not block each other. If a session in addition to taking a lock on a row also has to take the same lock on the table, that advantage is gone. So instead of taking an exclusive lock (X) on the table, the session requests an intend-exclusive lock (IX). This lock is compatible with other intend locks but not with other “real” locks. So another session can take an intend-exclusive lock on the same table as well. The intend-exclusive lock says, that the session intends to take an exclusive lock on a lower level resource. The same happens on the page level, if the intended lock is a row lock, so after all is done, the session has an IX lock on the table and on one of the pages and an X lock on one of the rows in that page. This also means, that you will never find an intend lock on a row as rows are the lowest level in the lock hierarchy.</p>
<p>In some circumstances a session holds an S lock on the table or a page. If the session now (within the same transaction) requests an X lock on a row in that same table, it first has to take an IX lock on the table/page. However, a session can hold only one lock on any given resource. So to take the IX lock, it would have to release the S lock wich is probably not desired, so SQL Server offers a combination: SIX.</p>
<p>The reason why you have a page lock is due to SQL Server sometimes deciding that it would be better to lock the page instead of locking each row. That happens often if there are very many locks taken between all sessions already, but can have many other reasons too.</p>
<p>So far the theory.</p>
<p>Now in your case the SIX lock is held by a three table join select query. A select never takes any type of lock that is not a shared lock unless you explicitly tell it to (e.g. with a XLOCK hint). Such a hint is not visible within the input buffer, so I assume the IX part is a left over from the last batch on this connection. If you are using connection pooling and forget to cleanup all open transactions, such a lock can live potentially forever. But it becomes also very hard to troubleshoot.</p>
<p>You could start by running an XEvent session that pairs OPEN TRANs with COMMITs and see if you can find the culprit that way.</p>
<hr>
<p><strong>Article link: <a href="http://xnerv.wang/understanding-six-lock-in-sql-server/">http://xnerv.wang/understanding-six-lock-in-sql-server/</a></strong><br>
Reprinted from: <a href="https://stackoverflow.com/questions/17319971/understanding-six-lock-in-sql-server">(StackOverflow) Understanding SIX lock in SQL Server</a></p>
]]></content>
      <categories>
        <category>DBMS</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>DBMS</tag>
        <tag>SQL Server</tag>
        <tag>Transaction</tag>
        <tag>SIX Lock</tag>
      </tags>
  </entry>
  <entry>
    <title>用VSCode代替Atom作为Markdown编辑器</title>
    <url>/use-vscode-instead-of-atom-as-markdown/</url>
    <content><![CDATA[<p>从大学开始我就有做编程笔记的习惯。最开始是写在txt文件中直接放本地硬盘，也因此由于不小心格式化硬盘而丢了一些原始的笔记。后来在云笔记开始兴起之后，使用过几年的为知笔记。再加上为知笔记有直接保存网页的插件，因此我也将浏览器收藏夹中收集的一些技术网页直接保存到了为知笔记中，避免了网页失效而造成的知识丢失（其实现在的技术博客会被套娃式地转载好多次，就算删除原始文章也基本能找到了。。。）。随着积累的没看过的网页越来越多，消耗的速度完全跟不上增长的速度，也慢慢开始总结和消化收集的网页上的知识，记录下要点并标注来源URL，因此开始转向了Markdown。我喜欢上Markdown的另一个原因是我有点很多码农都有的编程洁癖，对于富文本总是想调整好每一处的格式、颜色和字体，因此支持富文本的Word、网络云笔记啥的简直就是我的噩梦，而Markdown则拯救了我这样的强迫症。</p>
<p>几年前，为了找了一款可以在Windows平台上运行的满意的Markdown编辑器，我曾经试用和对比了能找到的几款Markdown编辑器。</p>
<span id="more"></span>
<p>作业部落的Cmd Markdown是当时我接触的完成度最高的Markdown编辑器，插入图片非常方便，各种辅助功能都已经事先做好，不需要自己去做一大堆的配置和安装插件，并且最大的特点是笔记会云同步备份在服务器上。我用过一段时间的Cmd Markdown，但最终还是迁走了。最大的原因是笔记是保存在编辑器的数据文件中，而不是以明文的md文件直接保存在本地。这让我有点不安，哪一天如果这个编辑器出了bug打不开程序，或者这编辑器背后的公司破产，我的数据可能就此付之一炬，而我没有任何办法导出我的文件。</p>
<p>马克飞翔是印象笔记Evernote的一个Markdown插件。我对马克飞翔的印象是UI做得很好，各种功能也很齐全。然而缺点跟Cmd Markdown是一样的，由于印象笔记的文件也是保存在数据文件中的，无法通过其它文本工具直接编辑。而我更希望将文件直接放在我的硬盘里，可以通过各种文本工具进行编辑。</p>
<p>我还用过一个叫做Typora的比较有特色的的Markdown编辑器。大多数的Markdown编辑器是将界面一分为二，左边写Markdown源码，右边是最终效果Preview，当然一般左边的编辑栏也会有一些基本的语法高亮。但Typora则是将两个界面整合在了一起，同时可以在源码视图和结果视图中进行切换。老实说这样的做法有利有弊，纯粹看个人喜好。Typora至今应该仍不支持File Tree，也就是说一次只能编辑一个文档，如果要同时编辑多个Markdown文档就需要同时打开多个Typora进程。我至今仍保留安装着Typora，并希望将来有机会能拿出来用用，虽然至今我仍未再次用过。</p>
<p>再后来，我开始使用github开源的Atom编辑器。有一个叫做Markdown Preview Enhanced的Atom插件，将一些常用的Markdown功能都整合到了一起，我非常喜欢这个插件。Atom应该是我使用时间最长且至今最为满意的Markdown编辑器了，配合各种Atom插件非常顺手，各种Markdown效果也基本满足我的需求。然后我再用Seafile搭建了个人云存储，将Markdown文件放在个人云盘里。</p>
<p>不知道是不是由于微软收购了github和微软大力推广VSCode的缘故，感觉Atom最近几年的更新已经很少了，而且经常会出现插件加载失败的问题。例如Atom官网论坛上的18年的帖子<a href="https://discuss.atom.io/t/is-atom-dead/55346">Is atom dead?</a>和19年的帖子<a href="https://discuss.atom.io/t/is-atom-dead-again/70550/23">Is atom dead, again?</a>都在讨论这个问题，相信不只是我的个人猜测。</p>
<p>而最后让我下定决心离开Atom的则是<a href="https://github.com/shd101wyy/markdown-preview-enhanced/issues/1380">Markdown Preview Enhanced not working in Atom 1.47.0 #1380</a>。我最爱的Markdown Preview Enhanced由于Atom的bug而彻底不能使用，但目前看来Atom方面的修复还遥遥无期。</p>
<p>很久以前我曾尝试过用VSCode写Markdown。当时Markdown Preview Enhanced还不支持VSCode，因此我在整合了一堆Markdown的插件后仍觉得效果不佳，因此放弃。不知道是不是Markdown Preview Enhanced的作者也察觉到了Atom正在走向死亡，因此也开始支持VSCode平台。在试用了最新的VSCode + Markdown Preview Enhanced后，我发现原本在Atom上常用的功能，在VSCode上都能找到，例如：</p>
<ul>
<li>Atom上可以用Tree View浏览目录结构，而VSCode自带File Explorer左侧边栏。</li>
<li>Atom上有Project Manager插件可以在左侧边栏上同时打开多个目录，这样我就可以将多个Markdown目录同时加入进来。而VSCode也支持Workspace的概念，可以将多个目录加入进来。</li>
<li>VSCode有和Atom类似的file-icons插件，可以在左侧边栏上针对不同类型的文件显示不同的icon便于区分。</li>
<li>VSCode自带minimap/autosave功能，而Atom上则是通过安装插件实现。</li>
<li>VSCode可以登录微软账号或github账号同步插件和配置。Atom则是通过安装插件实现，配置保存在指定Gist。但根据我使用了几年的体验，如果有多台电脑同步配置的情况下，经常会出现一些问题，因此我从去年开始屏蔽了Atom上的同步插件。</li>
<li>但遗憾的是，像Cmd Markdown等编辑器所支持的TOC大纲（就是有一个单独的窗口或者下拉菜单显示各级标题，类似Word的左侧边栏的大纲视图），在VSCode和Atom中都没有相应的插件可以支持，而只是可以在文章中插入TOC链接。我所希望的是有一个插件可以在VSCode的左侧边栏上可以显示TOC大纲，但目前暂未发现有这样的插件。</li>
</ul>
<h2 id="2023-08-20刚发现VSCode已经-原生支持显示TOC大纲-Document-outline-了。效果如图："><a class="header-anchor" href="#2023-08-20刚发现VSCode已经-原生支持显示TOC大纲-Document-outline-了。效果如图："></a><strong>2023/08/20</strong><br>
刚发现VSCode已经[原生支持显示TOC大纲](Document outline)了。效果如图：<br>
<img src="https://code.visualstudio.com/assets/docs/languages/Markdown/markdown-outline-view.png" alt=""></h2>
<p><strong>本文地址：<a href="http://xnerv.wang/use-vscode-instead-of-atom-as-markdown/">http://xnerv.wang/use-vscode-instead-of-atom-as-markdown/</a></strong></p>
]]></content>
      <categories>
        <category>程序员生活</category>
      </categories>
      <tags>
        <tag>程序员生活</tag>
        <tag>VSCode</tag>
        <tag>Atom</tag>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title>linux共享库的版本控制和使用（转载）</title>
    <url>/version-control-and-usage-of-linux-shared-library/</url>
    <content><![CDATA[<h2 id="linux约定"><a class="header-anchor" href="#linux约定"></a>linux约定</h2>
<p>经常看到linux中，共享库的名字后面跟了一串数字，比如：<code>libperl.so.5.18.2</code>。其实就是版本号，作用是为了更加方便的管理动态库，比如升级。往往系统中存在一个库的多个版本，那么Linux 系统如何控制多个版本的问题？Window之前没有处理好，为此专门有个名词来形容这个问题：“Dll hell”，其严重影响软件的升级和维护。“Dll hell”是指windows上动态库的新版本覆盖了旧版本，﻿﻿但是却不兼容老版本，所以程序升级之后，动态库更新导致程序运行不起来。在Linux操作系统下也有同样的问题，那么它是怎么解决的呢？</p>
<p>Linux引入了一套机制，如果遵守这个机制就可以避免这个问题。 但是这只事一个约定，不是强制的。通常建议用户遵守这个约定，否则也会出现Linux版的“Dll hell”问题。 下面来介绍一个这个机制。 这个机制是通过文件名，来控制动态库（shared library）的版本。</p>
<span id="more"></span>
<p>Linux上的shared library有三个名字，分别是：</p>
<ul>
<li>
<p><strong>共享库本身的文件名（real name)</strong></p>
<p>其通常包含完整的版本号，比如：libmath.so.1.1.1234 。lib是Linux库的约定前缀，math是共享库名字，so是共享库的后缀名，1.1.1234的是共享库的版本号，由<code>主版本号+小版本号+build号</code>组成。主版本号，代表当前动态库的版本，如果共享库的接口发生变化，那么这个版本号就要加1；后面的两个版本号（<code>小版本号</code>和 <code>build号</code>）是用来指示库的更新迭代号，表示在接口没有改变的情况下，由于需求发生变化等因素，开发的新代码。</p>
</li>
<li>
<p><strong>共享库的soname（Short for shared object name）</strong></p>
<p>用来告诉应用程序，在加载共享库的时候，应该使用的文件名。其格式为<code>lib + math + .so + (major version number)</code> 其只包含主版本号，换句话说，也就是只要共享库的接口没有变，soname就能与real name保持一致，因为主版本号一样。所以在库的real name的<code>小版本号</code>和 <code>build号</code>发生改变时，应用程序仍然可以通过soname得知，要使用的是哪个real name。不明白？等会给个例子来说明。</p>
</li>
<li>
<p><strong>共享库的链接名（link name）</strong></p>
<p>是专门为应用程序在编译时的链接阶段而用的名字。这个名字就是lib + math +.so ,<a href="http://xn--libmath-i22ms57k.so">比如libmath.so</a>。其是不带任何版本信息的。在共享库的编译过程中，编译器将生成一个共享库及real name，同时将共享库的soname写在共享库文件里的文件头里面。可以用命令<code>readelf -d sharelibrary | grep soname</code>查看。 在应用程序引用共享库时，链接选项里面用的是共享库的link name。通过link名字找到对应的real name动态库，并且把其中的soname提取出来，写在应用程序自己的文件头的共享库字段里面。当应用程序运行时，就会通过soname，结合动态链接程序（<a href="http://ld.so">ld.so</a>），在给定的路径下加载real name的共享库。</p>
</li>
</ul>
<p>##如何使用 这里我们写了一个简单的例子，包含了三个文件，分别是：</p>
<ul>
<li>test.h</li>
</ul>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifndef</span> _TEST_H_</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> _TEST_H_</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">print_hello</span><span class="params">()</span>;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure>
<ul>
<li>test.c</li>
</ul>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;test.h&quot;</span></span></span><br><span class="line"><span class="type">void</span> <span class="title function_">print_hello</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;this is a test for shared lib&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>main.c</li>
</ul>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;test.h&quot;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">	print_hello();</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>首先编译共享库：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gcc -fPIC -o test.o -c test.c</span><br><span class="line">gcc -shared -Wl,-soname,libtest.so.0 -o libtest.so.0.0.0 test.o</span><br></pre></td></tr></table></figure>
<p>然后就生成了libtest.so.0.0.0,这就是库的real name。另外，链接选项里面的<code>-Wl,-soname,libtest.so.0</code>告诉编译器，库的soname是libtest.so.0,我们可以看到real name的头文件里面，已经包含了这样的信息：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">readelf -d libtest.so.0.0.0 | grep soname</span><br><span class="line"> 0x0000000e (SONAME) Library soname: [libtest.so.0]</span><br></pre></td></tr></table></figure>
<p>如果没有指定soname，库的头文件里面是没有这个字段的。 有了库以后，下一步是链接到应用程序里面，我们需要这样写：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gcc -c -o main.o main.c</span><br><span class="line">gcc -L. -o main main.o -ltest</span><br></pre></td></tr></table></figure>
<p>但是会报错“cannot find -ltest”。这里因为，链接选项制定的是link name，而根据linux的规则，此目录下面并没有libtest.so文件，所以需要先生成link name文件。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">ln</span> -s libtest.so.0.0.0  libtest.so.0</span><br><span class="line"><span class="built_in">ln</span> -s libtest.so.0 libtest.so</span><br></pre></td></tr></table></figure>
<p>或者一步到位：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">ln</span> -s libtest.so.0.0.0 libtest.so</span><br></pre></td></tr></table></figure>
<p>然后再进行应用程序的编译：<strong>gcc -L. -o main main.o -ltest</strong></p>
<p>ok，生成了我们需要的main可执行程序。查看一下，其引用的共享库：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ldd main</span><br><span class="line">	linux-gate.so.1 =&gt;  (0xb76fb000)</span><br><span class="line">	libtest.so.0 =&gt; not found</span><br><span class="line">	libc.so.6 =&gt; /lib/i386-linux-gnu/libc.so.6 (0xb752e000)</span><br><span class="line">	/lib/ld-linux.so.2 (0xb76fc000)</span><br></pre></td></tr></table></figure>
<p>没错，链接时，应用程序需要的库正是我们指定的soname，而不是link name或者real name。所以应用程序正是通过soname去寻找真正的real name库。这有什么好处吗？答案后面揭晓。另外，上面的输出中，我们发现，libtest.so.0是<code>not found</code>的状态。为什么呢？因为这个库的当前所在路径并不在链接程序（<a href="http://ld.so">ld.so</a>)的搜索路径之中，所以无法找到。如何解决？这篇文章就不多说了，这里提供几个方案：</p>
<ul>
<li>
<p><strong>改变LD_LIBRARY_PATH</strong></p>
<p><code>export LD_LIBRARY_PATH=/home/bow/all/program/test/lib_version_test:$LD_LIBRARY_PATH</code></p>
<p>这里<code>/home/bow/all/program/test/lib_version_test</code>是共享库的路径。虽然改变LD_LIBRARY_PATH能达到目的，但是不推荐使用，因为这是一个全局的变量，其他应用程序可能受此影响，导致各种库的覆盖问题。如果要清楚这个全局变量，使用命令<strong>unset LD_LIBRARY_PATH</strong></p>
</li>
<li>
<p><strong>用rpath</strong></p>
<p>在编译应用程序时，利用rpath指定加载路径。 <code>gcc -L. -Wl,-rpath=/home/bow/all/program/test/lib_version_test -o test main.o -ltest</code> 这样，虽然避免了各种路径找不到的问题，但是也失去了灵活性。因为库的路径被定死了。</p>
</li>
<li>
<p><strong>改变ld.so.conf</strong></p>
<p>将路径添加到此文件，然后使用<code>ldconfig</code>更新加载程序的cache。 可以使用命令<code>ldconfig -p</code>查看当前所有库的soname-&gt;real name的对应关系信息</p>
</li>
</ul>
<p>这里我们选择最后一种方式。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">bow@bow-Aspire-4752:vim /etc/ld.so.conf</span><br><span class="line"><span class="comment">##添加路径到文件末：/home/bow/all/program/test/lib_version_test</span></span><br><span class="line">bow@bow-Aspire-4752:ldconfig</span><br><span class="line">bow@bow-Aspire-4752:~/all/program/test/lib_version_test$ ./main</span><br><span class="line">this is a <span class="built_in">test</span> <span class="keyword">for</span> shared lib</span><br></pre></td></tr></table></figure>
<p>最后说一下，应用程序在编译链接和运行加载时，库的搜索路径的先后顺序。</p>
<ul>
<li>编译链接时，查找顺序
<ul>
<li>/usr/local/lib</li>
<li>/usr/lib</li>
<li>用-L指定的路径，按命令行里面的顺序依次查找</li>
</ul>
</li>
<li>运行加载时的顺序
<ul>
<li>可执行程序指定的的DT_RPATH</li>
<li>LD_LIBRARY_PATH. 但是如果使用了setuid/setgid，由于安全因素，此路径将被忽略.</li>
<li>可执行程序指定的的DT_RUNPATH. 但是如果使用了setuid/setgid，由于安全因素，此路径将被忽略</li>
<li>/etc/ld/so/cache. 如果链接时指定了‘-z nodeflib’，此路径将被忽略.</li>
<li>/lib. 如果链接时指定了‘-z nodeflib’，此路径将被忽略</li>
<li>/usr/lib. 如果链接时指定了‘-z nodeflib’，此路径将被忽略</li>
</ul>
</li>
</ul>
<h2 id="版本控制"><a class="header-anchor" href="#版本控制"></a>版本控制</h2>
<p>基于上面的例子，看看linux的这种约定，如何达到版本控制的目的。上面我们留下了一个问题：通过soname去寻找真正的real name库，这有什么好处？ 假设，我们现在对上面的test共享库进行升级，有2中情况：</p>
<ul>
<li>修改了原来的接口</li>
<li>增加了新的接口</li>
</ul>
<p>(1) 修改了原来的接口</p>
<p>我们修改test.c的代码，并修改原来的接口：</p>
<ul>
<li>test.c</li>
</ul>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;test.h&quot;</span></span></span><br><span class="line"><span class="type">void</span> <span class="title function_">print_hello</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;this is a test for shared lib&quot;</span>);</span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">&quot;this is a new building version&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>然后我们重新编译生成共享库，并且定义为新的building版本</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gcc -fPIC -o test.o -c test.c</span><br><span class="line">gcc -shared -Wl,-soname,libtest.so.0 -o libtest.so.0.0.1 test.o</span><br></pre></td></tr></table></figure>
<p>注意，按照约定，由于新的版本只是修改了接口，可以兼容之前的版本，所以soname并不需要改变。生成新的real name库以后，我们只需要执行ldconfig，即可自动 更新soname到新real name库的软链接。</p>
<ul>
<li>之前的链接</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">bow@bow-Aspire-4752:~/all/program/test/lib_version_test$ ll</span><br><span class="line">total 44</span><br><span class="line">drwxrwxr-x  2 bow bow 4096  6月 28 12:53 ./</span><br><span class="line">drwxrwxr-x 10 bow bow 4096  6月 27 21:21 ../</span><br><span class="line">lrwxrwxrwx  1 bow bow   12  6月 28 12:50 libtest.so -&gt; libtest.so.0*</span><br><span class="line">lrwxrwxrwx  1 bow bow   16  6月 28 12:50 libtest.so.0 -&gt; libtest.so.0.0.0*</span><br><span class="line">-rwxrwxr-x  1 bow bow 6894  6月 28 12:42 libtest.so.0.0.0*</span><br><span class="line">-rwxrwxr-x  1 bow bow 7287  6月 28 12:53 main*</span><br><span class="line">-rwxrwxr-x  1 bow bow   81  6月 27 23:16 main.c*</span><br><span class="line">-rw-rw-r--  1 bow bow  936  6月 28 12:46 main.o</span><br><span class="line">-rw-rw-r--  1 bow bow  104  6月 27 21:20 test.c</span><br><span class="line">-rw-rw-r--  1 bow bow   61  6月 27 21:19 test.h</span><br><span class="line">-rw-rw-r--  1 bow bow 1344  6月 28 12:39 test.o</span><br></pre></td></tr></table></figure>
<ul>
<li>ldconfig更新之后</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">bow@bow-Aspire-4752:~/all/program/test/lib_version_test$ ll</span><br><span class="line">total 52</span><br><span class="line">drwxrwxr-x  2 bow  bow  4096  6月 28 15:07 ./</span><br><span class="line">drwxrwxr-x 10 bow  bow  4096  6月 27 21:21 ../</span><br><span class="line">lrwxrwxrwx  1 bow  bow    12  6月 28 12:50 libtest.so -&gt; libtest.so.0*</span><br><span class="line">lrwxrwxrwx  1 root root   16  6月 28 15:07 libtest.so.0 -&gt; libtest.so.0.0.1*</span><br><span class="line">-rwxrwxr-x  1 bow  bow  6894  6月 28 12:42 libtest.so.0.0.0*</span><br><span class="line">-rwxrwxr-x  1 bow  bow  6894  6月 28 15:06 libtest.so.0.0.1*</span><br><span class="line">-rwxrwxr-x  1 bow  bow  7287  6月 28 12:53 main*</span><br><span class="line">-rwxrwxr-x  1 bow  bow    81  6月 27 23:16 main.c*</span><br><span class="line">-rw-rw-r--  1 bow  bow   936  6月 28 12:46 main.o</span><br><span class="line">-rw-rw-r--  1 bow  bow   104  6月 27 21:20 test.c</span><br><span class="line">-rw-rw-r--  1 bow  bow    61  6月 27 21:19 test.h</span><br><span class="line">-rw-rw-r--  1 bow  bow  1344  6月 28 12:39 test.o</span><br></pre></td></tr></table></figure>
<p>看到没有，soname自动更新到了新版本的共享库。所以之前的应用程序main会使用新的共享库。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">bow@bow-Aspire-4752:~/all/program/test/lib_version_test$ ./main</span><br><span class="line">this is a <span class="built_in">test</span> <span class="keyword">for</span> shared libthis is a new building version</span><br></pre></td></tr></table></figure>
<p>(2) 增加了新的接口</p>
<p>我们修改test.c的代码，并增加接口：</p>
<ul>
<li>test.h</li>
</ul>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifndef</span> _TEST_H_</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> _TEST_H_</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">print_hello</span><span class="params">()</span>;</span><br><span class="line"><span class="type">void</span> <span class="title function_">print_hello2</span><span class="params">()</span>;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure>
<ul>
<li>test.c</li>
</ul>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;test.h&quot;</span></span></span><br><span class="line"><span class="type">void</span> <span class="title function_">print_hello</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">&quot;this is a test for shared lib&quot;</span>);</span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">&quot;this is a new release version&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">print_hello2</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">&quot;this is a new release version&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>然后编译，根据约定，real name的主版本号需要更新。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gcc -fPIC -o test.o -c test.c</span><br><span class="line">gcc -shared -Wl,-soname,libtest.so.1 -o libtest.so.1.0.0 test.o</span><br></pre></td></tr></table></figure>
<p>这时，就会生成新的共享库libtest.so.1.0.0，然后ldconfig更新软链接和cache。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">total 60</span><br><span class="line">drwxrwxr-x  2 bow  bow  4096  6月 28 15:15 ./</span><br><span class="line">drwxrwxr-x 10 bow  bow  4096  6月 27 21:21 ../</span><br><span class="line">lrwxrwxrwx  1 bow  bow    12  6月 28 12:50 libtest.so -&gt; libtest.so.0*</span><br><span class="line">lrwxrwxrwx  1 root root   16  6月 28 15:07 libtest.so.0 -&gt; libtest.so.0.0.1*</span><br><span class="line">-rwxrwxr-x  1 bow  bow  6894  6月 28 12:42 libtest.so.0.0.0*</span><br><span class="line">-rwxrwxr-x  1 bow  bow  6894  6月 28 15:06 libtest.so.0.0.1*</span><br><span class="line">lrwxrwxrwx  1 root root   16  6月 28 15:15 libtest.so.1 -&gt; libtest.so.1.0.0*</span><br><span class="line">-rwxrwxr-x  1 bow  bow  6894  6月 28 15:15 libtest.so.1.0.0*</span><br><span class="line">-rwxrwxr-x  1 bow  bow  7287  6月 28 12:53 main*</span><br><span class="line">-rwxrwxr-x  1 bow  bow    81  6月 27 23:16 main.c*</span><br><span class="line">-rw-rw-r--  1 bow  bow   936  6月 28 12:46 main.o</span><br><span class="line">-rw-rw-r--  1 bow  bow   104  6月 27 21:20 test.c</span><br><span class="line">-rw-rw-r--  1 bow  bow    61  6月 27 21:19 test.h</span><br><span class="line">-rw-rw-r--  1 bow  bow  1344  6月 28 12:39 test.o</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">bow@bow-Aspire-4752:~/all/program/test/lib_version_test$ ./main</span><br><span class="line">this is a <span class="built_in">test</span> <span class="keyword">for</span> shared libthis is a new building version</span><br></pre></td></tr></table></figure>
<p>这个时候，虽然我们更新了共享库，但是main还是会加载旧的共享库。这就保证了，即使共享库更新，以前的程序也能正常工作。 因为main里面的soname没变，而且soname对应的real name没变。 如果你想更新应用程序main，使其使用新的库，那么需要重新编译，让libtest.so的软链接指向libtest.so.1</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">bow@bow-Aspire-4752:~/all/program/test/lib_version_test$ <span class="built_in">ln</span> -sf libtest.so.1 libtest.so</span><br><span class="line">bow@bow-Aspire-4752:~/all/program/test/lib_version_test$ ll</span><br><span class="line">total 60</span><br><span class="line">drwxrwxr-x  2 bow  bow  4096  6月 28 15:32 ./</span><br><span class="line">drwxrwxr-x 10 bow  bow  4096  6月 27 21:21 ../</span><br><span class="line">lrwxrwxrwx  1 bow  bow    12  6月 28 15:32 libtest.so -&gt; libtest.so.1*</span><br><span class="line">lrwxrwxrwx  1 root root   16  6月 28 15:07 libtest.so.0 -&gt; libtest.so.0.0.1*</span><br><span class="line">-rwxrwxr-x  1 bow  bow  6894  6月 28 12:42 libtest.so.0.0.0*</span><br><span class="line">-rwxrwxr-x  1 bow  bow  6894  6月 28 15:24 libtest.so.0.0.1*</span><br><span class="line">lrwxrwxrwx  1 root root   16  6月 28 15:15 libtest.so.1 -&gt; libtest.so.1.0.0*</span><br><span class="line">-rwxrwxr-x  1 bow  bow  6923  6月 28 15:25 libtest.so.1.0.0*</span><br><span class="line">-rwxrwxr-x  1 bow  bow  7287  6月 28 12:53 main*</span><br><span class="line">-rwxrwxr-x  1 bow  bow    81  6月 27 23:16 main.c*</span><br><span class="line">-rw-rw-r--  1 bow  bow   936  6月 28 12:46 main.o</span><br><span class="line">-rw-rw-r--  1 bow  bow   216  6月 28 15:25 test.c</span><br><span class="line">-rw-rw-r--  1 bow  bow    82  6月 28 15:25 test.h</span><br><span class="line">-rw-rw-r--  1 bow  bow  1516  6月 28 15:25 test.o</span><br><span class="line">bow@bow-Aspire-4752:~/all/program/test/lib_version_test$ gcc -L. -o main main.o -ltest</span><br><span class="line">bow@bow-Aspire-4752:~/all/program/test/lib_version_test$ ./main</span><br><span class="line">this is a <span class="built_in">test</span> <span class="keyword">for</span> shared libthis is a new release version</span><br></pre></td></tr></table></figure>
<p>ok。通过以上操作，linux下面的共享库的版本约定和控制，就很清楚了。当碰到一些譬如无法找到共享库或接口，或者引用的库 发生变化的时候，看看应用程序到底时如何查找共享库的，已经在使用的是哪个版本的共享库，根据以上原则去分析，一定可以解决问题。 一般通过这几个命令去分析：</p>
<ul>
<li>nm 查看共享库暴露的接口</li>
<li>ldconfig 可以自动生成soname的链接接文件。并更新共享库的搜索cache，加速查找。 example: ldconfig -p | grep libtest</li>
<li>readelf 可以查看动态库的信息，本身的soname。 example: readelf -d libtest.so.0.0.0 | grep soname</li>
<li>ldd 可以查看应用程序或共享库依赖的库 example: ldd main</li>
<li>objdump 与readelf 类似</li>
</ul>
<h2 id="参考资料"><a class="header-anchor" href="#参考资料"></a>参考资料</h2>
<ul>
<li><a href="http://tldp.org/HOWTO/Program-Library-HOWTO/shared-libraries.html">http://tldp.org/HOWTO/Program-Library-HOWTO/shared-libraries.html</a></li>
<li><a href="http://www.cprogramming.com/tutorial/shared-libraries-linux-gcc.html">http://www.cprogramming.com/tutorial/shared-libraries-linux-gcc.html</a></li>
<li><a href="http://www.linuxidc.com/Linux/2012-04/59071p2.htm">http://www.linuxidc.com/Linux/2012-04/59071p2.htm</a></li>
</ul>
<hr>
<p><a href="http://liaoph.com/linux-shared-libary/">Linux 共享库指南</a></p>
<blockquote>
<p>当创建一个库文件时，是需要创建 real name 的库文件（包含具体的版本信息）。当安装新版本的库文件时，将它们安装在系统默认的几个文件夹中(/lib，/lib64，/usr/lib，/usr/lib64)，执行 ldconfig 命令，ldconfig 会在系统默认的库文件目录和指定目录( /etc/ld.so.conf 和 /etc/ld.so.conf.d/*.conf )中检索所有的文件，并自动对 real name 的真实库文件创建 soname 的软链接，并将文件路径缓存至 /etc/ld.so.cache 文件中。</p>
<p>ldconfig 不会设置库文件的 linker name，这通常是库文件安装时设置的，linker name 通常是指向对应最新版本库文件 soname 的软链接文件。不自动设置 linker name 的原因是开发时，可能会需要使用旧版本的库文件。</p>
<p>举例来说，对于 libreadline 这个库，/usr/lib64/libreadline.so.5 是其完全限定 soname，ldconfig 命令会将其链接至 real name 库文件如 /usr/lib64/libreadline.so.5.1。还应该有一个 linker name 供编译器使用，如 /usr/lib64/libreadline.so，它是 /usr/lib64/libreadline.so.5 的软链接。</p>
<p>共享库文件查询的目录存放在 /etc/ld.so.conf 中（或临时设置LD_LIBRARY_PATH）。注意，对于红帽 Linux 系统，/etc/ld.so.conf 这个文件中并没有包含 /usr/local/lib 这个常用的库文件目录。</p>
<p>如果只是想要覆盖一个库文件的某些函数，但保留其余的内容，可以将覆盖库文件名（.o 后缀文件）保存至 /etc/ld.so.preload 文件中（或临时设置LD_PRELOAD）。这些覆盖库文件会比标准库文件优先读取，这通常用于紧急的版本补丁。</p>
<p>每次都查找 /etc/ld.so.conf 中的目录是很低效的，因此 ldconfig 程序会读取 /etc/ld.so.conf 文件中的所有目录中的文件，将库文件 real name 设置合适的软链接 soname，并将这些文件名缓存至 /etc/ld.so.cache 中。这样会大大加快库文件的寻找速度。</p>
</blockquote>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/version-control-and-usage-of-linux-shared-library/">http://xnerv.wang/version-control-and-usage-of-linux-shared-library/</a></strong><br>
转载自：<a href="http://lovewubo.github.io/shared_library">linux共享库的版本控制和使用</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Linux</tag>
        <tag>Shared Library</tag>
      </tags>
  </entry>
  <entry>
    <title>虚函数与虚继承寻踪（转载）</title>
    <url>/virtual-function-and-virtual-table/</url>
    <content><![CDATA[<p>封装、继承、多态是面向对象语言的三大特性，熟悉C++的人对此应该不会有太多异议。C语言提供的struct，顶多算得上对数据的简单封装，而C++的引入把struct“升级”为class，使得面向对象的概念更加强大。继承机制解决了对象复用的问题，然而多重继承又会产生成员冲突的问题，虚继承在我看来更像是一种“不得已”的解决方案。多态让对象具有了运行时特性，并且它是软件设计复用的本质，虚函数的出现为多态性质提供了实现手段。</p>
<p>如果说C语言的struct相当于对数据成员简单的排列（可能有对齐问题），那么C++的class让对象的数据的封装变得更加复杂。所有的这些问题来源于C++的一个关键字——virtual！virtual在C++中最大的功能就是声明虚函数和虚基类，有了这种机制，C++对象的机制究竟发生了怎样的变化，让我们一起探寻之。</p>
<p>为了查看对象的结构模型，我们需要在编译器配置时做一些初始化。在VS2010中，在项目——属性——配置属性——C/C++——命令行——其他选项中添加选项“/d1reportAllClassLayout”。再次编译时候，编译器会输出所有定义类的对象模型。由于输出的信息过多，我们可以使用“Ctrl+F”查找命令，找到对象模型的输出。</p>
<span id="more"></span>
<h2 id="一、基本对象模型"><a class="header-anchor" href="#一、基本对象模型"></a>一、基本对象模型</h2>
<p>首先，我们定义一个简单的类，它含有一个数据成员和一个虚函数。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyClass</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> var;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">fun</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;&#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>编译输出的MyClass对象结构如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">class</span> MyClass    <span class="title">size</span><span class="params">(<span class="number">8</span>)</span>:</span></span><br><span class="line"><span class="function">    +---</span></span><br><span class="line"><span class="function"> <span class="number">0</span>    | &#123;</span>vfptr&#125;</span><br><span class="line"> <span class="number">4</span>    | var</span><br><span class="line">    +---</span><br><span class="line"></span><br><span class="line">MyClass::$vftable@:</span><br><span class="line">    | &amp;MyClass_meta</span><br><span class="line">    |  <span class="number">0</span></span><br><span class="line"> <span class="number">0</span>    | &amp;MyClass::fun</span><br><span class="line"></span><br><span class="line">MyClass::fun <span class="keyword">this</span> adjustor: <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>从这段信息中我们看出，MyClass对象大小是8个字节。前四个字节存储的是虚函数表的指针vfptr，后四个字节存储对象成员var的值。虚函数表的大小为4字节，就一条函数地址，即虚函数fun的地址，它在虚函数表vftable的偏移是0。因此，MyClass对象模型的结果如图1所示。</p>
<center>
<img src="/assets/virtual-function-and-virtual-table/1.jpg" />
<p>图1 MyClass对象模型</p>
</center>
<p>MyClass的虚函数表虽然只有一条函数记录，但是它的结尾处是由4字节的0作为结束标记的。</p>
<p>adjust表示虚函数机制执行时，this指针的调整量，假如fun被多态调用的话，那么它的形式如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">*(<span class="keyword">this</span>+<span class="number">0</span>)[<span class="number">0</span>]()</span><br></pre></td></tr></table></figure>
<p>总结虚函数调用形式，应该是：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">*(<span class="keyword">this</span>指针+调整量)[虚函数在vftable内的偏移]()</span><br></pre></td></tr></table></figure>
<h2 id="二、单重继承对象模型"><a class="header-anchor" href="#二、单重继承对象模型"></a>二、单重继承对象模型</h2>
<p>我们定义一个继承于MyClass类的子类MyClassA，它重写了fun函数，并且提供了一个新的虚函数funA。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyClassA</span>:<span class="keyword">public</span> MyClass</span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> varA;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">fun</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;&#125;</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">funA</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;&#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>它的对象模型为：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">class</span> MyClassA    <span class="title">size</span><span class="params">(<span class="number">12</span>)</span>:</span></span><br><span class="line"><span class="function">    +---</span></span><br><span class="line"><span class="function">    | +--- (base class MyClass)</span></span><br><span class="line"><span class="function"> <span class="number">0</span>    | | &#123;</span>vfptr&#125;</span><br><span class="line"> <span class="number">4</span>    | | var</span><br><span class="line">    | +---</span><br><span class="line"> <span class="number">8</span>    | varA</span><br><span class="line">    +---</span><br><span class="line"></span><br><span class="line">MyClassA::$vftable@:</span><br><span class="line">    | &amp;MyClassA_meta</span><br><span class="line">    |  <span class="number">0</span></span><br><span class="line"> <span class="number">0</span>    | &amp;MyClassA::fun</span><br><span class="line"> <span class="number">1</span>    | &amp;MyClassA::funA</span><br><span class="line"></span><br><span class="line">MyClassA::fun <span class="keyword">this</span> adjustor: <span class="number">0</span></span><br><span class="line">MyClassA::funA <span class="keyword">this</span> adjustor: <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>可以看出，MyClassA将基类MyClass完全包含在自己内部，包括vfptr和var。并且虚函数表内的记录多了一条——MyClassA自己定义的虚函数funA。它的对象模型如图2所示。</p>
<center>
<img src="/assets/virtual-function-and-virtual-table/2.jpg" />
<p>图2 MyClassA对象模型</p>
</center>
<p>我们可以得出结论：在单继承形式下，子类的完全获得父类的虚函数表和数据。子类如果重写了父类的虚函数（如fun），就会把虚函数表原本fun对应的记录（内容MyClass::fun）覆盖为新的函数地址（内容MyClassA::fun），否则继续保持原本的函数地址记录。如果子类定义了新的虚函数，虚函数表内会追加一条记录，记录该函数的地址（如MyClassA::funA）。</p>
<p>使用这种方式，就可以实现多态的特性。假设我们使用如下语句：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">MyClass*pc=<span class="keyword">new</span> MyClassA;</span><br><span class="line">pc-&gt;<span class="built_in">fun</span>();</span><br></pre></td></tr></table></figure>
<p>编译器在处理第二条语句时，发现这是一个多态的调用，那么就会按照上边我们对虚函数的多态访问机制调用函数fun。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">*(pc+<span class="number">0</span>)[<span class="number">0</span>]()</span><br></pre></td></tr></table></figure>
<p>因为虚函数表内的函数地址已经被子类重写的fun函数地址覆盖了，因此该处调用的函数正是MyClassA::fun，而不是基类的MyClass::fun。</p>
<p>如果使用MyClassA对象直接访问fun，则不会出发多态机制，因为这个函数调用在编译时期是可以确定的，编译器只需要直接调用MyClassA::fun即可。</p>
<h2 id="三、多重继承对象模型"><a class="header-anchor" href="#三、多重继承对象模型"></a>三、多重继承对象模型</h2>
<p>和前边MyClassA类似，我们也定义一个类MyClassB。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyClassB</span>:<span class="keyword">public</span> MyClass</span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> varB;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">fun</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;&#125;</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">funB</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;&#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>它的对象模型和MyClassA完全类似，这里就不再赘述了。</p>
<p>为了实现多重继承，我们再定义一个类MyClassC。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyClassC</span>:<span class="keyword">public</span> MyClassA,<span class="keyword">public</span> MyClassB</span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> varC;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">funB</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;&#125;</span><br><span class="line"><span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">funC</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;&#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>为了简化，我们让MyClassC只重写父类MyClassB的虚函数funB，它的对象模型如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">class</span> MyClassC    <span class="title">size</span><span class="params">(<span class="number">28</span>)</span>:</span></span><br><span class="line"><span class="function">    +---</span></span><br><span class="line"><span class="function">    | +--- (base class MyClassA)</span></span><br><span class="line"><span class="function">    | | +--- (base class MyClass)</span></span><br><span class="line"><span class="function"> <span class="number">0</span>    | | | &#123;</span>vfptr&#125;</span><br><span class="line"> <span class="number">4</span>    | | | var</span><br><span class="line">    | | +---</span><br><span class="line"> <span class="number">8</span>    | | varA</span><br><span class="line">    | +---</span><br><span class="line">    | +--- (base <span class="keyword">class</span> MyClassB)</span><br><span class="line">    | | +--- (base <span class="keyword">class</span> MyClass)</span><br><span class="line"><span class="number">12</span>    | | | &#123;vfptr&#125;</span><br><span class="line"><span class="number">16</span>    | | | var</span><br><span class="line">    | | +---</span><br><span class="line"><span class="number">20</span>    | | varB</span><br><span class="line">    | +---</span><br><span class="line"><span class="number">24</span>    | varC</span><br><span class="line">    +---</span><br><span class="line"></span><br><span class="line">MyClassC::$vftable@MyClassA@:</span><br><span class="line">    | &amp;MyClassC_meta</span><br><span class="line">    |  <span class="number">0</span></span><br><span class="line"> <span class="number">0</span>    | &amp;MyClassA::fun</span><br><span class="line"> <span class="number">1</span>    | &amp;MyClassA::funA</span><br><span class="line"> <span class="number">2</span>    | &amp;MyClassC::funC</span><br><span class="line"></span><br><span class="line">MyClassC::$vftable@MyClassB@:</span><br><span class="line">    | <span class="number">-12</span></span><br><span class="line"> <span class="number">0</span>    | &amp;MyClassB::fun</span><br><span class="line"> <span class="number">1</span>    | &amp;MyClassC::funB</span><br><span class="line"></span><br><span class="line">MyClassC::funB <span class="keyword">this</span> adjustor: <span class="number">12</span></span><br><span class="line">MyClassC::funC <span class="keyword">this</span> adjustor: <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>和单重继承类似，多重继承时MyClassC会把所有的父类全部按序包含在自身内部。而且每一个父类都对应一个单独的虚函数表。MyClassC的对象模型如图3所示。</p>
<center>
<img src="/assets/virtual-function-and-virtual-table/3.jpg" />
<p>图3 MyClassC对象模型</p>
</center>
<p>多重继承下，子类不再具有自身的虚函数表，它的虚函数表与第一个父类的虚函数表合并了。同样的，如果子类重写了任意父类的虚函数，都会覆盖对应的函数地址记录。如果MyClassC重写了fun函数（两个父类都有该函数），那么两个虚函数表的记录都需要被覆盖！在这里我们发现MyClassC::funB的函数对应的adjust值是12，按照我们前边的规则，可以发现该函数的多态调用形式为：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">*(<span class="keyword">this</span>+<span class="number">12</span>)[<span class="number">1</span>]()</span><br></pre></td></tr></table></figure>
<p>此处的调整量12正好是MyClassB的vfptr在MyClassC对象内的偏移量。</p>
<h2 id="四、虚拟继承对象模型"><a class="header-anchor" href="#四、虚拟继承对象模型"></a>四、虚拟继承对象模型</h2>
<p>虚拟继承是为了解决多重继承下公共基类的多份拷贝问题。比如上边的例子中MyClassC的对象内包含MyClassA和MyClassB子对象，但是MyClassA和MyClassB内含有共同的基类MyClass。为了消除MyClass子对象的多份存在，我们需要让MyClassA和MyClassB都虚拟继承于MyClass，然后再让MyClassC多重继承于这两个父类。相对于上边的例子，类内的设计不做任何改动，先修改MyClassA和MyClassB的继承方式：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyClassA</span>:<span class="keyword">virtual</span> <span class="keyword">public</span> MyClass</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyClassB</span>:<span class="keyword">virtual</span> <span class="keyword">public</span> MyClass</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyClassC</span>:<span class="keyword">public</span> MyClassA,<span class="keyword">public</span> MyClassB</span><br></pre></td></tr></table></figure>
<p>由于虚继承的本身语义，MyClassC内必须重写fun函数，因此我们需要再重写fun函数。这种情况下，MyClassC的对象模型如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">class</span> MyClassC    <span class="title">size</span><span class="params">(<span class="number">36</span>)</span>:</span></span><br><span class="line"><span class="function">    +---</span></span><br><span class="line"><span class="function">    | +--- (base class MyClassA)</span></span><br><span class="line"><span class="function"> <span class="number">0</span>    | | &#123;</span>vfptr&#125;</span><br><span class="line"> <span class="number">4</span>    | | &#123;vbptr&#125;</span><br><span class="line"> <span class="number">8</span>    | | varA</span><br><span class="line">    | +---</span><br><span class="line">    | +--- (base <span class="keyword">class</span> MyClassB)</span><br><span class="line"><span class="number">12</span>    | | &#123;vfptr&#125;</span><br><span class="line"><span class="number">16</span>    | | &#123;vbptr&#125;</span><br><span class="line"><span class="number">20</span>    | | varB</span><br><span class="line">    | +---</span><br><span class="line"><span class="number">24</span>    | varC</span><br><span class="line">    +---</span><br><span class="line">    +--- (<span class="keyword">virtual</span> base MyClass)</span><br><span class="line"><span class="number">28</span>    | &#123;vfptr&#125;</span><br><span class="line"><span class="number">32</span>    | var</span><br><span class="line">    +---</span><br><span class="line"></span><br><span class="line">MyClassC::$vftable@MyClassA@:</span><br><span class="line">    | &amp;MyClassC_meta</span><br><span class="line">    |  <span class="number">0</span></span><br><span class="line"> <span class="number">0</span>    | &amp;MyClassA::funA</span><br><span class="line"> <span class="number">1</span>    | &amp;MyClassC::funC</span><br><span class="line"></span><br><span class="line">MyClassC::$vftable@MyClassB@:</span><br><span class="line">    | <span class="number">-12</span></span><br><span class="line"> <span class="number">0</span>    | &amp;MyClassC::funB</span><br><span class="line"></span><br><span class="line">MyClassC::$vbtable@MyClassA@:</span><br><span class="line"> <span class="number">0</span>    | <span class="number">-4</span></span><br><span class="line"> <span class="number">1</span>    | <span class="number">24</span> (<span class="built_in">MyClassCd</span>(MyClassA+<span class="number">4</span>)MyClass)</span><br><span class="line"></span><br><span class="line">MyClassC::$vbtable@MyClassB@:</span><br><span class="line"> <span class="number">0</span>    | <span class="number">-4</span></span><br><span class="line"> <span class="number">1</span>    | <span class="number">12</span> (<span class="built_in">MyClassCd</span>(MyClassB+<span class="number">4</span>)MyClass)</span><br><span class="line"></span><br><span class="line">MyClassC::$vftable@MyClass@:</span><br><span class="line">     | <span class="number">-28</span></span><br><span class="line">  <span class="number">0</span>    | &amp;MyClassC::fun</span><br><span class="line"></span><br><span class="line"> MyClassC::fun <span class="keyword">this</span> adjustor: <span class="number">28</span></span><br><span class="line"> MyClassC::funB <span class="keyword">this</span> adjustor: <span class="number">12</span></span><br><span class="line"> MyClassC::funC <span class="keyword">this</span> adjustor: <span class="number">0</span></span><br><span class="line"></span><br><span class="line">vbi:       <span class="keyword">class</span>  <span class="title class_">offset</span> o.vbptr  o.vbte fVtorDisp</span><br><span class="line">         MyClass      <span class="number">28</span>       <span class="number">4</span>       <span class="number">4</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>虚继承的引入把对象的模型变得十分复杂，除了每个基类（MyClassA和MyClassB）和公共基类（MyClass）的虚函数表指针需要记录外，每个虚拟继承了MyClass的父类还需要记录一个虚基类表vbtable的指针vbptr。MyClassC的对象模型如图4所示。</p>
<center>
<img src="/assets/virtual-function-and-virtual-table/4.jpg" />
<p>图4 MyClassC对象模型</p>
</center>
<p>虚基类表每项记录了被继承的虚基类子对象相对于虚基类表指针的偏移量。比如MyClassA的虚基类表第二项记录值为24，正是MyClass::vfptr相对于MyClassA::vbptr的偏移量，同理MyClassB的虚基类表第二项记录值12也正是MyClass::vfptr相对于MyClassA::vbptr的偏移量。</p>
<p>和虚函数表不同的是，虚基类表的第一项记录着当前子对象相对于虚基类表指针的偏移。MyClassA和MyClassB子对象内的虚表指针都是存储在相对于自身的4字节偏移处，因此该值是-4。假定MyClassA和MyClassC或者MyClassB内没有定义新的虚函数，即不会产生虚函数表，那么虚基类表第一项字段的值应该是0。</p>
<p>通过以上的对象组织形式，编译器解决了公共虚基类的多份拷贝的问题。通过每个父类的虚基类表指针，都能找到被公共使用的虚基类的子对象的位置，并依次访问虚基类子对象的数据。至于虚基类定义的虚函数，它和其他的虚函数的访问形式相同，本例中，如果使用虚基类指针MyClass*pc访问MyClassC对象的fun，将会被转化为如下形式：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">*(pc+<span class="number">28</span>)[<span class="number">0</span>]()</span><br></pre></td></tr></table></figure>
<p>通过以上的描述，我们基本认清了C++的对象模型。尤其是在多重、虚拟继承下的复杂结构。通过这些真实的例子，使得我们认清C++内class的本质，以此指导我们更好的书写我们的程序。本文从对象结构的角度结合图例为大家阐述对象的基本模型，和一般描述C++虚拟机制的文章有所不同。作者只希望借助于图表能把C++对象以更好理解的形式为大家展现出来，希望本文对你有所帮助。</p>
<hr>
<p>编者注：</p>
<ol>
<li>
<p>对于VC++和GCC，内存布局还是有不少细节上的实现区别的，本文仅具参考意义，详情可参考<a href="http://blog.csdn.net/haoel/article/details/3081328">C++ 对象的内存布局</a>和<a href="https://zh.wikipedia.org/wiki/%E8%99%9A%E7%BB%A7%E6%89%BF">（维基百科）虚继承</a>。</p>
</li>
<li>
<p>此外，如果Base类没有虚函数，而Derived类有虚函数，目前绝大多数编译器的实现，都是将vfptr放在Base对象之前，参考<a href="https://stackoverflow.com/questions/10062299/is-pointer-to-base-always-pointer-to-derived-class">is pointer to base always &lt;= pointer to derived class?</a>。</p>
</li>
</ol>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/virtual-function-and-virtual-table/">http://xnerv.wang/virtual-function-and-virtual-table/</a></strong><br>
转载自：<a href="http://www.cnblogs.com/fanzhidongyzby/archive/2013/01/14/2859064.html">虚函数与虚继承寻踪</a></p>
]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>编程语言</tag>
        <tag>C++</tag>
        <tag>虚表</tag>
        <tag>多态</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL - 信号处理机制分析（转载）</title>
    <url>/what-analysis-of-signal-processing-mechanism/</url>
    <content><![CDATA[<h2 id="背景"><a class="header-anchor" href="#背景"></a>背景</h2>
<p>在 <a href="https://github.com/alibaba/AliSQL/issues/68">AliSQL</a> 上面有人提交了一个 bug，在使用主备的时候 service stop mysql 不能关闭主库，一直显示 shutting down mysql …，到底怎么回事呢，先来看一下 service stop mysql 是怎么停止数据库的。配置 MySQL 在系统启动时启动需要把 MYSQL_BASEDIR/support-files 目录下的脚本 mysql.sever 放到 /etc/init.d/ 目录下，脚本来控制 mysqld 的启动和停止。看一下脚本中的代码 ：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if test -s &quot;$mysqld_pid_file_path&quot;</span><br><span class="line">     then</span><br><span class="line">       mysqld_pid=`cat &quot;$mysqld_pid_file_path&quot;`</span><br><span class="line"></span><br><span class="line">       if (kill -0 $mysqld_pid 2&gt;/dev/null)</span><br><span class="line">       then</span><br><span class="line">         echo $echo_n &quot;Shutting down MySQL&quot;</span><br><span class="line">         kill $mysqld_pid</span><br><span class="line">         # mysqld should remove the pid file when it exits, so wait for it.</span><br><span class="line">         wait_for_pid removed &quot;$mysqld_pid&quot; &quot;$mysqld_pid_file_path&quot;; return_value=$?</span><br><span class="line">	...</span><br></pre></td></tr></table></figure>
<p>实际上的关闭动作就是向 mysqld 进程发送一个 kill pid 的信号，也就是 TERM ， wait_for_pid 函数中就是不断检测 $MYSQL_DATADIR 下面的 pid 文件是否存在，并且打印 ‘.’，所以上述问题应该是 mysqld 没有正确处理接收到的信号。</p>
<span id="more"></span>
<h2 id="信号处理机制"><a class="header-anchor" href="#信号处理机制"></a>信号处理机制</h2>
<h3 id="多线程信号处理"><a class="header-anchor" href="#多线程信号处理"></a>多线程信号处理</h3>
<p>进程中的信号处理是异步的，当信号发送给进程之后，就会中断进程当前的执行流程，跳到注册的对应信号处理函数中，执行完毕后再返回进程的执行流程。在多线程信号处理中，一般采用一个单独的线程阻塞的等待信号集，然后处理信号，重新阻塞等待。线程的信号处理有以下几个特点：</p>
<ul>
<li>每个线程都有自己的信号屏蔽字（单个线程可以屏蔽某些信号）</li>
<li>信号的处理是整个进程中所有线程共享的（某个线程修改信号处理行为后，也会影响其它线程）</li>
<li>进程中的信号是递送到单个线程的，如果一个信号和硬件故障相关，那么该信号就会被递送到引起该事件的线程，否是是发送到任意一个线程。</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">pthread_sigmask</span><span class="params">(<span class="type">int</span> how, <span class="type">const</span> <span class="type">sigset_t</span> * restrict set, <span class="type">sigset_t</span> *restrict oset)</span></span>;</span><br></pre></td></tr></table></figure>
<p>在进程中使用 sigprocmask 设置信号屏蔽字，在线程中使用 pthread_sigmask，他们的基本相同，pthread_sigmask 工作在线程中，失败时返回错误码，而 sigprocmask 会设置 errno 并返回 -1。参数 how 控制设置屏蔽字的行为，值为 SIG_BLOCK（把信号集添加到现有信号集中，取并集）, SIG_SET_MASK（设置信号集为 set）, SIG_UNBLOCK（从信号集中移除 set 中的信号）。set 表示需要操纵的信号集合。oset 返回设置之前的信号屏蔽字，如果设置 set 为 NULL，可以通过 oset 获得当前的信号屏蔽字。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">sigwait</span><span class="params">(<span class="type">const</span> <span class="type">sigset_t</span> \*restrict set, <span class="type">int</span> \*restrict sig)</span></span></span><br></pre></td></tr></table></figure>
<p>sigwait 将会挂起调用线程，直到接收到 set 中设置的信号，具体的信号将会通过 sig 返回，同时会从 set 中删除 sig 信号。 在调用 sigwait 之前，必须阻塞那些它正在等待的信号，否则在调用的时间窗口就可能接收到信号。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">pthread_kill</span><span class="params">(<span class="type">pthread_t</span> thread, <span class="type">int</span> sig)</span></span></span><br></pre></td></tr></table></figure>
<p>发送信号到指定线程，如果 sig 为 0，可以用来判断线程是否还活着。</p>
<p>man pthread_sigmask 里面给了一个例子：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;signal.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;errno.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* Simple error handling functions */</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> handle_error_en(en, msg) \</span></span><br><span class="line"><span class="meta">    do &#123; errno = en; perror(msg); exit(EXIT_FAILURE); &#125; while (0)</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">static</span> <span class="type">void</span> *</span></span><br><span class="line"><span class="function"><span class="title">sig_thread</span><span class="params">(<span class="type">void</span> *arg)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">sigset_t</span> *set = (<span class="type">sigset_t</span> *) arg;</span><br><span class="line">    <span class="type">int</span> s, sig;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">        s = <span class="built_in">sigwait</span>(set, &amp;sig);</span><br><span class="line">        <span class="keyword">if</span> (s != <span class="number">0</span>)</span><br><span class="line">            <span class="built_in">handle_error_en</span>(s, <span class="string">&quot;sigwait&quot;</span>);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Signal handling thread got signal %d\n&quot;</span>, sig);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> *argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">pthread_t</span> thread;</span><br><span class="line">    <span class="type">sigset_t</span> set;</span><br><span class="line">    <span class="type">int</span> s;</span><br><span class="line">    <span class="comment">/* Block SIGINT; other threads created by main() will inherit</span></span><br><span class="line"><span class="comment">     *               a copy of the signal mask. */</span></span><br><span class="line">    <span class="comment">/* Block SIGINT; other threads created by main() will inherit</span></span><br><span class="line"><span class="comment">     *               a copy of the signal mask. */</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">sigemptyset</span>(&amp;set);</span><br><span class="line">    <span class="built_in">sigaddset</span>(&amp;set, SIGQUIT);</span><br><span class="line">    <span class="built_in">sigaddset</span>(&amp;set, SIGUSR1);</span><br><span class="line">    s = <span class="built_in">pthread_sigmask</span>(SIG_BLOCK, &amp;set, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="comment">//s = sigprocmask(SIG_BLOCK, &amp;set, NULL);</span></span><br><span class="line">    <span class="keyword">if</span> (s != <span class="number">0</span>)</span><br><span class="line">        <span class="built_in">handle_error_en</span>(s, <span class="string">&quot;pthread_sigmask&quot;</span>);</span><br><span class="line"></span><br><span class="line">    s = <span class="built_in">pthread_create</span>(&amp;thread, <span class="literal">NULL</span>, &amp;sig_thread, (<span class="type">void</span> *) &amp;set);</span><br><span class="line">    <span class="keyword">if</span> (s != <span class="number">0</span>)</span><br><span class="line">        <span class="built_in">handle_error_en</span>(s, <span class="string">&quot;pthread_create&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Main thread carries on to create other threads and/or do</span></span><br><span class="line"><span class="comment">     *               other work */</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">pause</span>();            <span class="comment">/* Dummy pause so we can test program */</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行一下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ ./a.out &amp;</span><br><span class="line">[1] 5423</span><br><span class="line">$ <span class="built_in">kill</span> -QUIT %1</span><br><span class="line">Signal handling thread got signal 3</span><br><span class="line">$ <span class="built_in">kill</span> -USR1 %1</span><br><span class="line">Signal handling thread got signal 10</span><br><span class="line">$ <span class="built_in">kill</span> -TERM %1</span><br><span class="line">[1]+  Terminated              ./a.out</span><br></pre></td></tr></table></figure>
<p>测试了一下，把上面代码的 pthread_sigmask 替换成 sigprocmask ，同样能够正确执行，说明线程也能够继承原进程的屏蔽字，不过还是尽量使用 pthread_sigmask, 表述清楚点，而且说不定还有其它坑。</p>
<h3 id="MySQL-信号处理"><a class="header-anchor" href="#MySQL-信号处理"></a>MySQL 信号处理</h3>
<p>MySQL 是典型的多线程处理，它的信号处理形式和上一小节介绍的差不多，在 mysqld 启动的时候调用 my_init_signal 初始化信号屏蔽字，把需要信号处理线程处理的信号屏蔽起来，然后启动信号处理函数，入口是 signal_hand 。</p>
<p>在 my_init_signal 函数中，设置 SIGSEGC, SIGABORT, SIGBUS, SIGILL, SIGFPE 的处理函数为 handle_fatal_signal，把 SIGPIPE，SIGQUIT, SIGHUP, SIGTERM, SIGTSTP 加入到信号屏蔽字里，调用 sigprocmask 和 pthread_sigmask 设置屏蔽字。这一系列动作是在 mysql 启动其它辅助线程之前完成的动作，意图很明显，就是让之后的线程都继承设置的信号屏蔽字，把所有的信号交给信号处理线程去处理。</p>
<p>signal_hand 函数首先把需要处理的信号放到信号集合里去，然后完成 create_pid_file ，data 目录下的 pid 文件实际上是由信号处理线程创建的。接着等待 mysqld 完成启动，各个线程之间需要同步，核心代码是一个死循环，通过 my_sigwait 调用 sigwait 阻塞的等待信号的到来。我们目前主要关心 SIGTERM 的处理，和 SIGQUIT, SIGKILL 处理方式相同，都是调用 kill_server 关闭整个数据库。</p>
<h2 id="Bug-Fix"><a class="header-anchor" href="#Bug-Fix"></a>Bug Fix</h2>
<p>文中开头的链接中提到 loose-rpl_semi_sync_master_enabled = 0 关闭就不会有问题， 如果为 1 就会出现无法关闭的情况，顺着这个线索寻找，rpl_semi_sync_master_enabled 在主备使用 semisync 情况下控制启动 Master 节点的 Ack Receiver 线程，初始化阶段的调用堆栈为:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">init_common_variables</span><br><span class="line">		|</span><br><span class="line">		|----- ReplSemiSyncMaster::initObject</span><br><span class="line">						|</span><br><span class="line">						|----- Ack_receiver::start</span><br></pre></td></tr></table></figure>
<p>而 init_common_variables 的调用是在 my_init_signal 之前，也就是 Ack Receiver 线程没有办法继承信号屏蔽字，不会屏蔽 SIGTERM 信号。在 my_init_signal 中还有一段这样的代码：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* Fix signals if blocked by parents (can happen on Mac OS X) */</span></span><br><span class="line">  ....</span><br><span class="line">  sa.sa_handler = print_signal_warning;</span><br><span class="line">  <span class="built_in">sigaction</span>(SIGTERM, &amp;sa, (<span class="keyword">struct</span> sigaction\*) <span class="number">0</span>);</span><br><span class="line">  ...</span><br></pre></td></tr></table></figure>
<p>对于信号的修改的作用于整个进程的，也就是说之前启动的 Ack Receiver 线程没有信号屏蔽字，而且注册了信号处理函数。当 SIGTERM 发生后，信号处理线程和 Ack Receiver 线程都可以接收信号处理，信号被随机的分发（测试高概率都是发给 Ack Receiver），print_signal_warning 仅仅打印信息到 errlog，就出现了无法关闭 mysqld 的情况了。</p>
<p>修改也比较简单，把 initObject 的操作放到 my_init_signal 之后就好，注意不能把 init_common_variables 整个移到 my_init_signal 之前，因为 my_init_signal 里面还有要初始化的变量呢。</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/what-analysis-of-signal-processing-mechanism/">http://xnerv.wang/what-analysis-of-signal-processing-mechanism/</a></strong><br>
转载自：<a href="http://mysql.taobao.org/monthly/2017/10/10/">信号处理机制分析</a></p>
]]></content>
      <categories>
        <category>DBMS</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>DBMS</tag>
        <tag>MySQL</tag>
        <tag>Signal</tag>
      </tags>
  </entry>
  <entry>
    <title>(Stack Overflow) What are the main uses of yield(), and how does it differ from join() and interrupt()?</title>
    <url>/what-are-the-main-uses-of-yield-and-how-does-it-differ-from-join-and-interrupt/</url>
    <content><![CDATA[<h2 id="Question"><a class="header-anchor" href="#Question"></a>Question</h2>
<p>I am a little bit confused about the use of <code>yield()</code> method in Java, specifically in the example code below. I’ve also read that yield() is ‘used to prevent execution of a thread’.</p>
<p>My questions are:</p>
<ol>
<li>I believe the code below result in the same output both when using <code>yield()</code> and when not using it. Is this correct?</li>
<li>What are, in fact, the main uses of <code>yield()</code>?</li>
<li>In what ways is <code>yield()</code> different from the <code>join()</code> and <code>interrupt()</code> methods?</li>
</ol>
<span id="more"></span>
<p>The code example:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyRunnable</span> implements Runnable &#123;</span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="type">static</span> <span class="type">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">      Thread t = <span class="keyword">new</span> <span class="built_in">Thread</span>(<span class="keyword">new</span> <span class="built_in">MyRunnable</span>());</span><br><span class="line">      t.<span class="built_in">start</span>();</span><br><span class="line"></span><br><span class="line">      <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i&lt;<span class="number">5</span>; i++) &#123;</span><br><span class="line">          System.out.<span class="built_in">println</span>(<span class="string">&quot;Inside main&quot;</span>);</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="type">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i&lt;<span class="number">5</span>; i++) &#123;</span><br><span class="line">          System.out.<span class="built_in">println</span>(<span class="string">&quot;Inside run&quot;</span>);</span><br><span class="line">          Thread.<span class="built_in">yield</span>();</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>I obtain the same output using the code above both with and without using <code>yield()</code>:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Inside main</span><br><span class="line">Inside main</span><br><span class="line">Inside main</span><br><span class="line">Inside main</span><br><span class="line">Inside main</span><br><span class="line">Inside run</span><br><span class="line">Inside run</span><br><span class="line">Inside run</span><br><span class="line">Inside run</span><br><span class="line">Inside run</span><br></pre></td></tr></table></figure>
<h2 id="Answer-by-Sathwick"><a class="header-anchor" href="#Answer-by-Sathwick"></a>Answer by Sathwick</h2>
<p>Source: <a href="http://www.javamex.com/tutorials/threads/yield.shtml">http://www.javamex.com/tutorials/threads/yield.shtml</a></p>
<blockquote>
<h3 id="Windows"><a class="header-anchor" href="#Windows"></a>Windows</h3>
<p>In the Hotspot implementation, the way that <code>Thread.yield()</code> works has changed between Java 5 and Java 6.</p>
<p>In Java 5, <code>Thread.yield()</code> calls the Windows API call <code>Sleep(0)</code>. This has the special effect of <strong>clearing the current thread’s quantum</strong> and putting it to the <strong>end of the queue for its <em>priority level</em></strong>. In other words, all runnable threads of the same priority (and those of greater priority) will get a chance to run before the yielded thread is next given CPU time. When it is eventually re-scheduled, it will come back with a full <a href="http://www.javamex.com/tutorials/threads/thread_scheduling.shtml#quantum">full quantum</a>, but doesn’t “carry over” any of the remaining quantum from the time of yielding. This behaviour is a little different from a non-zero sleep where the sleeping thread generally loses 1 quantum value (in effect, 1/3 of a 10 or 15ms tick).</p>
<!--more-->
<p>In Java 6, this behaviour was changed. The Hotspot VM now implements <code>Thread.yield()</code> using the Windows <code>SwitchToThread()</code> API call. This call makes the current thread <strong>give up its <em>current timeslice</em></strong>, but not its entire quantum. This means that depending on the priorities of other threads, the yielding thread can be <strong>scheduled back in one interrupt period later</strong>. (See the section on <a href="http://www.javamex.com/tutorials/threads/thread_scheduling.shtml">thread scheduling</a> for more information on timeslices.)</p>
<h4 id="Linux"><a class="header-anchor" href="#Linux"></a>Linux</h4>
<p>Under Linux, Hotspot simply calls <code>sched_yield()</code>. The consequences of this call are a little different, and possibly more severe than under Windows:</p>
<ul>
<li>a yielded thread will not get another slice of CPU <strong>until <em>all</em> other threads have had a slice of CPU</strong>;</li>
<li>(at least in kernel 2.6.8 onwards), the fact that the thread has yielded is implicitly taken into account by the scheduler’s heuristics on its recent CPU allocation— thus, implicitly, a thread that has yielded could be given more CPU when scheduled in the future.</li>
</ul>
<p>(See the section on <a href="http://www.javamex.com/tutorials/threads/thread_scheduling.shtml">thread scheduling</a> for more details on priorities and scheduling algorithms.)</p>
<h3 id="When-to-use-yield"><a class="header-anchor" href="#When-to-use-yield"></a>When to use <code>yield()</code>?</h3>
<p>I would say <strong>practically never</strong>. Its behaviour isn’t standardly defined and there are generally better ways to perform the tasks that you might want to perform with yield():</p>
<ul>
<li>if you’re trying to <strong>use only a portion of the CPU</strong>, you can do this in a more controllable way by estimating how much CPU the thread has used in its last chunk of processing, then <strong>sleeping</strong> for some amount of time to compensate: see the <a href="http://www.javamex.com/tutorials/threads/sleep.shtml">sleep()</a> method;</li>
<li>if you’re <strong>waiting for a process or resource</strong> to complete or become available, there are more efficient ways to accomplish this, such as by using <a href="http://www.javamex.com/tutorials/threads/yield.shtml#join">join()</a> to wait for another thread to complete, using the <a href="http://www.javamex.com/tutorials/synchronization_wait_notify.shtml">wait/notify</a> mechanism to allow one thread to signal to another that a task is complete, or ideally by using one of the Java 5 concurrency constructs such as a <a href="http://www.javamex.com/tutorials/synchronization_concurrency_semaphore.shtml">Semaphore</a> or <a href="http://www.javamex.com/tutorials/synchronization_concurrency_8_queues.shtml">blocking queue</a>.</li>
</ul>
</blockquote>
<hr>
<p><strong>Article link: <a href="http://xnerv.wang/what-are-the-main-uses-of-yield-and-how-does-it-differ-from-join-and-interrupt/">http://xnerv.wang/what-are-the-main-uses-of-yield-and-how-does-it-differ-from-join-and-interrupt/</a></strong><br>
Reprinted from: <a href="https://stackoverflow.com/q/6979796">(StackOverflow) What are the main uses of yield(), and how does it differ from join() and interrupt()?</a></p>
]]></content>
      <categories>
        <category>OS</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>OS</tag>
        <tag>Stack Overflow</tag>
        <tag>yield</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL - InnoDB mini transation（转载）</title>
    <url>/what-innodb-mini-transation/</url>
    <content><![CDATA[<h2 id="前言"><a class="header-anchor" href="#前言"></a>前言</h2>
<p>InnoDB有两个非常重要的日志，undo log 和 redo log；通过undo log可以看到数据较早版本，实现MVCC，或回滚事务等功能；redo log用来保证事务持久性</p>
<p>本文以一条insert语句为线索介绍 mini transaction</p>
<h2 id="mini-transaction-简介"><a class="header-anchor" href="#mini-transaction-简介"></a>mini transaction 简介</h2>
<p>mini transation 主要用于innodb redo log 和 undo log写入，保证两种日志的ACID特性</p>
<p>mini-transaction遵循以下三个协议:</p>
<ol>
<li>
<p>The FIX Rules</p>
</li>
<li>
<p>Write-Ahead Log</p>
</li>
<li>
<p>Force-log-at-commit</p>
</li>
</ol>
<span id="more"></span>
<h4 id="The-FIX-Rules"><a class="header-anchor" href="#The-FIX-Rules"></a>The FIX Rules</h4>
<p>修改一个页需要获得该页的x-latch</p>
<p>访问一个页是需要获得该页的s-latch或者x-latch</p>
<p>持有该页的latch直到修改或者访问该页的操作完成</p>
<h4 id="Write-Ahead-Log"><a class="header-anchor" href="#Write-Ahead-Log"></a>Write-Ahead Log</h4>
<p>持久化一个数据页之前，必须先将内存中相应的日志页持久化</p>
<p>每个页有一个LSN,每次页修改需要维护这个LSN,当一个页需要写入到持久化设备时，要求内存中小于该页LSN的日志先写入到持久化设备中</p>
<h4 id="Force-log-at-commit"><a class="header-anchor" href="#Force-log-at-commit"></a>Force-log-at-commit</h4>
<p>一个事务可以同时修改了多个页，Write-AheadLog单个数据页的一致性，无法保证事务的持久性</p>
<p>Force -log-at-commit要求当一个事务提交时，其产生所有的mini-transaction日志必须刷到持久设备中</p>
<p>这样即使在页数据刷盘的时候宕机，也可以通过日志进行redo恢复</p>
<h4 id="代码简介"><a class="header-anchor" href="#代码简介"></a>代码简介</h4>
<p>本文使用 MySQL 5.6.16 版本进行分析</p>
<p>mini transation 相关代码路径位于 storage/innobase/mtr/ 主要有 <a href="http://mtr0mtr.cc">mtr0mtr.cc</a> 和 <a href="http://mtr0log.cc">mtr0log.cc</a> 两个文件</p>
<p>另有部分代码在 storage/innobase/include/ 文件名以 mtr0 开头</p>
<p>mini transaction 的信息保存在结构体 mtr_t 中，结构体成员描述如下</p>
<table>
<thead>
<tr>
<th>成员属性</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>state</td>
<td>mini transaction所处状态 MTR_ACTIVE, MTR_COMMITTING, MTR_COMMITTED</td>
</tr>
<tr>
<td>memo</td>
<td>mtr 持有锁的栈</td>
</tr>
<tr>
<td>log</td>
<td>mtr产生的日志</td>
</tr>
<tr>
<td>inside_ibuf</td>
<td>insert buffer 是否修改</td>
</tr>
<tr>
<td>modifications</td>
<td>是否修改buffer pool pages</td>
</tr>
<tr>
<td>made_dirty</td>
<td>是否产生buffer pool脏页</td>
</tr>
<tr>
<td>n_log_recs</td>
<td>log 记录数</td>
</tr>
<tr>
<td>n_freed_pages</td>
<td>释放page数</td>
</tr>
<tr>
<td>log_mode</td>
<td>日志模式，默认MTR_LOG_ALL</td>
</tr>
<tr>
<td>start_lsn</td>
<td>lsn 起始值</td>
</tr>
<tr>
<td>end_lsn</td>
<td>lsn 结束值</td>
</tr>
<tr>
<td>magic_n</td>
<td>魔术字</td>
</tr>
</tbody>
</table>
<p>一个 mini transaction 从 mtr_start(mtr)开始，到 mtr_commit(mtr)结束</p>
<h2 id="一条insert语句涉及的-mini-transaction"><a class="header-anchor" href="#一条insert语句涉及的-mini-transaction"></a>一条insert语句涉及的 mini transaction</h2>
<p>下面涉及 mtr 的嵌套，在代码中，每个 mtr_t 对象变量名都叫 mtr，本文中为了区分不同 mtr，给不同的对象加编号</p>
<p>下面一般省略 mtr_t 以外的参数</p>
<p>第一个 mtr 从 row_ins_clust_index_entry_low 开始</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mtr_start(mtr_1) // mtr_1 贯穿整条insert语句</span><br><span class="line">row_ins_clust_index_entry_low</span><br><span class="line"></span><br><span class="line">mtr_s_lock(dict_index_get_lock(index), mtr_1) // 对index加s锁</span><br><span class="line">btr_cur_search_to_nth_level</span><br><span class="line">row_ins_clust_index_entry_low</span><br><span class="line"></span><br><span class="line">mtr_memo_push(mtr_1) // buffer RW_NO_LATCH 入栈</span><br><span class="line">buf_page_get_gen</span><br><span class="line">btr_cur_search_to_nth_level</span><br><span class="line">row_ins_clust_index_entry_low</span><br><span class="line"></span><br><span class="line">mtr_memo_push(mtr_1) // page RW_X_LATCH 入栈</span><br><span class="line">buf_page_get_gen</span><br><span class="line">btr_block_get_func</span><br><span class="line">btr_cur_latch_leaves</span><br><span class="line">btr_cur_search_to_nth_level</span><br><span class="line">row_ins_clust_index_entry_low</span><br><span class="line"></span><br><span class="line">	mtr_start(mtr_2) // mtr_2 用于记录 undo log</span><br><span class="line">	trx_undo_report_row_operation</span><br><span class="line">	btr_cur_ins_lock_and_undo</span><br><span class="line">	btr_cur_optimistic_insert</span><br><span class="line">	row_ins_clust_index_entry_low</span><br><span class="line"></span><br><span class="line">		mtr_start(mtr_3) // mtr_3 分配或复用一个 undo log</span><br><span class="line">		trx_undo_assign_undo</span><br><span class="line">		trx_undo_report_row_operation</span><br><span class="line">		btr_cur_ins_lock_and_undo</span><br><span class="line">		btr_cur_optimistic_insert</span><br><span class="line">		row_ins_clust_index_entry_low</span><br><span class="line"></span><br><span class="line">		mtr_memo_push(mtr_3) // 对复用（也可能是分配）的 undo log page 加 RW_X_LATCH 入栈</span><br><span class="line">		buf_page_get_gen</span><br><span class="line">		trx_undo_page_get</span><br><span class="line">		trx_undo_reuse_cached // 这里先尝试复用，如果复用失败，则分配新的 undo log</span><br><span class="line">		trx_undo_assign_undo</span><br><span class="line">		trx_undo_report_row_operation</span><br><span class="line"></span><br><span class="line"> 		trx_undo_insert_header_reuse(mtr_3) // 写 undo log header</span><br><span class="line">		trx_undo_reuse_cached</span><br><span class="line">		trx_undo_assign_undo</span><br><span class="line">		trx_undo_report_row_operation</span><br><span class="line"></span><br><span class="line">		trx_undo_header_add_space_for_xid(mtr_3) // 在 undo header 中预留 XID 空间</span><br><span class="line">		trx_undo_reuse_cached</span><br><span class="line">		trx_undo_assign_undo</span><br><span class="line">		trx_undo_report_row_operation</span><br><span class="line"></span><br><span class="line">		mtr_commit(mtr_3) // 提交 mtr_3</span><br><span class="line">		trx_undo_assign_undo</span><br><span class="line">		trx_undo_report_row_operation</span><br><span class="line">		btr_cur_ins_lock_and_undo</span><br><span class="line">		btr_cur_optimistic_insert</span><br><span class="line">		row_ins_clust_index_entry_low</span><br><span class="line"></span><br><span class="line">	mtr_memo_push(mtr_2) // 即将写入的 undo log page 加 RW_X_LATCH 入栈</span><br><span class="line">	buf_page_get_gen</span><br><span class="line">	trx_undo_report_row_operation</span><br><span class="line">	btr_cur_ins_lock_and_undo</span><br><span class="line">	btr_cur_optimistic_insert</span><br><span class="line">	row_ins_clust_index_entry_low</span><br><span class="line"></span><br><span class="line">	trx_undo_page_report_insert(mtr_2) // undo log 记录 insert 操作</span><br><span class="line">	trx_undo_report_row_operation</span><br><span class="line">	btr_cur_ins_lock_and_undo</span><br><span class="line">	btr_cur_optimistic_insert</span><br><span class="line">	row_ins_clust_index_entry_low</span><br><span class="line"></span><br><span class="line">	mtr_commit(mtr_2) // 提交 mtr_2</span><br><span class="line">	trx_undo_report_row_operation</span><br><span class="line">	btr_cur_ins_lock_and_undo</span><br><span class="line">	btr_cur_optimistic_insert</span><br><span class="line">	row_ins_clust_index_entry_low</span><br><span class="line"></span><br><span class="line">/*</span><br><span class="line">	mtr_2 提交后开始执行 insert 操作</span><br><span class="line">	page_cur_insert_rec_low 具体执行 insert 操作</span><br><span class="line">	在该函数末尾调用 page_cur_insert_rec_write_log 写 redo log</span><br><span class="line">*/</span><br><span class="line"></span><br><span class="line">page_cur_insert_rec_write_log(mtr_1) // insert 操作写 redo log</span><br><span class="line">page_cur_insert_rec_lowpage_cur_tuple_insert</span><br><span class="line">btr_cur_optimistic_insert</span><br><span class="line"></span><br><span class="line">mtr_commit(mtr_1) // 提交 mtr_1</span><br><span class="line">row_ins_clust_index_entry_low</span><br></pre></td></tr></table></figure>
<p>至此 insert 语句执行结束后</p>
<p>一条 insert 是一个单语句事务，事务提交时也会涉及 mini transaction</p>
<p>提交事务时，第一个 mtr 从 trx_prepare 开始</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mtr_start(mtr_4) // mtr_4 用于 prepare transaction</span><br><span class="line">trx_prepare</span><br><span class="line">trx_prepare_for_mysql</span><br><span class="line">innobase_xa_prepare</span><br><span class="line">ha_prepare_low</span><br><span class="line">MYSQL_BIN_LOG::prepare</span><br><span class="line">ha_commit_trans</span><br><span class="line">trans_commit_stmt</span><br><span class="line">mysql_execute_command</span><br><span class="line"></span><br><span class="line">mtr_memo_push(mtr_4) // undo page 加 RW_X_LATCH 入栈</span><br><span class="line">buf_page_get_gen</span><br><span class="line">trx_undo_page_get</span><br><span class="line">trx_undo_set_state_at_prepare</span><br><span class="line">trx_prepare</span><br><span class="line"></span><br><span class="line">mlog_write_ulint(seg_hdr + TRX_UNDO_STATE, undo-&gt;state, MLOG_2BYTES, mtr_4) 写入TRX_UNDO_STATE</span><br><span class="line">trx_undo_set_state_at_prepare</span><br><span class="line">trx_prepare</span><br><span class="line"></span><br><span class="line">mlog_write_ulint(undo_header + TRX_UNDO_XID_EXISTS, TRUE, MLOG_1BYTE, mtr_4) 写入 TRX_UNDO_XID_EXISTS</span><br><span class="line">trx_undo_set_state_at_prepare</span><br><span class="line">trx_prepare</span><br><span class="line"></span><br><span class="line">trx_undo_write_xid(undo_header, &amp;undo-&gt;xid, mtr_4) undo 写入 xid</span><br><span class="line">trx_undo_set_state_at_prepare</span><br><span class="line">trx_prepare</span><br><span class="line"></span><br><span class="line">mtr_commit(mtr_4) // 提交 mtr_4</span><br><span class="line">trx_prepare</span><br><span class="line"></span><br><span class="line">mtr_start(mtr_5) // mtr_5 用于 commit transaction</span><br><span class="line">trx_commit</span><br><span class="line">trx_commit_for_mysql</span><br><span class="line">innobase_commit_low</span><br><span class="line">innobase_commit</span><br><span class="line">ha_commit_low</span><br><span class="line">MYSQL_BIN_LOG::process_commit_stage_queue</span><br><span class="line">MYSQL_BIN_LOG::ordered_commit</span><br><span class="line">MYSQL_BIN_LOG::commit</span><br><span class="line">ha_commit_trans</span><br><span class="line">trans_commit_stmt</span><br><span class="line">mysql_execute_command</span><br><span class="line"></span><br><span class="line">mtr_memo_push(mtr_5) // undo page 加 RW_X_LATCH 入栈</span><br><span class="line">buf_page_get_gen</span><br><span class="line">trx_undo_page_get</span><br><span class="line">trx_undo_set_state_at_finish</span><br><span class="line">trx_write_serialisation_history</span><br><span class="line">trx_commit_low</span><br><span class="line">trx_commit</span><br><span class="line"></span><br><span class="line">trx_undo_set_state_at_finish(mtr_5) // set undo state， 这里是 TRX_UNDO_CACHED</span><br><span class="line">trx_write_serialisation_history</span><br><span class="line">trx_commit_low</span><br><span class="line">trx_commit</span><br><span class="line"></span><br><span class="line">mtr_memo_push(mtr_5) // 系统表空间 transaction system header page 加 RW_X_LATCH 入栈</span><br><span class="line">buf_page_get_gen</span><br><span class="line">trx_sysf_get</span><br><span class="line">trx_sys_update_mysql_binlog_offset</span><br><span class="line">trx_write_serialisation_history</span><br><span class="line">trx_commit_low</span><br><span class="line">trx_commit</span><br><span class="line"></span><br><span class="line">trx_sys_update_mysql_binlog_offset // 更新偏移量信息到系统表空间</span><br><span class="line">trx_write_serialisation_history</span><br><span class="line">trx_commit_low</span><br><span class="line">trx_commit</span><br><span class="line"></span><br><span class="line">mtr_commit(mtr_5) // 提交 mtr_5</span><br><span class="line">trx_commit_low</span><br><span class="line">trx_commit</span><br></pre></td></tr></table></figure>
<p>至此 insert 语句涉及的 mini transaction 全部结束</p>
<h2 id="总结"><a class="header-anchor" href="#总结"></a>总结</h2>
<p>上面可以看到加锁、写日志到 mlog 等操作在 mini transaction 过程中进行</p>
<p>解锁、把日志刷盘等操作全部在 mtr_commit 中进行，和事务类似</p>
<p>mini transaction 没有回滚操作， 因为只有在 mtr_commit 才将修改落盘，如果宕机，内存丢失，无需回滚；如果落盘过程中宕机，崩溃恢复时可以看出落盘过程不完整，丢弃这部分修改</p>
<p>mtr_commit 主要包含以下步骤</p>
<ol>
<li>mlog 中日志刷盘</li>
<li>释放 mtr 持有的锁，锁信息保存在 memo 中，以栈形式保存，后加的锁先释放</li>
<li>清理 mtr 申请的内存空间，memo 和 log</li>
<li>mtr—&gt;state 设置为 MTR_COMMITTED</li>
</ol>
<p>上面的步骤 1. 中，日志刷盘策略和 innodb_flush_log_at_trx_commit 有关</p>
<ul>
<li>当设置该值为1时，每次事务提交都要做一次fsync，这是最安全的配置，即使宕机也不会丢失事务</li>
<li>当设置为2时，则在事务提交时只做write操作，只保证写到系统的page cache，因此实例crash不会丢失事务，但宕机则可能丢失事务</li>
<li>当设置为0时，事务提交不会触发redo写操作，而是留给后台线程每秒一次的刷盘操作，因此实例crash将最多丢失1秒钟内的事务</li>
</ul>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/what-innodb-mini-transation/">http://xnerv.wang/what-innodb-mini-transation/</a></strong><br>
转载自：<a href="http://mysql.taobao.org/monthly/2017/10/03/">InnoDB mini transation</a></p>
]]></content>
      <categories>
        <category>DBMS</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>DBMS</tag>
        <tag>MySQL</tag>
        <tag>InnoDB</tag>
        <tag>MTR</tag>
      </tags>
  </entry>
  <entry>
    <title>(Stack Overflow) What is private bytes, virtual bytes, working set?</title>
    <url>/what-is-private-bytes-virtual-bytes-working-set/</url>
    <content><![CDATA[<h2 id="Question"><a class="header-anchor" href="#Question"></a>Question</h2>
<p>I am trying to use the perfmon windows utility to debug memory leaks in a process.</p>
<p>This is how perfmon explains the terms:</p>
<p><strong>Working Set</strong> is the current size, in bytes, of the Working Set of this process. The Working Set is the set of memory pages touched recently by the threads in the process. If free memory in the computer is above a threshold, pages are left in the Working Set of a process even if they are not in use. When free memory falls below a threshold, pages are trimmed from Working Sets. If they are needed they will then be soft-faulted back into the Working Set before leaving main memory.</p>
<p><strong>Virtual Bytes</strong> is the current size, in bytes, of the virtual address space the process is using. Use of virtual address space does not necessarily imply corresponding use of either disk or main memory pages. Virtual space is finite, and the process can limit its ability to load libraries.</p>
<p><strong>Private Bytes</strong> is the current size, in bytes, of memory that this process has allocated that cannot be shared with other processes.</p>
<span id="more"></span>
<p>These are the questions I have:</p>
<p><em>Is it the Private Bytes which I should measure to be sure if the process is having any leaks as it does not involve any shared libraries and any leaks, if happening, will come from the process itself?</em></p>
<p><em>What is the total memory consumed by the process? Is it the Virtual Bytes or is it the sum of Virtual Bytes and Working Set?</em></p>
<p><em>Is there any relation between Private Bytes, Working Set and Virtual Bytes?</em></p>
<p><em>Are there any other tools that give a better idea of the memory usage?</em></p>
<h2 id="Answer-by-pankajt"><a class="header-anchor" href="#Answer-by-pankajt"></a>Answer by pankajt</h2>
<p>The short answer to this question is that <strong>none of these values are a reliable indicator of how much memory an executable is actually using, and none of them are really appropriate for debugging a memory leak.</strong></p>
<p><strong>Private Bytes</strong> refer to the amount of memory that the process executable has <em>asked for</em> - not necessarily the amount it is <em>actually using</em>. They are “private” because they (usually) exclude memory-mapped files (i.e. shared DLLs). But - here’s the catch - they don’t necessarily exclude memory <em>allocated by those files</em>. There is no way to tell whether a change in private bytes was due to the executable itself, or due to a linked library. Private bytes are also <strong>not</strong> exclusively physical memory; they can be paged to disk or in the standby page list (i.e. no longer in use, but not paged yet either).</p>
<p><strong>Working Set</strong> refers to the total <strong>physical</strong> memory (RAM) used by the process. However, unlike private bytes, this also includes memory-mapped files and various other resources, so it’s an even less accurate measurement than the private bytes. This is the same value that gets reported in Task Manager’s “Mem Usage” and has been the source of endless amounts of confusion in recent years. Memory in the Working Set is “physical” in the sense that it can be addressed without a page fault; however, the standby page list is <em>also</em> still physically in memory but not reported in the Working Set, and this is why you might see the “Mem Usage” suddenly drop when you minimize an application.</p>
<p><strong>Virtual Bytes</strong> are the total <strong>virtual address space</strong> occupied by the entire process. This is like the working set, in the sense that it includes memory-mapped files (shared DLLs), but it also includes data in the standby list and data that has already been paged out and is sitting in a pagefile on disk somewhere. The total virtual bytes used by every process on a system under heavy load will add up to significantly more memory than the machine actually has.</p>
<!--more-->
<p>So the relationships are:</p>
<ul>
<li>Private Bytes are what your app has actually allocated, but include pagefile usage;</li>
<li>Working Set is the non-paged Private Bytes plus memory-mapped files;</li>
<li>Virtual Bytes are the Working Set plus paged Private Bytes and standby list.</li>
</ul>
<p>There’s another problem here; just as shared libraries can allocate memory inside your application module, leading to potential false positives reported in your app’s Private Bytes, <em>your</em> application may also end up allocating memory inside the <em>shared</em> modules, leading to false <em>negatives</em>. That means it’s actually possible for your application to have a memory leak that never manifests itself in the Private Bytes at all. Unlikely, but possible.</p>
<p>Private Bytes are a reasonable <strong>approximation</strong> of the amount of memory your executable is using and can be used to help <em>narrow down</em> a list of potential candidates for a memory leak; if you see the number growing and growing constantly and endlessly, you would want to check that process for a leak. This cannot, however, <em>prove</em> that there is or is not a leak.</p>
<p>One of the most effective tools for detecting/correcting memory leaks in Windows is actually <a href="http://msdn.microsoft.com/en-us/library/x98tx3cf(VS.80).aspx">Visual Studio</a> (link goes to page on using VS for memory leaks, not the product page). <a href="http://www-01.ibm.com/software/awdtools/purify/">Rational Purify</a> is another possibility. Microsoft also has a more general <a href="http://msdn.microsoft.com/en-us/library/dd744766(VS.85).aspx">best practices document</a> on this subject. There are more tools listed in this <a href="https://stackoverflow.com/questions/413477/is-there-a-good-valgrind-substitute-for-windows">previous question</a>.</p>
<p>I hope this clears a few things up! Tracking down memory leaks is one of the most difficult things to do in debugging. Good luck.</p>
<hr>
<p><strong>Article link: <a href="http://xnerv.wang/what-is-private-bytes-virtual-bytes-working-set/">http://xnerv.wang/what-is-private-bytes-virtual-bytes-working-set/</a></strong><br>
Reprinted from: <a href="https://stackoverflow.com/q/1984186">(StackOverflow) What is private bytes, virtual bytes, working set?</a></p>
]]></content>
      <categories>
        <category>OS</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>OS</tag>
        <tag>Stack Overflow</tag>
        <tag>Memory Management</tag>
        <tag>Virtual Memory</tag>
        <tag>Private bytes</tag>
        <tag>Working Set</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL - set names 都做了什么（转载）</title>
    <url>/what-set-names-does/</url>
    <content><![CDATA[<h2 id="背景"><a class="header-anchor" href="#背景"></a>背景</h2>
<p>最近有同事问，set names 时会同时设置了3个session变量</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SET</span> character_set_client <span class="operator">=</span> charset_name;</span><br><span class="line"><span class="keyword">SET</span> character_set_results <span class="operator">=</span> charset_name;</span><br><span class="line"><span class="keyword">SET</span> character_set_connection <span class="operator">=</span> charset_name;</span><br></pre></td></tr></table></figure>
<p>就从变量名字来看，character_set_client 是设置客户端相关的字符集，character_set_results 是设置返回结果相关的字符集，character_set_connection 这个就有点不太明白了，这个有啥用呢？</p>
<h2 id="概念说明"><a class="header-anchor" href="#概念说明"></a>概念说明</h2>
<p>通过<a href="http://dev.mysql.com/doc/refman/5.6/en/charset-connection.html">官方文档</a>来看:</p>
<ol>
<li>character_set_client 是指客户端发送过来的语句的编码;</li>
<li>character_set_connection 是指mysqld收到客户端的语句后，要转换到的编码；</li>
<li>而 character_set_results 是指server执行语句后，返回给客户端的数据的编码。</li>
</ol>
<span id="more"></span>
<p>对人来说，能够理解的是各种各样的符号，而对计算机来说，只能理解二进制，二进制和符号之间的对应关系就是编码。不同地域国家都有自己的一套符号集合，每个都各自用一组二进制数字表示，从而形成了不同的编码，字符集就可以看作是编码和符号的对应关系集合。同一个二进制数在不同的字符集下可能对应完全不一样的字符，如在GBK字符集中，<code>C4E3</code> 对应的是<code>你</code>，而在big5字符集中对应的是<code>斕</code>，而 <code>你</code>在unicode中的编码是<code>4F60</code>，在<a href="http://collation-charts.org/">Collation-Charts</a> 这个网站有字符集和编码对应关系图，可以非常直观地看到不同编码下二进制数和符号的对应关系。</p>
<p>set names 设置的3个变量就是设置mysqld和客户端通信时，mysqld应该如何解读client发来的字符，以及返回给客户端什么样的编码。</p>
<h2 id="实验测试"><a class="header-anchor" href="#实验测试"></a>实验测试</h2>
<p>环境如下：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">show</span> variables <span class="keyword">like</span> <span class="string">&#x27;character%&#x27;</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">--------------------------+-------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> Variable_name            <span class="operator">|</span> <span class="keyword">Value</span>                               <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">--------------------------+-------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> character_set_client     <span class="operator">|</span> utf8                                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> character_set_connection <span class="operator">|</span> utf8                                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> character_set_database   <span class="operator">|</span> utf8                                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> character_set_filesystem <span class="operator">|</span> <span class="type">binary</span>                              <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> character_set_results    <span class="operator">|</span> utf8                                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> character_set_server     <span class="operator">|</span> utf8                                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> character_set_system     <span class="operator">|</span> utf8                                <span class="operator">|</span></span><br></pre></td></tr></table></figure>
<p>server端的3个编码设置都是utf8。 另外，客户端是标准 mysql client，使用的编码是utf8，和sever端编码是一致的。</p>
<p>建一张表作为测试</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> t1(id <span class="type">INT</span>, name <span class="type">VARCHAR</span>(<span class="number">200</span>) CHARSET utf8) engine<span class="operator">=</span>InnoDB;</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> t1 <span class="keyword">VALUES</span>(<span class="number">0</span>, <span class="string">&#x27;你好&#x27;</span>);</span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> id, name, hex(name) <span class="keyword">FROM</span> t1;</span><br><span class="line"><span class="operator">+</span><span class="comment">------+--------+--------------+</span></span><br><span class="line"><span class="operator">|</span> id   <span class="operator">|</span> name   <span class="operator">|</span> hex(name)    <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------+--------+--------------+</span></span><br><span class="line"><span class="operator">|</span>    <span class="number">0</span> <span class="operator">|</span> 你好   <span class="operator">|</span> E4BDA0E5A5BD <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------+--------+--------------+</span></span><br></pre></td></tr></table></figure>
<p>下面我们分别改变这3个值，来看下结果会有什么变化</p>
<p><strong>Case 1 只改变 character_set_client</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SET</span> character_set_client<span class="operator">=</span>gbk;</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> t1 <span class="keyword">VALUES</span>(<span class="number">1</span>, <span class="string">&#x27;你好&#x27;</span>);</span><br><span class="line">mysql<span class="operator">&gt;</span>  <span class="keyword">SELECT</span> id, name, hex(name) <span class="keyword">FROM</span> t1;</span><br><span class="line"><span class="operator">+</span><span class="comment">------+-----------+--------------------+</span></span><br><span class="line"><span class="operator">|</span> id   <span class="operator">|</span> name      <span class="operator">|</span> hex(name)          <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------+-----------+--------------------+</span></span><br><span class="line"><span class="operator">|</span>    <span class="number">0</span> <span class="operator">|</span> 你好      <span class="operator">|</span> E4BDA0E5A5BD       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>    <span class="number">1</span> <span class="operator">|</span> 浣犲ソ    <span class="operator">|</span> E6B5A3E78AB2E382BD <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------+-----------+--------------------+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>
<p>可以看到返回的数据已经乱码了，并且数据库里存的确实和第一条记录不一样。</p>
<p><strong>case 2 只改变 character_set_connection</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SET</span> names utf8;</span><br><span class="line"><span class="keyword">SET</span> character_set_connection <span class="operator">=</span> gbk;</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> t1 <span class="keyword">VALUES</span>(<span class="number">2</span>, <span class="string">&#x27;你好&#x27;</span>);</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span>  <span class="keyword">SELECT</span> id, name, hex(name) <span class="keyword">FROM</span> t1;</span><br><span class="line"><span class="operator">+</span><span class="comment">------+-----------+--------------------+</span></span><br><span class="line"><span class="operator">|</span> id   <span class="operator">|</span> name      <span class="operator">|</span> hex(name)          <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------+-----------+--------------------+</span></span><br><span class="line"><span class="operator">|</span>    <span class="number">0</span> <span class="operator">|</span> 你好      <span class="operator">|</span> E4BDA0E5A5BD       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>    <span class="number">1</span> <span class="operator">|</span> 浣犲ソ    <span class="operator">|</span> E6B5A3E78AB2E382BD <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>    <span class="number">2</span> <span class="operator">|</span> 你好      <span class="operator">|</span> E4BDA0E5A5BD       <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------+-----------+--------------------+</span></span><br><span class="line"><span class="number">3</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>
<p><strong>case 3 只改变 character_set_results</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SET</span> names utf8;</span><br><span class="line"><span class="keyword">SET</span> character_set_results <span class="operator">=</span> gbk;</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> t1 <span class="keyword">VALUES</span>(<span class="number">3</span>, <span class="string">&#x27;你好&#x27;</span>);</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">select</span> id, name, hex(name) <span class="keyword">from</span> t1;</span><br><span class="line"><span class="operator">+</span><span class="comment">------+--------+--------------------+</span></span><br><span class="line"><span class="operator">|</span> id   <span class="operator">|</span> name   <span class="operator">|</span> hex(name)          <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------+--------+--------------------+</span></span><br><span class="line"><span class="operator">|</span>    <span class="number">0</span> <span class="operator">|</span>        <span class="operator">|</span> E4BDA0E5A5BD       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>    <span class="number">1</span> <span class="operator">|</span> 你好   <span class="operator">|</span> E6B5A3E78AB2E382BD <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>    <span class="number">2</span> <span class="operator">|</span>        <span class="operator">|</span> E4BDA0E5A5BD       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>    <span class="number">3</span> <span class="operator">|</span>        <span class="operator">|</span> E4BDA0E5A5BD       <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------+--------+--------------------+</span></span><br><span class="line"><span class="number">4</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>
<p>再改回原样，看下结果</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SET</span> names utf8;</span><br><span class="line">mysql<span class="operator">&gt;</span>  <span class="keyword">SELECT</span> id, name, hex(name) <span class="keyword">FROM</span> t1;</span><br><span class="line"><span class="operator">+</span><span class="comment">------+-----------+--------------------+</span></span><br><span class="line"><span class="operator">|</span> id   <span class="operator">|</span> name      <span class="operator">|</span> hex(name)          <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------+-----------+--------------------+</span></span><br><span class="line"><span class="operator">|</span>    <span class="number">0</span> <span class="operator">|</span> 你好      <span class="operator">|</span> E4BDA0E5A5BD       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>    <span class="number">1</span> <span class="operator">|</span> 浣犲ソ    <span class="operator">|</span> E6B5A3E78AB2E382BD <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>    <span class="number">2</span> <span class="operator">|</span> 你好      <span class="operator">|</span> E4BDA0E5A5BD       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>    <span class="number">3</span> <span class="operator">|</span> 你好      <span class="operator">|</span> E4BDA0E5A5BD       <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------+-----------+--------------------+</span></span><br><span class="line"><span class="number">4</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>
<h2 id="分析"><a class="header-anchor" href="#分析"></a>分析</h2>
<p>我们先理下字符集在整个过程中是怎样变化的，然后再分析上面的case</p>
<p>客户发送请求时：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">A1 客户端发送出语句(总是以utf8)------&gt; A2 sever收到语句解析(按character_set_client指定编码)</span><br><span class="line">                                                                    |</span><br><span class="line">                                                                    v</span><br><span class="line">A4 数据进入mysqld内部存储&lt;--------- A3 sever判断是否需要转换编码(以character_set_connection 目标编码)</span><br></pre></td></tr></table></figure>
<p>server返回结果时：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">B1 server返回结果(按character_set_results 指定编码) -----&gt;B2客户端解析编码显示(总是以utf8)</span><br></pre></td></tr></table></figure>
<p>A3步是否需要转换编码，代码中的逻辑是这样的，在sql_yacc.yy文件中：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">LEX_STRING tmp;</span><br><span class="line">THD *thd= YYTHD;</span><br><span class="line"><span class="type">const</span> CHARSET_INFO *cs_con= thd-&gt;variables.collation_connection;</span><br><span class="line"><span class="type">const</span> CHARSET_INFO *cs_cli= thd-&gt;variables.character_set_client;</span><br><span class="line">uint repertoire= thd-&gt;lex-&gt;text_string_is_7bit &amp;&amp;</span><br><span class="line">                 <span class="built_in">my_charset_is_ascii_based</span>(cs_cli) ?</span><br><span class="line">                 MY_REPERTOIRE_ASCII : MY_REPERTOIRE_UNICODE30;</span><br><span class="line"><span class="keyword">if</span> (thd-&gt;charset_is_collation_connection ||</span><br><span class="line">    (repertoire == MY_REPERTOIRE_ASCII &amp;&amp;</span><br><span class="line">     <span class="built_in">my_charset_is_ascii_based</span>(cs_con)))</span><br><span class="line">   tmp= $<span class="number">1</span>;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">if</span> (thd-&gt;<span class="built_in">convert_string</span>(&amp;tmp, cs_con, $<span class="number">1.</span>str, $<span class="number">1.l</span>ength, cs_cli))</span><br><span class="line">      MYSQL_YYABORT;</span><br><span class="line">&#125;</span><br><span class="line">$= <span class="built_in">new</span> (thd-&gt;mem_root) <span class="built_in">Item_string</span>(tmp.str, tmp.length, cs_con,</span><br><span class="line">                                    DERIVATION_COERCIBLE,</span><br><span class="line">                                    repertoire);</span><br><span class="line"><span class="keyword">if</span> ($ == <span class="literal">NULL</span>)</span><br><span class="line">   MYSQL_YYABORT;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>如果 <code>character_set_client</code> 和 <code>character_set_connection</code> 一样，或者当前的字符编码是和ASCII兼容，并且都是ASCII范围内的，就不转换，其它情况就转。</p>
<p>对于case1 实际上客户端发过来是UTF8的，但A2步骤server认为客户端的编码是GBK的，就按GBK来解析，同时满足A3步骤的转换条件，所以就误将UTF8编码认为是GBK，然后又给转成了UTF8。 <code>你好</code>的UTF8编码是 <code>E4BDA0E5A5BD</code> 6个字节，每个字符3个字节，按GBK来解析的话，因为GBK是固定2个字节，就认为有3个字符，然后转成UTF8，虽然UTF8是变长的，但是这里的3个GBK字符按值都是要占3个字节的，转出来一共9个字节。所以case1看到的实际存储的值一共9个字节，比原来的大。 在返回时，是按UTF8返回的，因为存了3个UTF8字符，所以客户端看到的就是3个。</p>
<p>对于case2 A2步骤没问题，问题是出在A3，按照转换逻辑，此时需要把UTF8转成GBK，这里因为<code>character_set_client</code>是正确的，所以转换的源不会识别错，转换成GBK自然也不会错，后面存储成UTF8时，再从GBK转成UTF8，也没错，因为UTF8和GBK字符集里都包含 ‘你’和’好’，所以相互转换也不会出错，只是多了2次转换。</p>
<p>对于case3 错在返回字符集设置的和客户端不匹配，在返回时，server将所有字符转成GBK的，结果客户端一根筋的认为是UTF8，就解析错了。 比较有意思的是第二条记录，即case1错误插进去的，显示出来是对的。 为什么呢，因为在case1中存的时候，是按 <code>UTF8-&gt;强制解析为GBK-&gt;然后转为UTF8</code> 这个逻辑存下去的，而返回的时候，因为server会将存的UTF8又给转回GBK，然后客户端又拿着这个GBK误以为是UTF8解析，实际上是case1的逆向过程，虽然2个方向都是错的，最终显示是好的，所谓的负负得正吧，哈哈。</p>
<p>对于case2 ，数据从客户端进入server的时候，多做了2次转换，最终显示还是对的，但不是所有场景都是这样，如下面这种</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">set</span> names utf8;</span><br><span class="line"><span class="keyword">set</span> character_set_connection  <span class="operator">=</span> latin1;</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> t1 <span class="keyword">VALUES</span>(<span class="number">4</span>, <span class="string">&#x27;你好&#x27;</span>);</span><br><span class="line"><span class="keyword">set</span> names utf8;</span><br><span class="line">mysql<span class="operator">&gt;</span>  <span class="keyword">SELECT</span> id, name, hex(name) <span class="keyword">FROM</span> t1;</span><br><span class="line"><span class="operator">+</span><span class="comment">------+-----------+--------------------+</span></span><br><span class="line"><span class="operator">|</span> id   <span class="operator">|</span> name      <span class="operator">|</span> hex(name)          <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------+-----------+--------------------+</span></span><br><span class="line"><span class="operator">|</span>    <span class="number">0</span> <span class="operator">|</span> 你好      <span class="operator">|</span> E4BDA0E5A5BD       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>    <span class="number">1</span> <span class="operator">|</span> 浣犲ソ    <span class="operator">|</span> E6B5A3E78AB2E382BD <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>    <span class="number">2</span> <span class="operator">|</span> 你好      <span class="operator">|</span> E4BDA0E5A5BD       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>    <span class="number">3</span> <span class="operator">|</span> 你好      <span class="operator">|</span> E4BDA0E5A5BD       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>    <span class="number">4</span> <span class="operator">|</span> ??        <span class="operator">|</span> <span class="number">3</span>F3F               <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------+-----------+--------------------+</span></span><br><span class="line"><span class="number">5</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>
<p>为什么呢，因为在 UTF8转latin1时，信息丢失了，latin1字符编码所能表达的字符集是远小于utf8的，<code>你</code> 和 <code>好</code>就不在其中，这2个字符在转换中被转成了 <code>?</code> 和 <code>?</code>，之后存储转换成UTF8时，<code>?</code>只有一个字节<code>3F</code>，还原回去还是 <code>3F</code>。</p>
<h2 id="总结"><a class="header-anchor" href="#总结"></a>总结</h2>
<p><code>character_set_client</code> 和 <code>character_set_results</code> 是一定要和客户端一致，不要依赖于负负得正，<code>character_set_connection</code> 设置和<code>character_set_client</code> 不一致，有丢失数据的风险，所以尽量也一致，总之这3个值就是要一样，还要和客户端一致，所以才有了 set names 这个快捷命令。关于为啥要有 <code>character_set_connection</code> 这一步转换，笔者目前还没看出来，以后理解了再更新，如果读者朋友知道的话，请不吝赐教。</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/what-set-names-does/">http://xnerv.wang/what-set-names-does/</a></strong><br>
转载自：<a href="http://mysql.taobao.org/monthly/2015/05/07/">set names 都做了什么</a></p>
]]></content>
      <categories>
        <category>DBMS</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>DBMS</tag>
        <tag>MySQL</tag>
        <tag>MySQL charset</tag>
      </tags>
  </entry>
  <entry>
    <title>(Stack Overflow) When does Windows decide to pull out pages from Working Set?</title>
    <url>/when-does-windows-decide-to-pull-out-pages-from-working-set/</url>
    <content><![CDATA[<h2 id="Question"><a class="header-anchor" href="#Question"></a>Question</h2>
<p>I am looking at the distribution of physical memory using the RAMMap tool by SysInternals. The distribution (see image below) shows</p>
<ol>
<li>7 GB in Free (Zeroed) memory list</li>
<li>2 GB in Working Set list</li>
<li>550 MB in Standby list</li>
<li>125 MB in Modified list</li>
</ol>
<p><img src="/assets/when-does-windows-decide-to-pull-out-pages-from-working-set/1.jpg" alt=""></p>
<p>I understand that when a process requires memory, Windows searches for memory in the lists in the order Free (Zeroed) -&gt; Standby -&gt; Modified. Hence, as long as we have Free page frames, everything should either be in the Working Set list or Free list.</p>
<ol>
<li>Is this assumption right?</li>
<li>If so, why do we see 125 MB of pages in the Modified list?</li>
<li>In general, when does Windows decide to pull out pages from Working set list to Modified/Standby list even when there is Free memory left?</li>
</ol>
<p>I am using Windows 7, with 4.0 GB of installed RAM, 3.5 GB being usable.</p>
<span id="more"></span>
<h2 id="Answer-by-Rick-Brant"><a class="header-anchor" href="#Answer-by-Rick-Brant"></a>Answer by Rick Brant</h2>
<p>No. If a page is going to be read from disk, or if it’s an allocation from kernel mode, the free list is checked first, then the zeroed list. If it isn’t, the zeroed list is checked first, then the free list (if allocated from the free list the page will be zeroed in-line before the faulting process gets to see it). In both cases, the standby list comes next. I don’t believe the modified list is ever used to satisfy page faults… since the pages have to be written out to disk before they can be assigned to other uses… so, might as well wait for the modified page writer to do its regular thing, whereupon the pages will show up on the standby list.<br>
1a. “As long as we have free page frames, everything should either be in the working set list or free list.” No. The standby list is considered “available” but until someone needs that RAM its pages are used for two different types of caches.</p>
<p>The second question (stupid automatic list formatting keeps starting over at “1” here): That’s rather a lot. Did you delete your pagefile?</p>
<p>The third question: First, keep in mind that there is a working set list for every process, not just one. And each has its own “limit”. When the limits are being enforced (they aren’t if there is plenty of free RAM), the process has to give up a page for every new page it faults in. There is also a working set reclamation process that tries to shrink long-idle processes.</p>
<p>When a process loses a page, it goes on the modified list if it was touched with a “modify”-style operand while it was in the working set, or on the standby list if not. If the process later faults to the page before it is assigned to some other use or process, it can be brought back into the process working set without going to disk for it. (This is a common example of a “soft” page fault.) In this way these lists form a sort of common system-wide extension to all processes’ working sets. But everything on the Standby list is still counted as part of “Available” memory, because it can be used by any other process immediately - noting has to be written out to disk.</p>
<p>Starting with Vista, there is a new concept called memory priority. Pages on the standby list that are of low priority can be reassigned for use by the new proactive file cache, SuperFetch. But this doesn’t cost any “available” RAM because they’re still on the standby list. (The old reactive cache is still there; it used to be part of the system working set; as of Windows 7 it has its own.)</p>
<p>This is but the tip of the iceberg. The Mm chapter of Windows Internals is 200 pages long, enough for a smallish book all by itself. But if you really want to understand this stuff, there isn’t really a substitute.</p>
<hr>
<p><strong>Article link: <a href="http://xnerv.wang/when-does-windows-decide-to-pull-out-pages-from-working-set/">http://xnerv.wang/when-does-windows-decide-to-pull-out-pages-from-working-set/</a></strong><br>
Reprinted from: <a href="https://superuser.com/q/632254">(StackOverflow) When does Windows decide to pull out pages from Working Set?</a></p>
]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>OS</tag>
        <tag>Windows</tag>
        <tag>Stack Overflow</tag>
        <tag>Memory Management</tag>
        <tag>Virtual Memory</tag>
        <tag>Working Set</tag>
      </tags>
  </entry>
  <entry>
    <title>(Stack Overflow) Why are hard links to directories not allowed in UNIX/Linux?</title>
    <url>/why-are-hard-links-to-directories-not-allowed-in-unix-linux/</url>
    <content><![CDATA[<h2 id="Question"><a class="header-anchor" href="#Question"></a>Question</h2>
<p>I read in text books that Unix/Linux doesn’t allow hard links to directories but does allow soft links. Is it because, when we have cycles and if we create hard links, and after some time we delete the original file, it will point to some garbage value?</p>
<p>If cycles were the sole reason behind not allowing hard links, then why are soft links to directories allowed?</p>
<span id="more"></span>
<h2 id="Answer-by-Chris-Down"><a class="header-anchor" href="#Answer-by-Chris-Down"></a>Answer by Chris Down</h2>
<p>This is just a bad idea, as there is no way to tell the difference between a hard link and an original name.</p>
<p>Allowing hard links to directories would break the directed acyclic graph structure of the filesystem, possibly creating directory loops and dangling directory subtrees, which would make fsck and any other file tree walkers error prone.</p>
<p>First, to understand this, let’s talk about inodes. The data in the filesystem is held in blocks on the disk, and those blocks are collected together by an inode. You can think of the inode as THE file.  Inodes lack filenames, though. That’s where links come in.</p>
<p>A link is just a pointer to an inode. A directory is an inode that holds links. Each filename in a directory is just a link to an inode. Opening a file in Unix also creates a link, but it’s a different type of link (it’s not a named link).</p>
<p>A hard link is just an extra directory entry pointing to that inode. When you ls -l, the number after the permissions is the named link count. Most regular files will have one link. Creating a new hard link to a file will make both filenames point to the same inode. Note:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">% <span class="built_in">ls</span> -l <span class="built_in">test</span></span><br><span class="line"><span class="built_in">ls</span>: <span class="built_in">test</span>: No such file or directory</span><br><span class="line">% <span class="built_in">touch</span> <span class="built_in">test</span></span><br><span class="line">% <span class="built_in">ls</span> -l <span class="built_in">test</span></span><br><span class="line">-rw-r--r--  1 danny  staff  0 Oct 13 17:58 <span class="built_in">test</span></span><br><span class="line">% <span class="built_in">ln</span> <span class="built_in">test</span> test2</span><br><span class="line">% <span class="built_in">ls</span> -l <span class="built_in">test</span>*</span><br><span class="line">-rw-r--r--  2 danny  staff  0 Oct 13 17:58 <span class="built_in">test</span></span><br><span class="line">-rw-r--r--  2 danny  staff  0 Oct 13 17:58 test2</span><br><span class="line">% <span class="built_in">touch</span> test3</span><br><span class="line">% <span class="built_in">ls</span> -l <span class="built_in">test</span>*</span><br><span class="line">-rw-r--r--  2 danny  staff  0 Oct 13 17:58 <span class="built_in">test</span></span><br><span class="line">-rw-r--r--  2 danny  staff  0 Oct 13 17:58 test2</span><br><span class="line">-rw-r--r--  1 danny  staff  0 Oct 13 17:59 test3</span><br><span class="line">            ^</span><br><span class="line">            ^ this is the <span class="built_in">link</span> count</span><br></pre></td></tr></table></figure>
<p>Now, you can clearly see that there is no such thing as a hard link. A hard link is the same as a regular name. In the above example, test or test2, which is the original file and which is the hard link? By the end, you can’t really tell (even by timestamps) because both names point to the same contents, the same inode:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">% <span class="built_in">ls</span> -li <span class="built_in">test</span>*</span><br><span class="line">14445750 -rw-r--r--  2 danny  staff  0 Oct 13 17:58 <span class="built_in">test</span></span><br><span class="line">14445750 -rw-r--r--  2 danny  staff  0 Oct 13 17:58 test2</span><br><span class="line">14445892 -rw-r--r--  1 danny  staff  0 Oct 13 17:59 test3</span><br></pre></td></tr></table></figure>
<p>The -i flag to ls shows you inode numbers in the beginning of the line. Note how test and test2 have the same inode number, but test3 has a different one.</p>
<p>Now, if you were allowed to do this for directories, two different directories in different points in the filesystem could point to the same thing. In fact, a subdir could point back to its grandparent, creating a loop.</p>
<p>Why is this loop a concern? Because when you are traversing, there is no way to detect you are looping (without keeping track of inode numbers as you traverse). Imagine you are writing the du command, which needs to recurse through subdirs to find out about disk usage. How would du know when it hit a loop? It is error prone and a lot of bookkeeping that du would have to do, just to pull off this simple task.</p>
<p>Symlinks are a whole different beast, in that they are a special type of “file” that many file filesystem APIs tend to automatically follow. Note, a symlink can point to a nonexistent destination, because they point by name, and not directly to an inode. That concept doesn’t make sense with hard links, because the mere existence of a “hard link” means the file exists.</p>
<p>So why can du deal with symlinks easily and not hard links? We were able to see above that hard links are indistinguishable from normal directory entries. Symlinks, however, are special, detectable, and skippable!  du notices that the symlink is a symlink, and skips it completely!</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">% <span class="built_in">ls</span> -l</span><br><span class="line">total 4</span><br><span class="line">drwxr-xr-x  3 danny  staff  102 Oct 13 18:14 test1/</span><br><span class="line">lrwxr-xr-x  1 danny  staff    5 Oct 13 18:13 test2@ -&gt; test1</span><br><span class="line">% <span class="built_in">du</span> -ah</span><br><span class="line">242M    ./test1/bigfile</span><br><span class="line">242M    ./test1</span><br><span class="line">4.0K    ./test2</span><br><span class="line">242M    .</span><br></pre></td></tr></table></figure>
<hr>
<p><strong>Article link: <a href="http://xnerv.wang/why-are-hard-links-to-directories-not-allowed-in-unix-linux/">http://xnerv.wang/why-are-hard-links-to-directories-not-allowed-in-unix-linux/</a></strong><br>
Reprinted from: <a href="https://unix.stackexchange.com/q/22394">(StackOverflow) Why are hard links to directories not allowed in UNIX/Linux?</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Linux</tag>
        <tag>Bash</tag>
        <tag>File System</tag>
        <tag>Stack Overflow</tag>
      </tags>
  </entry>
  <entry>
    <title>(Stack Overflow) Why can&#39;t variables be declared in a switch statement?</title>
    <url>/why-cant-variables-be-declared-in-a-switch-statement/</url>
    <content><![CDATA[<h2 id="Question"><a class="header-anchor" href="#Question"></a>Question</h2>
<p>I’ve always wondered this - why can’t you declare variables after a case label in a switch statement? In C++ you can declare variables pretty much anywhere (and declaring them close to first use is obviously a good thing) but the following still won’t work:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">switch (val)</span><br><span class="line">&#123;</span><br><span class="line">case VAL:</span><br><span class="line">  // This won&#x27;t work</span><br><span class="line">  int newVal = 42;</span><br><span class="line">  break;</span><br><span class="line">case ANOTHER_VAL:</span><br><span class="line">  ...</span><br><span class="line">  break;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>The above gives me the following error (MSC):</p>
<blockquote>
<p>initialization of ‘newVal’ is skipped by ‘case’ label</p>
</blockquote>
<p>This seems to be a limitation in other languages too. Why is this such a problem?</p>
<span id="more"></span>
<h2 id="Answer-by-Rob"><a class="header-anchor" href="#Answer-by-Rob"></a>Answer by Rob</h2>
<p>This question is tagged as [C] and [C++] at the same time. The original code is indeed invalid in both C and C++, but for completely different unrelated reasons. I believe this important detail was missed (or obfuscated) by the existing answers.</p>
<ul>
<li>
<p>In C++ this code is invalid because the <code>case ANOTHER_VAL:</code> label jumps into the scope of variable <code>newVal</code> bypassing its initialization. Jumps that bypass initialization of local objects are illegal in C++. This side of the issue is correctly addressed by most answers.</p>
</li>
<li>
<p>However, in C language bypassing variable initialization is not an error. Jumping into the scope of a variable over it initialization is legal in C. It simply means that the variable is left uninitialized. The original code does not compile in C for a completely different reason. Label <code>case VAL:</code> in the original code is attached to the declaration of variable <code>newVal</code>. In C language declarations are not statements. They cannot be labeled. And this is what causes the error when this code is interpreted as C code.</p>
</li>
</ul>
<!--more-->
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">switch</span> (val)</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">case</span> VAL:             <span class="comment">/* &lt;- C error is here */</span></span><br><span class="line">    <span class="type">int</span> newVal = <span class="number">42</span>;</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">case</span> ANOTHER_VAL:     <span class="comment">/* &lt;- C++ error is here */</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Adding an extra <code>&#123;&#125;</code> block fixes both C++ and C problems, even though these problems happen to be very different. On the C++ side it restricts the scope of <code>newVal</code>, making sure that <code>case ANOTHER_VAL:</code> no longer jumps into that scope, which eliminates the C++ issue. On the C side that extra <code>&#123;&#125;</code> introduces a compound statement, thus making the <code>case VAL:</code> label to apply to a statement, which eliminates the C issue.</p>
<ul>
<li>
<p>In C case the problem can be easily solved without the <code>&#123;&#125;</code>. Just add an empty statement after the <code>case VAL:</code> label and the code will become valid</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">switch</span> (val)</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">case</span> VAL:;            <span class="comment">/* Now it works in C! */</span></span><br><span class="line">    <span class="type">int</span> newVal = <span class="number">42</span>;</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">case</span> ANOTHER_VAL:</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Note that even though it is now valid from C point of view, it remains invalid from C++ point of view.</p>
</li>
<li>
<p>Symmetrically, in C++ case the the problem can be easily solved without the <code>&#123;&#125;</code>. Just remove the initializer from variable declaration and the code will become valid</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">switch</span> (val)</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">case</span> VAL:</span><br><span class="line">  <span class="type">int</span> newVal;</span><br><span class="line">  newVal = <span class="number">42</span>;</span><br><span class="line">  <span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">case</span> ANOTHER_VAL:     <span class="comment">/* Now it works in C++! */</span></span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Note that even though it is now valid from C++ point of view, it remains invalid from C point of view.</p>
</li>
</ul>
<hr>
<p><strong>Article link: <a href="http://xnerv.wang/why-cant-variables-be-declared-in-a-switch-statement/">http://xnerv.wang/why-cant-variables-be-declared-in-a-switch-statement/</a></strong><br>
Reprinted from: <a href="https://stackoverflow.com/a/19830820">(StackOverflow) Why can’t variables be declared in a switch statement? (answered by AnT)</a></p>
]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>C++</tag>
        <tag>Stack Overflow</tag>
        <tag>Programing</tag>
      </tags>
  </entry>
  <entry>
    <title>Why do we need Intent Locks in SQL Server?（转载）</title>
    <url>/why-do-we-need-intent-locks-in-sql-server/</url>
    <content><![CDATA[<p>I blogged 2 years ago about <a href="/why-do-we-need-update-locks-in-sql-server/">why we need UPDATE locks</a> in SQL Server. Today I want to continue this discussion by talking about Intent Locks in SQL Server, and why they are needed.</p>
<h2 id="The-Lock-Hierarchy-in-SQL-Server"><a class="header-anchor" href="#The-Lock-Hierarchy-in-SQL-Server"></a>The Lock Hierarchy in SQL Server</h2>
<p>When I talked about <a href="/lock-escalations/">Lock Escalations in SQL Server</a>, I started by briefly mentioning that SQL Server uses a Lock Hierarchy when you read or change your data.</p>
<p><img src="http://www.sqlpassion.at/wp-content/uploads/2016/04/Picture1-2.png" alt="The Locking Hiearchy in SQL Server" title="The Locking Hiearchy in SQL Server"></p>
<p>When you read a row, SQL Server always acquires by default a <strong>Shared Lock</strong> (S), and when you change a row SQL Server acquires an <strong>Exclusive Lock</strong> (X). Those Locks are incompatible with each other, and that will introduce blocking situations when you want to read/write a row concurrently.</p>
<p>In addition to the row level locks, SQL Server also acquires so-called <strong>Intent Locks</strong> at higher levels within the Lock Hierarchy: at the page and at the table level. SQL Server acquires the following Intent-Locks based on the requested row level lock:</p>
<ul>
<li>Intent Shared Lock (IS), when you have a Shared Lock at the row level</li>
<li>Intent Update Lock (IU), when you have an Update Lock at the row level</li>
<li>Intent Exclusive Lock (IX), when you have an Exclusive Lock at the row level</li>
</ul>
<p>Therefore you always get the Lock Hierarchy as shown above when you read and write your records. But why is SQL Server using these Intent Locks?</p>
<span id="more"></span>
<h2 id="Intent-Locks-in-SQL-Server"><a class="header-anchor" href="#Intent-Locks-in-SQL-Server"></a>Intent Locks in SQL Server</h2>
<p>From a technical perspective the Intent Locks are not really needed by SQL Server. They have to do with performance optimization. Let’s have a look on that in more detail. With an Intent Lock SQL Server just indicates at a higher level within the Lock Hierarchy that you have acquired a Lock somewhere else. A <strong>Intent Shared Lock</strong> tells SQL Server that there is a <strong>Shared Lock</strong> somewhere else. <strong>A Intent Update</strong> or <strong>Intent Exclusive Lock</strong> does the same, but this time SQL Server knows that there is an <strong>Update Lock</strong> or an <strong>Exclusive Lock</strong> somewhere. It is just an indication, nothing more.</p>
<p>But how does that indication help SQL Server with performance optimization? Imagine you want to acquire an Exclusive Lock at the table level. In that case, SQL Server has to know if there is an incompatible lock (like a Shared or Update Lock) somewhere else on a record. Without Intent Locks SQL Server would have to check every record to see if an incompatible lock has been granted.</p>
<p>But with an Intent Shared Lock on the table level, SQL Server knows immediately that a Shared Lock has been granted somewhere else, and therefore an Exclusive Lock can’t be granted at the table level. That’s the whole reason why Intent Locks exist in SQL Server: to allow efficient checking if an incompatible lock exists somewhere within the Lock Hierarchy. Quite easy, isn’t it?</p>
<h2 id="Summary"><a class="header-anchor" href="#Summary"></a>Summary</h2>
<p>Intent Locks are technically not needed by SQL Server, because they only indicate if there is some other specific Lock Type somewhere else within the Lock Hierarchy. But based on that fact SQL Server can check in a much more efficient way if an incompatible Lock exists somewhere else if you want to acquire a specific lock at the page or table level.</p>
<p>Thanks for your time,</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/why-do-we-need-intent-locks-in-sql-server/">http://xnerv.wang/why-do-we-need-intent-locks-in-sql-server/</a></strong><br>
转载自：<a href="https://www.sqlpassion.at/archive/2016/05/16/why-do-we-need-intent-locks-in-sql-server/">Why do we need Intent Locks in SQL Server?</a></p>
]]></content>
      <categories>
        <category>DBMS</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>DBMS</tag>
        <tag>SQL Server</tag>
        <tag>Transaction</tag>
        <tag>Intent Lock</tag>
      </tags>
  </entry>
  <entry>
    <title>Why do we need UPDATE Locks in SQL Server?（转载）</title>
    <url>/why-do-we-need-update-locks-in-sql-server/</url>
    <content><![CDATA[<p>Today I want to talk about a specific question that I almost get every time when I teach about Locking &amp; Blocking in SQL Server: Why does SQL Server need to have Update Locks? Before we go down to the details of why they are needed, I first want to give you a basic overview of when an Update (U) Lock is acquired, and how the lock itself behaves regarding its compatibility.</p>
<p>In general an Update Lock is used in SQL Server when performing an UPDATE statement. When you look at the underlying query plan, you can see that such a plan always consists of 3 parts:</p>
<ul>
<li>Reading data</li>
<li>Calculating new values</li>
<li>Writing data</li>
</ul>
<p><img src="http://www.sqlpassion.at/wp-content/uploads/2014/07/UpdateQueryPlan.png" alt="Update Query Plan" title="Update Query Plan"></p>
<p>When SQL Server initially reads the data to be changed in the first part of the query plan, Update Locks are acquired on the individual records. And finally these Update Locks are converted to Exclusive (X) Locks when the data is changed in the third part of the query plan. The question that arrises with this approach is always the same: why does SQL Server acquire Update Locks instead of Shared (S) Locks in the first phase? When you normally read data through a SELECT statement, a Shared Lock is also good enough. Why is there now a different approach with UPDATE query plans? Let’s have a more detailed look at it.</p>
<span id="more"></span>
<h2 id="Deadlock-Avoidance"><a class="header-anchor" href="#Deadlock-Avoidance"></a>Deadlock Avoidance</h2>
<p>First of all UPDATE Locks are needed to avoid deadlock situations in UPDATE query plans. Let’s try to imagine what happens when multiple UPDATE query plans acquire Shared Locks in the first phase of the plan, and afterwards convert these Shared Locks to Exclusive Locks when the data is finally changed in the third phase of the query plan:</p>
<ul>
<li>The 1st query can’t convert the Shared Lock to an Exclusive Lock, because the 2nd query has already acquired a Shared Lock.</li>
<li>The 2nd query can’t convert the Shared Lock to an Exclusive Lock, because the 1st query has already acquired a Shared Lock.</li>
</ul>
<p>That approach would lead to a traditional deadlock situation in a relational database:<br>
<img src="http://www.sqlpassion.at/wp-content/uploads/2014/07/UpdateDeadlock.png" alt="Update Deadlock" title="Update Deadlock"><br>
That’s one of the main reasons why implementers of relational database engines have introduced Update Locks to avoid that specific deadlock situation. An Update Lock is only compatible with a Shared Lock, but isn’t compatible with another Update or Exclusive Lock. Therefore a deadlock situation can be avoided, because 2 UPDATE query plans can’t run concurrently at the same time. The 2nd query will just wait until the Update Lock can be acquired in the 1st phase of the query plan. An unpublished study of <a href="http://en.wikipedia.org/wiki/IBM_System_R">System R</a> also showed that this kind of deadlock was the most prominent one. System R was initially implemented without any Update Locks.</p>
<h2 id="Improved-Concurrency"><a class="header-anchor" href="#Improved-Concurrency"></a>Improved Concurrency</h2>
<p>Instead of acquiring an Update Lock during the 1st phase, it would be also a viable option to acquire an Exclusive Lock directly in that phase. This will also overcome the deadlock problem, because an Exclusive Lock is not compatible with another Exclusive Lock. But the problem with that approach is limited concurrency, because in the mean time no other SELECT query can read the data that is currently exclusively locked. Therefore there is also the need for the Update Lock, because this specific lock is compatible with the traditional Shared Lock. As a result this means that other SELECT queries can read data, as long as individual Update Locks are not yet converted to Exclusive Locks. As a side-effect this will improve the concurrency of our parallel running queries.</p>
<p>In traditional relational literature an Update Lock is a so-called <strong>Asymmetric Lock</strong>. In the context of the Update Lock that means that the Update Lock is compatible with the Shared Lock, but not vice-versa: the Shared Lock is not compatible with the Update Lock. But SQL Server doesn’t implement the Update Lock as an asymmetric one. The Update Lock is a <strong>symmetric</strong> one, which means that Update and Shared Locks are compatible in both directions. This will also improve the overall concurrency of the system, because it doesn’t introduce blocking situations between both lock types.</p>
<h2 id="Summary"><a class="header-anchor" href="#Summary"></a>Summary</h2>
<p>In todays blog posting I gave you an overview of Update Locks in SQL Server, and why they are needed. As you have seen there is a really strong need for Update Locks in a relational database, because otherwise it would yield to deadlock situations and decreased concurrency. I hope that you now have a better understanding of Update Locks, and how they are used in SQL Server.</p>
<p>Thanks for reading!</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/why-do-we-need-update-locks-in-sql-server/">http://xnerv.wang/why-do-we-need-update-locks-in-sql-server/</a></strong><br>
转载自：<a href="http://www.sqlpassion.at/archive/2014/07/28/why-do-we-need-update-locks-in-sql-server/">Why do we need UPDATE Locks in SQL Server?</a></p>
]]></content>
      <categories>
        <category>DBMS</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>DBMS</tag>
        <tag>SQL Server</tag>
        <tag>Transaction</tag>
        <tag>Update Lock</tag>
      </tags>
  </entry>
  <entry>
    <title>为什么Docker能运行不同的Linux发行版？</title>
    <url>/why-docker-has-ability-to-run-different-linux-distribution/</url>
    <content><![CDATA[<p>结合<a href="https://stackoverflow.com/questions/18786209/what-is-the-relationship-between-the-docker-host-os-and-the-container-base-image">What is the relationship between the docker host OS and the container base image OS?</a>、<a href="https://stackoverflow.com/questions/32841982/how-can-docker-run-distros-with-different-kernels">How can Docker run distros with different kernels?</a>和[Why docker has ability to run different linux distribution?(<a href="https://stackoverflow.com/questions/25444099/why-docker-has-ability-to-run-different-linux-distribution">https://stackoverflow.com/questions/25444099/why-docker-has-ability-to-run-different-linux-distribution</a>)这几篇文章看来，Docker实例和Host OS之间通讯的唯一桥梁就是Host OS的内核。挡在Fedora上跑一个Ubuntu 16.04的Docker实例时，Docker实例用的内核仍然是Fedora的内核，而不是Ubuntu 16.04所对应的的内核，因此有可能和原生的Ubuntu 16.04有一些内核上的区别。</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/why-docker-has-ability-to-run-different-linux-distribution/">http://xnerv.wang/why-docker-has-ability-to-run-different-linux-distribution/</a></strong></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>Linux</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>为什么PostgreSQL要使用OS缓存？</title>
    <url>/why-pg-uses-os-cache/</url>
    <content><![CDATA[<p>与MySQL等开源数据库不同的是，PostgreSQL（PG）并不使用O_DIRECT来写data文件，而是依赖于OS缓存，并且强调在设置shared buffer在大小时不能过大，否则会造成过于频繁的swap而导致IO性能下降。这与MySQL等数据库的buffer pool size越大性能越好的指导原则是相反的。并且PG依赖于OS缓存的这一特性也给提供PostgreSQL云服务造成了很多问题。例如云服务要求multiple tenants资源隔离，也就是说跑在同一个VM上的多个PG servers相互之间不能互相影响，但共用OS缓存显然会造成资源竞争。不知道Docker是否可以进行OS缓存的资源隔离，但现阶段还还依赖于Service Fabric架构的Azure PG显然得自己解决这个问题，也因此造成了架构设计上不得不考虑OS缓存的隔离。</p>
<p>从<a href="http://www.interdb.jp/pg/pgsql02.html">The Internals of PostgreSQL: Chapter 2 Process and Memory Architecture</a>这篇文章看来，与MySQL使用多线程或线程池和架构不同的是，PG使用的是多进程架构。多进程模型在Windows平台上会造成很大的性能问题，这暂且不提。但多进程之间是共用的shared buffer。既然如此，那就应该不是寄希望于OS缓存来便于多进程之间共享shared buffer吧。</p>
<span id="more"></span>
<p><img src="/assets/why-pg-uses-os-cache/1.png" alt=""></p>
<p><img src="/assets/why-pg-uses-os-cache/2.png" alt=""></p>
<p><a href="http://liuyangming.tech/10-2019/INNODB-vs-PgSQL-buffer.html">PgSQL和MySQL的bufferpool探讨</a>这篇文章提出了一种猜想，认为由于PostgreSQL是诞生在实验室中，主要为了研究数据库内核原理，那么使用buffer io能够减少IO栈的代码开发，进而能够减少额外的debug。这种说法是有可能的、虽然PG的代码比MySQL的干净太多，MySQL的代码中经常有类似xxx_function，xxx_function2，another_xxx_function2这种奇怪的函数名字，而且毫无注释完全不明所以。但是PG很明显在工程化和成熟度上不如MySQL。文章中提到PG中有这么一段代码：</p>
<p><img src="/assets/why-pg-uses-os-cache/3.png" alt=""></p>
<p>也就是说PG依赖于OS缓存来减少日志归档和流复制中的文件IO读取次数。但这应该仅限于WAL xlog文件。对于shared buffer pool，是什么原因使得还需要保留这种double buffering的设计呢？</p>
<p><a href="http://www.interdb.jp/pg/pgsql08.html">The Internals of PostgreSQL: Chapter 8 Buffer Manager</a>提到可以参考<a href="https://www.postgresql.org/message-id/529E267F.4050700@agliodbs.com">Why we are going to have to go DirectIO</a>这篇讨论和<a href="https://lwn.net/Articles/580542/">Thread summary: the Linux kernel and PostgreSQL</a>这篇文章。目前看来，应该还是PG的storage layer实现上过于简陋，效率上存在很大的问题，不足以脱离OS缓存而独自运行。这也印证了<a href="http://liuyangming.tech/10-2019/INNODB-vs-PgSQL-buffer.html">PgSQL和MySQL的bufferpool探讨</a>这篇文章的说法。<a href="https://madusudanan.com/blog/understanding-postgres-caching-in-depth/#OSCaching">Understanding caching in Postgres - An in-depth guide</a>这里也提到，PG依赖于OS缓存来调度写请求，这恐怕也是PG storage layer本身缺乏相应调度机制的一种表现。</p>
<p><a href="https://lwn.net/Articles/591723/">PostgreSQL pain points</a>中也有提到flow fsync和double buffering等问题，看起来PG的developers依赖于Linux kernel提供相应的解决方案。我不知道这是否是一种正确的方向，毕竟这种与特定OS紧耦合的方案也就限制了PG在其它OS平台上运行的能力。但是考虑到现在PG本来就在Windows上跑得很差像个demo，如果PG本身的开发力量不够的话，也许这也算是一种解决方案吧。</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/why-pg-uses-os-cache/">http://xnerv.wang/why-pg-uses-os-cache/</a></strong></p>
]]></content>
      <categories>
        <category>DBMS</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>DBMS</tag>
        <tag>PostgreSQL</tag>
        <tag>PG</tag>
      </tags>
  </entry>
  <entry>
    <title>Your visual how-to guide for SELinux policy enforcement（转载）</title>
    <url>/your-visual-how-to-guide-for-selinux-policy-enforcement/</url>
    <content><![CDATA[<p><img src="https://opensource.com/sites/default/files/styles/image-full-size/public/lead-images/selinux_rules_lead_image.png?itok=N4TKqxei" alt=""><br>
<em><strong>Image by</strong> : <a href="http://opensource.com">opensource.com</a></em></p>
<p>We are celebrating the SELinux 10th year anversary this year. Hard to believe it. SELinux was first introduced in Fedora Core 3 and later in Red Hat Enterprise Linux 4. For those who have never used SELinux, or would like an explanation…</p>
<p>SElinux is a labeling system. Every process has a label. Every file/directory object in the operating system has a label. Even network ports, devices, and potentially hostnames have labels assigned to them. We write rules to control the access of a process label to an a object label like a file. We call this <em>policy</em>. The kernel enforces the rules. Sometimes this enforcement is called Mandatory Access Control (MAC).</p>
<p>The owner of an object does not have discretion over the security attributes of a object. Standard Linux access control, owner/group + permission flags like rwx, is often called Discretionary Access Control (DAC). SELinux has no concept of UID or ownership of files. Everything is controlled by the labels. Meaning an SELinux system can be setup without an all powerful root process.</p>
<p><strong>Note:</strong> _SELinux does not let you side step DAC Controls. SELinux is a parallel enforcement model. An application has to be allowed by BOTH SELinux and DAC to do certain activities. This can lead to confusion for administrators because the process gets Permission Denied. Administrators see Permission Denied means something is wrong with DAC, not SELinux labels.</p>
<span id="more"></span>
<h3 id="Type-enforcement"><a class="header-anchor" href="#Type-enforcement"></a>Type enforcement</h3>
<p>Lets look a little further into the labels. The SELinux primary model or enforcement is called <em>type enforcement</em>. Basically this means we define the label on a process based on its type, and the label on a file system object based on its type.</p>
<p><em>Analogy</em></p>
<p>Imagine a system where we define types on objects like cats and dogs. A cat and dog are process types.</p>
<p><em>*all cartoons by <a href="https://opensource.com/users/mairin" title="profile on Opensource.com">Máirín Duffy</a></em></p>
<p><img src="https://opensource.com/sites/default/files/images/life-uploads/type-enforcement_01_catdog.png" alt="Image showing a cartoon of a cat and dog."></p>
<p>We have a class of objects that they want to interact with which we call food. And I want to add types to the food, <em>cat_food</em> and <em>dog_food</em>.</p>
<p><img src="https://opensource.com/sites/default/files/images/life-uploads/type-enforcement_03_foods.png" alt="Cartoon Cat eating Cat Food and Dog eating Dog Food"></p>
<p>As a policy writer, I would say that a dog has permission to eat <em>dog_chow</em> food and a cat has permission to eat <em>cat_chow</em> food. In SELinux we would write this rule in policy.</p>
<p><img src="https://opensource.com/sites/default/files/images/life-uploads/type-enforcement_04_policy.png" alt="allow cat cat_chow:food eat; allow dog dog_chow:food eat" title="SELinux rule"></p>
<p>allow cat cat_chow:food eat;</p>
<p>allow dog dog_chow:food eat;</p>
<p>With these rules the kernel would allow the cat process to eat food labeled <em>cat_chow</em> and the dog to eat food labeled <em>dog_chow</em>.</p>
<p><img src="https://opensource.com/sites/default/files/images/life-uploads/type-enforcement_02_eat.png" alt="Cartoon Cat eating Cat Food and Dog eating Dog Food"></p>
<p>But in an SELinux system everything is denied by default. This means that if the dog process tried to eat the <em>cat_chow</em>, the kernel would prevent it.</p>
<p><img src="https://opensource.com/sites/default/files/images/life-uploads/type-enforcement_06_tux-dog-leash.png" alt=""></p>
<p>Likewise cats would not be allowed to touch dog food.</p>
<p><img src="https://opensource.com/sites/default/files/images/life-uploads/mcs-enforcement_07_tux-cat-no.png" alt="Cartoon cat not allowed to eat dog fooda" title="Cartoon cat not allowed to eat dog fooda"></p>
<p><em>Real world</em></p>
<p>We label Apache processes as <em>httpd_t</em> and we label Apache content as <em>httpd_sys_content_t</em> and <em>httpd_sys_content_rw_t</em>. Imagine we have credit card data stored in a mySQL database which is labeled <em>msyqld_data_t</em>. If an Apache process is hacked, the hacker could get control of the <em>httpd_t process</em> and would be allowed to read <em>httpd_sys_content_t</em> files and write to <em>httpd_sys_content_rw_t</em>. But the hacker would not be allowed to read the credit card data (<em>mysqld_data_t</em>) even if the process was running as root. In this case SELinux has mitigated the break in.</p>
<h3 id="MCS-enforcement"><a class="header-anchor" href="#MCS-enforcement"></a>MCS enforcement</h3>
<p>_Analogy _</p>
<p>Above, we typed the dog process and cat process, but what happens if you have multiple dogs processes: Fido and Spot. You want to stop Fido from eating Spot’s <em>dog_chow</em>.</p>
<p><img src="https://opensource.com/sites/default/files/resize/images/life-uploads/mcs-enforcement_02_fido-eat-spot-food-500x251.png" alt="SELinux rule" title="SELinux rule"></p>
<p>One solution would be to create lots of new types, like <em>Fido_dog</em> and <em>Fido_dog_chow</em>. But, this will quickly become unruly because all dogs have pretty much the same permissions.</p>
<p>To handle this we developed a new form of enforcement, which we call Multi Category Security (MCS). In MCS, we add another section of the label which we can apply to the dog process and to the dog_chow food. Now we label the dog process as <em>dog:random1</em> (Fido) and <em>dog:random2</em> (Spot).</p>
<p><img src="https://opensource.com/sites/default/files/images/life-uploads/mcs-enforcement_01_fido-spot.png" alt="Cartoon of two dogs fido and spot"></p>
<p>We label the dog chow as <em>dog_chow:random1 (Fido)</em> and <em>dog_chow:random2</em> (Spot).</p>
<p><img src="https://opensource.com/sites/default/files/images/life-uploads/mcs-enforcement_03_foods.png" alt="SELinux rule" title="SELinux rule"></p>
<p>MCS rules say that if the type enforcement rules are OK and the random MCS labels match exactly, then the access is allowed, if not it is denied.</p>
<p>Fido (dog:random1) trying to eat <em>cat_chow:food</em> is denied by type enforcement.</p>
<p><img src="https://opensource.com/sites/default/files/images/life-uploads/mcs-enforcement_04-bad-fido-cat-chow.png" alt="Cartoon of Kernel (Penquin) holding leash to prevent Fido from eating cat food."></p>
<p>Fido (dog:random1) is allowed to eat <em>dog_chow:random1.</em></p>
<p><img src="https://opensource.com/sites/default/files/images/life-uploads/mcs-enforcement_05_fido-eat-fido-food.png" alt="Cartoon Fido happily eating his dog food"></p>
<p>Fido (dog:random1) denied to eat spot’s (<em>dog_chow:random2</em>) food.</p>
<p><img src="https://opensource.com/sites/default/files/images/life-uploads/mcs-enforcement_06_fido-no-spot-food.png" alt="Cartoon of Kernel (Penquin) holding leash to prevent Fido from eating spots dog food."></p>
<p><em>Real world</em></p>
<p>In computer systems we often have lots of processes all with the same access, but we want them separated from each other. We sometimes call this a <em>multi-tenant environment</em>. The best example of this is virtual machines. If I have a server running lots of virtual machines, and one of them gets hacked, I want to prevent it from attacking the other virtual machines and virtual machine images. But in a type enforcement system the KVM virtual machine is labeled <em>svirt_t</em> and the image is labeled <em>svirt_image_t</em>. We have rules that say <em>svirt_t</em> can read/write/delete content labeled <em>svirt_image_t</em>. With libvirt we implemented not only type enforcement separation, but also MCS separation. When libvirt is about to launch a virtual machine it picks out a random MCS label like <em>s0:c1,c2</em>, it then assigns the <em>svirt_image_t:s0:c1,c2</em> label to all of the content that the virtual machine is going to need to manage. Finally, it launches the virtual machine as <em>svirt_t:s0:c1,c2</em>. Then, the SELinux kernel controls that <em>svirt_t:s0:c1,c2</em> can not write to <em>svirt_image_t:s0:c3,c4</em>, even if the virtual machine is controled by a hacker and takes it over. Even if it is running as root.</p>
<p>We use <a href="http://people.fedoraproject.org/~dwalsh/SELinux/Presentations/openshift_selinux.ogv" title="SELinux and OpenShift">similar separation</a> in OpenShift. Each gear (user/app process)runs with the same SELinux type (openshift_t). Policy defines the rules controlling the access of the gear type and a unique MCS label to make sure one gear can not interact with other gears.</p>
<p>Watch <a href="http://people.fedoraproject.org/~dwalsh/SELinux/Presentations/openshift_selinux.ogv" title="Fedora Project: Openshift gear becomes root">this short video</a> on what would happen if an Openshift gear became root.</p>
<h3 id="MLS-enforcement"><a class="header-anchor" href="#MLS-enforcement"></a>MLS enforcement</h3>
<p>Another form of SELinux enforcement, used much less frequently, is called Multi Level Security (MLS); it was developed back in the 60s and is used mainly in trusted operating systems like Trusted Solaris.</p>
<p>The main idea is to control processes based on the level of the data they will be using. A <em>secret</em> process can not read <em>top secret</em> data.</p>
<p>MLS is very similar to MCS, except it adds a concept of dominance to enforcement. Where MCS labels have to match exactly, one MLS label can dominate another MLS label and get access.</p>
<p><em>Analogy</em></p>
<p>Instead of talking about different dogs, we now look at different breeds. We might have a Greyhound and a Chihuahua.</p>
<p><img src="https://opensource.com/sites/default/files/images/life-uploads/mls-enforcement_01_chigrey.png" alt="Cartoon of a Greyhound and a Chihuahua"></p>
<p>We might want to allow the Greyhound to eat any dog food, but a Chihuahua could choke if it tried to eat Greyhound dog food.</p>
<p>We want to label the Greyhound as <em>dog:Greyhound</em> and his dog food as _dog_chow:Greyhound, _and label the Chihuahua as <em>dog:Chihuahua</em> and his food as <em>dog_chow:Chihuahua</em>.</p>
<p><img src="https://opensource.com/sites/default/files/images/life-uploads/mls-enforcement_04_mlstypes.png" alt="Cartoon of a Greyhound dog food and a Chihuahua dog food."></p>
<p>With the MLS policy, we would have the MLS Greyhound label dominate the Chihuahua label. This means <em>dog:Greyhound</em> is allowed to eat _dog_chow:Greyhound _and <em>dog_chow:Chihuahua</em>.</p>
<p><img src="https://opensource.com/sites/default/files/images/life-uploads/mls-enforcement_05_chigreyeating.png" alt="SELinux rule" title="SELinux rule"></p>
<p>But <em>dog:Chihuahua</em> is not allowed to eat <em>dog_chow:Greyhound</em>.</p>
<p><img src="https://opensource.com/sites/default/files/images/life-uploads/mls-enforcement_03_chichoke.png" alt="Cartoon of Kernel (Penquin) stopping the Chihahua from eating the greyhound food.  Telling him it would be a big too beefy for him."><br>
Of course, <em>dog:Greyhound</em> and <em>dog:Chihuahua</em> are still prevented from eating <em>cat_chow:Siamese</em> by type enforcement, even if the MLS type Greyhound dominates Siamese.</p>
<p><img src="https://opensource.com/sites/default/files/images/life-uploads/mls-enforcement_06_nocatchow.png" alt="Cartoon of Kernel (Penquin) holding leash to prevent both dogs from eating cat food."></p>
<p><em>Real world</em></p>
<p>I could have two Apache servers: one running as <em>httpd_t:TopSecret</em> and another running as <em>httpd_t:Secret</em>. If the Apache process <em>httpd_t:Secret</em> were hacked, the hacker could read <em>httpd_sys_content_t:Secret</em> but would be prevented from reading <em>httpd_sys_content_t:TopSecret</em>.</p>
<p>However, if the Apache server running <em>httpd_t:TopSecret</em> was hacked, it could read <em>httpd_sys_content_t:Secret data</em> as well as <em>httpd_sys_content_t:TopSecret</em>.</p>
<p>We use the MLS in military environments where a user might only be allowed to see <em>secret</em> data, but another user on the same system could read <em>top secret</em> data.</p>
<h3 id="Conclusion"><a class="header-anchor" href="#Conclusion"></a>Conclusion</h3>
<p>SELinux is a powerful labeling system, controlling access granted to individual processes by the kernel. The primary feature of this is type enforcement where rules define the access allowed to a process is allowed based on the labeled type of the process and the labeled type of the object. Two additional controls have been added to separate processes with the same type from each other called MCS, total separtion from each other, and MLS, allowing for process domination.</p>
<hr>
<p><strong>本文地址：<a href="http://xnerv.wang/your-visual-how-to-guide-for-selinux-policy-enforcement/">http://xnerv.wang/your-visual-how-to-guide-for-selinux-policy-enforcement/</a></strong><br>
转载自：<a href="https://opensource.com/business/13/11/selinux-policy-guide">Your visual how-to guide for SELinux policy enforcement</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>SELinux</tag>
      </tags>
  </entry>
</search>
