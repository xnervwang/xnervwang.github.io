{"meta":{"title":"XNERV SURVEYS","subtitle":"God's in his heaven.<br/>All's right with the world.","description":"Xnerv Wang (xnervwang) 的技术博客，主要涉及C/C++、数据库引擎开发、文件系统、TCP/IP与网络、分布式系统和Linux等领域，也会偶尔刷一刷LeetCode等题库。毕业于南京大学软件学院，曾经在腾讯、百度、微软上海等大型互联网企业工作，目前奋斗在微软西雅图，从事Azure上的MySQL/PostgreSQL开源数据库云服务开发。","author":"Xnerv Wang (xnervwang)","url":"https://xnerv.wang","root":"/"},"pages":[{"title":"404页面","date":"2017-05-16T00:53:23.000Z","updated":"2017-05-15T10:11:03.000Z","comments":true,"path":"/404.html","permalink":"https://xnerv.wang/404.html","excerpt":"","text":""},{"title":"于是，开始写博客吧！","date":"2017-05-28T19:06:00.000Z","updated":"2018-03-14T12:46:31.000Z","comments":true,"path":"about/index.html","permalink":"https://xnerv.wang/about/index.html","excerpt":"记忆中从小的时候，大概还是在初中吧，就一直希望有自己的网站。当时还是2001年还是2002年的时候，博客的概念还没有兴起，很多人唯一接触电脑的机会就是在那些破旧小巷里的网吧。现在想来我走上IT之路的星星之火就是从这时开始闪烁出微弱的光芒的。那时候还不懂编程，唯一接触过跟编程相关的可能就是那种类似小霸王学习机上自带的被阉割过的QBasic语言吧。那时候也不像现在这样是一个知识爆炸的年代，有什么不懂都可以百度一下谷歌一下。身边的人大多还不明白电脑是什么，仅有的接触过电脑的人也只是在电脑上玩过CS、红警、以及后来的传奇。于是小霸王说明书的“CTRL+C”就这么困扰了我两三年，一直不明白“+”到底代表什么。直到后来突然有一天如醍醐灌顶般顿悟，同时按下CTRL和C两个键，Bingo！","text":"记忆中从小的时候，大概还是在初中吧，就一直希望有自己的网站。当时还是2001年还是2002年的时候，博客的概念还没有兴起，很多人唯一接触电脑的机会就是在那些破旧小巷里的网吧。现在想来我走上IT之路的星星之火就是从这时开始闪烁出微弱的光芒的。那时候还不懂编程，唯一接触过跟编程相关的可能就是那种类似小霸王学习机上自带的被阉割过的QBasic语言吧。那时候也不像现在这样是一个知识爆炸的年代，有什么不懂都可以百度一下谷歌一下。身边的人大多还不明白电脑是什么，仅有的接触过电脑的人也只是在电脑上玩过CS、红警、以及后来的传奇。于是小霸王说明书的“CTRL+C”就这么困扰了我两三年，一直不明白“+”到底代表什么。直到后来突然有一天如醍醐灌顶般顿悟，同时按下CTRL和C两个键，Bingo！ 上大学选择了软件工程专业，有机会也有能力搭建自己的网站了。此时个人博客的概念开始火起来，我也在CSDN、博客园等技术网站上申请了博客，虽然不那么积极更新就是。网页收藏夹中的技术文章链接常常达到几百篇，不断地消化又不断地堆积。从大一到现在已十年，现在收藏夹中仍有近百篇文章等待去啃。关于技术的总结和笔记也很多，也经历了记事本，Word，印象笔记，为知笔记，Cmd Markdown，Atom+OneDrive这样一条不断演化的笔记书写和保存之路。关于Atom我后面应该会再另开一篇文章来总结，这也是一个挺不错的编辑工具，无论是编辑博客还是编辑代码。 走出校园走上工作之后，经常会想重拾博客这条曾经还没走多远就放弃了的路。虽然现在博客的时代已经过去，就连微博的光芒也已暗淡，朋友圈看似已经占领了碎片化阅读的整个世界。不过对于搞IT技术的人而言，技术博客仍然是我们平时学习的重要一环。也很想将自己这些年来学习到的知识通过博客的形式分享给大家，只是这几年来从大学到腾讯到百度到微软，经历过很多产品和技术，零零碎碎的东西收集了一大堆，却一直没有好的机会拾掇拾掇，用更简洁的直观的方式展示给大家。分享的过程，也是总结和复习的过程。无论是工作还是生活，走得更远，有时也会更加迷茫。偶尔停下匆忙的脚步，回想和记录下自己曾经经历过的一切，提醒自己真正想要追寻的一切。 因此，这段时间也一直在摸索如何在自己的精力范围内搭建自己的博客。最终还是选择用Hexo再加上NexT这样的简洁主题，Markdown肯定是工程师的不二选择，没有哪个工程师会愿意深陷在类似word这种富文本编辑的泥坑中：“为什么第二段的行间间距比第一段大？”，“如何让列表重新从1开始编号？”……Hexo的优势之一是可以用Atom等编辑器来编辑和管理文章，然后直接用Hexo就可以发布到GitHub Pages等可以托管静态web内容的地方，也可以绑定一级域名。但是Hexo还是有很多的细节耗费了不少的精力，例如访问计数、评论系统等，尤其是最近多说评论关闭，不得不让我担忧，即使使用其它的免费评论系统，最终哪天也不得不面对系统关闭的命运，到时备份和导出评论的工作可能会坑爹。最终还是决定暂时不开放评论，等到博客有一定人气的时候再考虑这个问题，现在评论系统对于我而言只是一个伪需求。 之所以没有采用WordPress，主要是因为对于我们工程师而言，WP的一大缺点可能就是Markdown的显示效果实在是不咋地，各种调整后还是不甚满意。而且由于我可能会时常修改已经发布的文章，例如纠错，或者补充内容等，所以还是希望能用Atom等编辑器管理文章内容（用vim也行啊哈哈），而不是用WP的web编辑框，然后用一个脚本批量更新发布。我也正在开发一个通过直接管理WP的数据库来发布和更新文章的脚本，这样以后就能像Hexo批量发布一样批量更新WP的文章列表了。WP的数据库结构不是很复杂，如果只是要批量更新文章的话，脚本逻辑应该还比较简单，到时候我也会开源道GitHub上供大家参考。 之前有写过一些相关的系列文章，如LeetCode刷题题解等，除了在本博客上再发布一次之外，我还会用GitBook单独发布出来。GitBook有点类似Hexo，但文章是以类似电子书而不是博客的形式进行组织，方便查找和阅读整个系列主题，而不是去一堆文章中遍历。但是GitBook刚面世也不久，bug不少feature不多，很多功能都不齐全，plugins也缺胳膊断腿很多都长期不更新或者不兼容了。后续我可能也会写一篇关于GitBook使用上的文章来说明我在使用中遇到的一些问题和解决的方法。 OK，说干就干，一颗博客界的新星冉冉升起！"},{"title":"分类","date":"2014-12-22T20:39:04.000Z","updated":"2019-12-16T05:24:12.000Z","comments":true,"path":"categories/index.html","permalink":"https://xnerv.wang/categories/index.html","excerpt":"","text":""},{"title":"schedule","date":"2019-11-18T06:28:31.000Z","updated":"2019-11-18T06:33:06.000Z","comments":true,"path":"schedule/index.html","permalink":"https://xnerv.wang/schedule/index.html","excerpt":"","text":""},{"title":"标签","date":"2015-10-01T19:39:04.000Z","updated":"2019-12-16T05:24:44.000Z","comments":true,"path":"tags/index.html","permalink":"https://xnerv.wang/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"用VSCode代替Atom作为Markdown编辑器","slug":"use-vscode-instead-of-atom-as-markdown","date":"2020-06-01T05:06:00.000Z","updated":"2025-03-10T01:04:55.823Z","comments":true,"path":"use-vscode-instead-of-atom-as-markdown/","link":"","permalink":"https://xnerv.wang/use-vscode-instead-of-atom-as-markdown/","excerpt":"从大学开始我就有做编程笔记的习惯。最开始是写在txt文件中直接放本地硬盘，也因此由于不小心格式化硬盘而丢了一些原始的笔记。后来在云笔记开始兴起之后，使用过几年的为知笔记。再加上为知笔记有直接保存网页的插件，因此我也将浏览器收藏夹中收集的一些技术网页直接保存到了为知笔记中，避免了网页失效而造成的知识丢失（其实现在的技术博客会被套娃式地转载好多次，就算删除原始文章也基本能找到了。。。）。随着积累的没看过的网页越来越多，消耗的速度完全跟不上增长的速度，也慢慢开始总结和消化收集的网页上的知识，记录下要点并标注来源URL，因此开始转向了Markdown。我喜欢上Markdown的另一个原因是我有点很多码农都有的编程洁癖，对于富文本总是想调整好每一处的格式、颜色和字体，因此支持富文本的Word、网络云笔记啥的简直就是我的噩梦，而Markdown则拯救了我这样的强迫症。 几年前，为了找了一款可以在Windows平台上运行的满意的Markdown编辑器，我曾经试用和对比了能找到的几款Markdown编辑器。","text":"从大学开始我就有做编程笔记的习惯。最开始是写在txt文件中直接放本地硬盘，也因此由于不小心格式化硬盘而丢了一些原始的笔记。后来在云笔记开始兴起之后，使用过几年的为知笔记。再加上为知笔记有直接保存网页的插件，因此我也将浏览器收藏夹中收集的一些技术网页直接保存到了为知笔记中，避免了网页失效而造成的知识丢失（其实现在的技术博客会被套娃式地转载好多次，就算删除原始文章也基本能找到了。。。）。随着积累的没看过的网页越来越多，消耗的速度完全跟不上增长的速度，也慢慢开始总结和消化收集的网页上的知识，记录下要点并标注来源URL，因此开始转向了Markdown。我喜欢上Markdown的另一个原因是我有点很多码农都有的编程洁癖，对于富文本总是想调整好每一处的格式、颜色和字体，因此支持富文本的Word、网络云笔记啥的简直就是我的噩梦，而Markdown则拯救了我这样的强迫症。 几年前，为了找了一款可以在Windows平台上运行的满意的Markdown编辑器，我曾经试用和对比了能找到的几款Markdown编辑器。 作业部落的Cmd Markdown是当时我接触的完成度最高的Markdown编辑器，插入图片非常方便，各种辅助功能都已经事先做好，不需要自己去做一大堆的配置和安装插件，并且最大的特点是笔记会云同步备份在服务器上。我用过一段时间的Cmd Markdown，但最终还是迁走了。最大的原因是笔记是保存在编辑器的数据文件中，而不是以明文的md文件直接保存在本地。这让我有点不安，哪一天如果这个编辑器出了bug打不开程序，或者这编辑器背后的公司破产，我的数据可能就此付之一炬，而我没有任何办法导出我的文件。 马克飞翔是印象笔记Evernote的一个Markdown插件。我对马克飞翔的印象是UI做得很好，各种功能也很齐全。然而缺点跟Cmd Markdown是一样的，由于印象笔记的文件也是保存在数据文件中的，无法通过其它文本工具直接编辑。而我更希望将文件直接放在我的硬盘里，可以通过各种文本工具进行编辑。 我还用过一个叫做Typora的比较有特色的的Markdown编辑器。大多数的Markdown编辑器是将界面一分为二，左边写Markdown源码，右边是最终效果Preview，当然一般左边的编辑栏也会有一些基本的语法高亮。但Typora则是将两个界面整合在了一起，同时可以在源码视图和结果视图中进行切换。老实说这样的做法有利有弊，纯粹看个人喜好。Typora至今应该仍不支持File Tree，也就是说一次只能编辑一个文档，如果要同时编辑多个Markdown文档就需要同时打开多个Typora进程。我至今仍保留安装着Typora，并希望将来有机会能拿出来用用，虽然至今我仍未再次用过。 再后来，我开始使用github开源的Atom编辑器。有一个叫做Markdown Preview Enhanced的Atom插件，将一些常用的Markdown功能都整合到了一起，我非常喜欢这个插件。Atom应该是我使用时间最长且至今最为满意的Markdown编辑器了，配合各种Atom插件非常顺手，各种Markdown效果也基本满足我的需求。然后我再用Seafile搭建了个人云存储，将Markdown文件放在个人云盘里。 不知道是不是由于微软收购了github和微软大力推广VSCode的缘故，感觉Atom最近几年的更新已经很少了，而且经常会出现插件加载失败的问题。例如Atom官网论坛上的18年的帖子Is atom dead?和19年的帖子Is atom dead, again?都在讨论这个问题，相信不只是我的个人猜测。 而最后让我下定决心离开Atom的则是Markdown Preview Enhanced not working in Atom 1.47.0 #1380。我最爱的Markdown Preview Enhanced由于Atom的bug而彻底不能使用，但目前看来Atom方面的修复还遥遥无期。 很久以前我曾尝试过用VSCode写Markdown。当时Markdown Preview Enhanced还不支持VSCode，因此我在整合了一堆Markdown的插件后仍觉得效果不佳，因此放弃。不知道是不是Markdown Preview Enhanced的作者也察觉到了Atom正在走向死亡，因此也开始支持VSCode平台。在试用了最新的VSCode + Markdown Preview Enhanced后，我发现原本在Atom上常用的功能，在VSCode上都能找到，例如： Atom上可以用Tree View浏览目录结构，而VSCode自带File Explorer左侧边栏。 Atom上有Project Manager插件可以在左侧边栏上同时打开多个目录，这样我就可以将多个Markdown目录同时加入进来。而VSCode也支持Workspace的概念，可以将多个目录加入进来。 VSCode有和Atom类似的file-icons插件，可以在左侧边栏上针对不同类型的文件显示不同的icon便于区分。 VSCode自带minimap/autosave功能，而Atom上则是通过安装插件实现。 VSCode可以登录微软账号或github账号同步插件和配置。Atom则是通过安装插件实现，配置保存在指定Gist。但根据我使用了几年的体验，如果有多台电脑同步配置的情况下，经常会出现一些问题，因此我从去年开始屏蔽了Atom上的同步插件。 但遗憾的是，像Cmd Markdown等编辑器所支持的TOC大纲（就是有一个单独的窗口或者下拉菜单显示各级标题，类似Word的左侧边栏的大纲视图），在VSCode和Atom中都没有相应的插件可以支持，而只是可以在文章中插入TOC链接。我所希望的是有一个插件可以在VSCode的左侧边栏上可以显示TOC大纲，但目前暂未发现有这样的插件。 2023/08/20 刚发现不知什么时候开始VSCode已经原生支持显示TOC大纲了。效果如图： 本文地址：https://xnerv.wang/use-vscode-instead-of-atom-as-markdown/","categories":[{"name":"程序员生活","slug":"程序员生活","permalink":"https://xnerv.wang/categories/%E7%A8%8B%E5%BA%8F%E5%91%98%E7%94%9F%E6%B4%BB/"}],"tags":[{"name":"程序员生活","slug":"程序员生活","permalink":"https://xnerv.wang/tags/%E7%A8%8B%E5%BA%8F%E5%91%98%E7%94%9F%E6%B4%BB/"},{"name":"VSCode","slug":"VSCode","permalink":"https://xnerv.wang/tags/VSCode/"},{"name":"Atom","slug":"Atom","permalink":"https://xnerv.wang/tags/Atom/"},{"name":"Markdown","slug":"Markdown","permalink":"https://xnerv.wang/tags/Markdown/"}]},{"title":"关于Linux X-Window的一些名词深究","slug":"linux-xwindow-investigation","date":"2020-05-06T06:25:00.000Z","updated":"2025-03-10T01:04:55.814Z","comments":true,"path":"linux-xwindow-investigation/","link":"","permalink":"https://xnerv.wang/linux-xwindow-investigation/","excerpt":"一直以来对X-Window、Xrdp、KDE、VNC等词半懂不懂，因此大致地调查了下。这篇文章包括了一些我自己的总结，因此可能有一些地方有不准确之处，敬请谅解。参考了http://cn.linux.vbird.org/linux_basic/0590xwindow_1.php。 X-Window/X Protocol：在XWindow 简介中有比较好的解释，这其实是一套图形接口（协议）。不同于Windows已经将图形接口与操作系统完全融为一体的做法，Linux的图形接口是可选的。而X-Window就是这样的一种图形接口。这个图形接口是属于CS架构的（client/server）。X Server负责画面的绘制和显示，以及接收用户的输入并传到给X Client。X Client负责处理传递过来的用户输入并决定呈现数据，然后由X Server来进行绘制。这与通常的对于CS架构的理解是相反的，与用户直接沟通的其实是X Server。 X-Window是一种协议，因此还需要具体的实现，例如Xfree86、Xorg，Xming和Xnest。 X11R6：X Protocol version 11 Release 6（X协议第11版第六次发行）。","text":"一直以来对X-Window、Xrdp、KDE、VNC等词半懂不懂，因此大致地调查了下。这篇文章包括了一些我自己的总结，因此可能有一些地方有不准确之处，敬请谅解。参考了http://cn.linux.vbird.org/linux_basic/0590xwindow_1.php。 X-Window/X Protocol：在XWindow 简介中有比较好的解释，这其实是一套图形接口（协议）。不同于Windows已经将图形接口与操作系统完全融为一体的做法，Linux的图形接口是可选的。而X-Window就是这样的一种图形接口。这个图形接口是属于CS架构的（client/server）。X Server负责画面的绘制和显示，以及接收用户的输入并传到给X Client。X Client负责处理传递过来的用户输入并决定呈现数据，然后由X Server来进行绘制。这与通常的对于CS架构的理解是相反的，与用户直接沟通的其实是X Server。 X-Window是一种协议，因此还需要具体的实现，例如Xfree86、Xorg，Xming和Xnest。 X11R6：X Protocol version 11 Release 6（X协议第11版第六次发行）。 Window Manager（WM）：个人看法，每一个窗口程序可能就对应一个（或多个？）X Client，而WM就是管理这些窗口移动、窗口大小和重叠显示的管理程序，常见的WM有GNOME、KDE、XFCE。 远程桌面：当你从另一台电脑上（主要是Windows）上想要通过图形化界面操作远程Linux时需要用到。常见的图形化远程桌面连接协议是RDP和VNC。Windows远程桌面用的就是RDP。RDP和VNC的区别可以参考VNC与RDP的区别。VNC主要传图像，适用于瘦客户端。RDP主要传指令，适用于低速网络。此外微软还有一项针对RDP的增强技术RemoteFX。 常见的VNC服务器软件有vnc4server、TightVNC，RealVNC等。 常见的VNC客户端有RealVNC Viewer、Ultra VNC等。 而如果你想用Windows自带的远程桌面连接Linux机器时，就必须用RDP协议了。需要在Linux上装兼容RDP的服务器，例如Xrdp。Xrdp使用Xvnc，X11rdp或xorgxrdp作为后端（XRDP与VNC的关系）。如果在Windows Hyper-V中安装Ubuntu等，在登录的时候就需要从几个选项中选择一个后端。根据What is x11rdp?和Xvnc中所提到的，X11rdp和Xvnc都属于X Server，用于显示“虚拟屏幕”，而不是物理屏幕。而Xorg中证实了Xorg是X-Window的一种实现，那感觉Xorg和Xvnc等并不是同一个层面上的概念，Xorg包括了X Server和X Client，而Xvnc只是X Server的一种实现。同时Xvnc对于用户而言又是VNC Server。 本文地址：https://xnerv.wang/linux-xwindow-investigation/","categories":[{"name":"Linux","slug":"Linux","permalink":"https://xnerv.wang/categories/Linux/"}],"tags":[{"name":"原创","slug":"原创","permalink":"https://xnerv.wang/tags/%E5%8E%9F%E5%88%9B/"},{"name":"Linux","slug":"Linux","permalink":"https://xnerv.wang/tags/Linux/"},{"name":"图形界面","slug":"图形界面","permalink":"https://xnerv.wang/tags/%E5%9B%BE%E5%BD%A2%E7%95%8C%E9%9D%A2/"},{"name":"X-Window","slug":"X-Window","permalink":"https://xnerv.wang/tags/X-Window/"},{"name":"X协议","slug":"X协议","permalink":"https://xnerv.wang/tags/X%E5%8D%8F%E8%AE%AE/"},{"name":"远程桌面","slug":"远程桌面","permalink":"https://xnerv.wang/tags/%E8%BF%9C%E7%A8%8B%E6%A1%8C%E9%9D%A2/"}]},{"title":"在美国第一次购买和使用树莓派时遇到的一些问题","slug":"the-first-time-to-buy-and-use-raspberry-in-usa","date":"2020-04-29T00:43:00.000Z","updated":"2025-03-10T01:04:55.822Z","comments":true,"path":"the-first-time-to-buy-and-use-raspberry-in-usa/","link":"","permalink":"https://xnerv.wang/the-first-time-to-buy-and-use-raspberry-in-usa/","excerpt":"新买了一个Raspberry Pi 4 Model B，第一次使用树莓派，遇到一些问题，记录下来希望对自己和他人所有帮助。 买什么套装 虽然在我买的时候2GB款的树莓派4B税前价格是35刀，但是亚马逊上是不直接卖板子的，一些要捆绑一些配件像Micro SD卡、电源、散热片、Micro HDMI线啥的。众所周知美国这边的各种线卖的巨贵无比，国内淘宝9块9包邮的线，在这边可能就是20刀不包税。而像CanaKit等可以直接卖板子的网站，则一般需要6到7刀左右的邮费。最后我还是在亚马逊上买了一个包括电源和三块散热片的套装，税前45刀左右。 树莓派4B的电源线是5V3A Type-C接口，我看了一下现在手机的充电线大多是5V2A这个样子，据说只要别接太多额外负载，手机充电线也是可以的。散热片不确定是否是必须的，我在不接散热片的情况下尽跑翻墙代理程序的时候在45摄氏度左右，但西雅图这边气温比较低，夏天最高温度也就32到34摄氏度左右。如果是在国内温度比较高的地区，建议还是贴散热片比较保险。 盒子的话淘宝20块就能买个很好的了，美国这边差不多20刀不包税。估计盒子会对散热造成一定负面影响，因此还是建议至少贴散热片。另外我一直在找有没有能装下一个2.5英寸或者3.5英寸硬盘的树莓派盒子，但是淘宝和亚马逊上都没有找到，移动硬盘只能单独放盒子外面，通过USB和树莓派连接在一起了。 如果是把树莓派作为翻墙代理等服务器用途的话，Micro HDMI不是必须的，我下面会讲到怎么远程初始化树莓派。","text":"新买了一个Raspberry Pi 4 Model B，第一次使用树莓派，遇到一些问题，记录下来希望对自己和他人所有帮助。 买什么套装 虽然在我买的时候2GB款的树莓派4B税前价格是35刀，但是亚马逊上是不直接卖板子的，一些要捆绑一些配件像Micro SD卡、电源、散热片、Micro HDMI线啥的。众所周知美国这边的各种线卖的巨贵无比，国内淘宝9块9包邮的线，在这边可能就是20刀不包税。而像CanaKit等可以直接卖板子的网站，则一般需要6到7刀左右的邮费。最后我还是在亚马逊上买了一个包括电源和三块散热片的套装，税前45刀左右。 树莓派4B的电源线是5V3A Type-C接口，我看了一下现在手机的充电线大多是5V2A这个样子，据说只要别接太多额外负载，手机充电线也是可以的。散热片不确定是否是必须的，我在不接散热片的情况下尽跑翻墙代理程序的时候在45摄氏度左右，但西雅图这边气温比较低，夏天最高温度也就32到34摄氏度左右。如果是在国内温度比较高的地区，建议还是贴散热片比较保险。 盒子的话淘宝20块就能买个很好的了，美国这边差不多20刀不包税。估计盒子会对散热造成一定负面影响，因此还是建议至少贴散热片。另外我一直在找有没有能装下一个2.5英寸或者3.5英寸硬盘的树莓派盒子，但是淘宝和亚马逊上都没有找到，移动硬盘只能单独放盒子外面，通过USB和树莓派连接在一起了。 如果是把树莓派作为翻墙代理等服务器用途的话，Micro HDMI不是必须的，我下面会讲到怎么远程初始化树莓派。 没有Micro HDMI线 第一次知道有Micro HDMI接口，所以很显然我没有这种线。电脑大多使用的都是普通大小的HDMI线。在美国买线相当划不来，一个这样的线得一、二十刀。所以我通过网线将树莓派接在路由器上，然后通过远程SSH的方式连接到树莓派上进行配置。 但是需要注意的是，虽然安装树莓派系统有两种方式（如何给树莓派安装操作系统）： 方式一：将NOOBS写入Micro SD卡 方式二：直接将操作系统镜像写入Micro SD卡 但方式一应该是需要将树莓派连接显示器才能操作安装程序的，所以我用的第二种方式，直接将操作系统Raspbian镜像写入Micro SD卡。树莓派上有一个Micro SD卡读卡器，需要将安装了Raspbian的Micro SD卡插入这里。 此外，树莓派4B的SSH默认是关闭的，在写入镜像完成后，还需要通过电脑在Micro SD里创建一个文件名为SSH的空文件。然后将Micro SD卡插入树莓派卡槽，通电后SSH Server才会启动，这样才能通过SSH Client连接上去。 然后问题来了，SSH连接的时候如何得知树莓派的IP？如果是自己家，你有路由器的管理密码的话，登录进去找找看所有连接上来的设备，看有没有类似Raspberry名字的设备连接上来。如果没有路由器的管理密码或者想偷懒的话，可以参考如何这没有显示器的情况下获取树莓派IP？这篇文章，或者用ipscan等局域网内IP扫描工具直接扫描所有IP。 启用WIFI 按照从网上找到的一些教程（例如树莓派4B，3B+和3B，如何配置WiFi和蓝牙），我在执行sudo iwlist wlan0 scan的时候遇到了类似interface doesnt support scanning的错误信息。在执行sudo ifconfig wlan0 up的时候，则遇到了SIOCSIFFLAGS: Operation not possible due to RF-kill的错误信息。据查rfkill是管理WIFI和蓝牙功能的一个软开关，跟控制耗电相关。根据SIOCSIFFLAGS: Operation not possible due to RF-kill关闭了相关的设置后解决问题。 通过蓝牙SSH 参考了一下文章但目前暂时未能解决这个问题，主要的问题是我的笔记本检测不到树莓派的蓝牙信号，虽然我的手机能够检测到树莓派的蓝牙。通过蓝牙SSH并不是刚需，等以后如果我能解决这个问题的时候再补完这一部分。 本文地址：https://xnerv.wang/the-first-time-to-buy-and-use-raspberry-in-usa/","categories":[{"name":"树莓派","slug":"树莓派","permalink":"https://xnerv.wang/categories/%E6%A0%91%E8%8E%93%E6%B4%BE/"}],"tags":[{"name":"原创","slug":"原创","permalink":"https://xnerv.wang/tags/%E5%8E%9F%E5%88%9B/"},{"name":"树莓派","slug":"树莓派","permalink":"https://xnerv.wang/tags/%E6%A0%91%E8%8E%93%E6%B4%BE/"},{"name":"Raspberry","slug":"Raspberry","permalink":"https://xnerv.wang/tags/Raspberry/"}]},{"title":"为什么PostgreSQL要使用OS缓存？","slug":"why-pg-uses-os-cache","date":"2020-01-02T02:47:00.000Z","updated":"2025-03-10T01:04:55.812Z","comments":true,"path":"why-pg-uses-os-cache/","link":"","permalink":"https://xnerv.wang/why-pg-uses-os-cache/","excerpt":"与MySQL等开源数据库不同的是，PostgreSQL（PG）并不使用O_DIRECT来写data文件，而是依赖于OS缓存，并且强调在设置shared buffer在大小时不能过大，否则会造成过于频繁的swap而导致IO性能下降。这与MySQL等数据库的buffer pool size越大性能越好的指导原则是相反的。并且PG依赖于OS缓存的这一特性也给提供PostgreSQL云服务造成了很多问题。例如云服务要求multiple tenants资源隔离，也就是说跑在同一个VM上的多个PG servers相互之间不能互相影响，但共用OS缓存显然会造成资源竞争。不知道Docker是否可以进行OS缓存的资源隔离，但现阶段还还依赖于Service Fabric架构的Azure PG显然得自己解决这个问题，也因此造成了架构设计上不得不考虑OS缓存的隔离。 从The Internals of PostgreSQL: Chapter 2 Process and Memory Architecture这篇文章看来，与MySQL使用多线程或线程池和架构不同的是，PG使用的是多进程架构。多进程模型在Windows平台上会造成很大的性能问题，这暂且不提。但多进程之间是共用的shared buffer。既然如此，那就应该不是寄希望于OS缓存来便于多进程之间共享shared buffer吧。","text":"与MySQL等开源数据库不同的是，PostgreSQL（PG）并不使用O_DIRECT来写data文件，而是依赖于OS缓存，并且强调在设置shared buffer在大小时不能过大，否则会造成过于频繁的swap而导致IO性能下降。这与MySQL等数据库的buffer pool size越大性能越好的指导原则是相反的。并且PG依赖于OS缓存的这一特性也给提供PostgreSQL云服务造成了很多问题。例如云服务要求multiple tenants资源隔离，也就是说跑在同一个VM上的多个PG servers相互之间不能互相影响，但共用OS缓存显然会造成资源竞争。不知道Docker是否可以进行OS缓存的资源隔离，但现阶段还还依赖于Service Fabric架构的Azure PG显然得自己解决这个问题，也因此造成了架构设计上不得不考虑OS缓存的隔离。 从The Internals of PostgreSQL: Chapter 2 Process and Memory Architecture这篇文章看来，与MySQL使用多线程或线程池和架构不同的是，PG使用的是多进程架构。多进程模型在Windows平台上会造成很大的性能问题，这暂且不提。但多进程之间是共用的shared buffer。既然如此，那就应该不是寄希望于OS缓存来便于多进程之间共享shared buffer吧。 PgSQL和MySQL的bufferpool探讨这篇文章提出了一种猜想，认为由于PostgreSQL是诞生在实验室中，主要为了研究数据库内核原理，那么使用buffer io能够减少IO栈的代码开发，进而能够减少额外的debug。这种说法是有可能的、虽然PG的代码比MySQL的干净太多，MySQL的代码中经常有类似xxx_function，xxx_function2，another_xxx_function2这种奇怪的函数名字，而且毫无注释完全不明所以。但是PG很明显在工程化和成熟度上不如MySQL。文章中提到PG中有这么一段代码： 也就是说PG依赖于OS缓存来减少日志归档和流复制中的文件IO读取次数。但这应该仅限于WAL xlog文件。对于shared buffer pool，是什么原因使得还需要保留这种double buffering的设计呢？ The Internals of PostgreSQL: Chapter 8 Buffer Manager提到可以参考Why we are going to have to go DirectIO这篇讨论和Thread summary: the Linux kernel and PostgreSQL这篇文章。目前看来，应该还是PG的storage layer实现上过于简陋，效率上存在很大的问题，不足以脱离OS缓存而独自运行。这也印证了PgSQL和MySQL的bufferpool探讨这篇文章的说法。Understanding caching in Postgres - An in-depth guide这里也提到，PG依赖于OS缓存来调度写请求，这恐怕也是PG storage layer本身缺乏相应调度机制的一种表现。 PostgreSQL pain points中也有提到flow fsync和double buffering等问题，看起来PG的developers依赖于Linux kernel提供相应的解决方案。我不知道这是否是一种正确的方向，毕竟这种与特定OS紧耦合的方案也就限制了PG在其它OS平台上运行的能力。但是考虑到现在PG本来就在Windows上跑得很差像个demo，如果PG本身的开发力量不够的话，也许这也算是一种解决方案吧。 本文地址：https://xnerv.wang/why-pg-uses-os-cache/","categories":[{"name":"DBMS","slug":"DBMS","permalink":"https://xnerv.wang/categories/DBMS/"}],"tags":[{"name":"原创","slug":"原创","permalink":"https://xnerv.wang/tags/%E5%8E%9F%E5%88%9B/"},{"name":"DBMS","slug":"DBMS","permalink":"https://xnerv.wang/tags/DBMS/"},{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"https://xnerv.wang/tags/PostgreSQL/"},{"name":"PG","slug":"PG","permalink":"https://xnerv.wang/tags/PG/"}]},{"title":"为什么Docker能运行不同的Linux发行版？","slug":"why-docker-has-ability-to-run-different-linux-distribution","date":"2019-12-26T07:58:00.000Z","updated":"2025-03-10T01:04:55.814Z","comments":true,"path":"why-docker-has-ability-to-run-different-linux-distribution/","link":"","permalink":"https://xnerv.wang/why-docker-has-ability-to-run-different-linux-distribution/","excerpt":"","text":"结合What is the relationship between the docker host OS and the container base image OS?、How can Docker run distros with different kernels?和[Why docker has ability to run different linux distribution?(https://stackoverflow.com/questions/25444099/why-docker-has-ability-to-run-different-linux-distribution)这几篇文章看来，Docker实例和Host OS之间通讯的唯一桥梁就是Host OS的内核。挡在Fedora上跑一个Ubuntu 16.04的Docker实例时，Docker实例用的内核仍然是Fedora的内核，而不是Ubuntu 16.04所对应的的内核，因此有可能和原生的Ubuntu 16.04有一些内核上的区别。 本文地址：https://xnerv.wang/why-docker-has-ability-to-run-different-linux-distribution/","categories":[{"name":"Linux","slug":"Linux","permalink":"https://xnerv.wang/categories/Linux/"}],"tags":[{"name":"原创","slug":"原创","permalink":"https://xnerv.wang/tags/%E5%8E%9F%E5%88%9B/"},{"name":"Linux","slug":"Linux","permalink":"https://xnerv.wang/tags/Linux/"},{"name":"Docker","slug":"Docker","permalink":"https://xnerv.wang/tags/Docker/"}]},{"title":"关于MinGW和Cygwin的一些个人总结和推测","slug":"mingw-cygwin-summary-and-thinking","date":"2019-12-25T23:40:00.000Z","updated":"2025-03-10T01:04:55.826Z","comments":true,"path":"mingw-cygwin-summary-and-thinking/","link":"","permalink":"https://xnerv.wang/mingw-cygwin-summary-and-thinking/","excerpt":"本文主要是对MinGW和Cygwin相关的一些名词的研究和推测，以求澄清一些似乎而非的概念，并记录当前已经弄清楚的一些问题，以及还需要进一步调研的一些细节。所有调研都基于Windows平台。 关于MinGW和Cygwin的关系 网上大部分博文复制粘贴的文章都是讨论MinGW和Cygwin的区别和优劣。而我主要是分析两者的联系，以及一些需要同时用到MinGW和Cygwin的交叉编译场景。 从MinGW的维基百科上看，Cygwin是提供一个模拟的POSIX层（cygwin1.dll）。我推测Cygwin也提供了一系列基于Cygwin的编译工具，在将需要移植的Linux代码在Cygwin上重新编译后，可以获得可以在Windows上直接运行的exe，而这个exe调用的还是POSIX风格的API，只不过这些API由cygwin1.dll提供模拟实现。而MinGW也提供了一系列编译工具，但MinGW-GCC是在编译时将代码中的POSIX API调用直接修改为对应的Windows API调用，从而不需要一个额外的dll转换层。需要额外提到的是，gcc的这种在编译时直接修改调用的API的行为不仅不少见，而且非常常见，在64位Linux上编译C++程序时，例如调用open这个函数，实际上在gcc编译后，调用的是libc中的open64函数，这个可以通过objdump导出外部依赖符号表来确认。另外就是，MinGW并不提供某些难以用Windows API实现的POSIX API，例如fork()，mmap()和ioctl()。","text":"本文主要是对MinGW和Cygwin相关的一些名词的研究和推测，以求澄清一些似乎而非的概念，并记录当前已经弄清楚的一些问题，以及还需要进一步调研的一些细节。所有调研都基于Windows平台。 关于MinGW和Cygwin的关系 网上大部分博文复制粘贴的文章都是讨论MinGW和Cygwin的区别和优劣。而我主要是分析两者的联系，以及一些需要同时用到MinGW和Cygwin的交叉编译场景。 从MinGW的维基百科上看，Cygwin是提供一个模拟的POSIX层（cygwin1.dll）。我推测Cygwin也提供了一系列基于Cygwin的编译工具，在将需要移植的Linux代码在Cygwin上重新编译后，可以获得可以在Windows上直接运行的exe，而这个exe调用的还是POSIX风格的API，只不过这些API由cygwin1.dll提供模拟实现。而MinGW也提供了一系列编译工具，但MinGW-GCC是在编译时将代码中的POSIX API调用直接修改为对应的Windows API调用，从而不需要一个额外的dll转换层。需要额外提到的是，gcc的这种在编译时直接修改调用的API的行为不仅不少见，而且非常常见，在64位Linux上编译C++程序时，例如调用open这个函数，实际上在gcc编译后，调用的是libc中的open64函数，这个可以通过objdump导出外部依赖符号表来确认。另外就是，MinGW并不提供某些难以用Windows API实现的POSIX API，例如fork()，mmap()和ioctl()。 MinGW和MinGW-w64 MinGW（mingw32）据说更新太慢代码太老，因此另一帮人就新搞了一个MinGW-w64，据说老的MinGW不支持编译64位程序。不知道是不是这就意味着可以完全放弃掉MinGW而直接采用MinGW-x64？ 在安装MinGW时需要选择线程模型：posix或win32。从mingw-w64 threads: posix vs win32看来，win32是在C++11之前MinGW-GCC搞的一套基于win32 threads模型的多线程库，而posix则是基于libwinpthreads，支持C++11的一些新的头文件。有另外一个单独的GitHub项目mingw-std-threads可以让win32模型也支持这些C++11头文件。 MinGW-w64可以安装在Windows上，可以安装在Linux上，甚至可以安装在Cygwin里（而CygWin看起来只能安装在Windows中）。MinGW（mingw32）好像有另外一个相关项目MinGW cross compiling environment提供Linux安装，但感觉项目不是很活跃。并且从这篇更新日志来看，似乎作者已经放弃更新并转向MinGW-w64。 MSYS 根据MinGW官网对于MSYS的描述，MSYS是对MinGW的补充，提供了bash，make， gawk和grep等GNU工具来辅助编译。从网上可以找到的一些MinGW编译入门文章来看，完全可以在Windows cmd环境中调用MinGW的gcc命令行去编译基于MinGW的Windows程序，并不是一定需要在bash环境中进行，但是像bash脚本这种应该还是需要bash环境的。另外据说MSYS是从Cygwin派生出来的分支，本来我推测像MSYS中的gcc应该是运行在cygwin1.dll或者类似名字的dll模拟层上。但是检查了gcc的dll依赖关系： 发现MinGW上的gcc最终似乎是直接依赖于Windows的dlls，并没有类似cygwin1.dll的东西。这种有点奇怪了，难道这个gcc是通过Cygwin上的MinGW-GCC用自举（bootstrapping）的方式创建出来的？找到关于MinGW-x64有关自举编译的一篇文章Creating a native Win64 compiler，我怀疑MinGW是不是也是用的类似的自举编译gcc。 但是再看bash的话，bash.exe却还是依赖于msys1.0.dll以及其它一些msys开头的dlls。猜测这些dlls应该就是类似于cygwin1.dll的模拟层。MinGW和MSYS是通过同一个安装程序来安装，推测由于gcc.exe属于MinGW，而bash.exe属于MSYS，而只有MSYS的工具才需要依赖msys相关的dlls。检查安装路径后果然发现，gcc.exe是在C:\\MinGW\\bin下面，而bash.exe是在C:\\MinGW\\msys\\1.0\\bin下面，印证了我的想法。 此外结合MinGW的中文维基百科和我自己的MinGW-w64安装经历，选择i686工具链时可以从DWARF和SJLJ这两种异常实现机制中二选一，而选择x86_64时需要从SEH和SJLJ中二选一。 MSYS2 回过头来再看看MSYS2。MSYS2似乎是配套MinGW-w64出现的，提供三种配置的模式：msys2，mingw64（使用mingw-w64 x86_64 toolchain工具链）和mingw32（使用mingw-w64 i686 toolchain工具链）。个人推测msys2模式编译出来的程序需要依赖msys2.0.dll，就像Cygwin下编译出来的程序一样。据说MSYS2相对于Cygwin的最大区别是移植了包管理工具Pacman。据说三种模式的主要区别是在$PATH中的搜索优先顺序不同，msys2只使用/usr/local/bin和/usr/bin下的工具，mingw64优先使用/mingw64/bin下的工具，mingw32优先使用/mingw32/bin下的工具。 类似于MinGW和MSYS，安装MSYS2的时候也会自动安装MinGW-w64。而且看起来在x64平台上是mingw64和mingw32会同时被安装。 我首先单独安装了MinGW-w64，看起来其中的gcc等工具也是直接依赖于Windows的dlls，并没有一个中间层dll。并且在安装的时候需要选择是用x86_64工具链还是i686工具链，以及异常的处理方式。这么看来安装MSYS2的话就可以同时拥有两种工具链了。安装MSYS2时并没有要求选择异常处理机制和所使用的线程库，根据What’s the difference between Mingw-builds and Mingw packages in Msys2这个帖子中的讨论，看起来 MSYS2 only provides posix thread model, dwarf for i686, seh for x86_64 使用Pacman直接安装的gcc依赖于msys2系列的dlls。我估计这就类似于在Cygwin上直接安装gcc，会依赖于cygwin1.dll。如果要安装只依赖于Windows native dlls的gcc，应该安装mingw版本的gcc。 安装mingw-w64-i686-toolchain和mingw-w64-x86_64-toolchain则分别会在mingw32\\bin和mingw64\\bin目录下产生gcc.exe，并且只依赖于Windows dlls和libwinpthread-1.dll，看来这个就是MinGW-w64版本的gcc，可以生成不依赖于任何dll的Windows程序。 本文地址：https://xnerv.wang/mingw-cygwin-summary-and-thinking/","categories":[{"name":"编译器","slug":"编译器","permalink":"https://xnerv.wang/categories/%E7%BC%96%E8%AF%91%E5%99%A8/"}],"tags":[{"name":"原创","slug":"原创","permalink":"https://xnerv.wang/tags/%E5%8E%9F%E5%88%9B/"},{"name":"MinGW","slug":"MinGW","permalink":"https://xnerv.wang/tags/MinGW/"},{"name":"编译器","slug":"编译器","permalink":"https://xnerv.wang/tags/%E7%BC%96%E8%AF%91%E5%99%A8/"},{"name":"Cygwin","slug":"Cygwin","permalink":"https://xnerv.wang/tags/Cygwin/"}]},{"title":"编译Windows版的Seafile客户端","slug":"compile-windows-seafile-client","date":"2019-12-23T20:20:00.000Z","updated":"2025-03-10T01:04:55.819Z","comments":true,"path":"compile-windows-seafile-client/","link":"","permalink":"https://xnerv.wang/compile-windows-seafile-client/","excerpt":"Seafile是国内少有的做的还不错的开源产品之一。相信很多朋友都经历过几年前的各大云盘厂商大战然后纷纷衰落的这个过程。金山快盘应该是我用过的个人觉得最好的一款云盘了，和Windows GUI的集成也非常完美。可惜现如今各大云盘不是停止运营了就是今非昔比了。因此与其每天提心吊胆地担心自己宝贵的“资源”是不是会被某度网盘封杀，作为码农的我们何不自己动手来搭建一个私有云盘。Seafile的UI是基于Qt，考虑到可移植性和跨平台兼容性，虽然不能像金山快盘那样拥有一些Windows上的特效，例如在托盘上查看当前在上传/下载哪些文件，以及上传/下载的进度。但优势是多平台，在Linux、安卓，iOS上都有相应的客户端。 Seafile官网只提供了Linux版本客户端的编译方法，并没有提供Windows版本的步骤。搜索了官方论坛，虽然有不少人提问问过，但是官方并没有给出回答。只能说国内的开源的文档还需要进一步完善，遮遮掩掩不算是真正的开源。搭建seafile windows客户端的交叉编译环境这篇文章给出了一种基于MinGW在Fedora上交叉编译Windows版本Seafile的方法。我曾尝试过在Ubuntu 18.04上重复这个步骤，但是因为一些packages的原因没能成功。不同的Linux发行版之间的package有一些区别。我也曾尝试过在Windows上的MinGW上交叉编译，但有一些packages死活找不到在Windows MinGW上对应的版本，而且编译时也有一些错误（Windows上的MinGW好像是跑在Cygwin上面的，也就是说Cygwin上的packages可能不全或者跟Fedora上有一些不同）。最终由于时间关系，我放弃了去弄清楚其中的原因，而是采用在Ubuntu上用docker安装Fedora镜像这种类似作弊的方法来重现这篇文章中的步骤。","text":"Seafile是国内少有的做的还不错的开源产品之一。相信很多朋友都经历过几年前的各大云盘厂商大战然后纷纷衰落的这个过程。金山快盘应该是我用过的个人觉得最好的一款云盘了，和Windows GUI的集成也非常完美。可惜现如今各大云盘不是停止运营了就是今非昔比了。因此与其每天提心吊胆地担心自己宝贵的“资源”是不是会被某度网盘封杀，作为码农的我们何不自己动手来搭建一个私有云盘。Seafile的UI是基于Qt，考虑到可移植性和跨平台兼容性，虽然不能像金山快盘那样拥有一些Windows上的特效，例如在托盘上查看当前在上传/下载哪些文件，以及上传/下载的进度。但优势是多平台，在Linux、安卓，iOS上都有相应的客户端。 Seafile官网只提供了Linux版本客户端的编译方法，并没有提供Windows版本的步骤。搜索了官方论坛，虽然有不少人提问问过，但是官方并没有给出回答。只能说国内的开源的文档还需要进一步完善，遮遮掩掩不算是真正的开源。搭建seafile windows客户端的交叉编译环境这篇文章给出了一种基于MinGW在Fedora上交叉编译Windows版本Seafile的方法。我曾尝试过在Ubuntu 18.04上重复这个步骤，但是因为一些packages的原因没能成功。不同的Linux发行版之间的package有一些区别。我也曾尝试过在Windows上的MinGW上交叉编译，但有一些packages死活找不到在Windows MinGW上对应的版本，而且编译时也有一些错误（Windows上的MinGW好像是跑在Cygwin上面的，也就是说Cygwin上的packages可能不全或者跟Fedora上有一些不同）。最终由于时间关系，我放弃了去弄清楚其中的原因，而是采用在Ubuntu上用docker安装Fedora镜像这种类似作弊的方法来重现这篇文章中的步骤。 基于搭建seafile windows客户端的交叉编译环境这篇文章，我写了一些脚本来自动化整个编译流程以及打包流程，这些脚本我都放到了GitHub上：xnervwang/SeafileClientBuildTools。脚本分成两种，一种是在Host环境（例如我的Ubuntu）上执行的，一种是在docker实例中执行的。先介绍一下各个脚本的作用： InitDockerVerification.sh：这个脚本是在Host环境中执行的。会根据Dockerfile创建相应的Fedora docker image，并且在当前的Host目录创建三个文件夹：build, ms-build, ms-build64，分别用于存放编译出来的Linux版本的Seafile客户端，32位Windows客户端，64位Windows客户端。build, ms-build, ms-build64这三个目录会通过docker volume映射到docker实例内，从而便于docker实例和Host共享目录。 Dockerfile：InitDockerVerification.sh在创建docker image时会使用该文件。这个Dockerfile指定docker镜像在创建时，会git clone我的git repo xnervwang/SeafileClientBuildTools，然后运行其中的InstallDevPackagesFedora.sh安装编译所需要的一些packages。然后基于该docker镜像创建的docker实例会自动执行DockerEntry.sh。 RunDockerVerification.sh：创建docker实例并启动。 DockerEntry.sh：这个脚本被docker实例在启动时执行，会先更新本地的git repo，然后执行OneKey.sh。OneKey.sh会编译Linux版本的Seafile客户端，32位Windows客户端，64位Windows客户端。然后调用ResolveDllDeps.py这个脚本分别对三种客户端进行打包，打包后的产物分别位于build, ms-build, ms-build64这三个目录内。 ResolveDllDeps.py：这是我写的一个比较有意思的脚本。可以自动递归分析binary所依赖的所有.so动态链接库文件，然后将这些.so文件都复制到打包目录中，从而便于发布。需要注意的是编译出来的Seafile客户端还依赖于qt5/plugins/imageformats和qt5/plugins/platforms这两个插件目录，但是我的这个脚本却无法从Seafile客户端的可执行文件推导出这样的依赖关系。我推测可能这两个插件目录中的插件是通过dlopen的方式动态加载的，因此不能通过静态分析获得依赖关系。所以我将这连个目录中的.so也加入到了第一级的binary列表中。 Makefile：这个是在docker实例中，在DockerEntry.sh执行编译时所使用的的Makefile。 Toolchain-cross-linux.i686.cmake/Toolchain-cross-linux.x86_64.cmake：MinGW编译工具所使用的配置文件，分别用于32位/64位Windows客户端。 DropDockerVerification.sh：删除docker实例和相关的生成目录。 因此，基本的使用方法就是，首先基于docker官方文档安装docker环境，然后git clone我的git repo，然后先执行InitDockerVerification.sh环境，然后以后就可以每次通过执行RunDockerVerification.sh来获取编译后的客户端，分别位于Host机器的build, ms-build, ms-build64这三个目录内。 本文地址：https://xnerv.wang/compile-windows-seafile-client/","categories":[{"name":"分布式及存储","slug":"分布式及存储","permalink":"https://xnerv.wang/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8F%8A%E5%AD%98%E5%82%A8/"}],"tags":[{"name":"原创","slug":"原创","permalink":"https://xnerv.wang/tags/%E5%8E%9F%E5%88%9B/"},{"name":"Windows","slug":"Windows","permalink":"https://xnerv.wang/tags/Windows/"},{"name":"分布式及存储","slug":"分布式及存储","permalink":"https://xnerv.wang/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8F%8A%E5%AD%98%E5%82%A8/"},{"name":"Seafile","slug":"Seafile","permalink":"https://xnerv.wang/tags/Seafile/"},{"name":"MinGW","slug":"MinGW","permalink":"https://xnerv.wang/tags/MinGW/"},{"name":"Docker","slug":"Docker","permalink":"https://xnerv.wang/tags/Docker/"}]},{"title":"TCP模型知识点总结","slug":"tcp-model-knowledge-summary","date":"2019-11-17T01:02:00.000Z","updated":"2025-03-10T01:04:55.826Z","comments":true,"path":"tcp-model-knowledge-summary/","link":"","permalink":"https://xnerv.wang/tcp-model-knowledge-summary/","excerpt":"协议格式 IPv4 IP首部中的校验和只覆盖IP的首部，不覆盖IP数据报中的任何数据。 IP层会丢弃传输中损坏的数据报，但是不产生错误消息，由上层去检测和重传。但是如果发生了分片，IP层应该能保证原子性。 在IP层下面的每一种数据链路层都有自己的帧格式，其中包括帧格式中的数据字段的最大长度，即最大传送单元 MTU (Maximum Transfer Unit)。当一个数据报封装成链路层的帧时，此数据报的总长度（即首部加上数据部分）最好不能超过下面的数据链路层的MTU值，否则要分片。 增加首部的可变部分是为了增加IP数据报的功能，但这同时也使得IP数据报的首部长度成为可变的。这就增加了每一个路由器处理数据报的开销，实际上这些选项很少被使用。新的IP版本IPv6就将IP数据报的首部长度做成固定的。 IP包中只有首部检验和，由TCP和UDP报文各自包含自身的数据校验和。","text":"协议格式 IPv4 IP首部中的校验和只覆盖IP的首部，不覆盖IP数据报中的任何数据。 IP层会丢弃传输中损坏的数据报，但是不产生错误消息，由上层去检测和重传。但是如果发生了分片，IP层应该能保证原子性。 在IP层下面的每一种数据链路层都有自己的帧格式，其中包括帧格式中的数据字段的最大长度，即最大传送单元 MTU (Maximum Transfer Unit)。当一个数据报封装成链路层的帧时，此数据报的总长度（即首部加上数据部分）最好不能超过下面的数据链路层的MTU值，否则要分片。 增加首部的可变部分是为了增加IP数据报的功能，但这同时也使得IP数据报的首部长度成为可变的。这就增加了每一个路由器处理数据报的开销，实际上这些选项很少被使用。新的IP版本IPv6就将IP数据报的首部长度做成固定的。 IP包中只有首部检验和，由TCP和UDP报文各自包含自身的数据校验和。 IPv6 IPv6的区别 首部长度 首部长度可变，IPv4首部的选项字段允许IP首部被扩展，由此导致数据报首部长度可变，故不能预先确定数据字段从何开始，同时也使路由器处理一个IP数据报所需时间差异很大(有的要处理选项，有的不需要)。基于此，IPv6采用固定40字节长度的报头长度(称基本报头)。IPv6如何实现IPv4选项字段类似的功能，答案是扩展报头，并由IPv6基本报头的下一个首部指向扩展报头(如果有的话)。路由器不处理扩展报头，提升了路由器处理效率。 分片/重组 IPv6，分片与重组只能在源与目的地上执行，不允许在中间路由器进行。分片与重组是个耗时的操作，将该功能从路由器转移到端系统，大大加快了网络中的IP转发速率。那，如果路由器收到IPv6数据报太大而不能转发到出链路上怎么办？该路由器丢弃该包，并向发送发发回一个&quot;分组太大&quot;的ICMP差错报文，于是发送发使用较小长度的IP数据报重发数据。 首部检查和 IPv4中由于TTL的递减，所以每经过一个路由器都需要重新计算校验和，导致路由器处理速度的低下。加之，传输层和链路层协议执行了检验操作，网络传输可靠性提升，所以IPv6不进行首部检查和，从而更快速处理IP分组。（但在网络传输的过程中，链路层packet是可能损坏的，考虑到厂商设备的多样性和高负载。所以TCP校验应该是关键，如果发现checksum不对，TCP可以要求对方重传丢失的内容。） TCP头 校验和是针对header和data计算出来的。TCP和UDP计算校验和时，都要加上一个12字节的伪首部。伪首部共有12字节，包含如下信息：源IP地址、目的IP地址、保留字节(置0)、传输层协议号(TCP是6)、TCP报文长度(报头+数据)。伪首部是为了增加TCP校验和的检错能力：如检查TCP报文是否收错了(目的IP地址)、传输层协议是否选对了(传输层协议号)等。 TCP和UDP的报文都没有一个字段可以表明自身长度，这个长度是由IP包中的总长度来记录的。 TCP报文段首部格式详解 TCP首部长度：由于TCP首部包含一个长度可变的选项部分，所以需要这么一个值来指定这个TCP报文段到底有多长。或者可以这么理解：就是表示TCP报文段中数据部分在整个TCP报文段中的位置。该字段的单位是32位字，即：4个字节。 选项部分：其最大长度可根据TCP首部长度进行推算。TCP首部长度用4位表示，那么选项部分最长为：(2^4-1)*4-20=40字节（但要全零填充为4字节的整数倍）。 选项部分的应用： MSS最大报文段长度(Maxium Segment Size)：指明数据字段的最大长度，数据字段的长度加上TCP首部的长度才等于整个TCP报文段的长度。MSS值指示自己期望对方发送TCP报文段时那个数据字段的长度。通信双方可以有不同的MSS值。如果未填写，默认采用536字节。MSS只出现在SYN报文中。即：MSS出现在SYN=1的报文段中。 窗口扩大选项(Windows Scaling)：由于TCP首部的窗口大小字段长度是16位，所以其表示的最大数是65535。但是随着时延和带宽比较大的通信产生（如卫星通信），需要更大的窗口来满足性能和吞吐率，所以产生了这个窗口扩大选项。 SACK选择确认项(Selective Acknowledgements)：用来确保只重传缺少的报文段，而不是重传所有报文段。比如主机A发送报文段1、2、3，而主机B仅收到报文段1、3。那么此时就需要使用SACK选项来告诉发送方只发送丢失的数据。那么又如何指明丢失了哪些报文段呢？使用SACK需要两个功能字节。一个表示要使用SACK选项，另一个指明这个选项占用多少字节。描述丢失的报文段2，是通过描述它的左右边界报文段1、3来完成的。而这个1、3实际上是表示序列号，所以描述一个丢失的报文段需要64位即8个字节的空间。那么可以推算整个选项字段最多描述(40-2)/8=4个丢失的报文段。 时间戳选项（Timestamps）：可以用来计算RTT(往返时间)，发送方发送TCP报文时，把当前的时间值放入时间戳字段，接收方收到后发送确认报文时，把这个时间戳字段的值复制到确认报文中，当发送方收到确认报文后即可计算出RTT。也可以用来防止回绕序号PAWS，也可以说可以用来区分相同序列号的不同报文。因为序列号用32为表示，每2^32个序列号就会产生回绕，那么使用时间戳字段就很容易区分相同序列号的不同报文。 NOP(NO-Operation)：它要求选项部分中的每种选项长度必须是4字节的倍数，不足的则用NOP填充。同时也可以用来分割不同的选项字段。如窗口扩大选项和SACK之间用NOP隔开。 UDP linux网络编程之：UDP数据包格式 UDP数据报格式有首部和数据两个部分。首部很简单，共8字节。包括： 源端口（Source Port）：2字节，源端口号。 目的端口（Destination Port ）：2字节，目的端口号。 长度（Length）：2字节，UDP用户数据报的总长度，以字节为单位。 检验和（Checksum）：2字节，用于校验UDP数据报的数字段和包含UDP数据报首部的“伪首部”。其校验方法同IP分组首部中的首部校验和。 伪首部，又称为伪包头（Pseudo Header）：是指在TCP的分段或UDP的数据报格式中，在数据报首部前面增加源IP地址、目的IP地址、IP分组的协议字段、TCP或UDP数据报的总长度等共12字节，所构成的扩展首部结构。此伪首部是一个临时的结构，它既不向上也不向下传递，仅仅只是为了保证可以校验套接字的正确性。 UDP的校验和是可选的，如果校验码为 0 ,意味着发送者末产生校验码。这表示对于数据段不使用校验,因为 IP 只是对 IP 首部进行校验。 RST 产生复位的一种常见情况是当连接请求到达时，目的端口没有进程正在监听。对于UDP，当一个数据报到达目的端口时，该端口没在使用，它将产生一个ICMP端口不可达的信息。而TCP则使用复位/重置连接。 RST报文段不会导致另一端产生任何响应，另一端根本不进行确认。收到RST的一方将终止该连接，并通知应用层连接复位。 带外数据SO_OOBINLINE 其实就是一个指针指向正常数据中的一个字节的后一个字节位置。 别用TCP的紧急数据提到带外数据已经不建议使用。同时提到带外数据可以用于控制意图，这样就不用像FTP一样得单独开一个控制连接了。 TCP的紧急指针，一般都不建议使用，而且不同的TCP/IP实现，也不同，一般说如果你有紧急数据宁愿再建立一个新的TCP/IP连接发送数据，让对方紧急处理。但是，虽然sendUrgentData的参数data是int类型，但只有这个int类型的低字节被发送，其它的三个字节被忽略。 接收端如何处理这个数据存在一些模糊。有的平台和API把它和平常数据分开处理，然后大多数解决方案是把它放到普通数据队列，让应用自己去从队列中获取处理。 一些TCP参数 tcp_max_syn_backlog Linux TCP队列相关参数的总结 建立连接涉及两个队列： 半连接队列，保存SYN_RECV状态的连接。队列长度由net.ipv4.tcp_max_syn_backlog设置。 accept队列，保存ESTABLISHED状态的连接。队列长度为min(net.core.somaxconn, backlog)。其中backlog是我们创建ServerSocket(intport, int backlog)时指定的参数，最终会传递给listen方法。 TCP SOCKET中backlog参数的用途是什么？ 在linux 2.2以前，backlog大小包括了半连接状态和全连接状态两种队列大小。linux 2.2以后，分离为两个backlog来分别限制半连接SYN_RCVD状态的未完成连接队列大小跟全连接ESTABLISHED状态的已完成连接队列大小。互联网上常见的TCP SYN FLOOD恶意DOS攻击方式就是用/proc/sys/net/ipv4/tcp_max_syn_backlog来控制的。 在使用listen函数时，内核会根据传入参数的backlog跟系统配置参数/proc/sys/net/core/somaxconn中，二者取最小值，作为“ESTABLISHED状态之后，完成TCP连接，等待服务程序ACCEPT”的队列大小。在kernel 2.4.25之前，是写死在代码常量SOMAXCONN，默认值是128。在kernel 2.4.25之后，在配置文件/proc/sys/net/core/somaxconn (即 /etc/sysctl.conf 之类 )中可以修改。 How TCP backlog works in Linux backlog为0 时在linux上表明允许不受限制的连接数，这是一个缺陷，因为它可能会导致SYN Flooding(拒绝服务型攻击。 tcp_tw_recycle ：BOOLEAN 默认值是0。 打开快速 TIME-WAIT sockets 回收。除非得到技术专家的建议或要求﹐请不要随意修改这个值。(做NAT的时候，建议打开它)。 tcp_tw_reuse：BOOLEAN 默认值是0。 该文件表示是否允许重新应用处于TIME-WAIT状态的socket用于新的TCP连接(这个对快速重启动某些服务,而启动后提示端口已经被使用的情形非常有帮助)。 tcp_max_orphans ：INTEGER 缺省值是8192。 系统所能处理不属于任何进程的TCP sockets最大数量。假如超过这个数量﹐那么不属于任何进程的连接会被立即reset，并同时显示警告信息。之所以要设定这个限制﹐纯粹为了抵御那些简单的 DoS 攻击﹐千万不要依赖这个或是人为的降低这个限制(这个值Redhat AS版本中设置为32768，但是很多防火墙修改的时候,，议该值修改为2000)。 tcp_abort_on_overflow ：BOOLEAN 缺省值是0。 当守护进程太忙而不能接受新的连接，就向对方发送reset消息，默认值是false。这意味着当溢出的原因是因为一个偶然的猝发，那么连接将恢复状态。只有在你确信守护进程真的不能完成连接请求时才打开该选项，该选项会影响客户的使用。(对待已经满载的sendmail，apache这类服务的时候，这个可以很快让客户端终止连接，可以给予服务程序处理已有连接的缓冲机会,所以很多防火墙上推荐打开它)。 TCP_NODELAY 神秘的40毫秒延迟与TCP_NODELAY Nagle’s Algorithm 是为了提高带宽利用率设计的算法，其做法是合并小的TCP 包为一个，避免了过多的小报文的 TCP 头所浪费的带宽。如果开启了这个算法 （默认），则协议栈会累积数据直到以下两个条件之一满足的时候才真正发送出 去： 积累的数据量到达最大的 TCP Segment Size。 收到了一个 Ack。 TCP Delayed Acknoledgement 也是为了类似的目的被设计出来的，它的作用就是延迟 Ack 包的发送，使得协议栈有机会合并多个 Ack，提高网络性能。 如果一个 TCP 连接的一端启用了 Nagle‘s Algorithm，而另一端启用了 TCP Delayed Ack，而发送的数据包又比较小，则可能会出现这样的情况：发送端在等待接收端对上一个packet 的 Ack 才发送当前的 packet，而接收端则正好延迟了 此 Ack 的发送，那么这个正要被发送的 packet 就会同样被延迟。当然 Delayed Ack 是有个超时机制的，而默认的超时正好就是 40ms。 现代的 TCP/IP 协议栈实现，默认几乎都启用了这两个功能，你可能会想，按我上面的说法，当协议报文很小的时候，岂不每次都会触发这个延迟问题？事实不是那样的。仅当协议的交互是发送端连续发送两个 packet，然后立刻 read 的时候才会出现问题。 Nagle算法主要是避免发送小的数据包，要求TCP连接上最多只能有一个未被确认的小分组，在该分组的确认到达之前不能发送其他的小分组。相反，TCP收集这些少量的小分组，并在确认到来时以一个分组的方式发出去。 SO_LINGER 设置函数close()关闭TCP连接时的行为。缺省close()的行为是，如果有数据残留在socket发送缓冲区中则系统将继续发送这些数据给对方，等待被确认，然后返回。SO_LINGER选项用来改变此缺省设置。使用如下结构： 1234struct linger &#123; int l_onoff; /* 0 = off, nozero = on */ int l_linger; /* linger time */&#125;; l_onoff l_linger closesocket行为 发送队列 底层行为 零 忽略 立即返回。 保持直至发送完成。 系统接管套接字并保证将数据发送至对端。 非零 零 立即返回。 立即放弃。 直接发送RST包，自身立即复位，不用经过2MSL状态。对端收到复位错误号。 非零 非零 阻塞直到l_linger时间超时或数据发送完成。(套接字必须设置为阻塞) 在超时时间段内保持尝试发送，若超时则立即放弃。 超时则同第二种情况，若发送完成则皆大欢喜。 第二种设置主要是为了避免主动断开连接方进入TIME_WAIT状态。丢失缓冲区中未丢失数据只是一种副作用。 SO_REUSEADDR / SO_REUSEPORT 浅析套接字中SO_REUSEPORT和SO_REUSEADDR的区别 SO_KEEPALIVE 貌似是由发起连接方（客户端）主动发给服务端的，就是一个data size为0的packet，服务器收到这个packet也会回复一个同样data size为0的packet表明连接仍存活。 SO_KEEPALIVE和心跳线程 SO_KEEPALIVE是系统底层的机制，用于系统维护每一个tcp连接的。 心跳线程属于应用层，主要用于终端和服务器连接的检查。 即使SO_KEEPALIVE检测到连接正常，但并不能保证终端和服务器连接的正常。有一种情况，服务器进程死了，但它和客户端的tcp连接还连着（该连接由系统维护的）。 这就是SO_KEEPALIVE不能取代心跳线程的原因吧。 TCP协议 四次挥手 其实也可以看成两次过程，任何一方发送FIN表明自己不会再发送数据。 TIME_WAIT（涉及主动断开连接一方） TCP协议在关闭连接的四次握手过程中，最终的ACK 是由 主动关闭连接 的一端（后面统称A端）发出的，如果这个ACK丢失，对方（后面统称B端）将重发出最终的FIN，因此A端必须维护状态信息（TIME_WAIT）允许它重发最终的ACK。如果A端不维持TIME_WAIT状态，而是处于CLOSED 状态，那么A端将响应RST分节，B端收到后将此分节解释成一个错误（在java中会抛出connection reset的SocketException)。 因而，要实现TCP全双工连接的正常终止，必须处理终止过程中四个分节任何一个分节的丢失情况，主动关闭连接的A端必须维持TIME_WAIT状态。 主动关闭的一方要负责处于TIME_WAIT状态中。MSL就是maximum segment lifetime(最大分节生命期），这是一个IP数据包能在互联网上生存的最长时间，超过这个时间IP数据包将在网络中消失 。MSL在RFC 1122上建议是2分钟，而源自berkeley的TCP实现传统上使用30秒。Windows使用的是2分钟，而Linux则是30秒。 CLOSE_WAIT（涉及被动断开连接一方） 在被动关闭连接情况下，在已经接收到FIN，但是还没有发送自己的FIN的时刻，连接处于CLOSE_WAIT状态。 出现大量CLOSE_WAIT的现象，主要原因是某种情况下对方关闭socket链接，但是我方忙与读或者写，没有关闭连接。代码需要判断socket，一旦读到0，断开连接，read返回负，检查一下errno，如果不是AGAIN，就断开连接。 服务器TIME_WAIT和CLOSE_WAIT详解和解决办法 拥塞控制 当cwnd&lt;ssthresh时，使用慢开始算法。 当cwnd&gt;ssthresh时，改用拥塞避免算法。 当cwnd=ssthresh时，慢开始与拥塞避免算法任意。 快重传和快恢复 快重传要求接收方在收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时捎带确认。快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。 快重传配合使用的还有快恢复算法，有以下两个要点: 当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把ssthresh门限减半。但是接下去并不执行慢开始算法。 考虑到如果网络出现拥塞的话就不会收到好几个重复的确认，所以发送方现在认为网络可能没有出现拥塞。所以此时不执行慢开始算法，而是将cwnd设置为ssthresh的大小，然后执行拥塞避免算法。如下图： 随机早期检测RED 若发生路由器的尾部丢弃，可能影响到很多条TCP连接，结果就是这许多的TCP连接在同一时间进入慢开始状态。这在术语中称为全局同步。全局同步会使得网络的通信量突然下降很多，而在网络恢复正常之后，其通信量又突然增大很多。 为避免发生网路中的全局同步现象，路由器采用随机早期检测(RED:randomearly detection)。 msl、ttl及rtt的区别 MSL 是Maximum Segment Lifetime英文的缩写，中文可以译为“报文最大生存时间”，他是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。例如RIP协议用经过的最大路由节点数作为MSL。 IP头中有一个TTL域，TTL是 time to live的缩写，中文可以译为“生存时间”，这个生存时间是由源主机设置初始值但不是存的具体时间，而是存储了一个ip数据报可以经过的最大路由数，每经 过一个处理他的路由器此值就减1，当此值为0则数据报将被丢弃，同时发送ICMP报文通知源主机。RFC 793中规定MSL为2分钟，实际应用中常用的是30秒，1分钟和2分钟等。 TTL与MSL是有关系的但不是简单的相等的关系，MSL要大于等于TTL。 RTT是客户到服务器往返所花时间（round-trip time，简称RTT），TCP含有动态估算RTT的算法。TCP还持续估算一个给定连接的RTT，这是因为RTT受网络传输拥塞程序的变化而变化。 本文地址：https://xnerv.wang/tcp-model-knowledge-summary/","categories":[{"name":"网络协议","slug":"网络协议","permalink":"https://xnerv.wang/categories/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"}],"tags":[{"name":"网络协议","slug":"网络协议","permalink":"https://xnerv.wang/tags/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"},{"name":"原创","slug":"原创","permalink":"https://xnerv.wang/tags/%E5%8E%9F%E5%88%9B/"},{"name":"TCP","slug":"TCP","permalink":"https://xnerv.wang/tags/TCP/"},{"name":"IP","slug":"IP","permalink":"https://xnerv.wang/tags/IP/"},{"name":"UDP","slug":"UDP","permalink":"https://xnerv.wang/tags/UDP/"}]},{"title":"线程同步与原子操作","slug":"thread-synchronization-and-atomic-operation","date":"2019-09-25T15:25:00.000Z","updated":"2025-03-10T01:04:55.819Z","comments":true,"path":"thread-synchronization-and-atomic-operation/","link":"","permalink":"https://xnerv.wang/thread-synchronization-and-atomic-operation/","excerpt":"volatile volatile使得代码每次在读写volatile变量时都需要从内存读写，而不能使用寄存器中缓存的值。并且也禁止编译器对volatible做编译优化。volatile本身并不是用于线程同步，也不保证原子读写（例如volatile a++这种需要几个指令才能完成的操作）。volatile主要用于access to memory mapped devices和variables in signal handlers and between setjmp and longjmp。C++标准禁止编译器reorder同一个线程内的volatile变量的读写，但不同线程则没有限制。non-volatile变量则有可能发生reorder（Stay away from Volatile in threaded code?）。 而根据为什么volatile++不是原子性的？中的说法，volatile的读操作后会插入LoadLoad和LoadStore屏障，避免volatile读操作与后面的普通读写发生reorder。而volatile的写操作前会插入StoreLoad和StoreStore屏障，避免volatile写操作与后面的普通读写发生reorder（我不太确定这种说法的正确性，毕竟在wikipediavolatile (computer programming)中并没有提到volatile会插入内存屏障，或者只有Java等语言才会这样做？）。 内存屏障中有提到 C与C++语言中，volatile关键字意图允许内存映射的I/O操作。这要求编译器对此的数据读写按照程序中的先后顺序执行，不能对volatile内存的读写重排序。因此关键字volatile并不保证是一个内存屏障。[4] 对于Visual Studio 2003，编译器保证对volatile的操作是有序的，但是不能保证处理器的乱序执行。因此，可以使用InterlockedCompareExchange或InterlockedExchange函数。 对于Visual Studio 2005及以后版本，编译器对volatile变量的读操作使用acquire semantics，对写操作使用release semantics。","text":"volatile volatile使得代码每次在读写volatile变量时都需要从内存读写，而不能使用寄存器中缓存的值。并且也禁止编译器对volatible做编译优化。volatile本身并不是用于线程同步，也不保证原子读写（例如volatile a++这种需要几个指令才能完成的操作）。volatile主要用于access to memory mapped devices和variables in signal handlers and between setjmp and longjmp。C++标准禁止编译器reorder同一个线程内的volatile变量的读写，但不同线程则没有限制。non-volatile变量则有可能发生reorder（Stay away from Volatile in threaded code?）。 而根据为什么volatile++不是原子性的？中的说法，volatile的读操作后会插入LoadLoad和LoadStore屏障，避免volatile读操作与后面的普通读写发生reorder。而volatile的写操作前会插入StoreLoad和StoreStore屏障，避免volatile写操作与后面的普通读写发生reorder（我不太确定这种说法的正确性，毕竟在wikipediavolatile (computer programming)中并没有提到volatile会插入内存屏障，或者只有Java等语言才会这样做？）。 内存屏障中有提到 C与C++语言中，volatile关键字意图允许内存映射的I/O操作。这要求编译器对此的数据读写按照程序中的先后顺序执行，不能对volatile内存的读写重排序。因此关键字volatile并不保证是一个内存屏障。[4] 对于Visual Studio 2003，编译器保证对volatile的操作是有序的，但是不能保证处理器的乱序执行。因此，可以使用InterlockedCompareExchange或InterlockedExchange函数。 对于Visual Studio 2005及以后版本，编译器对volatile变量的读操作使用acquire semantics，对写操作使用release semantics。 volatile跟const一样属于变量修饰符，因此也和const一样必须弄清楚修饰的是指针还是变量自身（或者甚至是第几级指针）。例如uchar * volatile reg;说明指针reg本身是volatile的，而volatile uchar *reg;说明*reg（也就是reg指向的变量）是volatile的。而且volatile也可以和const同时使用。 volatile陷阱一文中有提到几种volatile的陷阱和误用。 “Volatile” can be harmful…中提到可以将函数参数标记为volatile避免编译器优化，从而便于debug。 临界区块（Critical section） Windows的CRITICAL_SECTION首先会在用户态自旋尝试几次获取锁，如果最终还是失败的话就会内核模式等待。 内存屏障（Memory barrier） 首先要明白的一点，reorder不仅可以发生在编译时，也可以发生在运行时。CPU流水线也可以重排某些指令顺序。所以即使是同一段编译好的程序，不同的CPU内核也可能执行不同的指令顺序。（Volatile and memory barriers） 根据Memory barrier，如果只有单个CPU，即使发生reorder也不会有什么问题，问题都是发生在多个线程之间。而且内存屏障只在运行时生效？？？而编译时需要用volatile？并且这篇wiki也提到volatile并不能阻止volatile变量和non-volatile变量的reorder。本质上，C/C++标准中volatile是通过控制编译器而实现的（虽然编译器实现有可能引入内存屏障来实现volatile），而内存屏障是通过特殊CPU指令实现的）。 How do I Understand Read Memory Barriers and Volatile中将对内存的操作比喻成有一个queue（因为CPU比内存快），所以Acquire操作就是flush all read requests in the queue（实际上并不是flush，而只是加一个标记，所以叫做内存屏障），而Release操作就是flush all write requests in the queue。因此在Acquire(lfence)之前的read requests一定会完成在Acquire之前，而Release(sfence)之前的write requests一定会完成在Release之后。类似于“半透膜”的效果。（那也就是说Acquire是LoadLoad屏障，而Release是WriteWrite屏障？）而full barrier (or full fence, mfence)就是禁止在此之前的所有read/write操作被reorder到本操作之后。 而C++11中的Acquire和Release定义则与上面的回答不同。C++11中的Acquire是LoadLoad+StoreLoad，Release是LoadStore+StoreStore。结合C++11内存模型，内存屏障与内存模型，C++内存屏障（内存顺序）总结，std::memory_order等文章，6中内存屏障级别的区别是： （建议仔细再阅读最后一篇文章。不太明白的是，当论及other thread acquire/release the same atomic时，是指代码上有acquire/release操作的线程，还是指在某一个时刻瞬间进行了acquire/release的线程？就目前看来前者的可能性更大一些） 条件变量（Condition Variable） C++11的条件变量跟win32的Event有一个区别，就是必须在wait之后signal，否则就必须结合预测条件（从而检查是否在wait之前已经signal）。C++ Core Guidelines: Be Aware of the Traps of Condition Variables Atomic Does the C++ 11 standard guarantees that std::atomic&lt;&gt; is implemented as a lock-free operation?，C++11不保证std::atomic是lock-free的，而是由数据类型长度等因素决定的，可以用std::atomic::is_lock_free()来判断该类型是否lock-free。 What is the difference between explicit atomic load/store and usual operator= and operator T?，两者是相等的，后者使用默认的memory_order_seq_cst级别内存屏障。 本文地址：https://xnerv.wang/thread-synchronization-and-atomic-operation/","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://xnerv.wang/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"原创","slug":"原创","permalink":"https://xnerv.wang/tags/%E5%8E%9F%E5%88%9B/"},{"name":"操作系统","slug":"操作系统","permalink":"https://xnerv.wang/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"线程同步","slug":"线程同步","permalink":"https://xnerv.wang/tags/%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5/"},{"name":"原子操作","slug":"原子操作","permalink":"https://xnerv.wang/tags/%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/"},{"name":"volatile","slug":"volatile","permalink":"https://xnerv.wang/tags/volatile/"}]},{"title":"分布式理论及架构的一些整理","slug":"summary-of-distributed-theory-and-architecture","date":"2017-11-26T23:19:00.000Z","updated":"2025-03-10T01:04:55.818Z","comments":true,"path":"summary-of-distributed-theory-and-architecture/","link":"","permalink":"https://xnerv.wang/summary-of-distributed-theory-and-architecture/","excerpt":"CAP理论及BASE理论 分布式系统的CAP理论 一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项。 麻省理工学院的Seth Gilbert和Nancy Lynch从理论上证明了CAP","text":"CAP理论及BASE理论 分布式系统的CAP理论 一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项。 麻省理工学院的Seth Gilbert和Nancy Lynch从理论上证明了CAP 分布式系统的BASE理论 eBay的架构师Dan Pritchett源于对大规模分布式系统的实践总结，在ACM上发表文章提出BASE理论，BASE理论是对CAP理论的延伸，核心思想是即使无法做到强一致性（Strong Consistency，CAP的一致性就是强一致性），但应用可以采用适合的方式达到最终一致性（Eventual Consitency）。 BASE是指基本可用（Basically Available）、软状态（ Soft State）、最终一致性（ Eventual Consistency）。 基本可用（Basically Available） 基本可用是指分布式系统在出现故障的时候，允许损失部分可用性，即保证核心可用。 电商大促时，为了应对访问量激增，部分用户可能会被引导到降级页面，服务层也可能只提供降级服务。这就是损失部分可用性的体现。 软状态（ Soft State） 软状态是指允许系统存在中间状态，而该中间状态不会影响系统整体可用性。分布式存储中一般一份数据至少会有三个副本，允许不同节点间副本同步的延时就是软状态的体现。mysql replication的异步复制也是一种体现。 最终一致性（ Eventual Consistency） 最终一致性是指系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。弱一致性和强一致性相反，最终一致性是弱一致性的一种特殊情况。 两阶段提交主要保证了分布式事务的原子性：即所有结点要么全做要么全不做。 一个协调者，多个参与者。协调者收集参与者的投票，全通过就commit，否则abort。 将提交分成两阶段进行的目的很明确，就是尽可能晚地提交事务，让事务在提交前尽可能地完成所有能完成的工作，这样，最后的提交阶段将是一个耗时极短的微小操作，这种操作在一个分布式系统中失败的概率是非常小的，也就是所谓的“网络通讯危险期”非常的短暂，这是两阶段提交确保分布式事务原子性的关键所在。（唯一理论上两阶段提交出现问题的情况是当协调者发出提交指令后当机并出现磁盘故障等永久性错误，导致事务不可追踪和恢复）。 （注意，二阶段提交相对的就是一阶段提交，就是普通的本地事务模式） 关于分布式事务、两阶段提交协议、三阶提交协议 无论是二阶段提交还是三阶段提交都无法彻底解决分布式的一致性问题。Google Chubby的作者Mike Burrows说过， there is only one consensus protocol, and that’s Paxos” – all other approaches are just broken versions of Paxos. 意即世上只有一种一致性算法，那就是Paxos，所有其他一致性算法都是Paxos算法的不完整版。 3PC在2PC的基础上，加上了第一个CanCommit阶段。在第三个doCommit阶段，如果超时会自动commit，其它阶段超时会自动rollback。 深入理解分布式系统的2PC和3PC 2PC协议中，如果出现协调者和参与者都挂了的情况，有可能导致数据不一致。（这个应该指的是一个参加者节点在一段很短的时间内处于数据不一致状态，这也是不允许的，即使之后能够逐步恢复） 简单概括一下就是，如果挂掉的那台机器已经执行了commit，那么协调者可以从所有未挂掉的参与者的状态中分析出来，并执行commit。如果挂掉的那个参与者执行了rollback，那么协调者和其他的参与者执行的肯定也是rollback操作。 所以，再多引入一个阶段之后，3PC解决了2PC中存在的那种由于协调者和参与者同时挂掉有可能导致的数据一致性问题。 3PC存在的问题 在doCommit阶段，如果参与者无法及时接收到来自协调者的doCommit或者rebort请求时，会在等待超时之后，会继续进行事务的提交。 所以，由于网络原因，协调者发送的abort响应没有及时被参与者接收到，那么参与者在等待超时之后执行了commit操作。这样就和其他接到abort命令并执行回滚的参与者之间存在数据不一致的情况。 XA事务 MySQL的XA事务，估计就是对XA事务的支持。这样如果有一个XA事务管理器，就可以在MySQL和其它支持XA事务的数据库如SQL Server之间，进行分布式事务处理了。 X/Open 组织（即现在的 Open Group ）定义了分布式事务处理模型。 X/Open DTP 模型（ 1994 ）包括应用程序（ AP ）、事务管理器（ TM ）、资源管理器（ RM ）、通信资源管理器（ CRM ）四部分。一般，常见的事务管理器（ TM ）是交易中间件，常见的资源管理器（ RM ）是数据库，常见的通信资源管理器（ CRM ）是消息中间件。 通常把一个数据库内部的事务处理，如对多个表的操作，作为本地事务看待。数据库的事务处理对象是本地事务，而分布式事务处理的对象是全局事务。 XA 就是 X/Open DTP 定义的交易中间件与数据库之间的接口规范（即接口函数），交易中间件用它来通知数据库事务的开始、结束以及提交、回滚等。 XA 接口函数由数据库厂商提供。 拜占庭将军问题 拜占庭将军问题（Byzantine Generals Problem），是由莱斯利兰伯特提出的点对点通信中的基本问题。 在分布式计算上，不同的计算机透过讯息交换，尝试达成共识；但有时候，系统上协调计算机（Coordinator / Commander）或成员计算机 （Member / Lieutanent）可能因系统错误并交换错的讯息，导致影响最终的系统一致性。拜占庭将军问题就根据错误计算机的数量，寻找可能的解决办法 ，这无法找到一个绝对的答案，但只可以用来验证一个机制的有效程度）。 开源分布式系统 HBase可以看作对应Google BigTable的开源实现。HBase不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库。另一个不同的是HBase基于列的而不是基于行的模式。 解析全球级分布式数据库Google Spanner OceanBase 一个高性能的分布式表格系统，提供类似BigTable的性能和扩展性，但表格中保存的是强类型的数据，比如integer, string， datetime等。 它使用C++编写，运行于64位Linux环境下。生产环境下需要使用多台机器搭建OceanBase集群以提供高可用和高性能，但是你也完全可以使用一台机器运行OceanBase。 TFS（Taobao !FileSystem） 淘宝针对海量非结构化数据存储设计的分布式系统，构筑在普通的Linux机器集群上，可为外部提供高可靠和高并发的存储访问。高可扩展、高可用、高性能、面向互联网服务。 Tair Tair是一个高性能，分布式，可扩展，高可靠的key/value结构存储系统。 tair的总体结构 tair的负载均衡算法 tair的分布采用的是一致性哈希算法，对于所有的key，分到Q个桶中，桶是负载均衡和数据迁移的基本单位。config server 根据一定的策略把每个桶指派到不同的data server上。因为数据按照key做hash算法，所以可以认为每个桶中的数据基本是平衡的。保证了桶分布的均衡性，就保证了数据分布的均衡性。 本文地址：https://xnerv.wang/summary-of-distributed-theory-and-architecture/","categories":[{"name":"分布式及存储","slug":"分布式及存储","permalink":"https://xnerv.wang/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8F%8A%E5%AD%98%E5%82%A8/"}],"tags":[{"name":"原创","slug":"原创","permalink":"https://xnerv.wang/tags/%E5%8E%9F%E5%88%9B/"},{"name":"分布式及存储","slug":"分布式及存储","permalink":"https://xnerv.wang/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8F%8A%E5%AD%98%E5%82%A8/"},{"name":"2PC","slug":"2PC","permalink":"https://xnerv.wang/tags/2PC/"},{"name":"3PC","slug":"3PC","permalink":"https://xnerv.wang/tags/3PC/"}]},{"title":"一些大学常用算法及知识点的回顾","slug":"some-knowledge-points-learned-in-university","date":"2017-11-21T05:13:00.000Z","updated":"2025-03-10T01:04:55.820Z","comments":true,"path":"some-knowledge-points-learned-in-university/","link":"","permalink":"https://xnerv.wang/some-knowledge-points-learned-in-university/","excerpt":"本文是关于大学时一些常见的数据结构、算法和知识点的总结。其实与其说工作中会用到，不如说面试时被面到的可能性更大一些。不过其中一些特定领域的算法，像银行家算法，BAT的面试中我也还没有遇到过。适当地回顾大学时学到的一些知识点，也许能给自己带来一些快乐吧，一种仅存在于回忆中的快乐。","text":"本文是关于大学时一些常见的数据结构、算法和知识点的总结。其实与其说工作中会用到，不如说面试时被面到的可能性更大一些。不过其中一些特定领域的算法，像银行家算法，BAT的面试中我也还没有遇到过。适当地回顾大学时学到的一些知识点，也许能给自己带来一些快乐吧，一种仅存在于回忆中的快乐。 排序算法 冒泡排序 通过相邻元素的两两比较和swap，每次都将当前子序列中的最大/最小元素交换到当前子序列的最后面。 快速排序 选定第一个元素作为中轴，然后当i &lt; j的前提下，指针j从右至左寻找一个比中轴小的元素，指针i从左至右寻找一个比中轴大的元素，然后swap两者。最终i=j，则将i所在元素和中轴再swap。 这里的重点是j必须先走。举个例子：3、1、2、5、4这个序列，如果i先移动，则最终的结构是5、1、2、3、4，显然是错误的。原因是：中轴选的是左边第一个元素（3），如果左边的指针先移动，极端案例下会使得左边指针停留在一个比中轴大的元素上（这里的5），而右边指针无法在i &lt; j的情况下找到一个比中轴小的元素，导致最终5和3交换而错误。 的确无法很好地进行证明，只能举个反例来说明。 12345678910111213141516171819202122232425262728293031323334#include &lt;stdio.h&gt;int a[101],n;//定义全局变量，这两个变量需要在子函数中使用void quicksort(int left,int right)&#123; int i,j,t,temp; if(left&gt;right) return; temp=a[left]; //temp中存的就是基准数 i=left; j=right; while(i!=j) &#123; //顺序很重要，要先从右边开始找 while(a[j]&gt;=temp &amp;&amp; i&lt;j) j--; //再找右边的 while(a[i]&lt;=temp &amp;&amp; i&lt;j) i++; //交换两个数在数组中的位置 if(i&lt;j) &#123; t=a[i]; a[i]=a[j]; a[j]=t; &#125; &#125; //最终将基准数归位 a[left]=a[i]; a[i]=temp; quicksort(left,i-1);//继续处理左边的，这里是一个递归的过程 quicksort(i+1,right);//继续处理右边的 ，这里是一个递归的过程&#125; 归并排序 1234567891011121314151617181920212223242526272829303132333435363738394041424344//将有二个有序数列a[first...mid]和a[mid...last]合并。void mergearray(int a[], int first, int mid, int last, int temp[])&#123; int i = first, j = mid + 1; int m = mid, n = last; int k = 0; while (i &lt;= m &amp;&amp; j &lt;= n) &#123; if (a[i] &lt;= a[j]) temp[k++] = a[i++]; else temp[k++] = a[j++]; &#125; while (i &lt;= m) temp[k++] = a[i++]; while (j &lt;= n) temp[k++] = a[j++]; for (i = 0; i &lt; k; i++) a[first + i] = temp[i];&#125;void mergesort(int a[], int first, int last, int temp[])&#123; if (first &lt; last) &#123; int mid = (first + last) / 2; mergesort(a, first, mid, temp); //左边有序 mergesort(a, mid + 1, last, temp); //右边有序 mergearray(a, first, mid, last, temp); //再将二个有序数列合并 &#125;&#125;bool MergeSort(int a[], int n)&#123; int *p = new int[n]; if (p == NULL) return false; mergesort(a, 0, n - 1, p); delete[] p; return true;&#125; 注：有的书上是在mergearray()合并有序数列时分配临时数组，但是过多的new操作会非常费时。因此作了下小小的变化。只在MergeSort()中new一个临时数组。后面的操作都共用这一个临时数组。 鸡尾酒排序 冒泡排序的变种，也被称作定向冒泡排序，鸡尾酒搅拌排序，搅拌排序（也可以视作选择排序的一种变形），涟漪排序，来回排序或快乐小时排序。 先找到最小的数字，把他放到第一位，然后找到最大的数字放到最后一位。然后再找到第二小的数字放到第二位，再找到第二大的数字放到倒数第二位。以此类推，直到完成排序。 二分查找 递归版本： 12345678910111213int BSearch(elemtype a[],elemtype x,int low,int high)/*在下届为low，上界为high的数组a中折半查找数据元素x*/&#123; int mid; if(low &gt; high) return -1; mid=(low + high) / 2; if(x == a[mid]) return mid; if(x &lt; a[mid]) return(BSearch(a, x, low, mid-1)); else return(BSearch(a, x, mid+1, high));&#125; 非递归版本 12345678910111213141516171819int binary_search(int* a, int len, int goal)&#123; int low = 0; int high = len - 1; while(low &lt;= high) &#123; int middle = (low + high)/2; if(a[middle] == goal) return middle; //在左半边 else if(a[middle] &gt; goal) high = middle - 1; //在右半边 else low = middle + 1; &#125; //没找到 return -1;&#125; 图的遍历 DFS深度遍历（邻接图） 首先申请一个visted[n]数组，标记每个节点是否已经访问。 循环这个数组，如果一个节点没有被访问。就对其进行DFS遍历。 DFS遍历：标记当前节点为已访问。然后从邻接图中获取该节点的第一个未访问的可连通邻居，递归对该邻居进行DFS。然后再获取第二个未访问的可连通邻居，重复这个循环直到所有可连通邻居都处理完。 BFS广度遍历（邻接图） 首先申请一个visted[n]数组，标记每个节点是否已经访问。 循环这个数组，如果一个节点没有被访问。就对其进行BFS遍历。 BFS遍历：标记当前节点为已访问。然后创建一个queue，将当前节点放入queue。然后类似于二叉树的层次遍历，以queue中的当前节点作为种子，在while循环中，每次弹出queue中的一个节点，获取其所有未访问的邻居节点加入到queue中。直到最后queue为空。 最短路径 Dijkstra最短路径算法（单源最短路径） 这个算法既可以被划入到贪心法的范畴，也可以划入到动态规划的范畴。（排序的操作涉及贪心法，而之后的推进过程可看作是动态规划） 首先算出V0到各点的直连路径，然后从小到大排列，例如是V1、V2、V3…… 建立一个大小为n的数组distances（下标从1开始），表示V0分别到这个n个点的最短距离，初始值就是直连距离。 首先V0到V1的最短路径一定就是V0到V1的直连路径，因为V1是距离V0最近的点，因此不可能有一条经过第三个点的绕路可以比V0到V1的直连路径更短。 然后V2则是比较V0-V1和V0-V1-V2，选取最短的那条。更新distances[2]。 而对于V3，则考察V0-V3直连距离，以及经过V1或V2到达V3的间接距离，选取最短的那条。更新distances[3]。 …… 这里有个问题，为什么V0到V3的最短距离，一定是从已知点集合U中选择路径，而不是从未知点集合V中选择，例如V0-V4-V3这样的路径? 这就是一开始对n个直连路径进行排序的原因，V0-V4一定 &gt;= V0-V3，因此V0-V4-V3一定 &gt;= V0-V3。 另外本算法不能处理负权重边，用上面的例子说明，如果V0-V4是负权重，则有可能V0-V4-V3一定 &lt; V0-V3，因此这种算法就不再使用。（此时有没有其它好的方法？除了各边都加上同一个偏移量，将负权重都转正。） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125/**************************************** About: 有向图的Dijkstra算法实现* Author: Tanky Woo* Blog: www.WuTianQi.com***************************************/#include &lt;iostream&gt;using namespace std;const int maxnum = 100;const int maxint = 999999;void Dijkstra(int n, int v, int *dist, int *prev, int c[maxnum][maxnum])&#123; bool s[maxnum]; // 判断是否已存入该点到S集合中 for(int i=1; i&lt;=n; ++i) &#123; dist[i] = c[v][i]; s[i] = 0; // 初始都未用过该点 if(dist[i] == maxint) prev[i] = 0; else prev[i] = v; &#125; dist[v] = 0; s[v] = 1; // 依次将未放入S集合的结点中，取dist[]最小值的结点，放入结合S中 // 一旦S包含了所有V中顶点，dist就记录了从源点到所有其他顶点之间的最短路径长度 for(int i=2; i&lt;=n; ++i) &#123; int tmp = maxint; int u = v; // 找出当前未使用的点j的dist[j]最小值 for(int j=1; j&lt;=n; ++j) if((!s[j]) &amp;&amp; dist[j]&lt;tmp) &#123; u = j; // u保存当前邻接点中距离最小的点的号码 tmp = dist[j]; &#125; s[u] = 1; // 表示u点已存入S集合中 // 更新dist for(int j=1; j&lt;=n; ++j) if((!s[j]) &amp;&amp; c[u][j]&lt;maxint) &#123; int newdist = dist[u] + c[u][j]; if(newdist &lt; dist[j]) &#123; dist[j] = newdist; prev[j] = u; &#125; &#125; &#125;&#125;void searchPath(int *prev,int v, int u)&#123; int que[maxnum]; int tot = 1; que[tot] = u; tot++; int tmp = prev[u]; while(tmp != v) &#123; que[tot] = tmp; tot++; tmp = prev[tmp]; &#125; que[tot] = v; for(int i=tot; i&gt;=1; --i) if(i != 1) cout &lt;&lt; que[i] &lt;&lt; &quot; -&gt; &quot;; else cout &lt;&lt; que[i] &lt;&lt; endl;&#125;int main()&#123; freopen(&quot;input.txt&quot;, &quot;r&quot;, stdin); // 各数组都从下标1开始 int dist[maxnum]; // 表示当前点到源点的最短路径长度 int prev[maxnum]; // 记录当前点的前一个结点 int c[maxnum][maxnum]; // 记录图的两点间路径长度 int n, line; // 图的结点数和路径数 // 输入结点数 cin &gt;&gt; n; // 输入路径数 cin &gt;&gt; line; int p, q, len; // 输入p, q两点及其路径长度 // 初始化c[][]为maxint for(int i=1; i&lt;=n; ++i) for(int j=1; j&lt;=n; ++j) c[i][j] = maxint; for(int i=1; i&lt;=line; ++i) &#123; cin &gt;&gt; p &gt;&gt; q &gt;&gt; len; if(len &lt; c[p][q]) // 有重边 &#123; c[p][q] = len; // p指向q c[q][p] = len; // q指向p，这样表示无向图 &#125; &#125; for(int i=1; i&lt;=n; ++i) dist[i] = maxint; for(int i=1; i&lt;=n; ++i) &#123; for(int j=1; j&lt;=n; ++j) printf(&quot;%8d&quot;, c[i][j]); printf(&quot;\\n&quot;); &#125; Dijkstra(n, 1, dist, prev, c); // 最短路径长度 cout &lt;&lt; &quot;源点到最后一个顶点的最短路径长度: &quot; &lt;&lt; dist[n] &lt;&lt; endl; // 路径 cout &lt;&lt; &quot;源点到最后一个顶点的路径为: &quot;; searchPath(prev, 1, n);&#125; Floyd最短路径算法（多源最短路径） Dijkstra算法是用于计算单点到其它点的最短距离，复杂度是O(n2)，则计算完n个点的数据的复杂度就是O(n3)。而Floyd的算法复杂度也是O(n3). 虽然两者的算法复杂度一样，但是如果依次对某个顶点运用Dijkstra算法,则与Floyd算法相比,很多路径和结果计算是重复的,虽然复杂度相同,但是运算量差了很多。 此外，Dijkstra算法使用的前提是图中路径长度必须大于等于0，但是Floyd算法则仅仅要求没有总和小于0的环路就可以了。因此Floyd 算法应用范围比Dijkstra算法要广。 Floyd算法的思路：首先求出各点之间的直连距离矩阵，然后逐步引入1号点、2号点。。。 12345678// 经过1号顶点for(i=1;i&lt;=n;i++) for(j=1;j&lt;=n;j++) if (e[i][j] &gt; e[i][1]+e[1][j]) e[i][j]=e[i][1]+e[1][j];// 经过2号顶点for(i=1;i&lt;=n;i++) for(j=1;j&lt;=n;j++) if (e[i][j] &gt; e[i][2]+e[2][j]) e[i][j]=e[i][2]+e[2][j]; 从而推导出一个三重循环 12345for(k=1;k&lt;=n;k++) for(i=1;i&lt;=n;i++) for(j=1;j&lt;=n;j++) if(e[i][j]&gt;e[i][k]+e[k][j]) e[i][j]=e[i][k]+e[k][j]; Floyd算法另一种理解DP，为理论爱好者准备的，上面这个形式的算法其实是Floyd算法的精简版，而真正的Floyd算法是一种基于DP(Dynamic Programming)的最短路径算法。设图G中n 个顶点的编号为1到n。令c [i, j, k]表示从i 到j 的最短路径的长度，其中k 表示该路径中的最大顶点，也就是说c[i,j,k]这条最短路径所通过的中间顶点最大不超过k。因此，如果G中包含边&lt; i, j &gt;，则c[i, j, 0] =边&lt; i, j &gt; 的长度；若i= j ，则c[i,j,0]=0；如果G中不包含边&lt; i, j &gt;，则c (i, j, 0)= +∞。c[i, j, n] 则是从i 到j 的最短路径的长度。对于任意的k&gt;0，通过分析可以得到：中间顶点不超过k 的i到j的最短路径有两种可能：该路径含或不含中间顶点k。若不含，则该路径长度应为c[i, j, k-1]，否则长度为 c[i, k, k-1] +c [k, j, k-1]。c[i, j, k]可取两者中的最小值。状态转移方程：c[i, j, k]=min{c[i, j, k-1], c [i, k, k-1]+c [k, j, k-1]}，k＞0。这样，问题便具有了最优子结构性质，可以用动态规划方法来求解。 最小生成树：Prim算法和Kruskal算法 网上的Prim实现方法的时间复杂度是O(N2)，但实际上先用快速排序对各边进行排序，然后用两个hashset，U和V记录两种点。然后遍历一次边的有序列表进行了，时间复杂度O(logN)。 Kruskal算法的实现思想是：也是先对所有边排序，然后一开始时将每条边当作一个连通分量。然后循环地遍历边的有序列表，如果边的两个顶点不在同一个连通分量中，就将这两个连通分量合并为同一个（新的连通分量标识选择两者中较小的那个）。 （描述不太清楚，还是不知道两个算法的区别） KMP算法 （待补完） 汉诺塔 12345678910111213141516class Solution: def __init__(self): self.i = 0 def move(self, n, src, dst): self.i += 1 print &quot;the %d step: move dish %d %s to %s.&quot; % (self.i, n, src, dst) def hanoi(self, n, src, dst, dep): if 1 == n: self.move(1, src, dst) else: self.hanoi(n - 1, src, dep, dst) self.move(n, src, dst) self.hanoi(n - 1, dep, dst, src) Bloom Filter Bloom Filter的这种高效是有一定代价的：在判断一个元素是否属于某个集合时，有可能会把不属于这个集合的元素误认为属于这个集合（false positive）。因此，Bloom Filter不适合那些“零错误”的应用场合。而在能容忍低错误率的应用场合下，Bloom Filter通过极少的错误换取了存储空间的极大节省。 无法从Bloom Filter集合中删除一个元素。因为该元素对应的位会牵动到其他的元素。所以一个简单的改进就是 counting Bloom filter，用一个counter数组代替位数组，就可以支持删除了。 此外，Bloom Filter的hash函数选择会影响算法的效果。 银行家算法 银行家算法：每个资源申请者要预先填写最大申请额度，然后以后每次能提出额度内的申请，银行家评估如果通过这次申请，那剩余的资源是否能构成安全序列。这里有一个假设是，每一名资源申请者只有在获取到最大额度的申请时，才会释放掉手中的资源。因此关键在于如何判断是否能够构成安全序列。 安全序列的判定：检查所有申请者，看当前剩余资源能够使得其中至少一个申请者可以满足最大额度申请而释放掉其资源。因为这是一个使得可用资源增长的过程，因此检查的顺序是不会影响最终判定结果的。 CA工作原理 SSL(Secure Socket Layer) 是一种加密技术，可以提供对称加密和非对称加密。由于它在协议层里正好是在传输层与应用层之间，这就决定了上层应用必须经过它，这就是它广泛流行和易于实现的原因。 对称加密有md5，sha1。由于md5已被学者证明可以计算出加密冲突，即它有一定的不安全性，所以建议用sha1加密。 非对称性加密有RSA，即密码有一对，一个私钥，一个公钥，公钥可以让所有人知道，私钥只有自己知道。 这样理解，服务器产生一对密钥，公钥给别人即客户端，客户端用它来加密，加密后发给服务端，服务端用自己的私钥解密后得到数据。 数字签名就和上面的过程相反，即数据由服务端用私钥加密，客户端用服务端的公钥解密，解得出来就说明这数据包的确是出服务端发过来的。 数字签名是由服务端自己签的，但没人去验证这个服务端是不是你所要访问的真实的，所以需要第三方来帮忙检验，就和支付宝处于第三方来协调的位置一样。这个第三方就叫CA。 所以服务器产生的公钥就交给CA，CA用CA自己的私钥加密，即数字签名，加密生会生成证书，证书还是要交给服务端，放在服务端那边。当客户端访问服务端时，服务端就会把这个证书安装到客户端上。 客户端就会用CA提供的CA自己的公钥来解密这个证书，（当然这个CA是浏览器预装时嵌入的可信的CA，如果不是预装时嵌入的CA，此时就没有CA的公钥，就解不了，就会弹出告警。）解得开就说明这个证书是某个CA认证过了的，是可信的，解开后就会得到数据，而这个数据就是服务端的公钥，此时用这个公钥与服务端进行数据传输。 数据传输过程中，由于RSA方式加解密速度非常慢，所以会把对称与非对称两者结合起来用，即用RSA把对称加密的密码进行加密传输，再用对称密码进行加解密，这样就可以提高效率，且是安全的。 B树 B树：分支节点和叶节点均保存记录的关键码和记录的指针 B+树：分支节点只保存记录关键码的复制，无记录指针。 所有记录都集中在叶节点一层，并且叶节点可以构成一维线性表，便于连续访问和范围查询。 两者的插入、删除基本一致。 对于同样阶的B树和B+树，B+树的树高和平均检索长度均大于B树（因为B+树必须检索到叶节点一层） 但实际上检索过程中，最耗时间的是…………IO，也就是访盘次数越少越好。 B+树的分支节点无记录指针，同样一个盘块可以存放的关键码数就更多，所以虽然平均检索长度大，但访盘次数反而少，速度也就比B树快。 deque、stack、queue、priority_queue，heap deque和list/vector一样是基本的容器类型。但stack/queue/priority_queue/heap则是抽象容器类型，必须基于一种基本容器类型。 stack和queue默认是使用deque，而priority_queue默认是使用vector。 queue是一种单向队列，push类似push_back，pop类似pop_front，其实就是用adapter模式将基本容器类型的接口变化了一下，所以目前看来实际应用的不多。stack也类似。 priority_queue/heap则是基于基本容器类型，实现了一种高层的抽象数据结构。 堆算法 堆中每一个节点的父节点的下标是(i-1)/2, i!=0。 第一个非叶子结点是size/2。 堆的建立 从最后一个非叶子结点开始，从后向前推，每次都比较一个非叶子结点和其两个子节点，将最大者交换到该非叶子结点的位置。时间复杂度是O(N)。 堆的插入 将元素放到最后面，然后逐步与父节点进行调整。 父节点的下标是(i-1)/2,i!=0，对于大顶堆，如果当前节点比其父节点大，则swap，然后重复这个过程。 时间复杂度是o(logN)。 堆的删除 将堆顶元素弹出，然后将最后一个元素填充到堆顶，然后逐步与子节点进行调整。 子节点的下标是2i+1和2i+2，比较这两个节点与当前节点，将（可能的）最大者与当前节点进行swap，重复这个过程。 时间复杂度是o(logN)。 堆排序 首先需要建立堆。 然后每次将堆顶的元素与当前子序列中的最后一个元素交换，这样就同时完成了一个元素的直接选择排序，又完成了堆删除中的一步：将最后一个元素填充到堆顶。重复这个过程。 时间复杂度是O(N)+Nlog(N)=Nlog(N) 另外堆排序是不稳定的排序。（有没有可能规定相等元素在比较、替换等时的一套规则，使得堆排序能够稳定？） 路由协议 LS/DV 路由协议分成链路状态协议（LS）、和距离矢量协议（DV）两大类。 链路状态协议：例如OSPF协议。使用链路状态路由协议时，每台路由创建自己的LSA（链路状态通告），并在路由更新中泛洪（将网络的所有细节通告给其他的所有路由器）LSA给其他的所有路由器。泛洪LSA就是路由器将LSA发给邻居，邻居再将它转发给他的邻居，知道所有的路由器都收到这个LSA，路由器相连的子网也会创建并泛洪链路LSA，最后每台路由器都有所有路由器的LSA和所有链路LSA。 距离矢量协议：例如RIP协议。它们发送的全部的周期性（默认每隔30秒）的路由更新。更新中只包括子网和各自的距离（即到达目的子网的度量值）。除了邻居路由之外，路由器不了解网络拓扑的细节（因为它之和邻居路由交换数据）。如果到相同的子网有多条路由时，路由器选择最低度量值的路由，如果度量值相同时，就都选择（如rip协议中，有时有2个最佳路由）。 自治系统AS 自治系统AS：每一个AS分配一个16位的ASN号码，中国貌似至少有几十个ASN号码，上海电信、广东电信啥的都有自己独立的ASN号码。 在互联网中，一个自治系统(AS)是一个有权自主地决定在本系统中应采用何种路由协议的小型单位。这个网络单位可以是一个简单的网络也可以是一个由一个或多个普通的网络管理员来控制的网络群体，它是一个单独的可管理的网络单元（例如一所大学，一个企业或者一个公司个体）。一个自治系统有时也被称为是一个路由选择域（routing domain）。一个自治系统将会分配一个全局的唯一的16位号码，有时我们把这个号码叫做自治系统号（ASN）。 IGP/EGP IGP是内部网关协议，是一类协议的统称，其本身并不是协议。例如OSPF、RIP就属于IGP协议。 EGP同样，是外部网关协议的统称。而BGP是EGP中一个具体的协议。 RIP协议 RIP协议被设计用于使用同种技术的中型网络，因此适应于大多数的校园网和使用速率变化不是很大的连续线的地区性网络。对于更复杂的环境，一般不使用RIP协议。 RIP作为一个系统长驻进程（daemon）而存在于路由器中，负责从网络系统的其它路由器接收路由信息，从而对本地IP层路由表作动态的维护，保证IP层发送报文时选择正确的路由。同时负责广播本路由器的路由信息，通知相邻路由器作相应的修改。RIP协议处于UDP协议的上层，RIP所接收的路由信息都封装在UDP协议的数据报中，RIP在520号UDP端口上接收来自远程路由器的路由修改信息，并对本地的路由表做相应的修改，同时通知其它路由器。 RIP路由协议用“更新（UNPDATES）”和“请求（REQUESTS）”这两种分组来传输信息的。每个具有RIP协议功能的路由器每隔30秒用UDP520端口给与之直接相连的机器广播更新信息。更新信息反映了该路由器所有的路由选择信息数据库。路由选择信息数据库的每个条目由“局域网上能达到的IP地址”和“与该网络的距离”两部分组成。请求信息用于寻找网络上能发出RIP报文的其他设备。 由于RIP的路由条目中并不保存完整路径，因此一旦网络波动，以及通讯延迟，可能会产生技术到无穷的问题。RIP设置最大条数15跳，也是为了避免这个问题。 水平分割：记录每条最佳路由是从哪个邻居的哪个端口收到的，将不会再通过该端口向该邻居广播这条最佳路由。但是局限是只能在两个路由器时有效，三个及更多的路由器，仍有可能形成环。 毒化逆转：与水平分割不同，还是会通过该端口向该邻居广播这条路由，但是会设置成距离16：不可达。有可能立刻解决路由选择环路。否则，不正确的路径将在路由表中驻留到超时为止。破坏逆转的缺点是它增加了路由更新的的数据大小，且还是有可能形成环。 保持定时器法：当一条路由被删除后，一定时间内（如180s）不会再更新该路由。 触发更新法：毒化逆转将任何两个路由器构成的环路打破，但三个或更多个路由器构成的环路仍会发生，直到无穷（16）时为止。触发式更新法可加速收敛时间，它的工作原理是当某个路径的跳数改变了，路由器立即发出更新信息，不管路由器是否到达常规信息更新时间都发出更新信息。 OSPF算法 OSPF算法真的不会成环么？例如A和B，两者交替地到目的IP的延时较短，那packet不就有可能在这两台路由器之间循环么？ 海明码 （待补完） 欧拉回路/哈密顿回路 欧拉回路是经过所有边一次然后回到原点，哈密顿回路是经过所有节点一次然后回到原点，TSP旅行商问题就是哈密顿回路。 可见欧拉回路是有可能重复经过一个点的，但哈密顿回路不能重复经过一条边。 本文地址：https://xnerv.wang/some-knowledge-points-learned-in-university/","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://xnerv.wang/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"原创","slug":"原创","permalink":"https://xnerv.wang/tags/%E5%8E%9F%E5%88%9B/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://xnerv.wang/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"},{"name":"排序算法","slug":"排序算法","permalink":"https://xnerv.wang/tags/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"},{"name":"查找算法","slug":"查找算法","permalink":"https://xnerv.wang/tags/%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95/"},{"name":"路由协议","slug":"路由协议","permalink":"https://xnerv.wang/tags/%E8%B7%AF%E7%94%B1%E5%8D%8F%E8%AE%AE/"}]},{"title":"彻底研究Python的编码问题","slug":"all-truths-about-python-encoding-problem","date":"2017-11-06T01:14:00.000Z","updated":"2025-03-10T01:04:55.825Z","comments":true,"path":"all-truths-about-python-encoding-problem/","link":"","permalink":"https://xnerv.wang/all-truths-about-python-encoding-problem/","excerpt":"Python的初学者（以及很多熟练工）相信都遇到过下面的运行时错误信息： UnicodeDecodeError: ‘ASCII’ codec can’t decode byte 0xe4 in position 0: ordinal not in range(128) 然后百度一下发现说明这个问题的网页有一大把，基本无非是下面两种解决方案： 在Python文件的开头加一句#coding=utf-8。 在代码中加入： 123import sysreload(sys)sys.setdefaultencoding(&#x27;utf8&#x27;) 一般大家的做法是把两者都加上，然后问题一般也会得到解决。但很少有人会去深究过Python会什么会产生这样的编码问题，以及为什么通过加上面的代码可以解决这个问题。作为一个合格的程序员，遇到这种问题就应该追根究底 :)","text":"Python的初学者（以及很多熟练工）相信都遇到过下面的运行时错误信息： UnicodeDecodeError: ‘ASCII’ codec can’t decode byte 0xe4 in position 0: ordinal not in range(128) 然后百度一下发现说明这个问题的网页有一大把，基本无非是下面两种解决方案： 在Python文件的开头加一句#coding=utf-8。 在代码中加入： 123import sysreload(sys)sys.setdefaultencoding(&#x27;utf8&#x27;) 一般大家的做法是把两者都加上，然后问题一般也会得到解决。但很少有人会去深究过Python会什么会产生这样的编码问题，以及为什么通过加上面的代码可以解决这个问题。作为一个合格的程序员，遇到这种问题就应该追根究底 :) string与Unicode string Python的编码问题一般只在Python2.x中存在，在Python3.x中则基本不会遇到这样的问题。根本原因在于Python2.x中存在两种字符串：string和Unicode string，两者都继承自basic string。 string类似于C语言中的char*，或者C++中的std::string，本质上都是byte数组，本身不具备特定的encoding类型，而是由string的使用者决定的。例如向string中写入一个汉字，如果是UTF-8编码，则可能是三个char（或者更多），如果是GBK编码，则可能是两个char，但对于Python解释器，它并不清楚string用的是encoding，一切都是bytes。。。 而Unicode string则明确地存储了Unicode编码的字符串。在Python2.x中，a1=&quot;abc&quot;;，a1就是一个string（是什么编码还不确定，等下再谈）。而a2=u&quot;abc&quot;;，a2就是一个Unicode string。 C/C++中的文件编码和字符串编码 C/C++不仅仅是一种编程语言，更是一个深入了解计算机底层原理的窗口和机会。我们先回过头来看看C/C++中是如何处理文件编码和字符串编码的问题的。以VC为例，VC下有两个编码的选项，分为Source encoding和Execution encoding。前者指定了源文件的编码（这比BOM更准确），后者是字符串常量等的编码。简单说，如果指定Source encoding为GBK，同时指定Execution encoding为UTF-8，则首先所有的源文件必须用GBK编码保存，否则VC在读入源文件时可能会无法解码其中的一些字符。同时，像const char* a3=&quot;中文&quot;;这样的常量字符串赋值语句，a3就是使用了UTF-8编码保存的字符串。在中文Windows系统下，如果不特意设置这两种编码，VC则一般使用的是system default encoding。 （参考 Char * encoding, /execution-charset (Set Execution Character Set), /source-charset (Set Source Character Set)。） Python中的文件编码和字符串编码 对比C/C++处理编码的方法，我们再看看Python是怎么做的。 首先，类似于Source encoding，Python可以通过在文件开头加上#coding=utf-8这句来向Python解析器指明本py源文件的编码。然后，麻烦事情来了，与C/C++中的Execution encoding有很大的不同，对于Python2.x的string而言，对其用字符串常量赋值时，string中存储的encoding，是跟#coding=utf-8挂钩的，而不是像C++中的Execution encoding一样有一个单独的选项来指定。也就是说，如果指定了#coding=utf-8，那么在运行时，a1=&quot;中文&quot;就会用UTF-8编码来存储和读取变量a1，如果没有设置#coding=utf-8及其它任何#coding=xxx，那么就是用默认的ASCII编码，但显然ASCII是无法编码&quot;中文&quot;的，于是在运行时你就会看到类似下面的报错： 1SyntaxError: Non-ASCII character &#x27;\\xe4&#x27; in file D:\\test.py on line 1, but no encoding declared; see http://python.org/dev/peps/pep-0263/ for details 而关于sys.defaultencoding，这个在没有明确指明解码方式的时候使用。比如有如下代码： 1234#! /usr/bin/env python# -*- coding: utf-8 -*-s = &#x27;中文&#x27;s.encode(&#x27;gb18030&#x27;) 这句代码将s（string类型）重新编码为gb18030的格式（仍然是string类型）， Python会自动的先将s解码为Unicode string类型，然后再编码成gb18030。因为解码是Python自动进行的，我们没有指明解码方式，Python就会使用sys.defaultencoding指明的方式来解码。很多情况下sys.defaultencoding是ASCII，如果s不是这个类型就会出错。 拿上面的情况来说，我的sys.defaultencoding是ASCII，而s的编码方式和文件的编码方式一致，是UTF-8的，所以出错了: 1UnicodeDecodeError: &#x27;ascii&#x27; codec can&#x27;t decode byte 0xe4 in position 0: ordinal not in range(128) 但是sys.setdefaultencoding('utf8')有的时候也会导致一些意想不到的问题，所以目前网上主流意见是不推荐使用 。例如这篇文章中提到使用sys.setdefaultencoding可能会遇到的一些问题：Why sys.setdefaultencoding() will break code 在Python3.x中，编码的问题基本不存在了，也没有了sys.setsystemencoding。因为Python3.x取消了string，只有Unicode string，也避免了很多编码转换的问题。 关于#coding:utf-8 #coding:utf-8指引Python解释器如何读取整个py文件，有些IDE也会根据这个comment来自动决定保存格式及显示格式，应该与py文件的保存格式一致。 根据PEP 263 – Defining Python Source Code Encodings中的说明，其实写成#coding=utf-8，#coding:utf-8或者#-*- coding:utf-8 -*-都是可以的，正则定义为coding[:=]\\s*([-\\w.]+)。 encode/decode encode是将Unicode string转化为指定encoding编码的string，而decode是将某种encoding编码的string转化为Unicode string。 如果decode指定错了encoding，例如，假设a1已经是Unicode编码的字符串变量，执行： 1print a1.decode(&#x27;utf-8&#x27;) 则可能报错： 1234567Traceback (most recent call last):... File &quot;C:\\Python27\\lib\\encodings\\utf_8.py&quot;, line 16, in decode return codecs.utf_8_decode(input, errors, True)UnicodeEncodeError: &#x27;ascii&#x27; codec can&#x27;t encode character u&#x27;\\u3010&#x27; in position 0: ordinal not in range(128) print/sys.xxx.write print和sys.xxx.write在输出unicode-object string时会自动转换编码为sys.xxx.encoding，无需自己来转。 但是，如果是utf8 string，而当前环境是Windows，则输出显然会乱码。如果是中文版Windows，用的是GB编码（code page 936）。如果是英文版Windows，用的可能是ANSI编码（code page 1252）。 最佳实践 本文地址：https://xnerv.wang/all-truths-about-python-encoding-problem/","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://xnerv.wang/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"编程语言","slug":"编程语言","permalink":"https://xnerv.wang/tags/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"},{"name":"Python","slug":"Python","permalink":"https://xnerv.wang/tags/Python/"},{"name":"原创","slug":"原创","permalink":"https://xnerv.wang/tags/%E5%8E%9F%E5%88%9B/"},{"name":"未完成","slug":"未完成","permalink":"https://xnerv.wang/tags/%E6%9C%AA%E5%AE%8C%E6%88%90/"}]},{"title":"Linux进程、内核及文件系统总结","slug":"linux-process-kernel-and-file-system-summary","date":"2017-11-03T23:58:00.000Z","updated":"2025-03-10T01:04:55.813Z","comments":true,"path":"linux-process-kernel-and-file-system-summary/","link":"","permalink":"https://xnerv.wang/linux-process-kernel-and-file-system-summary/","excerpt":"fork 关于linux进程间的close-on-exec机制 一般我们会调用exec执行另一个程序，此时会用全新的程序替换子进程的正文，数据，堆和栈等。此时保存文件描述符的变量当然也不存在 了，我们就无法关闭无用的文件描述符了。所以通常我们会fork子进程后在子进程中直接执行close关掉无用的文件描述符，然后再执行exec。 但是在复杂系统中，有时我们fork子进程时已经不知道打开了多少个文件描述符（包括socket句柄等），这此时进行逐一清理确实有很大难 度。我们期望的是能在fork子进程前打开某个文件句柄时就指定好：“这个句柄我在fork子进程后执行exec时就关闭”。其实时有这样的方法的：即所 谓 的 close-on-exec。 回到我们的应用场景中来，只要我们在创建socket的时候加上 SOCK_CLOEXEC标志，就能够达到我们要求的效果，在fork子进程中执行exec的时候，会清理掉父进程创建的socket。","text":"fork 关于linux进程间的close-on-exec机制 一般我们会调用exec执行另一个程序，此时会用全新的程序替换子进程的正文，数据，堆和栈等。此时保存文件描述符的变量当然也不存在 了，我们就无法关闭无用的文件描述符了。所以通常我们会fork子进程后在子进程中直接执行close关掉无用的文件描述符，然后再执行exec。 但是在复杂系统中，有时我们fork子进程时已经不知道打开了多少个文件描述符（包括socket句柄等），这此时进行逐一清理确实有很大难 度。我们期望的是能在fork子进程前打开某个文件句柄时就指定好：“这个句柄我在fork子进程后执行exec时就关闭”。其实时有这样的方法的：即所 谓 的 close-on-exec。 回到我们的应用场景中来，只要我们在创建socket的时候加上 SOCK_CLOEXEC标志，就能够达到我们要求的效果，在fork子进程中执行exec的时候，会清理掉父进程创建的socket。 Are child processes created with fork() automatically killed when the parent is killed? No. If the parent is killed, children become children of the init process (that has the process id 1 and is launched as the first user process by the kernel). The init process checks periodically for new children, and kills them if they have exited (thus freeing resources that are allocated by their return value). How to make child process die after parent exits? Child can ask kernel to deliver SIGHUP (or other signal) when parent dies by specifying option PR_SET_PDEATHSIG in prctl() syscall like this: prctl(PR_SET_PDEATHSIG, SIGHUP); See man 2 prctl for details. Linux 技巧：让进程在后台可靠运行的几种方法 线程实现 LinuxThreads的不足 按照POSIX定义，同一进程的所有线程应该共享一个进程id和父进程id，这在目前的&quot;一对一&quot;模型下是无法实现的。 由于异步信号是内核以进程为单位分发的，而LinuxThreads的每个线程对内核来说都是一个进程，且没有实现&quot;线程组&quot;，因此，某些语义不符合POSIX标准，比如没有实现向进程中所有线程发送信号，README对此作了说明。 LinuxThreads将每个进程的线程最大数目定义为1024，但实际上这个数值还受到整个系统的总进程数限制，这又是由于线程其实是核心进程。 管理线程容易成为瓶颈，这是这种结构的通病；同时，管理线程又负责用户线程的清理工作，因此，尽管管理线程已经屏蔽了大部分的信号，但一旦管理线程死亡，用户线程就不得不手工清理了，而且用户线程并不知道管理线程的状态，之后的线程创建等请求将无人处理。 LinuxThreads中的线程同步很大程度上是建立在信号基础上的，这种通过内核复杂的信号处理机制的同步方式，效率一直是个问题。 其他的线程实现机制 LinuxThreads的问题，特别是兼容性上的问题，严重阻碍了Linux上的跨平台应用（如Apache）采用多线程设计，从而使得Linux上的线程应用一直保持在比较低的水平。在Linux社区中，已经有很多人在为改进线程性能而努力，其中既包括用户级线程库，也包括核心级和用户级配合改进的线程库。目前最为人看好的有两个项目，一个是RedHat公司牵头研发的NPTL（Native Posix Thread Library），另一个则是IBM投资开发的NGPT（Next Generation Posix Threading），二者都是围绕完全兼容POSIX 1003.1c，同时在核内和核外做工作以而实现多对多线程模型。这两种模型都在一定程度上弥补了LinuxThreads的缺点，且都是重起炉灶全新设计的。 Linux 线程模型的比较：LinuxThreads 和 NPTL LinuxThreads 的限制已经在 NPTL 以及 LinuxThreads 后期的一些版本中得到了克服。例如，最新的 LinuxThreads 实现使用了线程注册来定位线程本地数据；例如在 Intel® 处理器上，它就使用了 %fs 和 %gs 段寄存器来定位访问线程本地数据所使用的虚拟地址。尽管这个结果展示了 LinuxThreads 所采纳的一些修改的改进结果，但是它在更高负载和压力测试中，依然存在很多问题，因为它过分地依赖于一个管理线程，使用它来进行信号处理等操作。 您应该记住，在使用 LinuxThreads 构建库时，需要使用 -D_REENTRANT 编译时标志。这使得库线程是安全的。 最后，也许是最重要的事情，请记住 LinuxThreads 项目的创建者已经不再积极更新它了，他们认为 NPTL 会取代 LinuxThreads。 LinuxThreads 的缺点并不意味着 NPTL 就没有错误。作为一个面向 SMP 的设计，NPTL 也有一些缺点。我曾经看到过在最近的 Red Hat 内核上出现过这样的问题：一个简单线程在单处理器的机器上运行良好，但在 SMP 机器上却挂起了。我相信在 Linux 上还有更多工作要做才能使它具有更好的可伸缩性，从而满足高端应用程序的需求。 SIGNAL Clarification on SIGKILL, SIGTERM, SIGINT, SIGQUIT, SIGSTP and SIGHUP SIGKILL: kill -9 SIGTERM: kill SIGINT: Ctrl+C (The difference between SIGINT and SIGTERM is that the former can be sent from a terminal as input characters.) SIGQUIT Ctrl+\\ (generates a core dump of the process and also cleans up resources held up by a process.) SIGSTP Ctrl+Z (Suspends a process. The process can be resumed by sending a SIGCONT signal.) SIGHUP Ctrl+D (Hangs up a process when the controlling terminal is disconnected.) Linux内核信号处理机制介绍 如果想要进程捕获某个信号，然后作出相应的处理，就需要注册信号处理函数。同中断类似，内核也为每个进程准备了一个信号向量表,信号向量表中记录着每个信号所对应的处理机制，默认情况下是调用默认处理机制。当进程为某个信号注册了信号处理程序后，发生该信号时，内核就会调用注册的函数。 信号是异步的，一个进程不可能等待信号的到来，也不知道信号会到来，那么，进程是如何发现和接受信号呢？实际上，信号的接收不是由用户进程来完成的，而是由内核代理。当一个进程P2向另一个进程P1发送信号后，内核接受到信号，并将其放在P1的信号队列当中。当P1再次陷入内核态时，会检查信号队列，并根据相应的信号调取相应的信号处理函数。 内核态与用户态 Intel x86架构的CPU来说一共有0~3四个特权级，0级最高，3级最低，硬件上在执行每条指令时都会对指令所具有的特权级做相应的检查，相关的概念有CPL、DPL和RPL 用户态切换到内核态的3种方式：系统调用、异常、外围设备的中断。其中系统调用可以认为是用户进程主动发起的，异常和外围设备中断则是被动的。 从触发方式上看，可以认为存在前述3种不同的类型，但是从最终实际完成由用户态到内核态的切换操作上来说，涉及的关键步骤是完全一致的，没有任何区别，都相当于执行了一个中断响应的过程，因为系统调用实际上最终是中断机制实现的，而异常和中断的处理机制基本上也是一致的。 涉及到由用户态切换到内核态的步骤主要包括： 从当前进程的描述符中提取其内核栈的ss0及esp0信息。 使用ss0和esp0指向的内核栈将当前进程的cs,eip,eflags,ss,esp信息保存起来，这个过程也完成了由用户栈到内核栈的切换过程，同时保存了被暂停执行的程序的下一条指令。 将先前由中断向量检索得到的中断处理程序的cs,eip信息装入相应的寄存器，开始执行中断处理程序，这时就转到了内核态的程序执行了。 内核态程序执行完毕时如果要从内核态返回用户态，可以通过执行指令iret来完成，指令iret会将先前压栈的进入内核态前的cs,eip,eflags,ss,esp信息从栈里弹出，加载到各个对应的寄存器中，重新开始执行用户态的程序。 处理器总处于以下状态中的一种： 内核态，运行于进程上下文，内核代表进程运行于内核空间； 内核态，运行于中断上下文，内核代表硬件运行于内核空间； 用户态，运行于用户空间。 系统调用 strace常用来跟踪进程执行时的系统调用和所接收的信号。 在Linux世界，进程不能直接访问硬件设备，当进程需要访问硬件设备(比如读取磁盘文件，接收网络数据等等)时，必须由用户态模式切换至内核态模式，通过系统调用访问硬件设备。strace可以跟踪到一个进程产生的系统调用,包括参数，返回值，执行消耗的时间。 GDB则主要依赖一个系统函数ptrace。 Windows上的替代物则是WinDbg的Logger.exe和wt调试命令，以及Process Monitor则工具。 中断及IO调度 Linux 设备驱动开发 —— Tasklets 机制浅析 tasklet是I/O驱动程序中实现可延迟函数的首选方法。 中断处理程序&amp;中断服务例程 Signals and interrupts a comparison Interrupts can be viewed as a mean of communication between the CPU and the OS kernel. Signals can be viewed as a mean of communication between the OS kernel and OS processes. Interrupts may be initiated by the CPU (exceptions - e.g.: divide by zero, page fault), devices (hardware interrupts - e.g: input available), or by a CPU instruction (traps - e.g: syscalls, breakpoints). They are eventually managed by the CPU, which “interrupts” the current task, and invokes an OS-kernel provided ISR/interrupt handler. Signals may be initiated by the OS kernel (e.g: SIGFPE, SIGSEGV, SIGIO), or by a process(kill()). They are eventually managed by the OS kernel, which delivers them to the target thread/process, invoking either a generic action (ignore, terminate, terminate and dump core) or a process-provided signal handler. Hardware interrupts can also generate signals, like a keyboard interrupt generates SIGINT. Thus interrupts and signals are closely tied to each other. Linux 2.4.x内核软中断机制 硬中断、软中断 中断：通常被定义成一个事件，该事件改变处理器执行的指令顺序。这样的事件与cpu芯片外部电路产生的电信号相对应。 中断的产生：每个能够发出中断请求的硬件设备控制器都有一条称为IRQ的输出线（中断线）。所有的IRQ线都与一个中断控制器的输入引脚相连，中断控制器与cpu的intr引脚相连。 中断向量：每个中断由0-255之间的一个8位数来标识。称为中断向量。 中断描述符表：IDT是一个系统表，它与每一个中断或者异常向量相联系，每一个向量在表中有相应的中断处理程 序的入口地址。cpu的idtr寄存器执行IDT表的物理基地址。 硬中断是由硬件产生的，比如，像磁盘，网卡，键盘，时钟等。每个设备或设备集都有它自己的IRQ（中断请求）。基于IRQ，CPU可以将相应的请求分发到对应的硬件驱动上（注：硬件驱动通常是内核中的一个子程序，而不是一个独立的进程）。 中断的硬件处理：在内核被init进程初始化后，cpu运行在保护模式下。当执行一条指令后，sc和eip这对寄存器包含了下一条将要执行的指令的逻辑地址。在执行这条指令之前，cpu控制单元会检查在运行前一条指令时是否发生了一个中断。如果发生了，cpu控制单元处理中断。 中断与信号的区别：软中断通常是硬中断服务程序对内核的中断。信号则是由内核或者其他进程对某个进程的中断。 硬中断可以直接中断CPU。它会引起内核中相关的代码被触发。对于那些需要花费一些时间去处理的进程，中断代码本身也可以被其他的硬中断中断。 对于时钟中断，内核调度代码会将当前正在运行的进程挂起，从而让其他的进程来运行。它的存在是为了让调度代码（或称为调度器）可以调度多任务。 软中断的处理非常像硬中断。然而，它们仅仅是由当前正在运行的进程所产生的。 软中断并不会直接中断CPU。也只有当前正在运行的代码（或进程）才会产生软中断。这种中断是一种需要内核为正在运行的进程去做一些事情（通常为I/O）的请求。有一个特殊的软中断是Yield调用，它的作用是请求内核调度器去查看是否有一些其他的进程可以运行。 int n - 触发软中断n。相应的中断处理函数的地址为：中断向量表地址 + 4 * n。软件中断处理程序是由操作系统提供的为保证系统异步执行的机制。如在linux下由用户态向内核态转换需要调用0x80软件中断。软中断是实现系统API函数调用的手段。 中断嵌套：Linux下硬中断是可以嵌套的，但是没有优先级的概念，也就是说任何一个新的中断都可以打断正在执行的中断，但同种中断除外。软中断不能嵌套，但相同类型的软中断可以在不同CPU上并行执行。 文件系统 Linux 文件系统剖析 Linux 虚拟系统文件交换器剖析 linux文件系统中superblock,inode,dentry及file的关系 需要注意的几点如下所示： 进程每打开一个文件，就会有一个file结构与之对应。同一个进程可以多次打开同一个文件而得到多个不同的file结构，file结构描述被打开文件的属性，如文件的当前偏移量等信息。 两个不同的file结构可以对应同一个dentry结构。进程多次打开同一个文件时，对应的只有一个dentry结构。Dentry结构存储目录项和对应文件（inode）的信息。 在存储介质中，每个文件对应唯一的inode结点，但是每个文件又可以有多个文件名。即可以通过不同的文件名访问同一个文件。这里多个文件名对应一个文件的关系在数据结构中表示就是dentry和inode的关系。 Inode中不存储文件的名字，它只存储节点号；而dentry则保存有名字和与其对应的节点号，所以就可以通过不同的dentry访问同一个inode。 不同的dentry则是同个文件链接（ln命令）来实现的。 How do file permissions apply to symlinks? macos不考虑，一般的linux在chmod符号链接时其实作用于指向的文件本身，但chmod在有些情况下是会跳过涉及符号链接的情况的。 Symbolic link permissions 权限是记录在inode上的，符号链接最终指向的也是同一个inode。 EXT2 文件系统 我们将 inode 与 block 区块用图解来说明一下，如下图所示，文件系统先格式化出 inode 与 block 的区块，假设某一个文件的属性与权限数据是放置到 inode 4 号(下图较小方格内)，而这个 inode 记录了文件数据的实际放置点为 2, 7, 13, 15 这四个 block 号码，此时我们的操作系统就能够据此来排列磁盘的阅读顺序，可以一口气将四个 block 内容读出来！ 那么数据的读取就如同下图中的箭头所指定的模样了。 这种数据存取的方法我们称为索引式文件系统(indexed allocation)。那有没有其他的惯用文件系统可以比较一下啊？ 有的，那就是我们惯用的闪盘(闪存)，闪盘使用的文件系统一般为 FAT 格式。FAT 这种格式的文件系统并没有 inode 存在，所以 FAT 没有办法将这个文件的所有 block 在一开始就读取出来。每个 block 号码都记录在前一个 block 当中， 他的读取方式有点像底下这样： 上图中我们假设文件的数据依序写入1-&gt;7-&gt;4-&gt;15号这四个 block 号码中， 但这个文件系统没有办法一口气就知道四个 block 的号码，他得要一个一个的将 block 读出后，才会知道下一个 block 在何处。 如果同一个文件数据写入的 block 分散的太过厉害时，则我们的磁盘读取头将无法在磁盘转一圈就读到所有的数据， 因此磁盘就会多转好几圈才能完整的读取到这个文件的内容！ 常常会听到所谓的『碎片整理』吧？ 需要碎片整理的原因就是文件写入的 block 太过于离散了，此时文件读取的效能将会变的很差所致。 这个时候可以透过碎片整理将同一个文件所属的 blocks 汇整在一起，这样数据的读取会比较容易啊！ 想当然尔，FAT 的文件系统需要经常的碎片整理一下，那么 Ext2 是否需要磁盘重整呢？ 由于 Ext2 是索引式文件系统，基本上不太需要常常进行碎片整理的。但是如果文件系统使用太久， 常常删除/编辑/新增文件时，那么还是可能会造成文件数据太过于离散的问题，此时或许会需要进行重整一下的。 每天进步一点点——Linux中的文件描述符与打开文件之间的关系 SUID(Set UID)是让执行一个可执行程序的process拥有owner的权限，如passwd程序修改/etc/passwd文件。 SGID(Set GID)可以设置在目录上，也可以设置在文件上。设置在目录上是强制本目录下新建的（一级）文件和（一级）目录的group自动变为该目录的group。而设置在文件上，则是让执行一个可执行程序的process拥有该目录group的权限。 SBIT（Sticky Bit）设置在目录上，该目录下的（一级）文件和目录只有owner和root可以删除。 Linux的chattr和lsattr可以达到和NTFS权限一样复杂的功能。 The difference between fsync() and fdatasync() is that the later does not necessarily update the meta-data associated with a file – such as the “last modified” date – but only the file data. 本文地址：https://xnerv.wang/linux-process-kernel-and-file-system-summary/","categories":[{"name":"Linux","slug":"Linux","permalink":"https://xnerv.wang/categories/Linux/"}],"tags":[{"name":"原创","slug":"原创","permalink":"https://xnerv.wang/tags/%E5%8E%9F%E5%88%9B/"},{"name":"Linux","slug":"Linux","permalink":"https://xnerv.wang/tags/Linux/"},{"name":"信号","slug":"信号","permalink":"https://xnerv.wang/tags/%E4%BF%A1%E5%8F%B7/"},{"name":"中断","slug":"中断","permalink":"https://xnerv.wang/tags/%E4%B8%AD%E6%96%AD/"},{"name":"内核态与用户态","slug":"内核态与用户态","permalink":"https://xnerv.wang/tags/%E5%86%85%E6%A0%B8%E6%80%81%E4%B8%8E%E7%94%A8%E6%88%B7%E6%80%81/"},{"name":"文件系统","slug":"文件系统","permalink":"https://xnerv.wang/tags/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"}]},{"title":"关于DLL的一些你不会想要知道的知识","slug":"everything-you-never-wanted-to-know-about-dlls-cn","date":"2017-10-23T06:16:00.000Z","updated":"2025-03-10T01:04:55.816Z","comments":true,"path":"everything-you-never-wanted-to-know-about-dlls-cn/","link":"","permalink":"https://xnerv.wang/everything-you-never-wanted-to-know-about-dlls-cn/","excerpt":"英文版本 Everything You Never Wanted To Know About DLLs. 最近因为一些原因，我需要调研动态链接在Windows平台上的实现细节。这篇文章主要是总结我在这个问题上所学到的知识，用于我将来的回顾和参考，但同时我也希望这篇文章对其他人所有帮助，因为我将要总结的这些内容，你可能需要东找西找才能找到。 废话不多说，让我们开始这趟旅程吧：","text":"英文版本 Everything You Never Wanted To Know About DLLs. 最近因为一些原因，我需要调研动态链接在Windows平台上的实现细节。这篇文章主要是总结我在这个问题上所学到的知识，用于我将来的回顾和参考，但同时我也希望这篇文章对其他人所有帮助，因为我将要总结的这些内容，你可能需要东找西找才能找到。 废话不多说，让我们开始这趟旅程吧： 导出和导入 Windows可执行文件加载器（Windows executable loader）负责在运行程序前完成所有动态加载和符号解析工作。链接器会分别计算出每一个可执行镜像（可执行镜像是一个DLL或者一个EXE文件）导出和导入了哪些函数，这个过程是通过检查可执行镜像的.edata段和.idata段来进行的。 关于.edata段和.idata段的详细信息，在PE/COFF specification这篇文档中有详细说明。 .edata段 .edata段记录了可执行镜像导出的符号（是的，EXE也可以导出符号）。主要包括： 导出地址表（export address table）：一个长度为N的数组，保存了导出的函数/变量的地址（相对于可执行镜像起始地址的相关地址）。这张表的索引称之为序号（ordinals）。 导出名称地址表（export name pointer table）：一个长度为M的并行数组（译者记：其实就是两个大小一样的数组，一个保存key，一个保存对应的value），保存的是符号地址到导出名称的映射。这个平行数组是按照导出名称的字典序排序的，从而允许进行对一个给定的导出符号名称进行二分查找。 导出序号表（export ordinal table）：也是一个长度为M的并行数组，保存了序号到对应的导出名称的映射，其中导出名称对应的是导出名称地址表中的键key。 （作为通过名称导入符号这一做法的另一种替代方法，也可以通过指定序号来导入一个符号。通过序号来导入符号的做法在运行时会稍微快一些，因为这种情况下动态链接器（dynamic linker）不需要进行查找（译者记：根据名称在导出名称地址表中找到名称对应的地址）。此外，如果导出符号的DLL并没有给某个导出项分配名称，那么通过序号来导入符号是唯一的可行之路。） 那么.edata段最初是怎样被创建的呢？主要有两种方法： 最常见的一种情况，在编译生成一些目标文件（object files）时会创建.edata段。这些目标文件对应的源码中，定义了一些带__declspec(dllimport)修饰符的函数或者变量。于是编译器就会产生一个包含了这些导出项的.edata段。 另一种比较少见的情况，开发人员会写一个.def文件，指定那些函数需要被导出。将这个.def文件提供给dll tool --output-exp，就能产生一个导出文件（export file）。导出文件是一个仅包含.edata段的目标文件，导出了在.def文件中声明的符号（导出了一些未解析的引用，通常链接器会填写这些引用到一个实际的地址）。程序员在将这些目标文件链接成DLL的时候，必须对这些导出库（export library）进行命名。 对于以上两种情况，链接器在链接时都会从所有的目标（objects）中收集.edata段，用于给整个可执行镜像文件创建一个.edata段。最后一种可能的方式是.edata段可以被链接器自身所创建，不需要将.edata段放入到任何目标文件中： 链接器可以选择在链接时导出目标文件中的所有符号。例如，这是GNU ld的默认行为（也可以通过–export-all-symbols显式地指定这种行为）。在这种情况下，由链接器来产生.edata段。（GNU ld也支持在命令行中指定一个.def文件，然后产生的.edata段就只会导出这个.def文件中声明的符号）。 .idata段 .idata段记录了可执行镜像导入的符号信息。包括： 对于导入符号涉及到的每一个可执行镜像： 可执行镜像的文件名。被动态链接器用于在磁盘上查找该文件。 导入符号查找表（import lookup table）：一个长度为N的数组，每一项要么是一个序号，要么是一个指向导入名称字符串的指针。 导入符号地址表（import address table）：一个长度为N的指针数组。动态链接器会用从导入符号查找表中对应顺序的符号的地址来填写该数组。 .idata段中的条目以如下方式被创建： 最常见的一种情况，这些条目来自目标文件中的导入库（import library）。可以对你希望导出符号的DLL或者我们之前讨论过的.def文件使用dlltool工具来创建导入库。和导出库一样，用户必须在链接这些导入库时指定名称。 或者，有一些链接器（像GNU ld）也可以让你在链接时直接指定DLL文件。对于你需要从这些DLL文件中导入的符号，链接器会自动产生相应的.idata段条目。 注意，跟导出符号不一样，__declspec(dllimport)修饰符并不会导致产生相应的.idata段。 比起第一次出现，导入库有点更复杂了。Windows动态加载器将导入符号（例如，函数Func的地址）的地址填入到导入符号地址表中。然而，当其它目标文件中的汇编代码执行call Func时，它们期待的是用Func来命名那段code的地址。但我们直到运行时的时候才知道这个地址：我们能够静态地得知的事情只有动态链接器会将这个地址存放在哪个地方。我们称这个地方为_imp_Func。 为了处理这一层额外的中间层，导入库导出的函数Func仅仅间接引用了_imp_Func（来获得实际的函数指针），然后执行jmp跳转到它。同一个工程中的所有其它的目标文件现在可以调用call Func，仿佛Func已经在其它目标文件而不是其它DLL中定义过了一样。基于这个原因，动态链接的函数的声明上的__declspec(dllimport)只是可有可无的（尽管实际上如果加上这个修饰符的话，代码的效率会有轻微的提升，我们之后会谈到这一点）。 不幸的是，如果你想要从另一个DLL中导入变量，则并没有类似的技巧。如果我们有一个导入的变量myData，并没有一种方法来定义一个导入库，使得链接到这个导入库的目标文件可以通过执行mov $eax, myData来写入到myData所在的内存位置。取而代之的是，导入库定义了一个符号__imp__myData，这个符号解析到一个可以找到myData链接地址的地方。然后编译器就会保证当你在读写用__declspec(dllimport)定义的变量时，这些读写其实是通过__imp_myData来间接进行的。因为需要在使用的时候再产生不同的代码，因此在导入变量时的__declspec声明是不可省去的。 应用实例 理论都很好，但在实践中看看所有这些的这些部分会对我们很有帮助。 构建DLL 首先，让我们来构建一个简单的DLL，同时导出了函数和变量。为了最大化地进行说明，我们将使用显式地导出库，而不是用declspec(dllexport)来修饰我们的函数，也不是提供一个.def文件给链接器。 先创建一个.def文件，library.def： 1234LIBRARY libraryEXPORTS function_export data_export DATA （DATA关键词和LIBRARY这一行仅仅影响到导入库如何被产生，之后本文会解释这一点。现在请暂时忽略这个。） 然后构建一个导出文件： 1$ dlltool --output-exp library_exports.o -d library.def 产生的目标文件基本上只包含了一个.edata段，导出了符号_data_export和_function_export，名称分别是data_export和function_export： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778$ objdump -xs library_exports.o...There is an export table in .edata at 0x0The Export Tables (interpreted .edata section contents)Export Flags 0Time/Date stamp 4e10e5c1Major/Minor 0/0Name 00000028 library_exports.o.dllOrdinal Base 1Number in: Export Address Table 00000002 [Name Pointer/Ordinal] Table 00000002Table Addresses Export Address Table 00000040 Name Pointer Table 00000048 Ordinal Table 00000050Export Address Table -- Ordinal Base 1[Ordinal/Name Pointer] Table [ 0] data_export [ 1] function_exportSections:Idx Name Size VMA LMA File off Algn 0 .text 00000000 00000000 00000000 00000000 2**2 ALLOC, LOAD, READONLY, CODE 1 .data 00000000 00000000 00000000 00000000 2**2 ALLOC, LOAD, DATA 2 .bss 00000000 00000000 00000000 00000000 2**2 ALLOC 3 .edata 00000070 00000000 00000000 000000b4 2**2 CONTENTS, ALLOC, LOAD, RELOC, READONLY, DATASYMBOL TABLE:[ 0](sec -2)(fl 0x00)(ty 0)(scl 103) (nx 1) 0x00000000 fakeFile[ 2](sec 4)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000028 name[ 3](sec 4)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000040 afuncs[ 4](sec 4)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000048 anames[ 5](sec 4)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000050 anords[ 6](sec 4)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000054 n1[ 7](sec 4)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000060 n2[ 8](sec 1)(fl 0x00)(ty 0)(scl 3) (nx 1) 0x00000000 .textAUX scnlen 0x0 nreloc 0 nlnno 0[ 10](sec 2)(fl 0x00)(ty 0)(scl 3) (nx 1) 0x00000000 .dataAUX scnlen 0x0 nreloc 0 nlnno 0[ 12](sec 3)(fl 0x00)(ty 0)(scl 3) (nx 1) 0x00000000 .bssAUX scnlen 0x0 nreloc 0 nlnno 0[ 14](sec 4)(fl 0x00)(ty 0)(scl 3) (nx 1) 0x00000000 .edataAUX scnlen 0x70 nreloc 8 nlnno 0[ 16](sec 0)(fl 0x00)(ty 0)(scl 2) (nx 0) 0x00000000 _data_export[ 17](sec 0)(fl 0x00)(ty 0)(scl 2) (nx 0) 0x00000000 _function_exportRELOCATION RECORDS FOR [.edata]:OFFSET TYPE VALUE0000000c rva32 .edata0000001c rva32 .edata00000020 rva32 .edata00000024 rva32 .edata00000040 rva32 _data_export00000044 rva32 _function_export00000048 rva32 .edata0000004c rva32 .edataContents of section .edata: 0000 00000000 c1e5104e 00000000 28000000 .......N....(... 0010 01000000 02000000 02000000 40000000 ............@... 0020 48000000 50000000 6c696272 6172795f H...P...library_ 0030 6578706f 7274732e 6f2e646c 6c000000 exports.o.dll... 0040 00000000 00000000 54000000 60000000 ........T...`... 0050 00000100 64617461 5f657870 6f727400 ....data_export. 0060 66756e63 74696f6e 5f657870 6f727400 function_export. 我们将会用一个简单的DLL实现来提供这些符号，library.c： 12345int data_export = 42;int function_export() &#123; return 1337 + data_export;&#125; 打包到一个DLL中： 1$ gcc -shared -o library.dll library.c library_exports.o 这个DLL的导出符号表如下，可见我们已经导出了我们所需的符号信息： 12345678910111213141516171819202122The Export Tables (interpreted .edata section contents)Export Flags 0Time/Date stamp 4e10e5c1Major/Minor 0/0Name 00005028 library_exports.o.dllOrdinal Base 1Number in: Export Address Table 00000002 [Name Pointer/Ordinal] Table 00000002Table Addresses Export Address Table 00005040 Name Pointer Table 00005048 Ordinal Table 00005050Export Address Table -- Ordinal Base 1 [ 0] +base[ 1] 200c Export RVA [ 1] +base[ 2] 10f0 Export RVA[Ordinal/Name Pointer] Table [ 0] data_export [ 1] function_export 使用DLL 当我们回过头来看看如何使用DLL时，事情变得更有有趣了。首先，我们需要一个导出库： 1$ dlltool --output-lib library.dll.a -d library.def （我们使用导入库library.dll.a而不是直接使用导出符号的对象文件library_exports.o，是因为使用库来导入允许链接器忽略.idata段中并没有被使用到的符号。而相反的是链接器无法忽略.edata段中的任何符号，因为任何一个符号都可能被这个DLL的使用者用到）。 导入库是相当复杂的。对于每一个导入符号，导入库中都包含一个对应的目标文件（disds00000.o和disds00001.o），同时也包含了其它两个目标文件（distdt.o和disdh.o），用于设立导入列表的头部和尾部。（导入列表的头部除了其它的一些东西，还包含了在运行时需要链接的DLL的名字，这是从.def文件的LIBRARY一行派生而来的。） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214$ objdump -xs library.dll.aIn archive library.dll.a:disdt.o: file format pe-i386...Sections:Idx Name Size VMA LMA File off Algn 0 .text 00000000 00000000 00000000 00000000 2**2 ALLOC, LOAD, READONLY, CODE 1 .data 00000000 00000000 00000000 00000000 2**2 ALLOC, LOAD, DATA 2 .bss 00000000 00000000 00000000 00000000 2**2 ALLOC 3 .idata$4 00000004 00000000 00000000 00000104 2**2 CONTENTS, ALLOC, LOAD, DATA 4 .idata$5 00000004 00000000 00000000 00000108 2**2 CONTENTS, ALLOC, LOAD, DATA 5 .idata$7 0000000c 00000000 00000000 0000010c 2**2 CONTENTS, ALLOC, LOAD, DATASYMBOL TABLE:[ 0](sec -2)(fl 0x00)(ty 0)(scl 103) (nx 1) 0x00000000 fakeFile[ 2](sec 1)(fl 0x00)(ty 0)(scl 3) (nx 1) 0x00000000 .textAUX scnlen 0x0 nreloc 0 nlnno 0[ 4](sec 2)(fl 0x00)(ty 0)(scl 3) (nx 1) 0x00000000 .dataAUX scnlen 0x0 nreloc 0 nlnno 0[ 6](sec 3)(fl 0x00)(ty 0)(scl 3) (nx 1) 0x00000000 .bssAUX scnlen 0x0 nreloc 0 nlnno 0[ 8](sec 4)(fl 0x00)(ty 0)(scl 3) (nx 1) 0x00000000 .idata$4AUX scnlen 0x4 nreloc 0 nlnno 0[ 10](sec 5)(fl 0x00)(ty 0)(scl 3) (nx 1) 0x00000000 .idata$5AUX scnlen 0x4 nreloc 0 nlnno 0[ 12](sec 6)(fl 0x00)(ty 0)(scl 3) (nx 1) 0x00000000 .idata$7AUX scnlen 0x7 nreloc 0 nlnno 0[ 14](sec 6)(fl 0x00)(ty 0)(scl 2) (nx 0) 0x00000000 __library_dll_a_inameContents of section .idata$4: 0000 00000000 ....Contents of section .idata$5: 0000 00000000 ....Contents of section .idata$7: 0000 6c696272 6172792e 646c6c00 library.dll.disdh.o: file format pe-i386...Sections:Idx Name Size VMA LMA File off Algn 0 .text 00000000 00000000 00000000 00000000 2**2 ALLOC, LOAD, READONLY, CODE 1 .data 00000000 00000000 00000000 00000000 2**2 ALLOC, LOAD, DATA 2 .bss 00000000 00000000 00000000 00000000 2**2 ALLOC 3 .idata$2 00000014 00000000 00000000 00000104 2**2 CONTENTS, ALLOC, LOAD, RELOC, DATA 4 .idata$5 00000000 00000000 00000000 00000000 2**2 ALLOC, LOAD, DATA 5 .idata$4 00000000 00000000 00000000 00000000 2**2 ALLOC, LOAD, DATASYMBOL TABLE:[ 0](sec -2)(fl 0x00)(ty 0)(scl 103) (nx 1) 0x00000000 fakeFile[ 2](sec 6)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000000 hname[ 3](sec 5)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000000 fthunk[ 4](sec 1)(fl 0x00)(ty 0)(scl 3) (nx 1) 0x00000000 .textAUX scnlen 0x0 nreloc 0 nlnno 0[ 6](sec 2)(fl 0x00)(ty 0)(scl 3) (nx 1) 0x00000000 .dataAUX scnlen 0x0 nreloc 0 nlnno 0[ 8](sec 3)(fl 0x00)(ty 0)(scl 3) (nx 1) 0x00000000 .bssAUX scnlen 0x0 nreloc 0 nlnno 0[ 10](sec 4)(fl 0x00)(ty 0)(scl 3) (nx 1) 0x00000000 .idata$2AUX scnlen 0x14 nreloc 3 nlnno 0[ 12](sec 6)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000000 .idata$4[ 13](sec 5)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000000 .idata$5[ 14](sec 4)(fl 0x00)(ty 0)(scl 2) (nx 0) 0x00000000 __head_library_dll_a[ 15](sec 0)(fl 0x00)(ty 0)(scl 2) (nx 0) 0x00000000 __library_dll_a_inameRELOCATION RECORDS FOR [.idata$2]:OFFSET TYPE VALUE00000000 rva32 .idata$40000000c rva32 __library_dll_a_iname00000010 rva32 .idata$5Contents of section .idata$2: 0000 00000000 00000000 00000000 00000000 ................ 0010 00000000 ....disds00001.o: file format pe-i386...Sections:Idx Name Size VMA LMA File off Algn 0 .text 00000008 00000000 00000000 0000012c 2**2 CONTENTS, ALLOC, LOAD, RELOC, READONLY, CODE 1 .data 00000000 00000000 00000000 00000000 2**2 ALLOC, LOAD, DATA 2 .bss 00000000 00000000 00000000 00000000 2**2 ALLOC 3 .idata$7 00000004 00000000 00000000 00000134 2**2 CONTENTS, RELOC 4 .idata$5 00000004 00000000 00000000 00000138 2**2 CONTENTS, RELOC 5 .idata$4 00000004 00000000 00000000 0000013c 2**2 CONTENTS, RELOC 6 .idata$6 00000012 00000000 00000000 00000140 2**1 CONTENTSSYMBOL TABLE:[ 0](sec 1)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000000 .text[ 1](sec 2)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000000 .data[ 2](sec 3)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000000 .bss[ 3](sec 4)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000000 .idata$7[ 4](sec 5)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000000 .idata$5[ 5](sec 6)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000000 .idata$4[ 6](sec 7)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000000 .idata$6[ 7](sec 1)(fl 0x00)(ty 0)(scl 2) (nx 0) 0x00000000 _function_export[ 8](sec 5)(fl 0x00)(ty 0)(scl 2) (nx 0) 0x00000000 __imp__function_export[ 9](sec 0)(fl 0x00)(ty 0)(scl 2) (nx 0) 0x00000000 __head_library_dll_aRELOCATION RECORDS FOR [.text]:OFFSET TYPE VALUE00000002 dir32 .idata$5RELOCATION RECORDS FOR [.idata$7]:OFFSET TYPE VALUE00000000 rva32 __head_library_dll_aRELOCATION RECORDS FOR [.idata$5]:OFFSET TYPE VALUE00000000 rva32 .idata$6RELOCATION RECORDS FOR [.idata$4]:OFFSET TYPE VALUE00000000 rva32 .idata$6Contents of section .text: 0000 ff250000 00009090 .%......Contents of section .idata$7: 0000 00000000 ....Contents of section .idata$5: 0000 00000000 ....Contents of section .idata$4: 0000 00000000 ....Contents of section .idata$6: 0000 01006675 6e637469 6f6e5f65 78706f72 ..function_expor 0010 7400 t.disds00000.o: file format pe-i386...Sections:Idx Name Size VMA LMA File off Algn 0 .text 00000000 00000000 00000000 00000000 2**2 ALLOC, LOAD, READONLY, CODE 1 .data 00000000 00000000 00000000 00000000 2**2 ALLOC, LOAD, DATA 2 .bss 00000000 00000000 00000000 00000000 2**2 ALLOC 3 .idata$7 00000004 00000000 00000000 0000012c 2**2 CONTENTS, RELOC 4 .idata$5 00000004 00000000 00000000 00000130 2**2 CONTENTS, RELOC 5 .idata$4 00000004 00000000 00000000 00000134 2**2 CONTENTS, RELOC 6 .idata$6 0000000e 00000000 00000000 00000138 2**1 CONTENTSSYMBOL TABLE:[ 0](sec 1)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000000 .text[ 1](sec 2)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000000 .data[ 2](sec 3)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000000 .bss[ 3](sec 4)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000000 .idata$7[ 4](sec 5)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000000 .idata$5[ 5](sec 6)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000000 .idata$4[ 6](sec 7)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000000 .idata$6[ 7](sec 5)(fl 0x00)(ty 0)(scl 2) (nx 0) 0x00000000 __imp__data_export[ 8](sec 0)(fl 0x00)(ty 0)(scl 2) (nx 0) 0x00000000 __head_library_dll_aRELOCATION RECORDS FOR [.idata$7]:OFFSET TYPE VALUE00000000 rva32 __head_library_dll_aRELOCATION RECORDS FOR [.idata$5]:OFFSET TYPE VALUE00000000 rva32 .idata$6RELOCATION RECORDS FOR [.idata$4]:OFFSET TYPE VALUE00000000 rva32 .idata$6Contents of section .idata$7: 0000 00000000 ....Contents of section .idata$5: 0000 00000000 ....Contents of section .idata$4: 0000 00000000 ....Contents of section .idata$6: 0000 00006461 74615f65 78706f72 7400 ..data_export. 注意data_export对应的目标包含一个空的.text段，然而function_export却有定义一些代码。如果我们反汇编就会看到： 1234500000000 &lt;_function_export&gt;: 0: ff 25 00 00 00 00 jmp *0x0 2: dir32 .idata$5 6: 90 nop 7: 90 nop 类型dir32的重定位告诉链接器如何填写被jmp间接引用的地址。我们可以看到当进入_function_export时，会直接跳到从名为.idata$5的内存处读取的地址。通过彻底地检查.idata段，可以发现.idata$5对应的是导入地址表中function_export这个导入名称所对应的地址，于是就能找到加载的导入项function_export的绝对地址。 虽然只有function_export拥有一个对应的_function_export函数，但是以上的两个导入项在导入库中分别对应了一个符号，这个符号的名称带有__imp__前缀（__imp__data_export和__imp__function_export)。就像我们之前探讨过的那样，这个符号代表了一个内存地址，这个地址中存放的是的指向函数或变量的指针，这个指针值由动态链接器负责填写。 通过一个导入库，我们就可以写一个使用这些导出函数的代码，例如这个main1.c： 12345678910111213141516#include &lt;stdio.h&gt;__declspec(dllimport) extern int function_export(void);__declspec(dllimport) extern int data_export;int main(int argc, char **argv) &#123; printf(&quot;%d\\n&quot;, function_export()); printf(&quot;%d\\n&quot;, data_export); data_export++; printf(&quot;%d\\n&quot;, function_export()); printf(&quot;%d\\n&quot;, data_export); return 0;&#125; 编译这段代码并连接导入库，我们就会得到我们期待的结果： 12345$ gcc main1.c library.dll.a -o main1 &amp;&amp; ./main1137942138043 之所以library.dll.a内没有定义data_export符号而这段代码仍能编译，是因为main.c文件中的data_export声明上的__declspec(dllimport)修饰符导致编译器生成了直接使用__imp_data_export符号的代码，反汇编的话我们就会看到： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465$ gcc -c main1.c -o main1.o &amp;&amp; objdump --disassemble -r main1.omain1.o: file format pe-i386Disassembly of section .text:00000000 &lt;_main&gt;: 0: 8d 4c 24 04 lea 0x4(%esp),%ecx 4: 83 e4 f0 and $0xfffffff0,%esp 7: ff 71 fc pushl -0x4(%ecx) a: 55 push %ebp b: 89 e5 mov %esp,%ebp d: 51 push %ecx e: 83 ec 14 sub $0x14,%esp 11: e8 00 00 00 00 call 16 &lt;_main+0x16&gt; 12: DISP32 ___main 16: a1 00 00 00 00 mov 0x0,%eax 17: dir32 __imp__function_export 1b: ff d0 call *%eax 1d: 89 44 24 04 mov %eax,0x4(%esp) 21: c7 04 24 00 00 00 00 movl $0x0,(%esp) 24: dir32 .rdata 28: e8 00 00 00 00 call 2d &lt;_main+0x2d&gt; 29: DISP32 _printf 2d: a1 00 00 00 00 mov 0x0,%eax 2e: dir32 __imp__data_export 32: 8b 00 mov (%eax),%eax 34: 89 44 24 04 mov %eax,0x4(%esp) 38: c7 04 24 00 00 00 00 movl $0x0,(%esp) 3b: dir32 .rdata 3f: e8 00 00 00 00 call 44 &lt;_main+0x44&gt; 40: DISP32 _printf 44: a1 00 00 00 00 mov 0x0,%eax 45: dir32 __imp__data_export 49: 8b 00 mov (%eax),%eax 4b: 8d 50 01 lea 0x1(%eax),%edx 4e: a1 00 00 00 00 mov 0x0,%eax 4f: dir32 __imp__data_export 53: 89 10 mov %edx,(%eax) 55: a1 00 00 00 00 mov 0x0,%eax 56: dir32 __imp__function_export 5a: ff d0 call *%eax 5c: 89 44 24 04 mov %eax,0x4(%esp) 60: c7 04 24 00 00 00 00 movl $0x0,(%esp) 63: dir32 .rdata 67: e8 00 00 00 00 call 6c &lt;_main+0x6c&gt; 68: DISP32 _printf 6c: a1 00 00 00 00 mov 0x0,%eax 6d: dir32 __imp__data_export 71: 8b 00 mov (%eax),%eax 73: 89 44 24 04 mov %eax,0x4(%esp) 77: c7 04 24 00 00 00 00 movl $0x0,(%esp) 7a: dir32 .rdata 7e: e8 00 00 00 00 call 83 &lt;_main+0x83&gt; 7f: DISP32 _printf 83: b8 00 00 00 00 mov $0x0,%eax 88: 83 c4 14 add $0x14,%esp 8b: 59 pop %ecx 8c: 5d pop %ebp 8d: 8d 61 fc lea -0x4(%ecx),%esp 90: c3 ret 91: 90 nop 92: 90 nop 93: 90 nop 实际上，我们可以看到生成的代码甚至都没有使用_function_export符号，取而代之的是使用了imp__function_export。本质上，导入库中的_function_export符号在每处使用的地方都已经被内联过了。这也就是为什么使用__declspec(dllimport)可以提高跨DLL调用的性能，不过这个修饰符在声明函数时不是必须写的。 我们也许会好奇，如果在声明时去掉__declspec(dllimport)修饰符会发生什么事情。鉴于我们之前讨论的关于导入变量和导入函数之间的差别，你也许以为会链接失败。我们的测试文件main2.c是： 12345678910111213141516#include &lt;stdio.h&gt;extern int function_export(void);extern int data_export;int main(int argc, char **argv) &#123; printf(&quot;%d\\n&quot;, function_export()); printf(&quot;%d\\n&quot;, data_export); data_export++; printf(&quot;%d\\n&quot;, function_export()); printf(&quot;%d\\n&quot;, data_export); return 0;&#125; 让我们来试一试： 12345$ gcc main2.c library.dll.a -o main2 &amp;&amp; ./main2137942138043 见鬼了！编译居然通过了？这有点令人惊讶。之所以导入库library.dll.a没有定义_data_export符号但这仍能编译通过，是由于GNU ld的一个叫做自动导入的有趣的特性。如果没有自动导入特性，链接器就会如我们所愿地报错： 123456$ gcc main2.c library.dll.a -o main2 -Wl,--disable-auto-import &amp;&amp; ./main2/tmp/ccGd8Urx.o:main2.c:(.text+0x2c): undefined reference to `_data_export&#x27;/tmp/ccGd8Urx.o:main2.c:(.text+0x41): undefined reference to `_data_export&#x27;/tmp/ccGd8Urx.o:main2.c:(.text+0x49): undefined reference to `_data_export&#x27;/tmp/ccGd8Urx.o:main2.c:(.text+0x63): undefined reference to `_data_export&#x27;collect2: ld returned 1 exit status 微软的链接器没有实现自动导入的特性，因此如果你用的是微软的工具链的话，你就会看到类似的错误信息。 然而，有一个方法可以使得在写代码时既不用依赖于自动导入的特定，也不用使用__declspec(dllimport)关键字。我们新的代码main3.c就是这么写的： 12345678910111213141516171819#include &lt;stdio.h&gt;extern int (*_imp__function_export)(void);extern int *_imp__data_export;#define function_export (*_imp__function_export)#define data_export (*_imp__data_export)int main(int argc, char **argv) &#123; printf(&quot;%d\\n&quot;, function_export()); printf(&quot;%d\\n&quot;, data_export); data_export++; printf(&quot;%d\\n&quot;, function_export()); printf(&quot;%d\\n&quot;, data_export); return 0;&#125; 在这段代码中，我们直接使用了源自导入库中的带__imp__前缀的符号。这些符号对应的是导入函数和导入变量的真实内存地址，就像代码中的预处理宏定义data_export和function_export所表示的那样。 即使没有自动编译特性，这段代码也能完美地编译通过： 12345$ gcc main3.c library.dll.a -o main3 -Wl,--disable-auto-import &amp;&amp; ./main3137942138043 如果你一直阅读到了这里，你应该已经对Windows上上DLL的导入和导出有了透彻的理解。 本文地址：https://xnerv.wang/everything-you-never-wanted-to-know-about-dlls-cn/","categories":[{"name":"Windows","slug":"Windows","permalink":"https://xnerv.wang/categories/Windows/"}],"tags":[{"name":"Windows","slug":"Windows","permalink":"https://xnerv.wang/tags/Windows/"},{"name":"DLL","slug":"DLL","permalink":"https://xnerv.wang/tags/DLL/"},{"name":"译文","slug":"译文","permalink":"https://xnerv.wang/tags/%E8%AF%91%E6%96%87/"}]},{"title":"IOCP的使用和技术内幕","slug":"iocp-usage-and-inside","date":"2017-10-23T04:40:00.000Z","updated":"2025-03-10T01:04:55.815Z","comments":true,"path":"iocp-usage-and-inside/","link":"","permalink":"https://xnerv.wang/iocp-usage-and-inside/","excerpt":"IOCP wiki 使用CreateIoCompletionPort函数创建IOCP，还可以把socket或文件句柄与IOCP关联起来。 一个线程，第一次调用GetQueuedCompletionStatus函数时，该线程变为关联了该IOCP的线程，直道下述三种情形之一发生： 该线程退出； 该线程调用GetQueuedCompletionStatus函数关联到其他的IOCP； 该IOCP被关闭。 即，一个线程在任何时刻最多关联一个IOCP。","text":"IOCP wiki 使用CreateIoCompletionPort函数创建IOCP，还可以把socket或文件句柄与IOCP关联起来。 一个线程，第一次调用GetQueuedCompletionStatus函数时，该线程变为关联了该IOCP的线程，直道下述三种情形之一发生： 该线程退出； 该线程调用GetQueuedCompletionStatus函数关联到其他的IOCP； 该IOCP被关闭。 即，一个线程在任何时刻最多关联一个IOCP。 线程调用GetQueuedCompletionStatus函数等待放入IOCP的I/O完成包（completion packet）。IOCP拥有一个线程池。阻塞在IOCP上的线程按照后进先出（LIFO）顺序被释放（这是为了减少线程切换的代价）；而一个线程的完成包按照先进先出（FIFO）顺序从IOCP的队列中取走。IOCP有一个最大允许并发的线程数量上限，在CreateIoCompletionPort函数中制定，每次I/O完成包在从队列取走前检查关联与该IOCP且正在并发执行的线程数量是否达到该限。因其他原因（如调用SuspendThread函数）而挂起的线程不算作正在执行的线程。CompletionKey(完成键)一般作为“单句柄数据”的结构体（PER_HANDLE_DATA），用来标识是哪个设备的I/O完成操作己经完成。IO重叠结构（Overlapped）一般作为“单IO数据”的结构体（PER_IO_DATA），该结构体的第1个成员为OVERLAPPED结构体，用来标识是设备的具体哪个操作。 线程可以用PostQueuedCompletionStatus函数在IOCP上放置一个完成包。 IOCP不能跨进程使用。 关闭IOCP之前，必须先关闭关联在该IOCP之上的所有File Handle或socket。 内部结构 Windows中利用CreateIoCompletionPort命令创建完成端口对象时， 操作系统内部为该对象自动创建了5个数据结构，分别是： 设备列表（Device List）： 每当调用CreateIoCompletionPort函数时，操作系统会将该设备句柄添加到设备列表中；每当调用CloseHandle关闭了某个设备句柄时，系统会将该设句柄从设备列表中删除 IO完成请求队列（I/O Completion Queue-FIFO）：当I/O请求操作完成时，或者调用了PostQueuedCompeltionStatus函数时，操作系统会将I/O请求完成包添加到I/O完成队列中。当操作系统从完成端口对象的等待线程队列中取出一个工作线程时，操作系统会同时从I/O完成队列中取出一个元素（I/O请求完成包。 等待线程队列（WaitingThread List-LIFO）：当线程中调用GetQueuedCompletionStatus函数时，操作系统会将该线程压入到等待* 线程队列中。为了减少线程切换，该队列是LIFO。当I/O完成队列非空，且工作线程并未超出总的并发数时，系统从等待线程队列中取出线程，该线程从自身代码的GetQueuedCompletoinStatus函数调用处返回并继续运行。 释放线程队列（Released Thread List）：当操作系统从等待线程队列中激活了一个工作线程时，或者挂起的线程重新被激活时，该线程被压入释放线程队列中，也即这个队列的线程处于运行状态。这个队列中的线程有两个出队列的机会：一是当线程重新调用GetQueuedCompeltionStatus函数时，线程被添加到等待线程队列中；二是当线程调用其他函数使得线程挂起时，该线程被添加到挂起线程队列中。 暂停线程队列（Paused Thread List）：释放线程队列中的线程被挂起的时候，线程被压入到挂起线程队列中；当挂起的线程重新被唤醒时，从挂起线程队列中取出放入到释放线程队列。 IOCP 浅析 IOCP 实现的基本步骤 那么 IOCP 完成端口模型又是怎样实现的呢？首先我们创建一个完成端口 CreateIOCompletionPort，然后再创建一个或多个工作线程，并指定它们到这个完成端口上去读取数据。再将远程连接的套接字句柄关联到这个完成端口。工作线程调用 getQueuedCompletionStatus 方法在关联到这个完成端口上的所有套接字上等待 I/O 的完成，再判断完成了什么类型的 I/O，然后接着发出 WSASend 和 WSARecv，并继续下一次循环阻塞在 getQueuedCompletionStatus。 具体的说，一个完成端口大概的处理流程包括： 创建一个完成端口； 1Port port = createIoCompletionPort(INVALID_HANDLE_VALUE, 0, 0, fixedThreadCount()); 创建一个线程 ThreadA； ThreadA 线程循环调用 GetQueuedCompletionStatus 方法来得到 I/O 操作结果，这个方法是一个阻塞方法； 123While(true)&#123; getQueuedCompletionStatus(port, ioResult);&#125; 主线程循环调用 accept 等待客户端连接上来； 主线程 accept 返回新连接建立以后，把这个新的套接字句柄用 CreateIoCompletionPort 关联到完成端口，然后发出一个异步的 Read 或者 Write 调用，因为是异步函数，Read/Write 会马上返回，实际的发送或者接收数据的操作由操作系统去做。 123if (handle != 0L) &#123; createIoCompletionPort(handle, port, key, 0); &#125; 主线程继续下一次循环，阻塞在 accept 这里等待客户端连接。 操作系统完成 Read 或者 Write 的操作，把结果发到完成端口。 ThreadA 线程里的 GetQueuedCompletionStatus() 马上返回，并从完成端口取得刚完成的 Read/Write 的结果。 在 ThreadA 线程里对这些数据进行处理 ( 如果处理过程很耗时，需要新开线程处理 )，然后接着发出 Read/Write，并继续下一次循环阻塞在 GetQueuedCompletionStatus() 这里。 更多参考 《Windows.Internals.Part.2.6th.Edition》 - CHAPTER 8: I/O System - I/O Completion Ports 本文地址：https://xnerv.wang/iocp-usage-and-inside/","categories":[{"name":"Windows","slug":"Windows","permalink":"https://xnerv.wang/categories/Windows/"}],"tags":[{"name":"原创","slug":"原创","permalink":"https://xnerv.wang/tags/%E5%8E%9F%E5%88%9B/"},{"name":"Windows","slug":"Windows","permalink":"https://xnerv.wang/tags/Windows/"},{"name":"Windows Internals","slug":"Windows-Internals","permalink":"https://xnerv.wang/tags/Windows-Internals/"},{"name":"IOCP","slug":"IOCP","permalink":"https://xnerv.wang/tags/IOCP/"}]},{"title":"一些基础的C++豆知识","slug":"cpp-bean-knowledge","date":"2017-07-23T23:34:00.000Z","updated":"2025-03-10T01:04:55.824Z","comments":true,"path":"cpp-bean-knowledge/","link":"","permalink":"https://xnerv.wang/cpp-bean-knowledge/","excerpt":"基础语法 由于C++的枚举不像C#中的枚举，其枚举类型名并不是标识符的一部分，因此经常可能发生命名冲突的问题，解决的方法有四个：在枚举元素名称前加限定前缀（如enum EnumFruit { EnumFruit_apple = 1 };），将枚举类型放在一个同名的命名空间中，或将枚举作为类的嵌套类型，或者使用C++11的enum class（What’s an enum class and why should I care?）。 struct和class的默认类继承方式都是private，这与struct的成员默认继承方式是public是不同的。 #include_next &lt;filename.h&gt;，include位于搜索路径中位于当前文件之后的文件filename.h。 在vc中，inlucde的路径的反斜杠不需要转义，如#include &quot;..\\..\\..\\Global\\Data\\GlobalPreferencesMgr.h&quot;。 对于namespace中的函数或class的前置声明，必须同样也包括在相同的namespace中，而不能用class ::std::A这种写法。（Why can’t I forward-declare a class in a namespace like this?） 没有&amp;&amp;=，只有&amp;=。 （-1 || 0） == 1，请想想为什么。","text":"基础语法 由于C++的枚举不像C#中的枚举，其枚举类型名并不是标识符的一部分，因此经常可能发生命名冲突的问题，解决的方法有四个：在枚举元素名称前加限定前缀（如enum EnumFruit { EnumFruit_apple = 1 };），将枚举类型放在一个同名的命名空间中，或将枚举作为类的嵌套类型，或者使用C++11的enum class（What’s an enum class and why should I care?）。 struct和class的默认类继承方式都是private，这与struct的成员默认继承方式是public是不同的。 #include_next &lt;filename.h&gt;，include位于搜索路径中位于当前文件之后的文件filename.h。 在vc中，inlucde的路径的反斜杠不需要转义，如#include &quot;..\\..\\..\\Global\\Data\\GlobalPreferencesMgr.h&quot;。 对于namespace中的函数或class的前置声明，必须同样也包括在相同的namespace中，而不能用class ::std::A这种写法。（Why can’t I forward-declare a class in a namespace like this?） 没有&amp;&amp;=，只有&amp;=。 （-1 || 0） == 1，请想想为什么。 位移 在C语言中，涉及位移的运算符有2个，&gt;&gt;表示右移，&lt;&lt;则表示左移。 而汇编指令中，SHL和SHR表示逻辑左移和逻辑右移，SAR和SAL表示算术左移和算术右移。 其中，逻辑左移和算术左移都是寄存器二进制位整体向左移动，并在右边补0。 而右移则不同，逻辑右移是整体向右移，并在左边补0，而算术左移则是根据原符号位的值补与其相同的值。 那么如何在C语言中分别实现逻辑和算术位移呢？根据C标准，如果在位移运算符左边的变量是有符号数，如int,char,short等，编译产生的汇编指令是算术位移指令，如果该变量是无符号数，如unsigned int,unsigned char等，编译产生的汇编指令则是逻辑位移指令。 虽然intel平台上都是little-endian字节序，如果看作左边是低端地址右边是高端地址，则左移似乎丢弃低端bits。其实，对于C语言，在移位逻辑上要看作是big-endian，例如0x1001，左边是高位，左移是丢弃高位bits。 变量 如果反码范围是-127~127，则0有00000000和10000000两种表示方法。补码由于负数是在反码的基础上+1，因此-128占用了10000000，因此补码的负数能多表示一个。 64位系统vc的long仍然只有4 bytes，64位gcc则是8 bytes。主要是由于64位Linux用的是LP64位数据模型，而64位Windows用的是LLP64位数据模型。（What is the bit size of long on 64-bit Windows?） 注意1.f也是一种合法的写法，与1.0f是等价的。（What is the difference between “1.0f” and “1.f”?） 当一个struct定义了构造函数，或者用新的C++11语法直接赋予成员默认值后（C++11 member initializer list vs in-class initializer?），就不能用new A{1, 2, “a”}这样的“集合初始化”语法了，必须提供构造函数。（Why can I not brace initialize a struct derived from another struct?） 全局变量可以用函数进行初始化，但注意static成员的初始化顺序不一定是按照定义的顺序进行的。（May I initialize a global variable with the result of a function call?） 字面常量（literal constant）根据平台的不同，有可能存储在text段，也可能存储在data段或其它地方，但具有static生命周期。 123456char *b;&#123; char *a = &quot;abc&quot;; b = a;&#125;// b仍然是有效指针 string类采用了Copy-On-Write，将str b赋值给str a之后，如果a不修改，则a和b其实用的是同样的char*内存。所以这也是一个警示，string的c_str()地址是可能变化的，不应该去依赖这个地址。 string本身是没有encoding的，取决于输入的字符串的encoding（What encoding does std::string.c_str() use?）。而字符串encoding一般由 const char * value lifetime 12345678const char **p = nullptr;&#123; const char *t = &quot;test&quot;; p = &amp;t;&#125;cout &lt;&lt; *p; &quot;test&quot;是字面常量，和global或static变量具有类似的生命周期。 变量修饰关键字 const是限制指针还是限制指向的变量，关键看const是在星号*的左边还是右边。。如const int *cptr和int const *cptr是限制int，说明指向的是一个常亮。int *const cptr是一个常量指针，不能再指向其它int变量。（更简单直观的看法是，看const的右边是什么，*cptr是原变量本身，而cptr是指针） const int *指针不能赋值给int *指针，因为一个是指向const int类型，一个是指向int类型。而int * const指针可以赋值给int *指针，因为两者都是指向int变量，指向同类型变量的指针之间的相互赋值，是不受指针本身是否为const的影响的。 对于func(const char*)，正如上面一条所说的，可以将char*实参传递过来。但是对于fun(const char*&amp; p)这种加了引用的函数，不能将char*的指针传给它，而必须传const char*指针，因为引用必须引用相同的类型，一个const char*的引用不能去引用一个char*的变量。 auto这个关键字用于声明变量的生存期为自动，即将不在任何类、结构、枚举、联合和函数中定义的变量视为全局变量，而在函数中定义的变量视为局部变量。它是存储类型标识符，表明变量（自动）具有本地范围。块范围的变量声明（如for循环体内的变量声明）默认为auto存储类型。 mutable关键是为了针对const而提出来的关键字。extern关键字则是针对static（C语言）提出来的关键字。register关键字是针对volatile提出来的关键字。volatile与const一样需要弄清楚修饰的是变量本身还是指针，以及哪一级的指针。 const int &amp;a =100是正确的，但去掉const就是错误的。 浮点数 浮点数是不能用 unsigned来规范的。unsigned 的意思就是把内存中的数据第一位也用来表示数据，而不用于表示符号位。而浮点数规定内存中数据的第一位必须是符号位（Double-precision floating-point format）。因此两者之间是互相矛盾的，这也就是为什么浮点数不会有unsigned类型。在某些编译器下unsigned float 和 unsigned double会被自动转换成unsigned int类型，而不报错。这时sizeof(unsigned float)和sizeof(unsigned double)的值是4。 定点数的优点是很简单，大部分运算实现起来和整数一样或者略有变化，但是缺点则是表示范围，而且在表示很小的数的时候，大部分位都是0，精度很差，不能充分运用存储单元。浮点数就是设计来克服这个缺点的，它相当于一个定点数加上一个阶码，阶码表示将这个定点数的小数点移动若干位。由于可以用阶码移动小数点，因此称为浮点数。（为什么叫浮点数?） 类型float和double通过==,&gt;,&lt;等比较不会引起编译错误，但是非常可能得到错误的结果。这是因为它们的内存分布不同，不可以直接比较。正确的方法是转换为同一类型后比较两者差值，如果结果小于规定的小值，则视为相等。 数组 对于数组char buff[] = “hello”，将buff 和 &amp;buff 用指针形式输出，结果是一样的。（Address of array - difference between having an ampersand and no ampersand） How to initialize all members of an array to the same value? int array[100] = {0};可以将100个元素都设置成0，但int array[100] = {-1};只能将第一个元素设置成-1，声誉99个元素则设置成0。 不能将一个char[100]的实参传给一个char*&amp;的形参，因为对于引用，必须是类型严格相同的。char[100]跟char*虽然可以相互转换，但编译时类型并不相同。可以将形参改成int (&amp;arr)[100]这样。 char * arr[n] = &#123; &quot;aaa&quot;, &quot;bbb&quot; &#125;是对的，是char的数组，每一个char指向一个字符串常量。而char ** arr = &#123; &quot;aaa&quot;, &quot;bbb&quot; &#125;是语法错误的，这是指向char*数组的二维指针，所以必须先arr = new char*[n]。 当数组定义时没有指定大小，当初始化采用列表初始化了，那么数组的大小由初始化时列表元素个数决定。如果明确指定了数组大小，当在初始化时指定的元素个数超过这个大小就会产生错误。如果初始化时指定的的元素个数比数组大小少，剩下的元素都回被初始化为0。字符数组可以方便地采用字符串直接初始化。因此，int a[10] = &#123;0&#125;这种写法，其实本来是将第一个元素置为0，但后续所有元素都会被默认置为0。 new/delete/malloc/free 深入探究C++的new/delete操作符 new/new[]调用的是operator new/new[]，前者是C++关键字，而后者其实就是（全局或class内的）操作符重载。所谓的placement new其实就是operator new/new[]的重载版本，我们也可以自定义提供了更多参数的placement new版本如operator(size_t size, P2, P3, P4)，然后通过new(P2, P3, P4)这样的语法进行调用。 calloc返回的是一个数组，而malloc返回的是一个对象。calloc的效率一般是比较低的。calloc相当于malloc后再加memset。关于realloc，原来的指针会被Free，申请可能不成功，会返回NULL。新增区域内的初始值则不确定。alloca是在栈(stack)上申请空间，用完马上就释放。某些系统在函数已被调用后不能增加栈帧长度，于是也就不能支持alloca函数。 cookie信息 当我们使用 operator new 为一个自定义类型对象分配内存时，实际上我们得到的内存要比实际对象的内存大一些，这些内存除了要存储对象数据外，还需要记录这片内存的大小，此方法称为 cookie。这一点上的实现依据不同的编译器不同。（例如 MFC 选择在所分配内存的头部存储对象实际数据，而后面的部分存储边界标志和内存大小信息。g++ 则采用在所分配内存的头4个字节存储相关信息，而后面的内存存储对象实际数据。）当我们使用 delete operator 进行内存释放操作时，delete operator 就可以根据这些信息正确的释放指针所指向的内存块。 以上论述的是对于单个对象的内存分配/释放，当我们为数组分配/释放内存时，虽然我们仍然使用 new operator 和 delete operator，但是其内部行为却有不同：new operator 调用了operator new 的数组版的兄弟－ operator new[]，而后针对每一个数组成员调用构造函数。而 delete operator 先对每一个数组成员调用析构函数，而后调用 operator delete[] 来释放内存。需要注意的是，当我们创建或释放由自定义数据类型所构成的数组时，编译器为了能够标识出在 operator delete[] 中所需释放的内存块的大小，也使用了编译器相关的 cookie 技术。 根据Inside The C++ Object Model上所言，现在的编译器大多使用两种方法， 一种是cookie, 一个记录分配空间大小的内存小块绑定在分配内存的地址头部。二是使用表来对分配了的指针进行管理，每一个分配了空间的指针都在表中对应着分配空间的大小。 指针 ANSI规定不能对void指针做++/+=等操作，但GNU将void的这些操作当作和char*一样。（Increment void pointer by one byte? by two?） 定义指向public成员函数的指针变量的一般形式为数据类型名 (类名::*指针变量名)(参数表列)。使指针变量指向一个公用成员函数的一般形式为指针变量名=&amp;类名::成员函数名。对于普通函数，函数名本身加不加&amp;都能表示函数指针，但是成员函数则必须加&amp;才能取地址。 在C语言里，一个指针可以指向一个函数。这个指针也有两个属性，但一个是函数的入口地址，另一个是函数的返值类型。但是C里面函数指针的形参列表可以不写出（obsolescent），而C++中则强制要求写出。（Function pointer without arguments types?） 函数 默认值可以是全局变量、全局常量，甚至是一个函数。但不可以是局部变量。因为默认参数的调用是在编译时确定的，而局部变量位置与默认值在编译时无法确定。 当一个stack上的数组如char arr[5]作为参数传递给一个函数void func(char* p)或void func(char p[5])时，就降级为一个指针，sizeof只能取到指针本身的大小。要记得sizeof是一个编译器的行为，对于函数而言，有可能被多处调用到，传递来不同大小的数组，因此不可能在编译器完成sizeof。（Why does a C-Array have a wrong sizeof() value when it’s passed to a function?）如果要保留数组类型，则要声明函数为void func(char (&amp;a)[5])。（When a function has a specific-size array parameter, why is it replaced with a pointer?） 数组的长度与参数声明无关。因此，下列三个声明是等价的： 123void putValues(int*);void putValues(int[]);void putValues(int[10]); 数组长度不是参数类型的一部分。函数不知道传递给它的数组的实际长度，编译器也不知道，当编译器对实参类型进行参数类型检查时，并不检查数组的长度。 一个返回void的函数，可以在内部return另一个返回void的函数。 参数默认值可以写在函数声明处，也可以写在函数定义处，但是不能两处同时写，即使两处写的默认值是一样的。但是不同的cpp在声明一个外部函数时，应该可以使用不同的函数参数默认值声明，虽然在同一个cpp中不能看见有两次同一个函数的声明，即使是同样的默认值。这说明，无论是函数的声明还是定义，无论默认值是否相同，同一个函数的默认值定义不能出现两次。 string, char*参数都可以用字符串常量作为默认值，说明一个类A的对象，并且支持类型B到A的隐式转换，就可以用B的一个实例b作为参数默认值。（How to set default parameter as class object in c++?） 如何定义一个函数指针，指向一个带有默认值参数的函数? 结论是做不到，只能用类似functor或者std::function等来科里化其中的一个或部分参数值。 普通的函数不需要通过&amp;来取地址，但是成员方法取地址则必须加上&amp;。（If ampersands aren’t needed for function pointers, why does boost::bind require one?） 内联函数 inline关键字更主要的含义是允许一个函数在不同的编译单元（cpp）同时存在实现，这和在h文件的class定义中直接实现一个方法，而不是将方法的实现放到cpp中，本质上是样的。至于是否会用内联代码代替函数调用，则是由编译器自身决定的。（Difference between implementing a class inside a .h file or in a .cpp file） 在cpp中定义inline函数（即使在头文件中再次用inline声明了这个函数），对于其它的cpp而言是没有inline效果的。因为对于编译器而言，每个cpp都是独立的编译单元，因此一个cpp是不能inline另一个cpp中定义实现的inline函数的。（C++ inline member function in .cpp file） 构造函数 explicit关键字用于取消构造函数的隐式转换，对有多个参数的构造函数使用explicit是个语法错误。即用explict修饰的构造函数有且只能有一个参数。 在构造函数里调用另一个构造函数的关键是让第二个构造函数在第一次分配好的内存上执行，而不是分配新的内存，这个可以用标准库的placement new做到。 1234A()&#123; new(this)A(11);&#125; 注： 若构造函数调用自身，则会出现无限递归调用。 成员初始化列表不能对基类成员变量赋值，而应该通过调用基类的构造函数达成目标。 C++初始化类成员时，是按照声明的顺序初始化的，而不是按照出现在初始化列表中的顺序。（Order of execution in constructor initialization list） 删除一个强转成void*的对象指针，会释放内存，但不会调用其析构函数。Is it safe to delete a void pointer? 不要在有虚表的类的构造函数和析构函数中调用虚函数，会调用到基类的函数。（[Calling virtual functions inside constructors(https://stackoverflow.com/questions/962132/calling-virtual-functions-inside-constructors)]，https://stackoverflow.com/questions/962132/calling-virtual-functions-inside-constructors） What is a non-trivial constructor in C++? 也就是说，trivial构造函数即没有定义构造函数。但没有自定义任何构造函数（包括拷贝构造函数）时，应该会由编译器自动生成trivial构造函数（其实就是什么都不做，进行对象的拷贝赋值时，直接进行memory copy）。如果只定义了一个带参数的构造函数的话，则不会再生成默认的构造函数。 If you define a constructor yourself, it is considered non-trivial, even if it doesn’t do anything, so a trivial constructor must be implicitly defined by the compiler. For a default constructor and destructor being “trivial” means literally “do nothing at all”. For copy-constructor and copy-assignment operator, being “trivial” means literally “be equivalent to simple raw memory copying” (like copy with memcpy). 成员函数隐藏 Reason for C++ member function hiding 当编译器于某一层找到能用（不一定最好，也许需要强制转换参数类型）的方法时，就不会继续再向上一层（父类）查找。不仅仅是类与类之间，嵌套的namespace也存在这个现象。 哑元函数 C++的哑元参数是指operator ++(int)这种。某个参数如果在子程序或函数中没有用到，那就被称为哑元。函数的形参又称“哑元”，实参又称“实元”。 。友元关系不能被继承。（Why does C++ not allow inherited friendship?） 至少在gcc里，int a; string b; 1 == 1 ? a : b;这种写法是可以的，但如果将这个表达式进行cout，就会编译报错提示两边类型不一直的。（Return type of ‘?:’ (ternary conditional operator)） 库函数 memmove和memcpy的区别，在于前者当src &lt; dest并且两者区间有重叠时，会改用从后向前复制。memmove函数为什么要先判断重叠，而不是直接从尾部向头部复制？因为当dst的头部和src的尾部覆盖时，从尾部开始复制是正确的。但是当dst的尾部和src的头部覆盖时，从头部开始复制才是正确的。所以要区分处理。 memccpy用来拷贝src所指的内存内容前n个字节到dest所指的地址上。与memcpy不同的是，memccpy如果在src中遇到某个特定值(int c)立即停止复制。 strtok是一个线程不安全的函数，因为它使用了静态分配的空间来存储被分割的字符串位置（C库还有其它使用了静态空间的线程不安全函数）。运用strtok来判断ip或者mac的时候务必要先用其他的方法判断’.‘或’:'的个数，因为用strtok截断的话，比如：&quot;192…168.0…8…&quot;这个字符串，strtok只会截取四次，中间的…无论多少都会被当作一个key。而这个函数的线程安全版本在linux中是strtok_r，在vc中则是strtok_s。 sprintf和vsprintf的区别，以及snprintf和vsnprintf的区别，在于后者接收的是va_list，而前者是不变参数列表，后者几乎不会被直接使用，而是在不定参数的函数内部调用，作为一种“转发”。 在C++中用longjmp，可能导致析构函数不被调用。 std::bind是基于functor仿函数实现的，也就是函数对象实现存储固定的参数值。 C++的4种cast操作 static_cast/dynamic_cast/reinterpret_cast不能将一个const T*转为T*，当然如果是将const T转化T是可以的。只有const_cast能将const T*转为T*。 reinterpret_cast转换后的bits是不变的，因此在将double=1.0转变为int时，显然reinterpret_cast会得到诡异的结果。 rtti包括typeid(type_info)和dynamic_cast两者，都需要虚表的支持。如果是没有虚函数的类，则dynamic_cast就只能从下往上安全转换了。此外，dynamic_cast只能对指针（引用）操作。static_cast是C++里面的类型安全转换，这个转换不允许将毫无关系的两个数据类型的指针互相转化。例如不能把int**转成void**，因为int*和void*没有关系，但是可以将int*转成void*。 综上所述，C风格的强制转换=static_cast + reinterpret_cast。对于有虚表的类的指针，reinterpret_cast由于不会调整this指针，也不会将vptr指针进行上溯或下溯，因此将会造成不可预期的结果。 static_cast可以将void*转换为A*，但是不能量B*转换为A*。 bad_cast这个关键字和bad_typeid类似，是dynamic_cast转换失败时（一般是错误地想把基类转换为子类时，此时转换结果为空指针），会抛出的异常。 const_cast：允许添加或删除表达式类型的const或volatile关键字. dynamic_cast：仅适用于多态类型的向下转换，被转换的类型必须是一个指向含有虚函数的类类型的指针，否则会编译错误。 reinterpret_cast：从位的角度来看待一个对象，从而允许将一个东西看成是完全不同的另一个东西，最强的一种转换。这个操作符能够在非相关的类型之间转换。操作结果只是简单的从一个指针到别的指针的值的二进制拷贝。在类型之间指向的内容不做任何类型的检查和转换。例如将一个double转化为int，reinterpret_cast仅仅复制bits，导致转化的值无意义。而static_cast就能得到正确的退一法值。 只有dynamic_cast是运行期行为，其它三种cast都是编译器行为。 How is dynamic_cast implemented dynamic_cast can know this by keeping this knowledge around. When the compiler generates code it keeps around the data about the class hierarchies in some sort of table that dynamic_cast can look up later. That table can be attached to the vtable pointer for easy lookup by the dynamic_cast implementation. The data neeeded for typeid for those classes can also be stored along with those. How dynamic_cast works internally? Formally, of course, it’s implementation defined, but in practice, there will be an additional pointer in the vtable, which points to a description of the object, probably as a DAG of objects which contain pointers to the various children (derived classes) and information regarding their type (a pointer to a type_info, perhaps). The compiler then generates code which walks the different paths in the graph until it either finds the targeted type, or has visited all of the nodes. If it finds the targeted type, the node will also contain the necessary information as to how to convert the pointer. One additional point occurs to me. Even if the generated code finds a match, it may have to continue navigating in order to ensure that it isn’t ambiguous. dynamic_cast失败时，有时是返回null，有时是抛出异常。原因在于C++没有null reference，所以只能throw exception。 123Base* b1 = new Derived;Derived* pd1 = dynamic_cast&lt;Derived *&gt;(b1); // fails: returns &#x27;NULL&#x27;Derived d1 = dynamic_cast&lt;Derived &amp;*&gt;(b1); // fails: exception thrown Why can’t I static_cast between char * and unsigned char *? 不同的两种类型的指针相互之间不能用static_cast转换，而必须用reinterprete_cast。而普通指针和void*之间则可以用static_cast相互转换。 sizeof sizeof，终极无惑（上） sizeof有三种语法形式，如下： sizeof( object ); // sizeof( 对象 ); sizeof( type_name ); // sizeof( 类型 ); sizeof object; // sizeof 对象; size_t sz = sizeof( foo() ); // foo() 的返回值类型为char，所以sz = sizeof( char )，foo()并不会被调用。但是foo不能返回为void。 c99标准支持对VLA取sizeof。 结构体的sizeof到底多大？ 在VC中规定， 结构体变量的首地址能够被其最宽基本类型成员的大小所整除；而在gcc中规定对齐模数最大只能是4，也就是说，即使结构体中有double类型，对齐模数还是4。 sizeof也是运算符，虽然不能被重载。 不能重载的运算符只有5个（Which operator cannot be overloaded in C++ and why?）： - (成员访问运算符) .* (成员指针访问运算符) :: (域运算符) sizeof (长度运算符) ?: (条件运算符） 为什么C++中空类和空结构体大小为1？ 这是因为，C++标准中规定，“no object shall have the same address in memory as any other variable” ，就是任何不同的对象不能拥有相同的内存地址。 如果空类大小为0，若我们声明一个这个类的对象数组，那么数组中的每个对象都拥有了相同的地址，这显然是违背标准的。 基本上所有的指针运算都依赖于sizeof T。 typedef typdef定义的struct/class如何前置声明？ 12345678typedef struct my_time_t&#123;int hour, minute, second;&#125; MY_TIME;struct my_time_t;typedef struct my_time_t MY_TIME;void func(MY_TIME* mt) &#123;&#125; 其实typedef作为一种类似宏的声明，在没有include头文件的情况下要想使用只能重新typedef。 #define没有作用域的限制，只要是之前预定义过的宏，在以后的程序中都可以使用。而typedef有自己的作用域。（Please explain syntax rules and scope for “typedef”） typedef会影响模板参数T的匹配吗？对于func(int, int32_t)和func(int, int)，会优先匹配哪个？实验发现编译错误：func重定义。一个int实参不能传给unsigned&amp;的形参，但typedef可以。以上都表明typedef有点类似define。但是，ifdef/ifndef不能检查typedef。 typedef register int FAST_COUNTER;，这种写法是错误的，编译通不过。问题出在你不能在声明中有多个存储类关键字（storage class specifier）。因为符号typedef已经占据了存储类关键字的位置， typedef声明中不能用register（或任何其它存储类关键字如static）。此外，由于存储类关键字本身并不是类型type的一部分，因此不允许其出现在typedef语句中也是合理的。（Why typedef can not be used with static?） typedef struct tagNode *pNode; struct tagNode &#123; &#125;;，在这个例子中，你用typedef给一个还未完全声明的类型起新名字。C语言编译器支持这种做法。 typedef struct tagNode &#123; &#125; *pNode;，定义了一种新的类型pNode，等于一个结构体指针类型。 typedef char *pStr1; #define pStr2 char *; pStr2 s3, s4; pStr2 s3, s4;，在上述的变量定义中，s1、s2、s3都被定义为char *，而s4则定义成了char，不是我们所预期的指针变量，根本原因就在于#define只是简单的字符串替换而typedef则是为一个类型起新名字。 typedef也有一个特别的长处：它符合范围规则（scope），使用typedef定义的变量类型其作用范围限制在所定义的函数或者文件内（取决于此变量定义的位置），而宏定义则没有这种特性。但typedef定义的类型不能用#ifdef 、#ifndef去检测。 typedef是一个语句，后面要加分号；。而define是预处理宏，不能加分号。 typedef char Line[81];，定义了一种新的类型Line，等于char[81]，不能错误地写作``typedef char[81] Line;。此外，最好用typedef struct Line &#123; char line[81]; &#125; Line; typedef char * pstr;，定义了一种新的类型pstr，等于char*。按照顺序，const pstr被解释为char * const（一个指向 char 的常量指针），而不是const char *（指向常量 char 的指针）。这个问题很容易解决：typedef const char * cpstr;。 cdecl和stdcall 实际上__cdecl和__stdcall函数参数都是从右到左入栈，它们的区别在于由谁来清栈，__cdecl由外部调用函数清栈，而__stdcall由被调用函数本身清栈， 显然对于可变参数的函数，函数本身没法知道外部函数调用它时传了多少参数（也许有人说例如printf，分析format string不就可以知道传了哪些参数了，但实际上，caller在调用printf时，可以额外多传一些没有用到的参数啊），所以没法支持被调用函数本身清栈（__stdcall）， 所以可变参数只能用__cdecll。 另外还要理解函数参数传递过程中堆栈是如何生长和变化的，从堆栈低地址到高地址，依次存储 被调用函数局部变量，上一函数堆栈桢基址，函数返回地址，参数1， 参数2， 参数3… 多态、继承 C++的派生类在重写virtual函数时，访问修饰符可以和基类不同，但是要注意派生类中对基类方法的重载将会导致罕见的“隐藏”问题，无论这个函数是不是虚函数。 重载方法（包括运算符重载）时是可以改变返回值类型的，因为返回值类型不是函数签名的一部分。 当有虚函数时，应该把析构函数声明为虚析构函数，否则通过基类指针释放派生类对象时，有可能会存在内存泄漏（object的空间本身应该无论如何是可以释放掉的，只是基类的析构函数由于没有被调用，可能会泄露基类对象本身拥有的一些其它内存或资源）。 三种继承方式下基类的私有成员对派生类都不可见，而公共成员和保护成员对派生类的方法而言都可以访问。三者的区别是，公共继承时基类的公共成员和保护成员对派生类而言仍然是公共成员和保护成员，私有继承时基类的公共成员和保护成员都成为派生类的私有成员，保护继承时基类的公共成员和保护成员都成为派生类的保护成员（而对于外界，无论是哪种继承方式，保护成员和私有成员都是不可见的）。 在protected和private继承时，基类指针不能指向派生类对象。简单的说这两种继承方式并不是所谓的is-a关系。详细一点讲,用了这两种继承方式后,子类对象中的继承方法都是在main中不能访问的，如果允许基类指针指向子类对象,就会出错了。当然你也可以用(Base*)进行强制转化。 C++的默认继承方式是private继承。 模板 函数模板的偏特化 严格的来说，函数模板并不支持偏特化，但由于可以对函数进行重载，所以可以达到类似于类模板偏特化的效果。 template &lt;class T&gt; void f(T); (a) 根据重载规则，对（a）进行重载 template &lt; class T&gt; void f(T*); (b) 如果将（a）称为基模板，那么（b）称为对基模板（a）的重载，而非对（a）的偏特化。C++的标准委员会仍在对下一个版本中是否允许函数模板的偏特化进行讨论。 C++ traits C++ traits是利用模板特化编译器来完成一定功能的技巧，本质是“利用类型固有的特性，判断类型是否具有特定的特性”，例如简单的例子（利用偏特化）： 1234567template &lt;typename T&gt;struct is_void&#123; static const bool value = false; &#125;template &lt;&gt;struct is_void&lt;void&gt;&#123; static const bool value = true; &#125; STL C++语言中的std::remove(vec.begin(), vec.end(), 5);并非是删除容器里变所有值等于5的数，而是用类似LeetCode中的27. Remove Element的算法，将后面的元素向前复制移动。因此vector的长度并不会改变，需要和erase方法结合使用：vec.erase(std::remove(vec.begin(), vec.end(), 5), vec.end());。 vector为了防止大量分配连续内存的开销，保持一块默认的尺寸的内存，clear只是清数据了，未清内存，因为vector的capacity容量未变化，系统维护一个的默认值。有什么方法可以释放掉vector中占用的全部内存呢？根据StackOverflow上的方法，可以用vector&lt; T &gt; vtTemp; veTemp.swap(vt);。 multimap/multiset不支持下标运算，可能是因为[]运算符可能有多个元素匹配。 const map不支持下标操作，根据StackOverflow的说法，[]运算符在key不存在时会插入新的元素，不符合const的语境。 stl的deque,queue,stack,heap：deque和vector、list一样是一种基础数据结构。然后stack，queue，priority_queue则是可以使用某个基础数据机构作为底层存储的二级数据结构。而heap本身不能持有数据存储，只能将某个基础数据结构对象作为托管的数据存储。 STL的模板参数T类型也可以带const修饰符。 STL中有bitset这种数据结构。 编译器优化 Object returned from function and copy constructor That is called Named Return Value Optimization and copy elision, and basically means that the compiler has figured out that the copy can be avoided by carefully placing the temporary and the object in the same memory location. By default there would be three objects in that piece of code, temp inside fun, the return value and ob inside main, and as many as two copies, but by carefully placing temp in the same memory location as the returned object inside fun and placing ob in the same memory address the two copies can be optimized away. Ref to Value semantics: NRVO, and Value semantics: Copy elision. 本文地址：https://xnerv.wang/cpp-bean-knowledge/","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://xnerv.wang/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"编程语言","slug":"编程语言","permalink":"https://xnerv.wang/tags/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"},{"name":"原创","slug":"原创","permalink":"https://xnerv.wang/tags/%E5%8E%9F%E5%88%9B/"},{"name":"C++","slug":"C","permalink":"https://xnerv.wang/tags/C/"}]},{"title":"Everything You Never Wanted To Know About DLLs（转载）","slug":"everything-you-never-wanted-to-know-about-dlls","date":"2011-07-04T07:00:00.000Z","updated":"2025-03-10T01:04:55.817Z","comments":true,"path":"everything-you-never-wanted-to-know-about-dlls/","link":"","permalink":"https://xnerv.wang/everything-you-never-wanted-to-know-about-dlls/","excerpt":"For the chinese translated version, please click 关于DLL的一些你不会想要知道的知识. I’ve recently had cause to investigate how dynamic linking is implemented on Windows. This post is basically a brain dump of everything I’ve learnt on the issue. This is mostly for my future reference, but I hope it will be useful to others too as I’m going to bring together lots of information you would otherwise have to hunt around for. Without further ado, here we go:","text":"For the chinese translated version, please click 关于DLL的一些你不会想要知道的知识. I’ve recently had cause to investigate how dynamic linking is implemented on Windows. This post is basically a brain dump of everything I’ve learnt on the issue. This is mostly for my future reference, but I hope it will be useful to others too as I’m going to bring together lots of information you would otherwise have to hunt around for. Without further ado, here we go: Export and import directories The Windows executable loader is responsible for doing all dynamic loading and symbol resolution before running the code. The linker works out what functions are exported or imported by each image (an image is a DLL or EXE file) by inspecting the .edata and .idata sections of those images, respectively. The contents of these sections is covered in detail by the PE/COFF specification. The .edata section This section records the exports of the image (yes, EXEs can export things). This takes the form of: The export address table: an array of length N holding the addresses of the exported functions/data (the addresses are stored relative to the image base). Indexes into this table are called ordinals. The export name pointer table: an array of length M holding pointers to strings that represent the name of an export. This array is lexically ordered by name, to allow binary searches for a given export. The export ordinal table: a parallel array of length M holding the ordinal of the corresponding name in the export name pointer table. (As an alternative to importing an image’s export by its name, it is possible to import by specifying an ordinal. Importing by ordinal is slightly faster at runtime because the dynamic linker doesn’t have to do a lookup. Furthermore, if the import is not given a name by the exporting DLL, importing by ordinal is the only way to do the import.) How does the .edata section get created in the first place? There are two main methods: Most commonly, they start life in the object files created by compiling some source code that defines a function/some data that was declared with the __declspec(dllimport) modifier. The compiler just emits an appropriate .edata section naming these exports. Less commonly, the programmer might write a .def file specifying which functions they would like to export. By supplying this to dlltool --output-exp, an export file can be generated. An export file is just an object file which only contains a .edata section, exporting (via some unresolved references that will be filled in by the linker in the usual way) the symbols named in the .def file. This export library must be named by the programmer when he comes to link together his object files into a DLL. In both these cases, the linker collects the .edata sections from all objects named on the link line to build the .edata for the overall image file. One last possible way that the .edata can be created is by the linker itself, without having to put .edata into any object files: The linker could choose to export all symbols defined by object files named on the link line. For example, this is the default behaviour of GNU ld (the behaviour can also be explicitly asked for using –-export-all-symbols). In this case, the linker generates the .edata section itself. (GNU ld also supports specifying a .def file on the command line, in which case the generated section will export just those things named by the .def). The .idata section The .idata section records those things that the image imports. It consists of: For every image from which symbols are imported: The filename of the image. Used by the dynamic linker to locate it on disk. The import lookup table: an array of length N, which each entry is either an ordinal or a pointer to a string representing the name to import. The import address table: an array of N pointers. The dynamic linker is responsible for filling out this array with the address of the function/data named by the corresponding symbol in the import lookup table. The ways in which .idata entries are created are as follows: Most commonly, they originate in a library of object files called an import library. This import library can be created by usingdlltool on the DLL you wish to export or a .def file of the type we discussed earlier. Just like the export library, the import library must be named by the user on the link line. Alternatively, some linkers (like GNU ld) let you specify a DLL directly on the link line. The linker will automatically generate .idata entries for any symbols that you must import from the DLL. Notice that unlike the case when we were exporting symbols, __declspec(dllimport) does not cause .idata sections to be generated. Import libraries are a bit more complicated than they first appear. The Windows dynamic loader fills the import address table with the addresses of the imported symbols (say, the address of a function Func). However, when the assembly code in other object files says call Func they expect that Func to name the address of that code. But we don’t know that address until runtime: the only thing we know statically is the address where that address will be placed by the dynamic linker. We will call this address __imp__Func. To deal with this extra level of indirection, the import library exports a function Func that just dereferences __imp__Func (to get the actual function pointer) and then jmps to it. All of the other object files in the project can now say call Func just as they would if Func had been defined in some other object file, rather than a DLL. For this reason, saying __declspec(dllimport) in the declaration of a dynamically linked function is optional (though in fact you will get slightly more efficient code if you add them, as we will see later). Unfortunately, there is no equivalent trick if you want to import data from another DLL. If we have some imported data myData, there is no way the import library can be defined so that a mov $eax, myData in an object file linked against it writes to the storage for myData in that DLL. Instead, the import library defines a symbol __imp__myData that resolves to the address at which the linked-in address of the storage can be found. The compiler then ensures that when you read or write from a variable defined with __declspec(dllimport) those reads and writes go through the __imp_myData indirection. Because different code needs to be generated at the use site, __declspec declarations on data imports are not optional. Practical example Theory is all very well but it can be helpful to see all the pieces in play. Building a DLL First, lets build a simple DLL exporting both functions and data. For maximum clarity, we’ll use an explicit export library rather instead of decorating our functions with declspec(dllexport) or supply a .def file to the linker. First lets write the .def file, library.def: 1234LIBRARY libraryEXPORTS function_export data_export DATA (The DATA keyword and LIBRARY line only affects how the import library is generated, as explained later on. Ignore them for now.) Build an export file from that: 1$ dlltool --output-exp library_exports.o -d library.def The resulting object basically just contains an .edata section that exports the symbols _data_export and _function_export under the names data_export and function_export respectively: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778$ objdump -xs library_exports.o...There is an export table in .edata at 0x0The Export Tables (interpreted .edata section contents)Export Flags 0Time/Date stamp 4e10e5c1Major/Minor 0/0Name 00000028 library_exports.o.dllOrdinal Base 1Number in: Export Address Table 00000002 [Name Pointer/Ordinal] Table 00000002Table Addresses Export Address Table 00000040 Name Pointer Table 00000048 Ordinal Table 00000050Export Address Table -- Ordinal Base 1[Ordinal/Name Pointer] Table [ 0] data_export [ 1] function_exportSections:Idx Name Size VMA LMA File off Algn 0 .text 00000000 00000000 00000000 00000000 2**2 ALLOC, LOAD, READONLY, CODE 1 .data 00000000 00000000 00000000 00000000 2**2 ALLOC, LOAD, DATA 2 .bss 00000000 00000000 00000000 00000000 2**2 ALLOC 3 .edata 00000070 00000000 00000000 000000b4 2**2 CONTENTS, ALLOC, LOAD, RELOC, READONLY, DATASYMBOL TABLE:[ 0](sec -2)(fl 0x00)(ty 0)(scl 103) (nx 1) 0x00000000 fakeFile[ 2](sec 4)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000028 name[ 3](sec 4)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000040 afuncs[ 4](sec 4)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000048 anames[ 5](sec 4)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000050 anords[ 6](sec 4)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000054 n1[ 7](sec 4)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000060 n2[ 8](sec 1)(fl 0x00)(ty 0)(scl 3) (nx 1) 0x00000000 .textAUX scnlen 0x0 nreloc 0 nlnno 0[ 10](sec 2)(fl 0x00)(ty 0)(scl 3) (nx 1) 0x00000000 .dataAUX scnlen 0x0 nreloc 0 nlnno 0[ 12](sec 3)(fl 0x00)(ty 0)(scl 3) (nx 1) 0x00000000 .bssAUX scnlen 0x0 nreloc 0 nlnno 0[ 14](sec 4)(fl 0x00)(ty 0)(scl 3) (nx 1) 0x00000000 .edataAUX scnlen 0x70 nreloc 8 nlnno 0[ 16](sec 0)(fl 0x00)(ty 0)(scl 2) (nx 0) 0x00000000 _data_export[ 17](sec 0)(fl 0x00)(ty 0)(scl 2) (nx 0) 0x00000000 _function_exportRELOCATION RECORDS FOR [.edata]:OFFSET TYPE VALUE0000000c rva32 .edata0000001c rva32 .edata00000020 rva32 .edata00000024 rva32 .edata00000040 rva32 _data_export00000044 rva32 _function_export00000048 rva32 .edata0000004c rva32 .edataContents of section .edata: 0000 00000000 c1e5104e 00000000 28000000 .......N....(... 0010 01000000 02000000 02000000 40000000 ............@... 0020 48000000 50000000 6c696272 6172795f H...P...library_ 0030 6578706f 7274732e 6f2e646c 6c000000 exports.o.dll... 0040 00000000 00000000 54000000 60000000 ........T...`... 0050 00000100 64617461 5f657870 6f727400 ....data_export. 0060 66756e63 74696f6e 5f657870 6f727400 function_export. We’ll fulfil these symbol with a trivial implementation of the DLL, library.c: 12345int data_export = 42;int function_export() &#123; return 1337 + data_export;&#125; We can put it together into a DLL: 1$ gcc -shared -o library.dll library.c library_exports.o The export table for the DLL is as follows, showing that we have exported what we wanted: 12345678910111213141516171819202122The Export Tables (interpreted .edata section contents)Export Flags 0Time/Date stamp 4e10e5c1Major/Minor 0/0Name 00005028 library_exports.o.dllOrdinal Base 1Number in: Export Address Table 00000002 [Name Pointer/Ordinal] Table 00000002Table Addresses Export Address Table 00005040 Name Pointer Table 00005048 Ordinal Table 00005050Export Address Table -- Ordinal Base 1 [ 0] +base[ 1] 200c Export RVA [ 1] +base[ 2] 10f0 Export RVA[Ordinal/Name Pointer] Table [ 0] data_export [ 1] function_export Using the DLL When we come to look at using the DLL, things become a lot more interesting. First, we need an import library: 1$ dlltool --output-lib library.dll.a -d library.def (The reason that we have an import library but an export object is because using a library for the imports allows the linker to discard .idata for any imports that are not used. Contrariwise ,he linker can never discard any .edata entry because any export may potentially be used by a user of the DLL). This import library is rather complex. It contains one object for each export (disds00000.o and disds00001.o) but also two other object files (distdt.o and disdh.o) that set up the header and footer of the import list. (The header of the import list contains, among other things, the name of the DLL to link in at runtime, as derived from the LIBRARY line of the .def file.) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214$ objdump -xs library.dll.aIn archive library.dll.a:disdt.o: file format pe-i386...Sections:Idx Name Size VMA LMA File off Algn 0 .text 00000000 00000000 00000000 00000000 2**2 ALLOC, LOAD, READONLY, CODE 1 .data 00000000 00000000 00000000 00000000 2**2 ALLOC, LOAD, DATA 2 .bss 00000000 00000000 00000000 00000000 2**2 ALLOC 3 .idata$4 00000004 00000000 00000000 00000104 2**2 CONTENTS, ALLOC, LOAD, DATA 4 .idata$5 00000004 00000000 00000000 00000108 2**2 CONTENTS, ALLOC, LOAD, DATA 5 .idata$7 0000000c 00000000 00000000 0000010c 2**2 CONTENTS, ALLOC, LOAD, DATASYMBOL TABLE:[ 0](sec -2)(fl 0x00)(ty 0)(scl 103) (nx 1) 0x00000000 fakeFile[ 2](sec 1)(fl 0x00)(ty 0)(scl 3) (nx 1) 0x00000000 .textAUX scnlen 0x0 nreloc 0 nlnno 0[ 4](sec 2)(fl 0x00)(ty 0)(scl 3) (nx 1) 0x00000000 .dataAUX scnlen 0x0 nreloc 0 nlnno 0[ 6](sec 3)(fl 0x00)(ty 0)(scl 3) (nx 1) 0x00000000 .bssAUX scnlen 0x0 nreloc 0 nlnno 0[ 8](sec 4)(fl 0x00)(ty 0)(scl 3) (nx 1) 0x00000000 .idata$4AUX scnlen 0x4 nreloc 0 nlnno 0[ 10](sec 5)(fl 0x00)(ty 0)(scl 3) (nx 1) 0x00000000 .idata$5AUX scnlen 0x4 nreloc 0 nlnno 0[ 12](sec 6)(fl 0x00)(ty 0)(scl 3) (nx 1) 0x00000000 .idata$7AUX scnlen 0x7 nreloc 0 nlnno 0[ 14](sec 6)(fl 0x00)(ty 0)(scl 2) (nx 0) 0x00000000 __library_dll_a_inameContents of section .idata$4: 0000 00000000 ....Contents of section .idata$5: 0000 00000000 ....Contents of section .idata$7: 0000 6c696272 6172792e 646c6c00 library.dll.disdh.o: file format pe-i386...Sections:Idx Name Size VMA LMA File off Algn 0 .text 00000000 00000000 00000000 00000000 2**2 ALLOC, LOAD, READONLY, CODE 1 .data 00000000 00000000 00000000 00000000 2**2 ALLOC, LOAD, DATA 2 .bss 00000000 00000000 00000000 00000000 2**2 ALLOC 3 .idata$2 00000014 00000000 00000000 00000104 2**2 CONTENTS, ALLOC, LOAD, RELOC, DATA 4 .idata$5 00000000 00000000 00000000 00000000 2**2 ALLOC, LOAD, DATA 5 .idata$4 00000000 00000000 00000000 00000000 2**2 ALLOC, LOAD, DATASYMBOL TABLE:[ 0](sec -2)(fl 0x00)(ty 0)(scl 103) (nx 1) 0x00000000 fakeFile[ 2](sec 6)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000000 hname[ 3](sec 5)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000000 fthunk[ 4](sec 1)(fl 0x00)(ty 0)(scl 3) (nx 1) 0x00000000 .textAUX scnlen 0x0 nreloc 0 nlnno 0[ 6](sec 2)(fl 0x00)(ty 0)(scl 3) (nx 1) 0x00000000 .dataAUX scnlen 0x0 nreloc 0 nlnno 0[ 8](sec 3)(fl 0x00)(ty 0)(scl 3) (nx 1) 0x00000000 .bssAUX scnlen 0x0 nreloc 0 nlnno 0[ 10](sec 4)(fl 0x00)(ty 0)(scl 3) (nx 1) 0x00000000 .idata$2AUX scnlen 0x14 nreloc 3 nlnno 0[ 12](sec 6)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000000 .idata$4[ 13](sec 5)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000000 .idata$5[ 14](sec 4)(fl 0x00)(ty 0)(scl 2) (nx 0) 0x00000000 __head_library_dll_a[ 15](sec 0)(fl 0x00)(ty 0)(scl 2) (nx 0) 0x00000000 __library_dll_a_inameRELOCATION RECORDS FOR [.idata$2]:OFFSET TYPE VALUE00000000 rva32 .idata$40000000c rva32 __library_dll_a_iname00000010 rva32 .idata$5Contents of section .idata$2: 0000 00000000 00000000 00000000 00000000 ................ 0010 00000000 ....disds00001.o: file format pe-i386...Sections:Idx Name Size VMA LMA File off Algn 0 .text 00000008 00000000 00000000 0000012c 2**2 CONTENTS, ALLOC, LOAD, RELOC, READONLY, CODE 1 .data 00000000 00000000 00000000 00000000 2**2 ALLOC, LOAD, DATA 2 .bss 00000000 00000000 00000000 00000000 2**2 ALLOC 3 .idata$7 00000004 00000000 00000000 00000134 2**2 CONTENTS, RELOC 4 .idata$5 00000004 00000000 00000000 00000138 2**2 CONTENTS, RELOC 5 .idata$4 00000004 00000000 00000000 0000013c 2**2 CONTENTS, RELOC 6 .idata$6 00000012 00000000 00000000 00000140 2**1 CONTENTSSYMBOL TABLE:[ 0](sec 1)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000000 .text[ 1](sec 2)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000000 .data[ 2](sec 3)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000000 .bss[ 3](sec 4)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000000 .idata$7[ 4](sec 5)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000000 .idata$5[ 5](sec 6)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000000 .idata$4[ 6](sec 7)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000000 .idata$6[ 7](sec 1)(fl 0x00)(ty 0)(scl 2) (nx 0) 0x00000000 _function_export[ 8](sec 5)(fl 0x00)(ty 0)(scl 2) (nx 0) 0x00000000 __imp__function_export[ 9](sec 0)(fl 0x00)(ty 0)(scl 2) (nx 0) 0x00000000 __head_library_dll_aRELOCATION RECORDS FOR [.text]:OFFSET TYPE VALUE00000002 dir32 .idata$5RELOCATION RECORDS FOR [.idata$7]:OFFSET TYPE VALUE00000000 rva32 __head_library_dll_aRELOCATION RECORDS FOR [.idata$5]:OFFSET TYPE VALUE00000000 rva32 .idata$6RELOCATION RECORDS FOR [.idata$4]:OFFSET TYPE VALUE00000000 rva32 .idata$6Contents of section .text: 0000 ff250000 00009090 .%......Contents of section .idata$7: 0000 00000000 ....Contents of section .idata$5: 0000 00000000 ....Contents of section .idata$4: 0000 00000000 ....Contents of section .idata$6: 0000 01006675 6e637469 6f6e5f65 78706f72 ..function_expor 0010 7400 t.disds00000.o: file format pe-i386...Sections:Idx Name Size VMA LMA File off Algn 0 .text 00000000 00000000 00000000 00000000 2**2 ALLOC, LOAD, READONLY, CODE 1 .data 00000000 00000000 00000000 00000000 2**2 ALLOC, LOAD, DATA 2 .bss 00000000 00000000 00000000 00000000 2**2 ALLOC 3 .idata$7 00000004 00000000 00000000 0000012c 2**2 CONTENTS, RELOC 4 .idata$5 00000004 00000000 00000000 00000130 2**2 CONTENTS, RELOC 5 .idata$4 00000004 00000000 00000000 00000134 2**2 CONTENTS, RELOC 6 .idata$6 0000000e 00000000 00000000 00000138 2**1 CONTENTSSYMBOL TABLE:[ 0](sec 1)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000000 .text[ 1](sec 2)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000000 .data[ 2](sec 3)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000000 .bss[ 3](sec 4)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000000 .idata$7[ 4](sec 5)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000000 .idata$5[ 5](sec 6)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000000 .idata$4[ 6](sec 7)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x00000000 .idata$6[ 7](sec 5)(fl 0x00)(ty 0)(scl 2) (nx 0) 0x00000000 __imp__data_export[ 8](sec 0)(fl 0x00)(ty 0)(scl 2) (nx 0) 0x00000000 __head_library_dll_aRELOCATION RECORDS FOR [.idata$7]:OFFSET TYPE VALUE00000000 rva32 __head_library_dll_aRELOCATION RECORDS FOR [.idata$5]:OFFSET TYPE VALUE00000000 rva32 .idata$6RELOCATION RECORDS FOR [.idata$4]:OFFSET TYPE VALUE00000000 rva32 .idata$6Contents of section .idata$7: 0000 00000000 ....Contents of section .idata$5: 0000 00000000 ....Contents of section .idata$4: 0000 00000000 ....Contents of section .idata$6: 0000 00006461 74615f65 78706f72 7400 ..data_export. Note that the object corresponding to data_export has an empty .text section, whereas function_export does define some code. If we disassemble it we get this: 1234500000000 &lt;_function_export&gt;: 0: ff 25 00 00 00 00 jmp *0x0 2: dir32 .idata$5 6: 90 nop 7: 90 nop The relocation of type dir32 tells the linker how to fill in the address being dereferenced by the jmp. We can see that _function_export, when entered, will jump directly to the function at the address loaded from the memory named .idata$5. Inspection of the complete .idata section satisfies us that .idata$5 corresponds to the address of the fragment of the import address table corresponding to the function_export import name, and hence the address where the absolute address of the loaded function_export import can be found. Although only function_export gets a corresponding _function_export function, both of the exports have lead to a symbol with the __imp__ prefix (__imp__data_export and __imp__function_export) being defined in the import library. As discussed before, this symbol stands for the address at which the pointer to the data/function will be inserted by the dynamic linker. As such, the __imp__ symbols always point directly into the import address table. With an import library in hand, we are capable of writing some client code that uses our exports, main1.c: 12345678910111213141516#include &lt;stdio.h&gt;__declspec(dllimport) extern int function_export(void);__declspec(dllimport) extern int data_export;int main(int argc, char **argv) &#123; printf(&quot;%d\\n&quot;, function_export()); printf(&quot;%d\\n&quot;, data_export); data_export++; printf(&quot;%d\\n&quot;, function_export()); printf(&quot;%d\\n&quot;, data_export); return 0;&#125; Build and link it against the import library and we will get the results we expect: 12345$ gcc main1.c library.dll.a -o main1 &amp;&amp; ./main1137942138043 The reason that this works even though there is no data_export symbol defined by library.dll.a is because the __declspec(dllimport) qualifier on our data_export declaration in main.c has caused the compiled to generate code that uses the __imp_data_export symbol directly, as we can see if we disassemble the generated code: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465$ gcc -c main1.c -o main1.o &amp;&amp; objdump --disassemble -r main1.omain1.o: file format pe-i386Disassembly of section .text:00000000 &lt;_main&gt;: 0: 8d 4c 24 04 lea 0x4(%esp),%ecx 4: 83 e4 f0 and $0xfffffff0,%esp 7: ff 71 fc pushl -0x4(%ecx) a: 55 push %ebp b: 89 e5 mov %esp,%ebp d: 51 push %ecx e: 83 ec 14 sub $0x14,%esp 11: e8 00 00 00 00 call 16 &lt;_main+0x16&gt; 12: DISP32 ___main 16: a1 00 00 00 00 mov 0x0,%eax 17: dir32 __imp__function_export 1b: ff d0 call *%eax 1d: 89 44 24 04 mov %eax,0x4(%esp) 21: c7 04 24 00 00 00 00 movl $0x0,(%esp) 24: dir32 .rdata 28: e8 00 00 00 00 call 2d &lt;_main+0x2d&gt; 29: DISP32 _printf 2d: a1 00 00 00 00 mov 0x0,%eax 2e: dir32 __imp__data_export 32: 8b 00 mov (%eax),%eax 34: 89 44 24 04 mov %eax,0x4(%esp) 38: c7 04 24 00 00 00 00 movl $0x0,(%esp) 3b: dir32 .rdata 3f: e8 00 00 00 00 call 44 &lt;_main+0x44&gt; 40: DISP32 _printf 44: a1 00 00 00 00 mov 0x0,%eax 45: dir32 __imp__data_export 49: 8b 00 mov (%eax),%eax 4b: 8d 50 01 lea 0x1(%eax),%edx 4e: a1 00 00 00 00 mov 0x0,%eax 4f: dir32 __imp__data_export 53: 89 10 mov %edx,(%eax) 55: a1 00 00 00 00 mov 0x0,%eax 56: dir32 __imp__function_export 5a: ff d0 call *%eax 5c: 89 44 24 04 mov %eax,0x4(%esp) 60: c7 04 24 00 00 00 00 movl $0x0,(%esp) 63: dir32 .rdata 67: e8 00 00 00 00 call 6c &lt;_main+0x6c&gt; 68: DISP32 _printf 6c: a1 00 00 00 00 mov 0x0,%eax 6d: dir32 __imp__data_export 71: 8b 00 mov (%eax),%eax 73: 89 44 24 04 mov %eax,0x4(%esp) 77: c7 04 24 00 00 00 00 movl $0x0,(%esp) 7a: dir32 .rdata 7e: e8 00 00 00 00 call 83 &lt;_main+0x83&gt; 7f: DISP32 _printf 83: b8 00 00 00 00 mov $0x0,%eax 88: 83 c4 14 add $0x14,%esp 8b: 59 pop %ecx 8c: 5d pop %ebp 8d: 8d 61 fc lea -0x4(%ecx),%esp 90: c3 ret 91: 90 nop 92: 90 nop 93: 90 nop In fact, we can see that the generated code doesn’t even use the _function_export symbol, preferring __imp__function_export. Essentially, the code of the _function_export symbol in the import library has been inlined at every use site. This is why using __declspec(dllimport) can improve performance of cross-DLL calls, even though it is entirely optional on function declarations. We might wonder what happens if we drop the __declspec(dllimport) qualifier on our declarations. Because of our discussion about the difference between data and function imports earlier, you might expect linking to fail. Our test file, main2.c is: 12345678910111213141516#include &lt;stdio.h&gt;extern int function_export(void);extern int data_export;int main(int argc, char **argv) &#123; printf(&quot;%d\\n&quot;, function_export()); printf(&quot;%d\\n&quot;, data_export); data_export++; printf(&quot;%d\\n&quot;, function_export()); printf(&quot;%d\\n&quot;, data_export); return 0;&#125; Let’s try it out: 12345$ gcc main2.c library.dll.a -o main2 &amp;&amp; ./main2137942138043 What the hell – it worked? This is a bit uprising. The reason that it works despite the fact that the import library library.dll.a not defining the _data_export symbol is because of a nifty feature of GNU ld called auto-import. Without auto-import the link fails as we would expect: 123456$ gcc main2.c library.dll.a -o main2 -Wl,--disable-auto-import &amp;&amp; ./main2/tmp/ccGd8Urx.o:main2.c:(.text+0x2c): undefined reference to `_data_export&#x27;/tmp/ccGd8Urx.o:main2.c:(.text+0x41): undefined reference to `_data_export&#x27;/tmp/ccGd8Urx.o:main2.c:(.text+0x49): undefined reference to `_data_export&#x27;/tmp/ccGd8Urx.o:main2.c:(.text+0x63): undefined reference to `_data_export&#x27;collect2: ld returned 1 exit status The Microsoft linker does not implement auto-import, so this is the error you would get if you were using the Microsoft toolchain. However, there is a way to write client code that does not depend on auto-import or use the __declspec(dllimport) keyword. Our new client, main3.c is as follows: 12345678910111213141516171819#include &lt;stdio.h&gt;extern int (*_imp__function_export)(void);extern int *_imp__data_export;#define function_export (*_imp__function_export)#define data_export (*_imp__data_export)int main(int argc, char **argv) &#123; printf(&quot;%d\\n&quot;, function_export()); printf(&quot;%d\\n&quot;, data_export); data_export++; printf(&quot;%d\\n&quot;, function_export()); printf(&quot;%d\\n&quot;, data_export); return 0;&#125; In this code, we directly use the __imp__-prefixed symbols from the import library. These name an address at which the real address of the import can be found, which is reflected by our C-preprocessor definitions of data_export and function_export. This code compiles perfectly even without auto-import: 12345$ gcc main3.c library.dll.a -o main3 -Wl,--disable-auto-import &amp;&amp; ./main3137942138043 If you have followed along until this point you should have a solid understanding of how DLL import and export are implemented on Windows. How auto-import works As a bonus, I’m going to explain how auto-import is implemented by the GNU linker. It is a rather cute hack you may get a kick out of. As a reminder, auto-import is a feature of the linker that allows the programmer to declare an item of DLL-imported data with a simple extern keyword, without having to explicitly use __declspec(dllimport). This is extremely convenient because this is exactly how most _nix source code declares symbols it expects to import from a shared library, so by supporting this use case that_nix code becomes more portable to Windows. Auto-import kicks in whenever the linker finds an object file making use of a symbol foo which is not defined by any other object in the link, but where a symbol __imp_foo is defined by some object. In this case, it assumes that the use of foo is an attempt to access some DLL-imported data item called foo. Now, the problem is that the linker needs to replace the use of foo with the address of foo itself. However, all we seem to know statically is an address where that address will be placed at runtime (__imp_foo). To square the circle, the linker plays a clever trick. The trick is to extend the .idata of the image being created with an entry for a “new” DLL. The new entry is set up as follows: The filename of the image being imported is set to the same filename as the .idata entry covering __imp_foo. So if __imp_foo was being filled out by an address in Bar.dll, our new .idata entry will use Bar.dll here. The import lookup table is of length 1, whose sole entry is a pointer to the name of the imported symbol corresponding to __imp_foo. So if __imp_foo is filled out by the address of the foo export from Bar.dll, the name of the symbol we put in here will be foo. The import address table is of length 1 – and here is the clever bit – is located precisely at the location in the object file that was referring to the (undefined) symbol foo. This solution neatly defers the task of filling out the address that the object file wants to the dynamic linker. The reason that the linker can play this trick is that it can see all of the object code that goes into the final image, and can thus fix all of the sites that need to refer to the imported data. Note that in general the final image’s .idata will contain several entries for the same DLL: one from the import library, and one for every place in any object file in the link which referred to some data exported by the DLL. Although this is somewhat unusual behaviour, the Windows linker has no problem with there being several imports of the same DLL. A wrinkle Unfortunately, the scheme described above only works if the object code has an undefined reference to foo itself. What if instead it has a reference to foo+N, an address N bytes after the address of foo itself? There is no way to set up the .idata so that the dynamic linker adds a constant to the address it fills in, so we seem to be stuck. Alas, such relocations are reasonably common, and originate from code that accesses a field of a DLL-imported structure type. Cygwin actually contains another hack to make auto-import work in such cases, known as “pseudo-relocations”. If you want to know the details of how these works, there is more information in the original thread on the topic. Conclusion Dynamic linking on Windows is hairier than it at first appears. I hope this article has gone some way to clearing up the meaning of the mysterious dllimport and dllexport keywords, and at clarifying the role of the import and export libraries. Linux and friends implement dynamic linking in a totally different manner to Windows. The scheme they use is more flexible and allows more in-memory sharing of code, but incurs a significant runtime penalty (especially on i386). For more details see here and the Dynamic Linking section of the the ELF spec. 本文地址：https://xnerv.wang/everything-you-never-wanted-to-know-about-dlls/ 转载自：Everything You Never Wanted To Know About DLLs","categories":[{"name":"Windows","slug":"Windows","permalink":"https://xnerv.wang/categories/Windows/"}],"tags":[{"name":"转载","slug":"转载","permalink":"https://xnerv.wang/tags/%E8%BD%AC%E8%BD%BD/"},{"name":"Windows","slug":"Windows","permalink":"https://xnerv.wang/tags/Windows/"},{"name":"DLL","slug":"DLL","permalink":"https://xnerv.wang/tags/DLL/"}]}],"categories":[{"name":"程序员生活","slug":"程序员生活","permalink":"https://xnerv.wang/categories/%E7%A8%8B%E5%BA%8F%E5%91%98%E7%94%9F%E6%B4%BB/"},{"name":"Linux","slug":"Linux","permalink":"https://xnerv.wang/categories/Linux/"},{"name":"树莓派","slug":"树莓派","permalink":"https://xnerv.wang/categories/%E6%A0%91%E8%8E%93%E6%B4%BE/"},{"name":"DBMS","slug":"DBMS","permalink":"https://xnerv.wang/categories/DBMS/"},{"name":"编译器","slug":"编译器","permalink":"https://xnerv.wang/categories/%E7%BC%96%E8%AF%91%E5%99%A8/"},{"name":"分布式及存储","slug":"分布式及存储","permalink":"https://xnerv.wang/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8F%8A%E5%AD%98%E5%82%A8/"},{"name":"网络协议","slug":"网络协议","permalink":"https://xnerv.wang/categories/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"},{"name":"操作系统","slug":"操作系统","permalink":"https://xnerv.wang/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://xnerv.wang/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"},{"name":"编程语言","slug":"编程语言","permalink":"https://xnerv.wang/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"},{"name":"Windows","slug":"Windows","permalink":"https://xnerv.wang/categories/Windows/"}],"tags":[{"name":"程序员生活","slug":"程序员生活","permalink":"https://xnerv.wang/tags/%E7%A8%8B%E5%BA%8F%E5%91%98%E7%94%9F%E6%B4%BB/"},{"name":"VSCode","slug":"VSCode","permalink":"https://xnerv.wang/tags/VSCode/"},{"name":"Atom","slug":"Atom","permalink":"https://xnerv.wang/tags/Atom/"},{"name":"Markdown","slug":"Markdown","permalink":"https://xnerv.wang/tags/Markdown/"},{"name":"原创","slug":"原创","permalink":"https://xnerv.wang/tags/%E5%8E%9F%E5%88%9B/"},{"name":"Linux","slug":"Linux","permalink":"https://xnerv.wang/tags/Linux/"},{"name":"图形界面","slug":"图形界面","permalink":"https://xnerv.wang/tags/%E5%9B%BE%E5%BD%A2%E7%95%8C%E9%9D%A2/"},{"name":"X-Window","slug":"X-Window","permalink":"https://xnerv.wang/tags/X-Window/"},{"name":"X协议","slug":"X协议","permalink":"https://xnerv.wang/tags/X%E5%8D%8F%E8%AE%AE/"},{"name":"远程桌面","slug":"远程桌面","permalink":"https://xnerv.wang/tags/%E8%BF%9C%E7%A8%8B%E6%A1%8C%E9%9D%A2/"},{"name":"树莓派","slug":"树莓派","permalink":"https://xnerv.wang/tags/%E6%A0%91%E8%8E%93%E6%B4%BE/"},{"name":"Raspberry","slug":"Raspberry","permalink":"https://xnerv.wang/tags/Raspberry/"},{"name":"DBMS","slug":"DBMS","permalink":"https://xnerv.wang/tags/DBMS/"},{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"https://xnerv.wang/tags/PostgreSQL/"},{"name":"PG","slug":"PG","permalink":"https://xnerv.wang/tags/PG/"},{"name":"Docker","slug":"Docker","permalink":"https://xnerv.wang/tags/Docker/"},{"name":"MinGW","slug":"MinGW","permalink":"https://xnerv.wang/tags/MinGW/"},{"name":"编译器","slug":"编译器","permalink":"https://xnerv.wang/tags/%E7%BC%96%E8%AF%91%E5%99%A8/"},{"name":"Cygwin","slug":"Cygwin","permalink":"https://xnerv.wang/tags/Cygwin/"},{"name":"Windows","slug":"Windows","permalink":"https://xnerv.wang/tags/Windows/"},{"name":"分布式及存储","slug":"分布式及存储","permalink":"https://xnerv.wang/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8F%8A%E5%AD%98%E5%82%A8/"},{"name":"Seafile","slug":"Seafile","permalink":"https://xnerv.wang/tags/Seafile/"},{"name":"网络协议","slug":"网络协议","permalink":"https://xnerv.wang/tags/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"},{"name":"TCP","slug":"TCP","permalink":"https://xnerv.wang/tags/TCP/"},{"name":"IP","slug":"IP","permalink":"https://xnerv.wang/tags/IP/"},{"name":"UDP","slug":"UDP","permalink":"https://xnerv.wang/tags/UDP/"},{"name":"操作系统","slug":"操作系统","permalink":"https://xnerv.wang/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"线程同步","slug":"线程同步","permalink":"https://xnerv.wang/tags/%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5/"},{"name":"原子操作","slug":"原子操作","permalink":"https://xnerv.wang/tags/%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/"},{"name":"volatile","slug":"volatile","permalink":"https://xnerv.wang/tags/volatile/"},{"name":"2PC","slug":"2PC","permalink":"https://xnerv.wang/tags/2PC/"},{"name":"3PC","slug":"3PC","permalink":"https://xnerv.wang/tags/3PC/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://xnerv.wang/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"},{"name":"排序算法","slug":"排序算法","permalink":"https://xnerv.wang/tags/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"},{"name":"查找算法","slug":"查找算法","permalink":"https://xnerv.wang/tags/%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95/"},{"name":"路由协议","slug":"路由协议","permalink":"https://xnerv.wang/tags/%E8%B7%AF%E7%94%B1%E5%8D%8F%E8%AE%AE/"},{"name":"编程语言","slug":"编程语言","permalink":"https://xnerv.wang/tags/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"},{"name":"Python","slug":"Python","permalink":"https://xnerv.wang/tags/Python/"},{"name":"未完成","slug":"未完成","permalink":"https://xnerv.wang/tags/%E6%9C%AA%E5%AE%8C%E6%88%90/"},{"name":"信号","slug":"信号","permalink":"https://xnerv.wang/tags/%E4%BF%A1%E5%8F%B7/"},{"name":"中断","slug":"中断","permalink":"https://xnerv.wang/tags/%E4%B8%AD%E6%96%AD/"},{"name":"内核态与用户态","slug":"内核态与用户态","permalink":"https://xnerv.wang/tags/%E5%86%85%E6%A0%B8%E6%80%81%E4%B8%8E%E7%94%A8%E6%88%B7%E6%80%81/"},{"name":"文件系统","slug":"文件系统","permalink":"https://xnerv.wang/tags/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"name":"DLL","slug":"DLL","permalink":"https://xnerv.wang/tags/DLL/"},{"name":"译文","slug":"译文","permalink":"https://xnerv.wang/tags/%E8%AF%91%E6%96%87/"},{"name":"Windows Internals","slug":"Windows-Internals","permalink":"https://xnerv.wang/tags/Windows-Internals/"},{"name":"IOCP","slug":"IOCP","permalink":"https://xnerv.wang/tags/IOCP/"},{"name":"C++","slug":"C","permalink":"https://xnerv.wang/tags/C/"},{"name":"转载","slug":"转载","permalink":"https://xnerv.wang/tags/%E8%BD%AC%E8%BD%BD/"}]}